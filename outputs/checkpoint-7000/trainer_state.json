{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9712756969867642,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.9702189564704895,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.9848,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.8240992426872253,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.925,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.968345582485199,
      "learning_rate": 1e-05,
      "loss": 1.1096,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0021036863327026,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.0403,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.772130012512207,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.9343,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.794104814529419,
      "learning_rate": 2e-05,
      "loss": 0.8486,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.7466166019439697,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.8663,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.7472412586212158,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.9363,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.6404107213020325,
      "learning_rate": 3e-05,
      "loss": 0.7817,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.6850345730781555,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.8612,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.49495092034339905,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.6798,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.3707665801048279,
      "learning_rate": 4e-05,
      "loss": 0.7748,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.3829348087310791,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.7549,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.37495115399360657,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.8068,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.26817697286605835,
      "learning_rate": 5e-05,
      "loss": 0.6742,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.30665236711502075,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.7145,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.29055407643318176,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.7197,
      "step": 17
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.29208090901374817,
      "learning_rate": 6e-05,
      "loss": 0.7439,
      "step": 18
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.29603835940361023,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.5913,
      "step": 19
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.33053672313690186,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.6733,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.26229822635650635,
      "learning_rate": 7e-05,
      "loss": 0.5534,
      "step": 21
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.27639198303222656,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.6538,
      "step": 22
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.24886314570903778,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.6227,
      "step": 23
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.22330135107040405,
      "learning_rate": 8e-05,
      "loss": 0.6945,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2050675004720688,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.6814,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.17721343040466309,
      "learning_rate": 8.666666666666667e-05,
      "loss": 0.4686,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.20736536383628845,
      "learning_rate": 9e-05,
      "loss": 0.5394,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.23327553272247314,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.5685,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2685520648956299,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.5249,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.22024010121822357,
      "learning_rate": 0.0001,
      "loss": 0.5519,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.10264797508716583,
      "learning_rate": 0.00010333333333333334,
      "loss": 0.3104,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1344147026538849,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.4419,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15405485033988953,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.4291,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.215621218085289,
      "learning_rate": 0.00011333333333333334,
      "loss": 0.5163,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.11477665603160858,
      "learning_rate": 0.00011666666666666668,
      "loss": 0.4149,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15755023062229156,
      "learning_rate": 0.00012,
      "loss": 0.4413,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1564071625471115,
      "learning_rate": 0.00012333333333333334,
      "loss": 0.4953,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.14329794049263,
      "learning_rate": 0.00012666666666666666,
      "loss": 0.4392,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.127530038356781,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.3288,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.14381371438503265,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.4205,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15410427749156952,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.5962,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1474694013595581,
      "learning_rate": 0.00014,
      "loss": 0.5432,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.12147431820631027,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.416,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19018493592739105,
      "learning_rate": 0.00014666666666666666,
      "loss": 0.4708,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.12172587960958481,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.3739,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.10878117382526398,
      "learning_rate": 0.00015333333333333334,
      "loss": 0.401,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.12428025156259537,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4854,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1825135350227356,
      "learning_rate": 0.00016,
      "loss": 0.4024,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.11075381934642792,
      "learning_rate": 0.00016333333333333334,
      "loss": 0.4648,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.13789980113506317,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.396,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.09907187521457672,
      "learning_rate": 0.00017,
      "loss": 0.3768,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.09092357009649277,
      "learning_rate": 0.00017333333333333334,
      "loss": 0.3798,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1296694427728653,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3837,
      "step": 53
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.07297886908054352,
      "learning_rate": 0.00018,
      "loss": 0.3551,
      "step": 54
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11118462681770325,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.3996,
      "step": 55
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10421288013458252,
      "learning_rate": 0.0001866666666666667,
      "loss": 0.597,
      "step": 56
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.16559207439422607,
      "learning_rate": 0.00019,
      "loss": 0.4738,
      "step": 57
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12429098039865494,
      "learning_rate": 0.00019333333333333333,
      "loss": 0.4053,
      "step": 58
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12747451663017273,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.4539,
      "step": 59
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12265349924564362,
      "learning_rate": 0.0002,
      "loss": 0.4189,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11506183445453644,
      "learning_rate": 0.00019999999004874854,
      "loss": 0.4609,
      "step": 61
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1666932851076126,
      "learning_rate": 0.00019999996019499613,
      "loss": 0.5174,
      "step": 62
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.14501886069774628,
      "learning_rate": 0.00019999991043874866,
      "loss": 0.4559,
      "step": 63
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12798653542995453,
      "learning_rate": 0.0001999998407800161,
      "loss": 0.511,
      "step": 64
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10826729983091354,
      "learning_rate": 0.0001999997512188123,
      "loss": 0.3839,
      "step": 65
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1451631486415863,
      "learning_rate": 0.00019999964175515506,
      "loss": 0.4008,
      "step": 66
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11902773380279541,
      "learning_rate": 0.0001999995123890662,
      "loss": 0.4244,
      "step": 67
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12054571509361267,
      "learning_rate": 0.00019999936312057145,
      "loss": 0.4309,
      "step": 68
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12384297698736191,
      "learning_rate": 0.00019999919394970048,
      "loss": 0.4064,
      "step": 69
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12281866371631622,
      "learning_rate": 0.00019999900487648704,
      "loss": 0.5304,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10363901406526566,
      "learning_rate": 0.00019999879590096867,
      "loss": 0.3403,
      "step": 71
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.15074020624160767,
      "learning_rate": 0.00019999856702318704,
      "loss": 0.4518,
      "step": 72
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10400057584047318,
      "learning_rate": 0.00019999831824318767,
      "loss": 0.4905,
      "step": 73
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1186402216553688,
      "learning_rate": 0.00019999804956102003,
      "loss": 0.3938,
      "step": 74
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.13071924448013306,
      "learning_rate": 0.0001999977609767377,
      "loss": 0.335,
      "step": 75
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.14857758581638336,
      "learning_rate": 0.00019999745249039803,
      "loss": 0.4767,
      "step": 76
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10346691310405731,
      "learning_rate": 0.00019999712410206244,
      "loss": 0.3656,
      "step": 77
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11108960211277008,
      "learning_rate": 0.00019999677581179626,
      "loss": 0.4501,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10724522918462753,
      "learning_rate": 0.00019999640761966884,
      "loss": 0.4467,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1432035118341446,
      "learning_rate": 0.0001999960195257535,
      "loss": 0.4422,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10293781012296677,
      "learning_rate": 0.0001999956115301274,
      "loss": 0.429,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11937693506479263,
      "learning_rate": 0.00019999518363287178,
      "loss": 0.3832,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11867678910493851,
      "learning_rate": 0.0001999947358340718,
      "loss": 0.3925,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12674346566200256,
      "learning_rate": 0.00019999426813381658,
      "loss": 0.4719,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12381777167320251,
      "learning_rate": 0.0001999937805321992,
      "loss": 0.4737,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12572656571865082,
      "learning_rate": 0.00019999327302931672,
      "loss": 0.4754,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1179409846663475,
      "learning_rate": 0.00019999274562527015,
      "loss": 0.4254,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.10736481100320816,
      "learning_rate": 0.00019999219832016443,
      "loss": 0.3973,
      "step": 88
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1319209635257721,
      "learning_rate": 0.00019999163111410851,
      "loss": 0.3902,
      "step": 89
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.09811317175626755,
      "learning_rate": 0.00019999104400721525,
      "loss": 0.3609,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11644987761974335,
      "learning_rate": 0.00019999043699960153,
      "loss": 0.553,
      "step": 91
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.10523971915245056,
      "learning_rate": 0.00019998981009138815,
      "loss": 0.3604,
      "step": 92
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11519289761781693,
      "learning_rate": 0.0001999891632826999,
      "loss": 0.4968,
      "step": 93
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12869371473789215,
      "learning_rate": 0.00019998849657366544,
      "loss": 0.4012,
      "step": 94
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13094671070575714,
      "learning_rate": 0.00019998780996441755,
      "loss": 0.3601,
      "step": 95
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13529671728610992,
      "learning_rate": 0.00019998710345509282,
      "loss": 0.4733,
      "step": 96
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2664095163345337,
      "learning_rate": 0.0001999863770458319,
      "loss": 0.4905,
      "step": 97
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12298315763473511,
      "learning_rate": 0.00019998563073677934,
      "loss": 0.4542,
      "step": 98
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11298283189535141,
      "learning_rate": 0.0001999848645280837,
      "loss": 0.4306,
      "step": 99
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.07041435688734055,
      "learning_rate": 0.00019998407841989745,
      "loss": 0.2796,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13357995450496674,
      "learning_rate": 0.00019998327241237704,
      "loss": 0.5079,
      "step": 101
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.09026381373405457,
      "learning_rate": 0.0001999824465056829,
      "loss": 0.3083,
      "step": 102
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13411465287208557,
      "learning_rate": 0.00019998160069997943,
      "loss": 0.4155,
      "step": 103
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.15603192150592804,
      "learning_rate": 0.00019998073499543492,
      "loss": 0.4261,
      "step": 104
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.10242384672164917,
      "learning_rate": 0.0001999798493922217,
      "loss": 0.3898,
      "step": 105
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1129574328660965,
      "learning_rate": 0.000199978943890516,
      "loss": 0.3822,
      "step": 106
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1672971248626709,
      "learning_rate": 0.0001999780184904981,
      "loss": 0.5334,
      "step": 107
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11370077729225159,
      "learning_rate": 0.0001999770731923521,
      "loss": 0.3942,
      "step": 108
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.09156589955091476,
      "learning_rate": 0.00019997610799626618,
      "loss": 0.3908,
      "step": 109
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12287542968988419,
      "learning_rate": 0.00019997512290243242,
      "loss": 0.5131,
      "step": 110
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.10971950739622116,
      "learning_rate": 0.0001999741179110469,
      "loss": 0.3608,
      "step": 111
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.10036376863718033,
      "learning_rate": 0.0001999730930223096,
      "loss": 0.3539,
      "step": 112
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12429390847682953,
      "learning_rate": 0.00019997204823642451,
      "loss": 0.4603,
      "step": 113
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.09587584435939789,
      "learning_rate": 0.00019997098355359962,
      "loss": 0.3659,
      "step": 114
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.16887907683849335,
      "learning_rate": 0.0001999698989740468,
      "loss": 0.4355,
      "step": 115
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13161426782608032,
      "learning_rate": 0.00019996879449798188,
      "loss": 0.3683,
      "step": 116
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1089661493897438,
      "learning_rate": 0.00019996767012562467,
      "loss": 0.4317,
      "step": 117
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14045751094818115,
      "learning_rate": 0.000199966525857199,
      "loss": 0.4347,
      "step": 118
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13796696066856384,
      "learning_rate": 0.00019996536169293258,
      "loss": 0.3454,
      "step": 119
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13256534934043884,
      "learning_rate": 0.00019996417763305712,
      "loss": 0.4504,
      "step": 120
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.10975474864244461,
      "learning_rate": 0.00019996297367780828,
      "loss": 0.3612,
      "step": 121
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1365571916103363,
      "learning_rate": 0.00019996174982742565,
      "loss": 0.3573,
      "step": 122
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.130079448223114,
      "learning_rate": 0.00019996050608215283,
      "loss": 0.403,
      "step": 123
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.09517743438482285,
      "learning_rate": 0.0001999592424422373,
      "loss": 0.3733,
      "step": 124
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12176822870969772,
      "learning_rate": 0.00019995795890793066,
      "loss": 0.4891,
      "step": 125
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.16578920185565948,
      "learning_rate": 0.0001999566554794883,
      "loss": 0.5054,
      "step": 126
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0950639471411705,
      "learning_rate": 0.00019995533215716967,
      "loss": 0.4556,
      "step": 127
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0981779396533966,
      "learning_rate": 0.00019995398894123807,
      "loss": 0.3549,
      "step": 128
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10371039062738419,
      "learning_rate": 0.00019995262583196092,
      "loss": 0.3482,
      "step": 129
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.14031553268432617,
      "learning_rate": 0.00019995124282960944,
      "loss": 0.4342,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11201638728380203,
      "learning_rate": 0.00019994983993445895,
      "loss": 0.3981,
      "step": 131
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1186540350317955,
      "learning_rate": 0.00019994841714678866,
      "loss": 0.4394,
      "step": 132
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.13132928311824799,
      "learning_rate": 0.00019994697446688164,
      "loss": 0.3335,
      "step": 133
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11131156980991364,
      "learning_rate": 0.00019994551189502513,
      "loss": 0.3296,
      "step": 134
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10509748756885529,
      "learning_rate": 0.00019994402943151015,
      "loss": 0.426,
      "step": 135
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.09878562390804291,
      "learning_rate": 0.00019994252707663182,
      "loss": 0.3579,
      "step": 136
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1381361484527588,
      "learning_rate": 0.00019994100483068907,
      "loss": 0.4199,
      "step": 137
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11308177560567856,
      "learning_rate": 0.0001999394626939849,
      "loss": 0.3372,
      "step": 138
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1125182956457138,
      "learning_rate": 0.00019993790066682622,
      "loss": 0.351,
      "step": 139
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.14643648266792297,
      "learning_rate": 0.00019993631874952396,
      "loss": 0.3679,
      "step": 140
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.09688626229763031,
      "learning_rate": 0.0001999347169423929,
      "loss": 0.3844,
      "step": 141
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10280001908540726,
      "learning_rate": 0.0001999330952457519,
      "loss": 0.3313,
      "step": 142
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10047902911901474,
      "learning_rate": 0.0001999314536599236,
      "loss": 0.3346,
      "step": 143
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12232235074043274,
      "learning_rate": 0.00019992979218523487,
      "loss": 0.4274,
      "step": 144
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10782156884670258,
      "learning_rate": 0.0001999281108220163,
      "loss": 0.4174,
      "step": 145
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11192818731069565,
      "learning_rate": 0.00019992640957060251,
      "loss": 0.3728,
      "step": 146
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.09298495948314667,
      "learning_rate": 0.00019992468843133213,
      "loss": 0.3975,
      "step": 147
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.24031172692775726,
      "learning_rate": 0.0001999229474045477,
      "loss": 0.6179,
      "step": 148
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1107291504740715,
      "learning_rate": 0.0001999211864905957,
      "loss": 0.3141,
      "step": 149
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12956476211547852,
      "learning_rate": 0.00019991940568982668,
      "loss": 0.4347,
      "step": 150
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10097075253725052,
      "learning_rate": 0.00019991760500259498,
      "loss": 0.3714,
      "step": 151
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.07800343632698059,
      "learning_rate": 0.000199915784429259,
      "loss": 0.3226,
      "step": 152
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10384363681077957,
      "learning_rate": 0.0001999139439701811,
      "loss": 0.4212,
      "step": 153
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11354999244213104,
      "learning_rate": 0.00019991208362572755,
      "loss": 0.4144,
      "step": 154
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0828632265329361,
      "learning_rate": 0.00019991020339626863,
      "loss": 0.3478,
      "step": 155
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1315978765487671,
      "learning_rate": 0.00019990830328217856,
      "loss": 0.3949,
      "step": 156
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.111504927277565,
      "learning_rate": 0.00019990638328383546,
      "loss": 0.4281,
      "step": 157
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10823381692171097,
      "learning_rate": 0.0001999044434016215,
      "loss": 0.4582,
      "step": 158
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.08424707502126694,
      "learning_rate": 0.00019990248363592277,
      "loss": 0.3707,
      "step": 159
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09005239605903625,
      "learning_rate": 0.0001999005039871293,
      "loss": 0.5703,
      "step": 160
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11045844852924347,
      "learning_rate": 0.0001998985044556351,
      "loss": 0.4426,
      "step": 161
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.08865899592638016,
      "learning_rate": 0.00019989648504183807,
      "loss": 0.377,
      "step": 162
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1080022007226944,
      "learning_rate": 0.00019989444574614021,
      "loss": 0.3845,
      "step": 163
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09286520630121231,
      "learning_rate": 0.0001998923865689473,
      "loss": 0.4032,
      "step": 164
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10753525793552399,
      "learning_rate": 0.00019989030751066928,
      "loss": 0.3597,
      "step": 165
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09824256598949432,
      "learning_rate": 0.00019988820857171983,
      "loss": 0.3757,
      "step": 166
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10612216591835022,
      "learning_rate": 0.00019988608975251676,
      "loss": 0.3203,
      "step": 167
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12363561987876892,
      "learning_rate": 0.00019988395105348172,
      "loss": 0.4888,
      "step": 168
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10209880024194717,
      "learning_rate": 0.0001998817924750404,
      "loss": 0.3431,
      "step": 169
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.08903653174638748,
      "learning_rate": 0.0001998796140176224,
      "loss": 0.3386,
      "step": 170
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11789187043905258,
      "learning_rate": 0.00019987741568166126,
      "loss": 0.3863,
      "step": 171
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10292457789182663,
      "learning_rate": 0.00019987519746759454,
      "loss": 0.3188,
      "step": 172
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1177792176604271,
      "learning_rate": 0.00019987295937586372,
      "loss": 0.481,
      "step": 173
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10418900847434998,
      "learning_rate": 0.0001998707014069142,
      "loss": 0.4127,
      "step": 174
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.08518170565366745,
      "learning_rate": 0.00019986842356119544,
      "loss": 0.368,
      "step": 175
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1290670931339264,
      "learning_rate": 0.00019986612583916072,
      "loss": 0.4457,
      "step": 176
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09319265186786652,
      "learning_rate": 0.0001998638082412674,
      "loss": 0.3545,
      "step": 177
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11600086838006973,
      "learning_rate": 0.00019986147076797665,
      "loss": 0.4671,
      "step": 178
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10536066442728043,
      "learning_rate": 0.0001998591134197538,
      "loss": 0.3431,
      "step": 179
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10075027495622635,
      "learning_rate": 0.00019985673619706793,
      "loss": 0.3983,
      "step": 180
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11105016618967056,
      "learning_rate": 0.00019985433910039223,
      "loss": 0.4259,
      "step": 181
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09490879625082016,
      "learning_rate": 0.00019985192213020373,
      "loss": 0.4178,
      "step": 182
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11098974943161011,
      "learning_rate": 0.00019984948528698352,
      "loss": 0.3955,
      "step": 183
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13222311437129974,
      "learning_rate": 0.00019984702857121656,
      "loss": 0.6169,
      "step": 184
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12179770320653915,
      "learning_rate": 0.0001998445519833918,
      "loss": 0.4162,
      "step": 185
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0855954959988594,
      "learning_rate": 0.00019984205552400216,
      "loss": 0.3654,
      "step": 186
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1161196380853653,
      "learning_rate": 0.00019983953919354446,
      "loss": 0.3878,
      "step": 187
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11275071650743484,
      "learning_rate": 0.00019983700299251955,
      "loss": 0.3729,
      "step": 188
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1188095286488533,
      "learning_rate": 0.0001998344469214322,
      "loss": 0.3747,
      "step": 189
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09163927286863327,
      "learning_rate": 0.0001998318709807911,
      "loss": 0.3361,
      "step": 190
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.07676220685243607,
      "learning_rate": 0.00019982927517110894,
      "loss": 0.2946,
      "step": 191
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10003312677145004,
      "learning_rate": 0.00019982665949290235,
      "loss": 0.3355,
      "step": 192
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.08892764151096344,
      "learning_rate": 0.00019982402394669196,
      "loss": 0.4098,
      "step": 193
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09671314060688019,
      "learning_rate": 0.00019982136853300225,
      "loss": 0.3325,
      "step": 194
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.14719721674919128,
      "learning_rate": 0.0001998186932523617,
      "loss": 0.3822,
      "step": 195
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.08805704861879349,
      "learning_rate": 0.00019981599810530286,
      "loss": 0.2969,
      "step": 196
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.08166174590587616,
      "learning_rate": 0.00019981328309236202,
      "loss": 0.3713,
      "step": 197
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1284017562866211,
      "learning_rate": 0.00019981054821407957,
      "loss": 0.4738,
      "step": 198
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09353422373533249,
      "learning_rate": 0.00019980779347099985,
      "loss": 0.3871,
      "step": 199
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0896751880645752,
      "learning_rate": 0.0001998050188636711,
      "loss": 0.4065,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09826420247554779,
      "learning_rate": 0.00019980222439264553,
      "loss": 0.4185,
      "step": 201
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09203485399484634,
      "learning_rate": 0.00019979941005847932,
      "loss": 0.3313,
      "step": 202
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.08968321979045868,
      "learning_rate": 0.00019979657586173256,
      "loss": 0.4235,
      "step": 203
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.08133640140295029,
      "learning_rate": 0.00019979372180296942,
      "loss": 0.3901,
      "step": 204
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09446154534816742,
      "learning_rate": 0.00019979084788275783,
      "loss": 0.3836,
      "step": 205
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09466523677110672,
      "learning_rate": 0.00019978795410166978,
      "loss": 0.4021,
      "step": 206
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09572619944810867,
      "learning_rate": 0.00019978504046028127,
      "loss": 0.3403,
      "step": 207
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10587351769208908,
      "learning_rate": 0.00019978210695917214,
      "loss": 0.5182,
      "step": 208
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.06858031451702118,
      "learning_rate": 0.00019977915359892627,
      "loss": 0.2965,
      "step": 209
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0921504944562912,
      "learning_rate": 0.00019977618038013138,
      "loss": 0.3795,
      "step": 210
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09130052477121353,
      "learning_rate": 0.00019977318730337928,
      "loss": 0.3785,
      "step": 211
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09498782455921173,
      "learning_rate": 0.00019977017436926563,
      "loss": 0.3283,
      "step": 212
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.08150545507669449,
      "learning_rate": 0.00019976714157839012,
      "loss": 0.2695,
      "step": 213
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10180898010730743,
      "learning_rate": 0.0001997640889313563,
      "loss": 0.3824,
      "step": 214
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13440339267253876,
      "learning_rate": 0.00019976101642877177,
      "loss": 0.3526,
      "step": 215
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12471131980419159,
      "learning_rate": 0.000199757924071248,
      "loss": 0.4209,
      "step": 216
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09306962043046951,
      "learning_rate": 0.00019975481185940047,
      "loss": 0.3028,
      "step": 217
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10110160708427429,
      "learning_rate": 0.00019975167979384854,
      "loss": 0.3691,
      "step": 218
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11114165186882019,
      "learning_rate": 0.00019974852787521562,
      "loss": 0.2833,
      "step": 219
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11045999825000763,
      "learning_rate": 0.00019974535610412905,
      "loss": 0.4282,
      "step": 220
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.09496348351240158,
      "learning_rate": 0.00019974216448122003,
      "loss": 0.3491,
      "step": 221
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10604080557823181,
      "learning_rate": 0.00019973895300712377,
      "loss": 0.4278,
      "step": 222
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12076526135206223,
      "learning_rate": 0.00019973572168247947,
      "loss": 0.351,
      "step": 223
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10844873636960983,
      "learning_rate": 0.00019973247050793024,
      "loss": 0.3662,
      "step": 224
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11201751977205276,
      "learning_rate": 0.00019972919948412315,
      "loss": 0.3829,
      "step": 225
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10759232938289642,
      "learning_rate": 0.00019972590861170916,
      "loss": 0.4496,
      "step": 226
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10340290516614914,
      "learning_rate": 0.0001997225978913433,
      "loss": 0.3679,
      "step": 227
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1392740160226822,
      "learning_rate": 0.00019971926732368446,
      "loss": 0.3236,
      "step": 228
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12249954789876938,
      "learning_rate": 0.00019971591690939552,
      "loss": 0.4594,
      "step": 229
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.08182284235954285,
      "learning_rate": 0.0001997125466491433,
      "loss": 0.3189,
      "step": 230
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09004911780357361,
      "learning_rate": 0.00019970915654359854,
      "loss": 0.3474,
      "step": 231
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12476880103349686,
      "learning_rate": 0.00019970574659343595,
      "loss": 0.5069,
      "step": 232
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12275810539722443,
      "learning_rate": 0.00019970231679933425,
      "loss": 0.4427,
      "step": 233
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.08597820997238159,
      "learning_rate": 0.00019969886716197599,
      "loss": 0.2902,
      "step": 234
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10798820108175278,
      "learning_rate": 0.00019969539768204775,
      "loss": 0.4491,
      "step": 235
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11406934261322021,
      "learning_rate": 0.00019969190836024008,
      "loss": 0.3632,
      "step": 236
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1211467757821083,
      "learning_rate": 0.00019968839919724742,
      "loss": 0.4024,
      "step": 237
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11280754953622818,
      "learning_rate": 0.0001996848701937682,
      "loss": 0.3605,
      "step": 238
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11744940280914307,
      "learning_rate": 0.0001996813213505047,
      "loss": 0.3946,
      "step": 239
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09829340130090714,
      "learning_rate": 0.00019967775266816333,
      "loss": 0.4436,
      "step": 240
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10151176899671555,
      "learning_rate": 0.0001996741641474543,
      "loss": 0.4081,
      "step": 241
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.08672751486301422,
      "learning_rate": 0.00019967055578909185,
      "loss": 0.3456,
      "step": 242
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10178228467702866,
      "learning_rate": 0.00019966692759379408,
      "loss": 0.3563,
      "step": 243
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.08267026394605637,
      "learning_rate": 0.0001996632795622831,
      "loss": 0.3137,
      "step": 244
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1014196127653122,
      "learning_rate": 0.000199659611695285,
      "loss": 0.428,
      "step": 245
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.08857525885105133,
      "learning_rate": 0.00019965592399352975,
      "loss": 0.3587,
      "step": 246
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.07767628133296967,
      "learning_rate": 0.00019965221645775128,
      "loss": 0.3345,
      "step": 247
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12221680581569672,
      "learning_rate": 0.00019964848908868752,
      "loss": 0.3934,
      "step": 248
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12366396933794022,
      "learning_rate": 0.0001996447418870803,
      "loss": 0.4861,
      "step": 249
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10781913995742798,
      "learning_rate": 0.00019964097485367536,
      "loss": 0.3603,
      "step": 250
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09424305707216263,
      "learning_rate": 0.00019963718798922248,
      "loss": 0.3606,
      "step": 251
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11687763035297394,
      "learning_rate": 0.00019963338129447538,
      "loss": 0.4131,
      "step": 252
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1207248866558075,
      "learning_rate": 0.0001996295547701916,
      "loss": 0.4823,
      "step": 253
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09511466324329376,
      "learning_rate": 0.00019962570841713275,
      "loss": 0.3665,
      "step": 254
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0976681262254715,
      "learning_rate": 0.00019962184223606437,
      "loss": 0.3649,
      "step": 255
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.06769749522209167,
      "learning_rate": 0.0001996179562277559,
      "loss": 0.2567,
      "step": 256
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09740106016397476,
      "learning_rate": 0.00019961405039298078,
      "loss": 0.4203,
      "step": 257
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09366639703512192,
      "learning_rate": 0.00019961012473251636,
      "loss": 0.388,
      "step": 258
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13223379850387573,
      "learning_rate": 0.0001996061792471439,
      "loss": 0.5471,
      "step": 259
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10426145792007446,
      "learning_rate": 0.00019960221393764872,
      "loss": 0.375,
      "step": 260
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.08209710568189621,
      "learning_rate": 0.00019959822880481998,
      "loss": 0.3559,
      "step": 261
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.08746996521949768,
      "learning_rate": 0.00019959422384945082,
      "loss": 0.353,
      "step": 262
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09660078585147858,
      "learning_rate": 0.00019959019907233832,
      "loss": 0.3599,
      "step": 263
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11309582740068436,
      "learning_rate": 0.00019958615447428354,
      "loss": 0.3878,
      "step": 264
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10187938064336777,
      "learning_rate": 0.0001995820900560914,
      "loss": 0.3482,
      "step": 265
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.09284788370132446,
      "learning_rate": 0.00019957800581857092,
      "loss": 0.3451,
      "step": 266
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09329354017972946,
      "learning_rate": 0.00019957390176253488,
      "loss": 0.35,
      "step": 267
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09627247601747513,
      "learning_rate": 0.0001995697778888001,
      "loss": 0.4531,
      "step": 268
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09099569171667099,
      "learning_rate": 0.00019956563419818736,
      "loss": 0.3403,
      "step": 269
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10173208266496658,
      "learning_rate": 0.00019956147069152136,
      "loss": 0.3689,
      "step": 270
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10961207747459412,
      "learning_rate": 0.0001995572873696307,
      "loss": 0.3135,
      "step": 271
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.06379403173923492,
      "learning_rate": 0.00019955308423334804,
      "loss": 0.4492,
      "step": 272
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09273090958595276,
      "learning_rate": 0.00019954886128350984,
      "loss": 0.3475,
      "step": 273
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16426652669906616,
      "learning_rate": 0.0001995446185209566,
      "loss": 0.3754,
      "step": 274
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10877036303281784,
      "learning_rate": 0.00019954035594653272,
      "loss": 0.374,
      "step": 275
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0979791060090065,
      "learning_rate": 0.00019953607356108658,
      "loss": 0.4268,
      "step": 276
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09492401778697968,
      "learning_rate": 0.0001995317713654705,
      "loss": 0.3572,
      "step": 277
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.13499301671981812,
      "learning_rate": 0.00019952744936054068,
      "loss": 0.4887,
      "step": 278
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.08588553965091705,
      "learning_rate": 0.00019952310754715733,
      "loss": 0.3413,
      "step": 279
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10297136753797531,
      "learning_rate": 0.00019951874592618455,
      "loss": 0.3913,
      "step": 280
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1282561868429184,
      "learning_rate": 0.00019951436449849047,
      "loss": 0.5047,
      "step": 281
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09702958166599274,
      "learning_rate": 0.00019950996326494706,
      "loss": 0.3034,
      "step": 282
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0925213024020195,
      "learning_rate": 0.0001995055422264303,
      "loss": 0.3824,
      "step": 283
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10922491550445557,
      "learning_rate": 0.00019950110138382005,
      "loss": 0.4583,
      "step": 284
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10289523005485535,
      "learning_rate": 0.0001994966407380002,
      "loss": 0.3014,
      "step": 285
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09920763224363327,
      "learning_rate": 0.00019949216028985846,
      "loss": 0.3805,
      "step": 286
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12242035567760468,
      "learning_rate": 0.00019948766004028662,
      "loss": 0.3483,
      "step": 287
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10804708302021027,
      "learning_rate": 0.00019948313999018034,
      "loss": 0.3578,
      "step": 288
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10482387244701385,
      "learning_rate": 0.00019947860014043917,
      "loss": 0.3627,
      "step": 289
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.08192146569490433,
      "learning_rate": 0.0001994740404919667,
      "loss": 0.2538,
      "step": 290
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10920112580060959,
      "learning_rate": 0.0001994694610456704,
      "loss": 0.3978,
      "step": 291
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.11436305940151215,
      "learning_rate": 0.00019946486180246167,
      "loss": 0.3582,
      "step": 292
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09170164167881012,
      "learning_rate": 0.0001994602427632559,
      "loss": 0.3208,
      "step": 293
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09605585783720016,
      "learning_rate": 0.00019945560392897242,
      "loss": 0.2995,
      "step": 294
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0762777253985405,
      "learning_rate": 0.00019945094530053443,
      "loss": 0.3418,
      "step": 295
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.11161578446626663,
      "learning_rate": 0.00019944626687886912,
      "loss": 0.3397,
      "step": 296
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10223428905010223,
      "learning_rate": 0.0001994415686649076,
      "loss": 0.4294,
      "step": 297
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.09739301353693008,
      "learning_rate": 0.000199436850659585,
      "loss": 0.3899,
      "step": 298
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1581811010837555,
      "learning_rate": 0.00019943211286384025,
      "loss": 0.5383,
      "step": 299
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10791391879320145,
      "learning_rate": 0.00019942735527861633,
      "loss": 0.436,
      "step": 300
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10587034374475479,
      "learning_rate": 0.0001994225779048601,
      "loss": 0.4066,
      "step": 301
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10199813544750214,
      "learning_rate": 0.00019941778074352237,
      "loss": 0.3617,
      "step": 302
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11123159527778625,
      "learning_rate": 0.00019941296379555792,
      "loss": 0.3577,
      "step": 303
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.08898112177848816,
      "learning_rate": 0.00019940812706192542,
      "loss": 0.3027,
      "step": 304
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.07475384324789047,
      "learning_rate": 0.0001994032705435875,
      "loss": 0.3785,
      "step": 305
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10059133917093277,
      "learning_rate": 0.00019939839424151074,
      "loss": 0.3662,
      "step": 306
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.08710434287786484,
      "learning_rate": 0.00019939349815666568,
      "loss": 0.3667,
      "step": 307
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11494375020265579,
      "learning_rate": 0.00019938858229002668,
      "loss": 0.3736,
      "step": 308
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11544954031705856,
      "learning_rate": 0.0001993836466425722,
      "loss": 0.4264,
      "step": 309
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09320943057537079,
      "learning_rate": 0.00019937869121528453,
      "loss": 0.4183,
      "step": 310
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1126343384385109,
      "learning_rate": 0.00019937371600914992,
      "loss": 0.429,
      "step": 311
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09952600300312042,
      "learning_rate": 0.00019936872102515853,
      "loss": 0.3654,
      "step": 312
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11344382911920547,
      "learning_rate": 0.00019936370626430454,
      "loss": 0.399,
      "step": 313
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09766057133674622,
      "learning_rate": 0.00019935867172758597,
      "loss": 0.3725,
      "step": 314
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1092476025223732,
      "learning_rate": 0.0001993536174160049,
      "loss": 0.435,
      "step": 315
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.08760707825422287,
      "learning_rate": 0.00019934854333056713,
      "loss": 0.3411,
      "step": 316
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1235421821475029,
      "learning_rate": 0.00019934344947228265,
      "loss": 0.4271,
      "step": 317
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10249342024326324,
      "learning_rate": 0.00019933833584216522,
      "loss": 0.4074,
      "step": 318
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0996313989162445,
      "learning_rate": 0.00019933320244123256,
      "loss": 0.3475,
      "step": 319
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09471343457698822,
      "learning_rate": 0.00019932804927050635,
      "loss": 0.3517,
      "step": 320
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10289925336837769,
      "learning_rate": 0.00019932287633101225,
      "loss": 0.3717,
      "step": 321
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10219959914684296,
      "learning_rate": 0.00019931768362377973,
      "loss": 0.4798,
      "step": 322
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.12992575764656067,
      "learning_rate": 0.00019931247114984236,
      "loss": 0.3992,
      "step": 323
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09797049313783646,
      "learning_rate": 0.00019930723891023745,
      "loss": 0.3475,
      "step": 324
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09431435912847519,
      "learning_rate": 0.00019930198690600644,
      "loss": 0.4465,
      "step": 325
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09703788161277771,
      "learning_rate": 0.00019929671513819455,
      "loss": 0.3822,
      "step": 326
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09908290952444077,
      "learning_rate": 0.000199291423607851,
      "loss": 0.422,
      "step": 327
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10300911962985992,
      "learning_rate": 0.00019928611231602897,
      "loss": 0.3698,
      "step": 328
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0878002941608429,
      "learning_rate": 0.00019928078126378552,
      "loss": 0.3877,
      "step": 329
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11823677271604538,
      "learning_rate": 0.00019927543045218164,
      "loss": 0.4433,
      "step": 330
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10320913791656494,
      "learning_rate": 0.0001992700598822823,
      "loss": 0.3663,
      "step": 331
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10124378651380539,
      "learning_rate": 0.00019926466955515638,
      "loss": 0.3003,
      "step": 332
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.08939307928085327,
      "learning_rate": 0.00019925925947187668,
      "loss": 0.3773,
      "step": 333
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1341991424560547,
      "learning_rate": 0.00019925382963351996,
      "loss": 0.4185,
      "step": 334
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10774528235197067,
      "learning_rate": 0.00019924838004116687,
      "loss": 0.4713,
      "step": 335
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09881731867790222,
      "learning_rate": 0.00019924291069590205,
      "loss": 0.4253,
      "step": 336
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09894528985023499,
      "learning_rate": 0.00019923742159881397,
      "loss": 0.3681,
      "step": 337
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09823421388864517,
      "learning_rate": 0.00019923191275099516,
      "loss": 0.408,
      "step": 338
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.086711585521698,
      "learning_rate": 0.000199226384153542,
      "loss": 0.3259,
      "step": 339
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09313579648733139,
      "learning_rate": 0.00019922083580755482,
      "loss": 0.3891,
      "step": 340
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09099448472261429,
      "learning_rate": 0.00019921526771413787,
      "loss": 0.3566,
      "step": 341
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10432339459657669,
      "learning_rate": 0.00019920967987439937,
      "loss": 0.2715,
      "step": 342
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10384204238653183,
      "learning_rate": 0.0001992040722894514,
      "loss": 0.3536,
      "step": 343
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.12824951112270355,
      "learning_rate": 0.00019919844496041003,
      "loss": 0.3757,
      "step": 344
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09959540516138077,
      "learning_rate": 0.00019919279788839522,
      "loss": 0.3629,
      "step": 345
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10489114373922348,
      "learning_rate": 0.0001991871310745309,
      "loss": 0.376,
      "step": 346
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09845041483640671,
      "learning_rate": 0.0001991814445199449,
      "loss": 0.3742,
      "step": 347
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09098081290721893,
      "learning_rate": 0.00019917573822576904,
      "loss": 0.3458,
      "step": 348
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.13128824532032013,
      "learning_rate": 0.00019917001219313892,
      "loss": 0.4694,
      "step": 349
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1071697250008583,
      "learning_rate": 0.0001991642664231942,
      "loss": 0.4462,
      "step": 350
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09952019155025482,
      "learning_rate": 0.00019915850091707847,
      "loss": 0.3996,
      "step": 351
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1080295518040657,
      "learning_rate": 0.00019915271567593916,
      "loss": 0.4158,
      "step": 352
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09755202382802963,
      "learning_rate": 0.0001991469107009277,
      "loss": 0.4487,
      "step": 353
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09645305573940277,
      "learning_rate": 0.00019914108599319941,
      "loss": 0.3905,
      "step": 354
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09720470011234283,
      "learning_rate": 0.00019913524155391361,
      "loss": 0.3908,
      "step": 355
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09702897816896439,
      "learning_rate": 0.00019912937738423344,
      "loss": 0.3875,
      "step": 356
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09693070501089096,
      "learning_rate": 0.000199123493485326,
      "loss": 0.3506,
      "step": 357
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1118786633014679,
      "learning_rate": 0.00019911758985836236,
      "loss": 0.3944,
      "step": 358
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10301733016967773,
      "learning_rate": 0.00019911166650451748,
      "loss": 0.3038,
      "step": 359
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.11412820965051651,
      "learning_rate": 0.0001991057234249703,
      "loss": 0.4335,
      "step": 360
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10286547988653183,
      "learning_rate": 0.00019909976062090355,
      "loss": 0.4361,
      "step": 361
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.23305465281009674,
      "learning_rate": 0.00019909377809350406,
      "loss": 0.3655,
      "step": 362
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1107562780380249,
      "learning_rate": 0.00019908777584396248,
      "loss": 0.4464,
      "step": 363
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09635069966316223,
      "learning_rate": 0.00019908175387347337,
      "loss": 0.3087,
      "step": 364
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.11678191274404526,
      "learning_rate": 0.00019907571218323532,
      "loss": 0.4185,
      "step": 365
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2089780867099762,
      "learning_rate": 0.00019906965077445073,
      "loss": 0.3875,
      "step": 366
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09316997230052948,
      "learning_rate": 0.00019906356964832596,
      "loss": 0.3908,
      "step": 367
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.12468700855970383,
      "learning_rate": 0.00019905746880607134,
      "loss": 0.4611,
      "step": 368
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1739904135465622,
      "learning_rate": 0.00019905134824890107,
      "loss": 0.4404,
      "step": 369
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10968005657196045,
      "learning_rate": 0.00019904520797803333,
      "loss": 0.4019,
      "step": 370
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10675179213285446,
      "learning_rate": 0.00019903904799469015,
      "loss": 0.3999,
      "step": 371
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10888608545064926,
      "learning_rate": 0.00019903286830009754,
      "loss": 0.398,
      "step": 372
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08182094991207123,
      "learning_rate": 0.00019902666889548538,
      "loss": 0.3503,
      "step": 373
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10482712835073471,
      "learning_rate": 0.00019902044978208755,
      "loss": 0.3673,
      "step": 374
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.07469111680984497,
      "learning_rate": 0.0001990142109611418,
      "loss": 0.3092,
      "step": 375
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11275798827409744,
      "learning_rate": 0.0001990079524338898,
      "loss": 0.389,
      "step": 376
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.09852753579616547,
      "learning_rate": 0.00019900167420157716,
      "loss": 0.3782,
      "step": 377
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08354530483484268,
      "learning_rate": 0.00019899537626545338,
      "loss": 0.3073,
      "step": 378
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11336246132850647,
      "learning_rate": 0.00019898905862677198,
      "loss": 0.4075,
      "step": 379
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10607190430164337,
      "learning_rate": 0.00019898272128679022,
      "loss": 0.3407,
      "step": 380
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08736999332904816,
      "learning_rate": 0.00019897636424676945,
      "loss": 0.2932,
      "step": 381
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10448284447193146,
      "learning_rate": 0.00019896998750797493,
      "loss": 0.3853,
      "step": 382
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08875229209661484,
      "learning_rate": 0.0001989635910716757,
      "loss": 0.3325,
      "step": 383
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.13356217741966248,
      "learning_rate": 0.00019895717493914486,
      "loss": 0.4927,
      "step": 384
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.1676647663116455,
      "learning_rate": 0.00019895073911165937,
      "loss": 0.3838,
      "step": 385
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10163288563489914,
      "learning_rate": 0.00019894428359050012,
      "loss": 0.413,
      "step": 386
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.12508608400821686,
      "learning_rate": 0.0001989378083769519,
      "loss": 0.364,
      "step": 387
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10204706341028214,
      "learning_rate": 0.00019893131347230346,
      "loss": 0.417,
      "step": 388
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11700171232223511,
      "learning_rate": 0.0001989247988778475,
      "loss": 0.3842,
      "step": 389
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11375465244054794,
      "learning_rate": 0.00019891826459488048,
      "loss": 0.379,
      "step": 390
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.1229005679488182,
      "learning_rate": 0.00019891171062470298,
      "loss": 0.3565,
      "step": 391
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08652960509061813,
      "learning_rate": 0.00019890513696861934,
      "loss": 0.432,
      "step": 392
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.09986025094985962,
      "learning_rate": 0.00019889854362793795,
      "loss": 0.4281,
      "step": 393
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.09669109433889389,
      "learning_rate": 0.00019889193060397095,
      "loss": 0.3229,
      "step": 394
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.12559691071510315,
      "learning_rate": 0.00019888529789803457,
      "loss": 0.5341,
      "step": 395
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.07803504914045334,
      "learning_rate": 0.00019887864551144892,
      "loss": 0.29,
      "step": 396
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08294523507356644,
      "learning_rate": 0.00019887197344553787,
      "loss": 0.3175,
      "step": 397
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.09497671574354172,
      "learning_rate": 0.00019886528170162944,
      "loss": 0.3917,
      "step": 398
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0867149606347084,
      "learning_rate": 0.0001988585702810554,
      "loss": 0.3441,
      "step": 399
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.09467849880456924,
      "learning_rate": 0.00019885183918515154,
      "loss": 0.3845,
      "step": 400
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10886886715888977,
      "learning_rate": 0.0001988450884152574,
      "loss": 0.3299,
      "step": 401
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.1268017739057541,
      "learning_rate": 0.00019883831797271672,
      "loss": 0.4049,
      "step": 402
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10160823911428452,
      "learning_rate": 0.00019883152785887687,
      "loss": 0.3267,
      "step": 403
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11001734435558319,
      "learning_rate": 0.00019882471807508928,
      "loss": 0.3998,
      "step": 404
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08757548779249191,
      "learning_rate": 0.00019881788862270927,
      "loss": 0.4039,
      "step": 405
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08836876600980759,
      "learning_rate": 0.00019881103950309607,
      "loss": 0.3433,
      "step": 406
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.08727502822875977,
      "learning_rate": 0.00019880417071761283,
      "loss": 0.3834,
      "step": 407
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0910300463438034,
      "learning_rate": 0.0001987972822676266,
      "loss": 0.3393,
      "step": 408
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09099513292312622,
      "learning_rate": 0.0001987903741545084,
      "loss": 0.338,
      "step": 409
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11541885137557983,
      "learning_rate": 0.00019878344637963306,
      "loss": 0.51,
      "step": 410
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09212399274110794,
      "learning_rate": 0.0001987764989443794,
      "loss": 0.3485,
      "step": 411
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09510719031095505,
      "learning_rate": 0.00019876953185013013,
      "loss": 0.3616,
      "step": 412
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09157680720090866,
      "learning_rate": 0.0001987625450982719,
      "loss": 0.2497,
      "step": 413
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.10528674721717834,
      "learning_rate": 0.00019875553869019518,
      "loss": 0.3426,
      "step": 414
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.13537070155143738,
      "learning_rate": 0.0001987485126272945,
      "loss": 0.453,
      "step": 415
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11189641058444977,
      "learning_rate": 0.0001987414669109682,
      "loss": 0.3936,
      "step": 416
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09544070065021515,
      "learning_rate": 0.00019873440154261854,
      "loss": 0.3214,
      "step": 417
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1211993396282196,
      "learning_rate": 0.00019872731652365171,
      "loss": 0.4392,
      "step": 418
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.10478182137012482,
      "learning_rate": 0.00019872021185547782,
      "loss": 0.4047,
      "step": 419
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1117057204246521,
      "learning_rate": 0.00019871308753951084,
      "loss": 0.4436,
      "step": 420
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.10746918618679047,
      "learning_rate": 0.00019870594357716874,
      "loss": 0.4386,
      "step": 421
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1561249941587448,
      "learning_rate": 0.00019869877996987333,
      "loss": 0.3569,
      "step": 422
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.08037222921848297,
      "learning_rate": 0.00019869159671905028,
      "loss": 0.3178,
      "step": 423
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11187276989221573,
      "learning_rate": 0.00019868439382612934,
      "loss": 0.42,
      "step": 424
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09588747471570969,
      "learning_rate": 0.000198677171292544,
      "loss": 0.3655,
      "step": 425
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.13749907910823822,
      "learning_rate": 0.00019866992911973176,
      "loss": 0.4606,
      "step": 426
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.10826413333415985,
      "learning_rate": 0.00019866266730913395,
      "loss": 0.3908,
      "step": 427
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11267325282096863,
      "learning_rate": 0.00019865538586219587,
      "loss": 0.3978,
      "step": 428
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11114669591188431,
      "learning_rate": 0.00019864808478036675,
      "loss": 0.4297,
      "step": 429
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.10317520797252655,
      "learning_rate": 0.00019864076406509966,
      "loss": 0.3849,
      "step": 430
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09507477283477783,
      "learning_rate": 0.00019863342371785158,
      "loss": 0.333,
      "step": 431
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.08632312715053558,
      "learning_rate": 0.00019862606374008348,
      "loss": 0.415,
      "step": 432
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09587030857801437,
      "learning_rate": 0.00019861868413326012,
      "loss": 0.3831,
      "step": 433
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1059689000248909,
      "learning_rate": 0.00019861128489885027,
      "loss": 0.4428,
      "step": 434
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.10249771177768707,
      "learning_rate": 0.00019860386603832652,
      "loss": 0.3743,
      "step": 435
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.10170050710439682,
      "learning_rate": 0.00019859642755316545,
      "loss": 0.3494,
      "step": 436
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09583687037229538,
      "learning_rate": 0.0001985889694448475,
      "loss": 0.4157,
      "step": 437
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.08898323774337769,
      "learning_rate": 0.00019858149171485698,
      "loss": 0.3181,
      "step": 438
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.09249511361122131,
      "learning_rate": 0.00019857399436468219,
      "loss": 0.3432,
      "step": 439
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1029491275548935,
      "learning_rate": 0.00019856647739581527,
      "loss": 0.4194,
      "step": 440
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.15463465452194214,
      "learning_rate": 0.0001985589408097523,
      "loss": 0.371,
      "step": 441
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1230495497584343,
      "learning_rate": 0.00019855138460799326,
      "loss": 0.4076,
      "step": 442
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.12309877574443817,
      "learning_rate": 0.00019854380879204194,
      "loss": 0.5087,
      "step": 443
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.10915207117795944,
      "learning_rate": 0.00019853621336340623,
      "loss": 0.4498,
      "step": 444
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.1247996836900711,
      "learning_rate": 0.00019852859832359773,
      "loss": 0.4483,
      "step": 445
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.1067807599902153,
      "learning_rate": 0.0001985209636741321,
      "loss": 0.3962,
      "step": 446
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09220202267169952,
      "learning_rate": 0.00019851330941652874,
      "loss": 0.318,
      "step": 447
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08623863756656647,
      "learning_rate": 0.00019850563555231108,
      "loss": 0.3669,
      "step": 448
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.11165007948875427,
      "learning_rate": 0.0001984979420830064,
      "loss": 0.3895,
      "step": 449
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08565020561218262,
      "learning_rate": 0.00019849022901014592,
      "loss": 0.3867,
      "step": 450
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08388953655958176,
      "learning_rate": 0.00019848249633526473,
      "loss": 0.4517,
      "step": 451
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.12594199180603027,
      "learning_rate": 0.0001984747440599018,
      "loss": 0.4333,
      "step": 452
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08772709965705872,
      "learning_rate": 0.00019846697218560002,
      "loss": 0.4003,
      "step": 453
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09449151903390884,
      "learning_rate": 0.00019845918071390625,
      "loss": 0.4213,
      "step": 454
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.1076209619641304,
      "learning_rate": 0.0001984513696463711,
      "loss": 0.3392,
      "step": 455
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09582774341106415,
      "learning_rate": 0.00019844353898454924,
      "loss": 0.4172,
      "step": 456
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09899074584245682,
      "learning_rate": 0.00019843568872999912,
      "loss": 0.3472,
      "step": 457
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.1428016722202301,
      "learning_rate": 0.00019842781888428318,
      "loss": 0.5822,
      "step": 458
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.10899960994720459,
      "learning_rate": 0.00019841992944896766,
      "loss": 0.4593,
      "step": 459
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.10157283395528793,
      "learning_rate": 0.00019841202042562283,
      "loss": 0.3937,
      "step": 460
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09676029533147812,
      "learning_rate": 0.00019840409181582272,
      "loss": 0.3607,
      "step": 461
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.1163087710738182,
      "learning_rate": 0.00019839614362114535,
      "loss": 0.4531,
      "step": 462
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08988036215305328,
      "learning_rate": 0.0001983881758431726,
      "loss": 0.3884,
      "step": 463
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.10803396254777908,
      "learning_rate": 0.00019838018848349027,
      "loss": 0.2758,
      "step": 464
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08418519049882889,
      "learning_rate": 0.00019837218154368803,
      "loss": 0.3417,
      "step": 465
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0687984973192215,
      "learning_rate": 0.00019836415502535947,
      "loss": 0.2758,
      "step": 466
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09888254851102829,
      "learning_rate": 0.00019835610893010206,
      "loss": 0.4339,
      "step": 467
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.11613290756940842,
      "learning_rate": 0.0001983480432595172,
      "loss": 0.4029,
      "step": 468
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08892324566841125,
      "learning_rate": 0.00019833995801521012,
      "loss": 0.3388,
      "step": 469
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.10077416151762009,
      "learning_rate": 0.00019833185319879,
      "loss": 0.3281,
      "step": 470
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09860429167747498,
      "learning_rate": 0.0001983237288118699,
      "loss": 0.2357,
      "step": 471
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.08878637105226517,
      "learning_rate": 0.0001983155848560668,
      "loss": 0.3361,
      "step": 472
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.16171225905418396,
      "learning_rate": 0.00019830742133300155,
      "loss": 0.36,
      "step": 473
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.12486022710800171,
      "learning_rate": 0.0001982992382442989,
      "loss": 0.4073,
      "step": 474
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.11174868792295456,
      "learning_rate": 0.00019829103559158742,
      "loss": 0.3439,
      "step": 475
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09971809387207031,
      "learning_rate": 0.0001982828133764997,
      "loss": 0.3945,
      "step": 476
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.12110459059476852,
      "learning_rate": 0.00019827457160067214,
      "loss": 0.4579,
      "step": 477
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.09518019109964371,
      "learning_rate": 0.00019826631026574515,
      "loss": 0.3774,
      "step": 478
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.16055099666118622,
      "learning_rate": 0.00019825802937336283,
      "loss": 0.3936,
      "step": 479
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.1320568025112152,
      "learning_rate": 0.00019824972892517332,
      "loss": 0.4497,
      "step": 480
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.09602561593055725,
      "learning_rate": 0.0001982414089228286,
      "loss": 0.3844,
      "step": 481
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.09331363439559937,
      "learning_rate": 0.00019823306936798463,
      "loss": 0.3412,
      "step": 482
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.07843272387981415,
      "learning_rate": 0.0001982247102623011,
      "loss": 0.2851,
      "step": 483
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.10327393561601639,
      "learning_rate": 0.00019821633160744178,
      "loss": 0.3873,
      "step": 484
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11281286925077438,
      "learning_rate": 0.00019820793340507415,
      "loss": 0.4794,
      "step": 485
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.10417264699935913,
      "learning_rate": 0.00019819951565686967,
      "loss": 0.3466,
      "step": 486
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.08934294432401657,
      "learning_rate": 0.0001981910783645037,
      "loss": 0.3474,
      "step": 487
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.14138512313365936,
      "learning_rate": 0.0001981826215296555,
      "loss": 0.4364,
      "step": 488
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11808652430772781,
      "learning_rate": 0.00019817414515400813,
      "loss": 0.4067,
      "step": 489
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.08738450706005096,
      "learning_rate": 0.00019816564923924866,
      "loss": 0.4422,
      "step": 490
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.09698313474655151,
      "learning_rate": 0.00019815713378706798,
      "loss": 0.3266,
      "step": 491
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.08582893013954163,
      "learning_rate": 0.00019814859879916082,
      "loss": 0.377,
      "step": 492
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.10401761531829834,
      "learning_rate": 0.00019814004427722595,
      "loss": 0.3953,
      "step": 493
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11821074783802032,
      "learning_rate": 0.00019813147022296583,
      "loss": 0.4368,
      "step": 494
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.07230410724878311,
      "learning_rate": 0.00019812287663808703,
      "loss": 0.3574,
      "step": 495
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0922190248966217,
      "learning_rate": 0.00019811426352429976,
      "loss": 0.3708,
      "step": 496
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.1074424609541893,
      "learning_rate": 0.00019810563088331834,
      "loss": 0.43,
      "step": 497
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.13482148945331573,
      "learning_rate": 0.00019809697871686085,
      "loss": 0.3839,
      "step": 498
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11824476718902588,
      "learning_rate": 0.00019808830702664927,
      "loss": 0.4407,
      "step": 499
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11249405890703201,
      "learning_rate": 0.00019807961581440951,
      "loss": 0.416,
      "step": 500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.09530352056026459,
      "learning_rate": 0.00019807090508187133,
      "loss": 0.3947,
      "step": 501
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11288241297006607,
      "learning_rate": 0.00019806217483076842,
      "loss": 0.4005,
      "step": 502
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11295107752084732,
      "learning_rate": 0.00019805342506283824,
      "loss": 0.4116,
      "step": 503
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.10657598078250885,
      "learning_rate": 0.00019804465577982224,
      "loss": 0.4007,
      "step": 504
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.08718837797641754,
      "learning_rate": 0.00019803586698346578,
      "loss": 0.3586,
      "step": 505
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.08448100835084915,
      "learning_rate": 0.000198027058675518,
      "loss": 0.3463,
      "step": 506
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.1339627504348755,
      "learning_rate": 0.000198018230857732,
      "loss": 0.2999,
      "step": 507
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.06890594959259033,
      "learning_rate": 0.0001980093835318647,
      "loss": 0.3339,
      "step": 508
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.12479562312364578,
      "learning_rate": 0.00019800051669967698,
      "loss": 0.4926,
      "step": 509
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11978426575660706,
      "learning_rate": 0.00019799163036293355,
      "loss": 0.324,
      "step": 510
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.10426720976829529,
      "learning_rate": 0.00019798272452340297,
      "loss": 0.3289,
      "step": 511
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.08039058744907379,
      "learning_rate": 0.0001979737991828578,
      "loss": 0.3206,
      "step": 512
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.08946893364191055,
      "learning_rate": 0.00019796485434307436,
      "loss": 0.3435,
      "step": 513
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.10609505325555801,
      "learning_rate": 0.0001979558900058329,
      "loss": 0.3994,
      "step": 514
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1096118837594986,
      "learning_rate": 0.00019794690617291755,
      "loss": 0.3664,
      "step": 515
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10894078761339188,
      "learning_rate": 0.00019793790284611634,
      "loss": 0.4515,
      "step": 516
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.11025471985340118,
      "learning_rate": 0.00019792888002722112,
      "loss": 0.4533,
      "step": 517
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.08525203168392181,
      "learning_rate": 0.00019791983771802766,
      "loss": 0.3874,
      "step": 518
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.12738806009292603,
      "learning_rate": 0.00019791077592033567,
      "loss": 0.4203,
      "step": 519
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10567853599786758,
      "learning_rate": 0.00019790169463594856,
      "loss": 0.4253,
      "step": 520
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10488972812891006,
      "learning_rate": 0.00019789259386667385,
      "loss": 0.3915,
      "step": 521
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10554889589548111,
      "learning_rate": 0.00019788347361432274,
      "loss": 0.4206,
      "step": 522
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10052156448364258,
      "learning_rate": 0.00019787433388071044,
      "loss": 0.3635,
      "step": 523
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.09344162791967392,
      "learning_rate": 0.00019786517466765594,
      "loss": 0.3392,
      "step": 524
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.11725690215826035,
      "learning_rate": 0.00019785599597698218,
      "loss": 0.3798,
      "step": 525
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10608165711164474,
      "learning_rate": 0.00019784679781051595,
      "loss": 0.329,
      "step": 526
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.08548622578382492,
      "learning_rate": 0.00019783758017008794,
      "loss": 0.3473,
      "step": 527
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.09508541226387024,
      "learning_rate": 0.00019782834305753262,
      "loss": 0.3771,
      "step": 528
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10078045725822449,
      "learning_rate": 0.00019781908647468845,
      "loss": 0.4234,
      "step": 529
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.11812779307365417,
      "learning_rate": 0.00019780981042339773,
      "loss": 0.3256,
      "step": 530
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10881491005420685,
      "learning_rate": 0.00019780051490550662,
      "loss": 0.4288,
      "step": 531
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.09163472056388855,
      "learning_rate": 0.00019779119992286516,
      "loss": 0.3821,
      "step": 532
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.11701755225658417,
      "learning_rate": 0.00019778186547732727,
      "loss": 0.3646,
      "step": 533
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.07917901128530502,
      "learning_rate": 0.0001977725115707507,
      "loss": 0.3467,
      "step": 534
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10601670295000076,
      "learning_rate": 0.00019776313820499714,
      "loss": 0.3657,
      "step": 535
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10753587633371353,
      "learning_rate": 0.00019775374538193218,
      "loss": 0.3819,
      "step": 536
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1104351356625557,
      "learning_rate": 0.00019774433310342513,
      "loss": 0.3426,
      "step": 537
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.12565070390701294,
      "learning_rate": 0.00019773490137134928,
      "loss": 0.4192,
      "step": 538
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.11710496246814728,
      "learning_rate": 0.00019772545018758187,
      "loss": 0.3783,
      "step": 539
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.22518177330493927,
      "learning_rate": 0.00019771597955400383,
      "loss": 0.5645,
      "step": 540
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10990975797176361,
      "learning_rate": 0.00019770648947250012,
      "loss": 0.33,
      "step": 541
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.08819267153739929,
      "learning_rate": 0.00019769697994495946,
      "loss": 0.3188,
      "step": 542
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.13298602402210236,
      "learning_rate": 0.00019768745097327448,
      "loss": 0.4785,
      "step": 543
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.12993133068084717,
      "learning_rate": 0.0001976779025593417,
      "loss": 0.3949,
      "step": 544
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10223372280597687,
      "learning_rate": 0.0001976683347050615,
      "loss": 0.3534,
      "step": 545
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10941433906555176,
      "learning_rate": 0.00019765874741233813,
      "loss": 0.3945,
      "step": 546
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.08374127745628357,
      "learning_rate": 0.00019764914068307965,
      "loss": 0.3081,
      "step": 547
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.08617345988750458,
      "learning_rate": 0.0001976395145191981,
      "loss": 0.4551,
      "step": 548
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.09899856895208359,
      "learning_rate": 0.0001976298689226093,
      "loss": 0.3219,
      "step": 549
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.10797976702451706,
      "learning_rate": 0.00019762020389523297,
      "loss": 0.4742,
      "step": 550
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.08750113099813461,
      "learning_rate": 0.0001976105194389927,
      "loss": 0.2851,
      "step": 551
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.12300409376621246,
      "learning_rate": 0.00019760081555581592,
      "loss": 0.3756,
      "step": 552
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10664983093738556,
      "learning_rate": 0.00019759109224763396,
      "loss": 0.3871,
      "step": 553
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10843437910079956,
      "learning_rate": 0.000197581349516382,
      "loss": 0.3761,
      "step": 554
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09524385631084442,
      "learning_rate": 0.00019757158736399908,
      "loss": 0.4201,
      "step": 555
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09794225543737411,
      "learning_rate": 0.0001975618057924281,
      "loss": 0.3768,
      "step": 556
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.0831029862165451,
      "learning_rate": 0.00019755200480361587,
      "loss": 0.3566,
      "step": 557
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.11607280373573303,
      "learning_rate": 0.000197542184399513,
      "loss": 0.52,
      "step": 558
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10905344784259796,
      "learning_rate": 0.00019753234458207405,
      "loss": 0.479,
      "step": 559
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10097672045230865,
      "learning_rate": 0.00019752248535325734,
      "loss": 0.3139,
      "step": 560
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.12459507584571838,
      "learning_rate": 0.00019751260671502512,
      "loss": 0.4267,
      "step": 561
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.07744017243385315,
      "learning_rate": 0.00019750270866934346,
      "loss": 0.273,
      "step": 562
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10134945064783096,
      "learning_rate": 0.00019749279121818235,
      "loss": 0.4191,
      "step": 563
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.0866188183426857,
      "learning_rate": 0.00019748285436351563,
      "loss": 0.3507,
      "step": 564
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09304583072662354,
      "learning_rate": 0.00019747289810732093,
      "loss": 0.3119,
      "step": 565
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09130743145942688,
      "learning_rate": 0.00019746292245157983,
      "loss": 0.3955,
      "step": 566
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09387427568435669,
      "learning_rate": 0.00019745292739827773,
      "loss": 0.338,
      "step": 567
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09255821257829666,
      "learning_rate": 0.00019744291294940386,
      "loss": 0.3865,
      "step": 568
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10866614431142807,
      "learning_rate": 0.0001974328791069514,
      "loss": 0.3779,
      "step": 569
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.11514551192522049,
      "learning_rate": 0.0001974228258729173,
      "loss": 0.395,
      "step": 570
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.08345800638198853,
      "learning_rate": 0.00019741275324930245,
      "loss": 0.3087,
      "step": 571
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10264978557825089,
      "learning_rate": 0.0001974026612381115,
      "loss": 0.4287,
      "step": 572
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09530199319124222,
      "learning_rate": 0.00019739254984135301,
      "loss": 0.2868,
      "step": 573
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.12264547497034073,
      "learning_rate": 0.00019738241906103947,
      "loss": 0.433,
      "step": 574
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09046722948551178,
      "learning_rate": 0.0001973722688991871,
      "loss": 0.305,
      "step": 575
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10233014076948166,
      "learning_rate": 0.00019736209935781605,
      "loss": 0.3973,
      "step": 576
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.11291208118200302,
      "learning_rate": 0.0001973519104389503,
      "loss": 0.4251,
      "step": 577
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.11859564483165741,
      "learning_rate": 0.00019734170214461772,
      "loss": 0.4058,
      "step": 578
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.10371719300746918,
      "learning_rate": 0.00019733147447685,
      "loss": 0.3928,
      "step": 579
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.1327846199274063,
      "learning_rate": 0.00019732122743768273,
      "loss": 0.4184,
      "step": 580
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.11571747809648514,
      "learning_rate": 0.0001973109610291553,
      "loss": 0.3979,
      "step": 581
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09426678717136383,
      "learning_rate": 0.00019730067525331103,
      "loss": 0.3842,
      "step": 582
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.11554880440235138,
      "learning_rate": 0.00019729037011219694,
      "loss": 0.3616,
      "step": 583
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.1085653081536293,
      "learning_rate": 0.00019728004560786412,
      "loss": 0.3547,
      "step": 584
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.09545484930276871,
      "learning_rate": 0.0001972697017423674,
      "loss": 0.3976,
      "step": 585
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11763188987970352,
      "learning_rate": 0.00019725933851776536,
      "loss": 0.371,
      "step": 586
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.0985000878572464,
      "learning_rate": 0.00019724895593612065,
      "loss": 0.4146,
      "step": 587
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11749427765607834,
      "learning_rate": 0.00019723855399949962,
      "loss": 0.431,
      "step": 588
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.12193160504102707,
      "learning_rate": 0.00019722813270997252,
      "loss": 0.5059,
      "step": 589
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10313156247138977,
      "learning_rate": 0.00019721769206961344,
      "loss": 0.3554,
      "step": 590
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11595458537340164,
      "learning_rate": 0.00019720723208050035,
      "loss": 0.3262,
      "step": 591
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.09223505854606628,
      "learning_rate": 0.00019719675274471504,
      "loss": 0.3578,
      "step": 592
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.09375710040330887,
      "learning_rate": 0.00019718625406434318,
      "loss": 0.3476,
      "step": 593
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.12452220171689987,
      "learning_rate": 0.00019717573604147422,
      "loss": 0.3795,
      "step": 594
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.15893308818340302,
      "learning_rate": 0.00019716519867820154,
      "loss": 0.404,
      "step": 595
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.09856238216161728,
      "learning_rate": 0.00019715464197662236,
      "loss": 0.341,
      "step": 596
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1318521350622177,
      "learning_rate": 0.00019714406593883768,
      "loss": 0.4059,
      "step": 597
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11788240820169449,
      "learning_rate": 0.00019713347056695243,
      "loss": 0.3833,
      "step": 598
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.08699845522642136,
      "learning_rate": 0.00019712285586307536,
      "loss": 0.3579,
      "step": 599
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10184416174888611,
      "learning_rate": 0.00019711222182931904,
      "loss": 0.371,
      "step": 600
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.09819208085536957,
      "learning_rate": 0.00019710156846779991,
      "loss": 0.394,
      "step": 601
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.08593802154064178,
      "learning_rate": 0.00019709089578063825,
      "loss": 0.3384,
      "step": 602
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10169418156147003,
      "learning_rate": 0.0001970802037699582,
      "loss": 0.3458,
      "step": 603
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.13424727320671082,
      "learning_rate": 0.0001970694924378878,
      "loss": 0.3401,
      "step": 604
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10899847000837326,
      "learning_rate": 0.00019705876178655878,
      "loss": 0.3379,
      "step": 605
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11053931713104248,
      "learning_rate": 0.0001970480118181068,
      "loss": 0.4239,
      "step": 606
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.07272762805223465,
      "learning_rate": 0.00019703724253467147,
      "loss": 0.2738,
      "step": 607
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11039625853300095,
      "learning_rate": 0.0001970264539383961,
      "loss": 0.4225,
      "step": 608
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10127898305654526,
      "learning_rate": 0.00019701564603142783,
      "loss": 0.3766,
      "step": 609
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11023557186126709,
      "learning_rate": 0.0001970048188159178,
      "loss": 0.3757,
      "step": 610
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11470445245504379,
      "learning_rate": 0.00019699397229402084,
      "loss": 0.3176,
      "step": 611
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10141060501337051,
      "learning_rate": 0.00019698310646789572,
      "loss": 0.3448,
      "step": 612
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11875201016664505,
      "learning_rate": 0.00019697222133970493,
      "loss": 0.3732,
      "step": 613
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10132826864719391,
      "learning_rate": 0.00019696131691161498,
      "loss": 0.3326,
      "step": 614
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10172886401414871,
      "learning_rate": 0.00019695039318579606,
      "loss": 0.3617,
      "step": 615
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10033527761697769,
      "learning_rate": 0.0001969394501644223,
      "loss": 0.3844,
      "step": 616
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.0921013280749321,
      "learning_rate": 0.00019692848784967163,
      "loss": 0.3334,
      "step": 617
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.08301391452550888,
      "learning_rate": 0.0001969175062437258,
      "loss": 0.3037,
      "step": 618
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.0916391909122467,
      "learning_rate": 0.00019690650534877045,
      "loss": 0.3968,
      "step": 619
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11549030244350433,
      "learning_rate": 0.00019689548516699503,
      "loss": 0.4293,
      "step": 620
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.10088717192411423,
      "learning_rate": 0.00019688444570059284,
      "loss": 0.3912,
      "step": 621
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11083554476499557,
      "learning_rate": 0.000196873386951761,
      "loss": 0.4018,
      "step": 622
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11852368712425232,
      "learning_rate": 0.00019686230892270042,
      "loss": 0.3265,
      "step": 623
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1223302036523819,
      "learning_rate": 0.00019685121161561598,
      "loss": 0.4374,
      "step": 624
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11376146227121353,
      "learning_rate": 0.00019684009503271633,
      "loss": 0.4025,
      "step": 625
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11244469881057739,
      "learning_rate": 0.0001968289591762139,
      "loss": 0.3388,
      "step": 626
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.08002810180187225,
      "learning_rate": 0.00019681780404832505,
      "loss": 0.3176,
      "step": 627
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.08970747888088226,
      "learning_rate": 0.00019680662965126987,
      "loss": 0.3198,
      "step": 628
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10559694468975067,
      "learning_rate": 0.00019679543598727242,
      "loss": 0.4146,
      "step": 629
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11107861250638962,
      "learning_rate": 0.00019678422305856045,
      "loss": 0.4056,
      "step": 630
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11996471136808395,
      "learning_rate": 0.00019677299086736562,
      "loss": 0.4005,
      "step": 631
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.09196864068508148,
      "learning_rate": 0.00019676173941592348,
      "loss": 0.3669,
      "step": 632
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.08419273793697357,
      "learning_rate": 0.00019675046870647328,
      "loss": 0.3803,
      "step": 633
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10210305452346802,
      "learning_rate": 0.00019673917874125823,
      "loss": 0.4141,
      "step": 634
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.0867868959903717,
      "learning_rate": 0.0001967278695225253,
      "loss": 0.434,
      "step": 635
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10443716496229172,
      "learning_rate": 0.00019671654105252523,
      "loss": 0.346,
      "step": 636
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.08522185683250427,
      "learning_rate": 0.00019670519333351278,
      "loss": 0.3371,
      "step": 637
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11503161489963531,
      "learning_rate": 0.00019669382636774638,
      "loss": 0.3319,
      "step": 638
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1029307171702385,
      "learning_rate": 0.00019668244015748836,
      "loss": 0.4055,
      "step": 639
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10125938802957535,
      "learning_rate": 0.00019667103470500484,
      "loss": 0.3924,
      "step": 640
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.11661965399980545,
      "learning_rate": 0.00019665961001256576,
      "loss": 0.2875,
      "step": 641
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10208573937416077,
      "learning_rate": 0.00019664816608244498,
      "loss": 0.3839,
      "step": 642
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.12559060752391815,
      "learning_rate": 0.00019663670291692012,
      "loss": 0.311,
      "step": 643
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10062957555055618,
      "learning_rate": 0.0001966252205182726,
      "loss": 0.3552,
      "step": 644
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.09699800610542297,
      "learning_rate": 0.00019661371888878774,
      "loss": 0.349,
      "step": 645
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.15923476219177246,
      "learning_rate": 0.00019660219803075465,
      "loss": 0.4274,
      "step": 646
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.08649509400129318,
      "learning_rate": 0.00019659065794646626,
      "loss": 0.3133,
      "step": 647
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10167738050222397,
      "learning_rate": 0.0001965790986382193,
      "loss": 0.3297,
      "step": 648
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.09528914093971252,
      "learning_rate": 0.0001965675201083144,
      "loss": 0.2862,
      "step": 649
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.0845816358923912,
      "learning_rate": 0.000196555922359056,
      "loss": 0.3556,
      "step": 650
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.08374188095331192,
      "learning_rate": 0.0001965443053927523,
      "loss": 0.3757,
      "step": 651
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.0988461822271347,
      "learning_rate": 0.00019653266921171542,
      "loss": 0.3328,
      "step": 652
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.09765876084566116,
      "learning_rate": 0.00019652101381826116,
      "loss": 0.3579,
      "step": 653
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.0963832288980484,
      "learning_rate": 0.0001965093392147093,
      "loss": 0.3561,
      "step": 654
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.07977364957332611,
      "learning_rate": 0.0001964976454033834,
      "loss": 0.2731,
      "step": 655
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.10906752198934555,
      "learning_rate": 0.00019648593238661072,
      "loss": 0.3378,
      "step": 656
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.11415678262710571,
      "learning_rate": 0.00019647420016672256,
      "loss": 0.3975,
      "step": 657
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09662333875894547,
      "learning_rate": 0.00019646244874605386,
      "loss": 0.3969,
      "step": 658
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.0965595617890358,
      "learning_rate": 0.00019645067812694346,
      "loss": 0.2849,
      "step": 659
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.07299981266260147,
      "learning_rate": 0.00019643888831173402,
      "loss": 0.2355,
      "step": 660
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.12484089285135269,
      "learning_rate": 0.00019642707930277203,
      "loss": 0.4702,
      "step": 661
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10026498138904572,
      "learning_rate": 0.00019641525110240772,
      "loss": 0.3973,
      "step": 662
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09886150807142258,
      "learning_rate": 0.00019640340371299524,
      "loss": 0.3739,
      "step": 663
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.12919799983501434,
      "learning_rate": 0.00019639153713689247,
      "loss": 0.4613,
      "step": 664
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.11502116918563843,
      "learning_rate": 0.0001963796513764612,
      "loss": 0.4392,
      "step": 665
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09886109083890915,
      "learning_rate": 0.000196367746434067,
      "loss": 0.4092,
      "step": 666
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10380009561777115,
      "learning_rate": 0.00019635582231207924,
      "loss": 0.3564,
      "step": 667
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.11556534469127655,
      "learning_rate": 0.0001963438790128711,
      "loss": 0.367,
      "step": 668
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10271771252155304,
      "learning_rate": 0.00019633191653881959,
      "loss": 0.3834,
      "step": 669
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10527357459068298,
      "learning_rate": 0.00019631993489230558,
      "loss": 0.373,
      "step": 670
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.08294166624546051,
      "learning_rate": 0.00019630793407571367,
      "loss": 0.3004,
      "step": 671
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10125511884689331,
      "learning_rate": 0.0001962959140914324,
      "loss": 0.4364,
      "step": 672
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.1598435789346695,
      "learning_rate": 0.000196283874941854,
      "loss": 0.3522,
      "step": 673
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09325038641691208,
      "learning_rate": 0.0001962718166293745,
      "loss": 0.3542,
      "step": 674
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09550395607948303,
      "learning_rate": 0.0001962597391563939,
      "loss": 0.3278,
      "step": 675
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10734409093856812,
      "learning_rate": 0.0001962476425253159,
      "loss": 0.4088,
      "step": 676
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09562677145004272,
      "learning_rate": 0.000196235526738548,
      "loss": 0.35,
      "step": 677
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.08829326927661896,
      "learning_rate": 0.00019622339179850156,
      "loss": 0.313,
      "step": 678
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10365092009305954,
      "learning_rate": 0.00019621123770759174,
      "loss": 0.4129,
      "step": 679
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09862200915813446,
      "learning_rate": 0.0001961990644682375,
      "loss": 0.3991,
      "step": 680
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.0901414304971695,
      "learning_rate": 0.00019618687208286165,
      "loss": 0.3236,
      "step": 681
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.07951302081346512,
      "learning_rate": 0.00019617466055389074,
      "loss": 0.2843,
      "step": 682
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.11129789054393768,
      "learning_rate": 0.0001961624298837552,
      "loss": 0.3493,
      "step": 683
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.1309485137462616,
      "learning_rate": 0.00019615018007488924,
      "loss": 0.459,
      "step": 684
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.11666776239871979,
      "learning_rate": 0.00019613791112973084,
      "loss": 0.4231,
      "step": 685
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.0844930112361908,
      "learning_rate": 0.00019612562305072184,
      "loss": 0.3561,
      "step": 686
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10527919232845306,
      "learning_rate": 0.0001961133158403079,
      "loss": 0.3723,
      "step": 687
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.11944253742694855,
      "learning_rate": 0.00019610098950093846,
      "loss": 0.4297,
      "step": 688
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.08602981269359589,
      "learning_rate": 0.00019608864403506676,
      "loss": 0.3106,
      "step": 689
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.09668497741222382,
      "learning_rate": 0.00019607627944514982,
      "loss": 0.3413,
      "step": 690
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.10426557064056396,
      "learning_rate": 0.0001960638957336486,
      "loss": 0.4217,
      "step": 691
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.12284012883901596,
      "learning_rate": 0.00019605149290302768,
      "loss": 0.4163,
      "step": 692
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.11151600629091263,
      "learning_rate": 0.00019603907095575558,
      "loss": 0.3858,
      "step": 693
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.0973806232213974,
      "learning_rate": 0.00019602662989430455,
      "loss": 0.4239,
      "step": 694
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1076257973909378,
      "learning_rate": 0.00019601416972115065,
      "loss": 0.4594,
      "step": 695
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12118745595216751,
      "learning_rate": 0.00019600169043877384,
      "loss": 0.3922,
      "step": 696
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.07292258739471436,
      "learning_rate": 0.00019598919204965776,
      "loss": 0.2811,
      "step": 697
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1028585359454155,
      "learning_rate": 0.0001959766745562899,
      "loss": 0.4084,
      "step": 698
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.10005497187376022,
      "learning_rate": 0.0001959641379611616,
      "loss": 0.4071,
      "step": 699
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.09591760486364365,
      "learning_rate": 0.00019595158226676788,
      "loss": 0.3266,
      "step": 700
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.10359055548906326,
      "learning_rate": 0.0001959390074756077,
      "loss": 0.4052,
      "step": 701
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.09023813903331757,
      "learning_rate": 0.00019592641359018372,
      "loss": 0.3595,
      "step": 702
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.08945615589618683,
      "learning_rate": 0.0001959138006130025,
      "loss": 0.2693,
      "step": 703
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.139026939868927,
      "learning_rate": 0.00019590116854657422,
      "loss": 0.4481,
      "step": 704
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.09341580420732498,
      "learning_rate": 0.00019588851739341313,
      "loss": 0.3828,
      "step": 705
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.09916677325963974,
      "learning_rate": 0.000195875847156037,
      "loss": 0.3507,
      "step": 706
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.08424654603004456,
      "learning_rate": 0.00019586315783696757,
      "loss": 0.3636,
      "step": 707
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.09007082134485245,
      "learning_rate": 0.00019585044943873036,
      "loss": 0.3477,
      "step": 708
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.0701676458120346,
      "learning_rate": 0.00019583772196385461,
      "loss": 0.3282,
      "step": 709
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.07798681408166885,
      "learning_rate": 0.00019582497541487345,
      "loss": 0.2788,
      "step": 710
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.10012896358966827,
      "learning_rate": 0.00019581220979432375,
      "loss": 0.4168,
      "step": 711
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12135683000087738,
      "learning_rate": 0.00019579942510474616,
      "loss": 0.4511,
      "step": 712
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12515845894813538,
      "learning_rate": 0.0001957866213486852,
      "loss": 0.4256,
      "step": 713
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.08569671958684921,
      "learning_rate": 0.00019577379852868908,
      "loss": 0.3797,
      "step": 714
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.10645588487386703,
      "learning_rate": 0.00019576095664730988,
      "loss": 0.3734,
      "step": 715
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12356103211641312,
      "learning_rate": 0.0001957480957071035,
      "loss": 0.3728,
      "step": 716
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.10133717954158783,
      "learning_rate": 0.00019573521571062956,
      "loss": 0.3694,
      "step": 717
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.11719013005495071,
      "learning_rate": 0.00019572231666045148,
      "loss": 0.352,
      "step": 718
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.07955628633499146,
      "learning_rate": 0.00019570939855913656,
      "loss": 0.2714,
      "step": 719
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.11792583018541336,
      "learning_rate": 0.0001956964614092557,
      "loss": 0.4127,
      "step": 720
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.14650271832942963,
      "learning_rate": 0.00019568350521338387,
      "loss": 0.3744,
      "step": 721
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1015305295586586,
      "learning_rate": 0.00019567052997409955,
      "loss": 0.3218,
      "step": 722
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12598496675491333,
      "learning_rate": 0.00019565753569398525,
      "loss": 0.4654,
      "step": 723
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.10432010143995285,
      "learning_rate": 0.00019564452237562705,
      "loss": 0.357,
      "step": 724
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.13851705193519592,
      "learning_rate": 0.00019563149002161496,
      "loss": 0.3623,
      "step": 725
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.09666288644075394,
      "learning_rate": 0.0001956184386345428,
      "loss": 0.3865,
      "step": 726
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.130121111869812,
      "learning_rate": 0.00019560536821700805,
      "loss": 0.3153,
      "step": 727
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.11062533408403397,
      "learning_rate": 0.0001955922787716121,
      "loss": 0.3193,
      "step": 728
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.09621205925941467,
      "learning_rate": 0.00019557917030096005,
      "loss": 0.3228,
      "step": 729
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.11984020471572876,
      "learning_rate": 0.0001955660428076608,
      "loss": 0.4686,
      "step": 730
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.11125119775533676,
      "learning_rate": 0.0001955528962943271,
      "loss": 0.4745,
      "step": 731
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.13182656466960907,
      "learning_rate": 0.00019553973076357544,
      "loss": 0.3781,
      "step": 732
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10101869702339172,
      "learning_rate": 0.000195526546218026,
      "loss": 0.3546,
      "step": 733
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.1329740732908249,
      "learning_rate": 0.0001955133426603029,
      "loss": 0.4314,
      "step": 734
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.11315185576677322,
      "learning_rate": 0.00019550012009303397,
      "loss": 0.4159,
      "step": 735
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10320740193128586,
      "learning_rate": 0.00019548687851885088,
      "loss": 0.3706,
      "step": 736
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.13159990310668945,
      "learning_rate": 0.00019547361794038895,
      "loss": 0.3744,
      "step": 737
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10667357593774796,
      "learning_rate": 0.0001954603383602874,
      "loss": 0.4043,
      "step": 738
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.09592663496732712,
      "learning_rate": 0.0001954470397811892,
      "loss": 0.287,
      "step": 739
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.08517304062843323,
      "learning_rate": 0.0001954337222057411,
      "loss": 0.3195,
      "step": 740
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.08369491994380951,
      "learning_rate": 0.00019542038563659367,
      "loss": 0.329,
      "step": 741
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.09108702093362808,
      "learning_rate": 0.00019540703007640112,
      "loss": 0.4303,
      "step": 742
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.0912264734506607,
      "learning_rate": 0.00019539365552782164,
      "loss": 0.2788,
      "step": 743
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.1115189865231514,
      "learning_rate": 0.0001953802619935171,
      "loss": 0.3717,
      "step": 744
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10449741780757904,
      "learning_rate": 0.0001953668494761531,
      "loss": 0.3951,
      "step": 745
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.16084539890289307,
      "learning_rate": 0.00019535341797839904,
      "loss": 0.4849,
      "step": 746
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.09885913133621216,
      "learning_rate": 0.0001953399675029282,
      "loss": 0.3203,
      "step": 747
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12421510368585587,
      "learning_rate": 0.00019532649805241748,
      "loss": 0.3076,
      "step": 748
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12678226828575134,
      "learning_rate": 0.00019531300962954772,
      "loss": 0.3427,
      "step": 749
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10469315201044083,
      "learning_rate": 0.00019529950223700344,
      "loss": 0.3744,
      "step": 750
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12123267352581024,
      "learning_rate": 0.00019528597587747292,
      "loss": 0.3253,
      "step": 751
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.09808235615491867,
      "learning_rate": 0.00019527243055364818,
      "loss": 0.3808,
      "step": 752
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.0950479656457901,
      "learning_rate": 0.00019525886626822522,
      "loss": 0.3218,
      "step": 753
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.08841115236282349,
      "learning_rate": 0.00019524528302390358,
      "loss": 0.3034,
      "step": 754
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10480961948633194,
      "learning_rate": 0.0001952316808233867,
      "loss": 0.3518,
      "step": 755
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.11889994889497757,
      "learning_rate": 0.00019521805966938173,
      "loss": 0.3803,
      "step": 756
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.11202853918075562,
      "learning_rate": 0.00019520441956459963,
      "loss": 0.4242,
      "step": 757
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12192326784133911,
      "learning_rate": 0.00019519076051175517,
      "loss": 0.4553,
      "step": 758
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.10892631113529205,
      "learning_rate": 0.00019517708251356677,
      "loss": 0.378,
      "step": 759
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.124603770673275,
      "learning_rate": 0.0001951633855727567,
      "loss": 0.4252,
      "step": 760
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.09321776032447815,
      "learning_rate": 0.00019514966969205107,
      "loss": 0.3035,
      "step": 761
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.11070288717746735,
      "learning_rate": 0.0001951359348741796,
      "loss": 0.4394,
      "step": 762
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.0975625291466713,
      "learning_rate": 0.0001951221811218759,
      "loss": 0.3504,
      "step": 763
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.09450981765985489,
      "learning_rate": 0.0001951084084378773,
      "loss": 0.304,
      "step": 764
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.07574164122343063,
      "learning_rate": 0.00019509461682492494,
      "loss": 0.2783,
      "step": 765
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11075960844755173,
      "learning_rate": 0.0001950808062857637,
      "loss": 0.3375,
      "step": 766
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.08881200104951859,
      "learning_rate": 0.00019506697682314213,
      "loss": 0.3725,
      "step": 767
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11601629108190536,
      "learning_rate": 0.0001950531284398127,
      "loss": 0.39,
      "step": 768
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10279843211174011,
      "learning_rate": 0.00019503926113853166,
      "loss": 0.3566,
      "step": 769
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10266716778278351,
      "learning_rate": 0.00019502537492205882,
      "loss": 0.3344,
      "step": 770
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.09591427445411682,
      "learning_rate": 0.00019501146979315797,
      "loss": 0.3555,
      "step": 771
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10897660255432129,
      "learning_rate": 0.00019499754575459655,
      "loss": 0.3901,
      "step": 772
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.13292832672595978,
      "learning_rate": 0.00019498360280914575,
      "loss": 0.4331,
      "step": 773
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11343179643154144,
      "learning_rate": 0.00019496964095958065,
      "loss": 0.4148,
      "step": 774
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11800427734851837,
      "learning_rate": 0.00019495566020867998,
      "loss": 0.383,
      "step": 775
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1104838103055954,
      "learning_rate": 0.00019494166055922626,
      "loss": 0.3766,
      "step": 776
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1190105602145195,
      "learning_rate": 0.00019492764201400572,
      "loss": 0.3783,
      "step": 777
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.12394311279058456,
      "learning_rate": 0.00019491360457580842,
      "loss": 0.4264,
      "step": 778
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.12891089916229248,
      "learning_rate": 0.00019489954824742823,
      "loss": 0.3568,
      "step": 779
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10397094488143921,
      "learning_rate": 0.00019488547303166262,
      "loss": 0.3859,
      "step": 780
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11728866398334503,
      "learning_rate": 0.00019487137893131298,
      "loss": 0.4493,
      "step": 781
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.08626027405261993,
      "learning_rate": 0.00019485726594918435,
      "loss": 0.2977,
      "step": 782
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10005185008049011,
      "learning_rate": 0.0001948431340880856,
      "loss": 0.4146,
      "step": 783
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10114946961402893,
      "learning_rate": 0.00019482898335082926,
      "loss": 0.3131,
      "step": 784
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.09639478474855423,
      "learning_rate": 0.00019481481374023174,
      "loss": 0.3131,
      "step": 785
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11049643158912659,
      "learning_rate": 0.0001948006252591131,
      "loss": 0.3946,
      "step": 786
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.09200090914964676,
      "learning_rate": 0.00019478641791029728,
      "loss": 0.3888,
      "step": 787
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.09609699249267578,
      "learning_rate": 0.00019477219169661183,
      "loss": 0.301,
      "step": 788
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10375883430242538,
      "learning_rate": 0.00019475794662088817,
      "loss": 0.3518,
      "step": 789
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.19359707832336426,
      "learning_rate": 0.00019474368268596135,
      "loss": 0.3535,
      "step": 790
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1037839949131012,
      "learning_rate": 0.00019472939989467034,
      "loss": 0.3439,
      "step": 791
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11572454124689102,
      "learning_rate": 0.0001947150982498577,
      "loss": 0.4129,
      "step": 792
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.06713324040174484,
      "learning_rate": 0.00019470077775436985,
      "loss": 0.2314,
      "step": 793
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1484646201133728,
      "learning_rate": 0.00019468643841105693,
      "loss": 0.4054,
      "step": 794
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1079038456082344,
      "learning_rate": 0.00019467208022277282,
      "loss": 0.3653,
      "step": 795
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.10231542587280273,
      "learning_rate": 0.0001946577031923752,
      "loss": 0.3044,
      "step": 796
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.12584049999713898,
      "learning_rate": 0.0001946433073227254,
      "loss": 0.3628,
      "step": 797
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.09183375537395477,
      "learning_rate": 0.00019462889261668854,
      "loss": 0.3733,
      "step": 798
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.2204185277223587,
      "learning_rate": 0.00019461445907713358,
      "loss": 0.3641,
      "step": 799
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.08965236693620682,
      "learning_rate": 0.00019460000670693312,
      "loss": 0.3377,
      "step": 800
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.09705545008182526,
      "learning_rate": 0.00019458553550896356,
      "loss": 0.2544,
      "step": 801
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11355068534612656,
      "learning_rate": 0.000194571045486105,
      "loss": 0.3922,
      "step": 802
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11771644651889801,
      "learning_rate": 0.00019455653664124132,
      "loss": 0.384,
      "step": 803
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.12406542897224426,
      "learning_rate": 0.00019454200897726015,
      "loss": 0.4889,
      "step": 804
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.09754463285207748,
      "learning_rate": 0.0001945274624970529,
      "loss": 0.3313,
      "step": 805
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.08408816903829575,
      "learning_rate": 0.00019451289720351462,
      "loss": 0.326,
      "step": 806
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11240428686141968,
      "learning_rate": 0.0001944983130995442,
      "loss": 0.3468,
      "step": 807
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10473596304655075,
      "learning_rate": 0.00019448371018804427,
      "loss": 0.3199,
      "step": 808
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10143112391233444,
      "learning_rate": 0.0001944690884719211,
      "loss": 0.3303,
      "step": 809
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.07209895551204681,
      "learning_rate": 0.00019445444795408484,
      "loss": 0.2648,
      "step": 810
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.12289784848690033,
      "learning_rate": 0.0001944397886374493,
      "loss": 0.3966,
      "step": 811
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10487329959869385,
      "learning_rate": 0.00019442511052493203,
      "loss": 0.3718,
      "step": 812
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.09089221805334091,
      "learning_rate": 0.0001944104136194544,
      "loss": 0.3201,
      "step": 813
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.09483800828456879,
      "learning_rate": 0.00019439569792394142,
      "loss": 0.2998,
      "step": 814
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10395622998476028,
      "learning_rate": 0.00019438096344132189,
      "loss": 0.3443,
      "step": 815
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11045919358730316,
      "learning_rate": 0.00019436621017452832,
      "loss": 0.4256,
      "step": 816
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11909452825784683,
      "learning_rate": 0.000194351438126497,
      "loss": 0.4222,
      "step": 817
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.14866894483566284,
      "learning_rate": 0.00019433664730016792,
      "loss": 0.3153,
      "step": 818
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10450237989425659,
      "learning_rate": 0.00019432183769848484,
      "loss": 0.4381,
      "step": 819
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.14223910868167877,
      "learning_rate": 0.00019430700932439527,
      "loss": 0.4098,
      "step": 820
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10895819216966629,
      "learning_rate": 0.00019429216218085036,
      "loss": 0.4183,
      "step": 821
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11271578073501587,
      "learning_rate": 0.00019427729627080514,
      "loss": 0.354,
      "step": 822
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.14386679232120514,
      "learning_rate": 0.00019426241159721823,
      "loss": 0.3296,
      "step": 823
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10287889838218689,
      "learning_rate": 0.0001942475081630521,
      "loss": 0.3907,
      "step": 824
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11758499592542648,
      "learning_rate": 0.00019423258597127288,
      "loss": 0.3944,
      "step": 825
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.08611203730106354,
      "learning_rate": 0.00019421764502485048,
      "loss": 0.2683,
      "step": 826
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11593315005302429,
      "learning_rate": 0.00019420268532675849,
      "loss": 0.3727,
      "step": 827
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.09080441296100616,
      "learning_rate": 0.00019418770687997428,
      "loss": 0.353,
      "step": 828
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11393765360116959,
      "learning_rate": 0.00019417270968747895,
      "loss": 0.2995,
      "step": 829
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.10259261727333069,
      "learning_rate": 0.0001941576937522573,
      "loss": 0.3773,
      "step": 830
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1022731363773346,
      "learning_rate": 0.0001941426590772979,
      "loss": 0.3847,
      "step": 831
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1344035565853119,
      "learning_rate": 0.00019412760566559303,
      "loss": 0.4405,
      "step": 832
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.09962530434131622,
      "learning_rate": 0.00019411253352013863,
      "loss": 0.334,
      "step": 833
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.09265001863241196,
      "learning_rate": 0.0001940974426439345,
      "loss": 0.3294,
      "step": 834
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1338740587234497,
      "learning_rate": 0.0001940823330399841,
      "loss": 0.4404,
      "step": 835
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10050357133150101,
      "learning_rate": 0.00019406720471129457,
      "loss": 0.3937,
      "step": 836
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10411201417446136,
      "learning_rate": 0.0001940520576608769,
      "loss": 0.3304,
      "step": 837
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.09281148761510849,
      "learning_rate": 0.00019403689189174565,
      "loss": 0.3603,
      "step": 838
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10015343874692917,
      "learning_rate": 0.00019402170740691926,
      "loss": 0.3374,
      "step": 839
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10707181692123413,
      "learning_rate": 0.00019400650420941978,
      "loss": 0.3455,
      "step": 840
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.15498140454292297,
      "learning_rate": 0.00019399128230227302,
      "loss": 0.3275,
      "step": 841
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10363481193780899,
      "learning_rate": 0.00019397604168850855,
      "loss": 0.3681,
      "step": 842
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.08174275606870651,
      "learning_rate": 0.0001939607823711596,
      "loss": 0.2798,
      "step": 843
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.09913969784975052,
      "learning_rate": 0.0001939455043532632,
      "loss": 0.2988,
      "step": 844
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10096260905265808,
      "learning_rate": 0.00019393020763786004,
      "loss": 0.3701,
      "step": 845
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.09218747913837433,
      "learning_rate": 0.00019391489222799453,
      "loss": 0.3241,
      "step": 846
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.08934778720140457,
      "learning_rate": 0.00019389955812671483,
      "loss": 0.2616,
      "step": 847
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.08639597147703171,
      "learning_rate": 0.00019388420533707283,
      "loss": 0.2833,
      "step": 848
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.11474284529685974,
      "learning_rate": 0.00019386883386212408,
      "loss": 0.3978,
      "step": 849
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.0869751125574112,
      "learning_rate": 0.00019385344370492796,
      "loss": 0.3455,
      "step": 850
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.13170698285102844,
      "learning_rate": 0.0001938380348685474,
      "loss": 0.3176,
      "step": 851
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.08626551926136017,
      "learning_rate": 0.00019382260735604923,
      "loss": 0.2987,
      "step": 852
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10174651443958282,
      "learning_rate": 0.00019380716117050386,
      "loss": 0.3574,
      "step": 853
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1089678630232811,
      "learning_rate": 0.00019379169631498545,
      "loss": 0.381,
      "step": 854
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10506238043308258,
      "learning_rate": 0.00019377621279257197,
      "loss": 0.2891,
      "step": 855
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.14392098784446716,
      "learning_rate": 0.00019376071060634494,
      "loss": 0.3955,
      "step": 856
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10536745190620422,
      "learning_rate": 0.00019374518975938978,
      "loss": 0.4923,
      "step": 857
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.0962921753525734,
      "learning_rate": 0.00019372965025479544,
      "loss": 0.3105,
      "step": 858
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.0953357145190239,
      "learning_rate": 0.0001937140920956547,
      "loss": 0.3156,
      "step": 859
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.08932777494192123,
      "learning_rate": 0.000193698515285064,
      "loss": 0.3779,
      "step": 860
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.09923480451107025,
      "learning_rate": 0.00019368291982612361,
      "loss": 0.3385,
      "step": 861
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.098798967897892,
      "learning_rate": 0.0001936673057219373,
      "loss": 0.3336,
      "step": 862
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.13986341655254364,
      "learning_rate": 0.00019365167297561274,
      "loss": 0.4156,
      "step": 863
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.09076006710529327,
      "learning_rate": 0.0001936360215902612,
      "loss": 0.324,
      "step": 864
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.12367463111877441,
      "learning_rate": 0.00019362035156899774,
      "loss": 0.3455,
      "step": 865
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.07847215235233307,
      "learning_rate": 0.000193604662914941,
      "loss": 0.2898,
      "step": 866
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10358651727437973,
      "learning_rate": 0.0001935889556312135,
      "loss": 0.3294,
      "step": 867
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.10992676764726639,
      "learning_rate": 0.00019357322972094138,
      "loss": 0.3982,
      "step": 868
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.0826774463057518,
      "learning_rate": 0.00019355748518725446,
      "loss": 0.2546,
      "step": 869
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.13685187697410583,
      "learning_rate": 0.00019354172203328628,
      "loss": 0.3788,
      "step": 870
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10621719062328339,
      "learning_rate": 0.0001935259402621741,
      "loss": 0.3565,
      "step": 871
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10612137615680695,
      "learning_rate": 0.00019351013987705897,
      "loss": 0.3774,
      "step": 872
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.09158021956682205,
      "learning_rate": 0.00019349432088108548,
      "loss": 0.3412,
      "step": 873
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.11634412407875061,
      "learning_rate": 0.000193478483277402,
      "loss": 0.3825,
      "step": 874
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10847629606723785,
      "learning_rate": 0.00019346262706916066,
      "loss": 0.3802,
      "step": 875
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.09775334596633911,
      "learning_rate": 0.00019344675225951724,
      "loss": 0.3611,
      "step": 876
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.12557385861873627,
      "learning_rate": 0.0001934308588516312,
      "loss": 0.4315,
      "step": 877
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.12277652323246002,
      "learning_rate": 0.00019341494684866573,
      "loss": 0.3695,
      "step": 878
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10782236605882645,
      "learning_rate": 0.0001933990162537877,
      "loss": 0.3931,
      "step": 879
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.16052930057048798,
      "learning_rate": 0.00019338306707016774,
      "loss": 0.3539,
      "step": 880
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.08722315728664398,
      "learning_rate": 0.00019336709930098007,
      "loss": 0.2958,
      "step": 881
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10565502196550369,
      "learning_rate": 0.00019335111294940273,
      "loss": 0.343,
      "step": 882
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.0996399000287056,
      "learning_rate": 0.00019333510801861743,
      "loss": 0.4273,
      "step": 883
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.128510981798172,
      "learning_rate": 0.00019331908451180948,
      "loss": 0.4096,
      "step": 884
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10821753740310669,
      "learning_rate": 0.00019330304243216802,
      "loss": 0.3904,
      "step": 885
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.08895634859800339,
      "learning_rate": 0.0001932869817828858,
      "loss": 0.3048,
      "step": 886
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.0874755010008812,
      "learning_rate": 0.00019327090256715925,
      "loss": 0.2902,
      "step": 887
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.09484640508890152,
      "learning_rate": 0.00019325480478818858,
      "loss": 0.405,
      "step": 888
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.09253133088350296,
      "learning_rate": 0.00019323868844917764,
      "loss": 0.3415,
      "step": 889
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10450859367847443,
      "learning_rate": 0.00019322255355333403,
      "loss": 0.4074,
      "step": 890
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.12705475091934204,
      "learning_rate": 0.00019320640010386895,
      "loss": 0.3778,
      "step": 891
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10696373134851456,
      "learning_rate": 0.00019319022810399735,
      "loss": 0.4049,
      "step": 892
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10103242844343185,
      "learning_rate": 0.00019317403755693784,
      "loss": 0.3622,
      "step": 893
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.12810614705085754,
      "learning_rate": 0.0001931578284659128,
      "loss": 0.5244,
      "step": 894
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.08568954467773438,
      "learning_rate": 0.0001931416008341482,
      "loss": 0.3162,
      "step": 895
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1341061145067215,
      "learning_rate": 0.00019312535466487374,
      "loss": 0.3539,
      "step": 896
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.09534390270709991,
      "learning_rate": 0.00019310908996132285,
      "loss": 0.3405,
      "step": 897
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.0825352817773819,
      "learning_rate": 0.00019309280672673258,
      "loss": 0.2956,
      "step": 898
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.10494589060544968,
      "learning_rate": 0.0001930765049643437,
      "loss": 0.3733,
      "step": 899
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.12028059363365173,
      "learning_rate": 0.00019306018467740073,
      "loss": 0.4168,
      "step": 900
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.11426356434822083,
      "learning_rate": 0.00019304384586915174,
      "loss": 0.3863,
      "step": 901
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1044556275010109,
      "learning_rate": 0.0001930274885428486,
      "loss": 0.3484,
      "step": 902
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.11555082350969315,
      "learning_rate": 0.00019301111270174682,
      "loss": 0.3932,
      "step": 903
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.11482181400060654,
      "learning_rate": 0.0001929947183491056,
      "loss": 0.4287,
      "step": 904
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1057850793004036,
      "learning_rate": 0.00019297830548818781,
      "loss": 0.3871,
      "step": 905
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.09855403006076813,
      "learning_rate": 0.00019296187412226007,
      "loss": 0.3645,
      "step": 906
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.12183522433042526,
      "learning_rate": 0.0001929454242545926,
      "loss": 0.3536,
      "step": 907
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.11564546078443527,
      "learning_rate": 0.00019292895588845932,
      "loss": 0.3905,
      "step": 908
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.0983731746673584,
      "learning_rate": 0.00019291246902713785,
      "loss": 0.3859,
      "step": 909
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.1255878210067749,
      "learning_rate": 0.00019289596367390953,
      "loss": 0.329,
      "step": 910
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.0933590978384018,
      "learning_rate": 0.0001928794398320593,
      "loss": 0.3379,
      "step": 911
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.07652302831411362,
      "learning_rate": 0.0001928628975048758,
      "loss": 0.3201,
      "step": 912
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.12149269133806229,
      "learning_rate": 0.0001928463366956514,
      "loss": 0.4744,
      "step": 913
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.09641040861606598,
      "learning_rate": 0.00019282975740768214,
      "loss": 0.3509,
      "step": 914
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.09911692887544632,
      "learning_rate": 0.00019281315964426768,
      "loss": 0.3773,
      "step": 915
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.10117961466312408,
      "learning_rate": 0.00019279654340871138,
      "loss": 0.373,
      "step": 916
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.10799884796142578,
      "learning_rate": 0.00019277990870432033,
      "loss": 0.3952,
      "step": 917
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.10745039582252502,
      "learning_rate": 0.0001927632555344052,
      "loss": 0.3457,
      "step": 918
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.07573852688074112,
      "learning_rate": 0.0001927465839022804,
      "loss": 0.2045,
      "step": 919
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.08811929821968079,
      "learning_rate": 0.00019272989381126406,
      "loss": 0.33,
      "step": 920
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.12557940185070038,
      "learning_rate": 0.00019271318526467782,
      "loss": 0.3908,
      "step": 921
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.10929650813341141,
      "learning_rate": 0.00019269645826584718,
      "loss": 0.404,
      "step": 922
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.10250066220760345,
      "learning_rate": 0.00019267971281810122,
      "loss": 0.3663,
      "step": 923
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.0842413678765297,
      "learning_rate": 0.0001926629489247727,
      "loss": 0.2578,
      "step": 924
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.11643527448177338,
      "learning_rate": 0.00019264616658919804,
      "loss": 0.3743,
      "step": 925
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.08752254396677017,
      "learning_rate": 0.00019262936581471735,
      "loss": 0.3366,
      "step": 926
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.09595654904842377,
      "learning_rate": 0.00019261254660467438,
      "loss": 0.3485,
      "step": 927
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.12346987426280975,
      "learning_rate": 0.00019259570896241663,
      "loss": 0.3949,
      "step": 928
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.14229393005371094,
      "learning_rate": 0.00019257885289129516,
      "loss": 0.5116,
      "step": 929
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.07497816532850266,
      "learning_rate": 0.0001925619783946648,
      "loss": 0.247,
      "step": 930
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.1076153889298439,
      "learning_rate": 0.00019254508547588393,
      "loss": 0.3589,
      "step": 931
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.16282589733600616,
      "learning_rate": 0.00019252817413831474,
      "loss": 0.3274,
      "step": 932
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.08816199749708176,
      "learning_rate": 0.000192511244385323,
      "loss": 0.3234,
      "step": 933
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.1224692091345787,
      "learning_rate": 0.00019249429622027807,
      "loss": 0.4028,
      "step": 934
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.13018718361854553,
      "learning_rate": 0.00019247732964655314,
      "loss": 0.3724,
      "step": 935
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.09273155778646469,
      "learning_rate": 0.00019246034466752497,
      "loss": 0.3885,
      "step": 936
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.11509048193693161,
      "learning_rate": 0.00019244334128657394,
      "loss": 0.3895,
      "step": 937
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.11129938811063766,
      "learning_rate": 0.00019242631950708425,
      "loss": 0.3801,
      "step": 938
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.14237521588802338,
      "learning_rate": 0.0001924092793324436,
      "loss": 0.2851,
      "step": 939
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.0874367281794548,
      "learning_rate": 0.00019239222076604338,
      "loss": 0.2968,
      "step": 940
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.09489580243825912,
      "learning_rate": 0.00019237514381127872,
      "loss": 0.2653,
      "step": 941
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.20595955848693848,
      "learning_rate": 0.00019235804847154837,
      "loss": 0.3335,
      "step": 942
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10495775192975998,
      "learning_rate": 0.00019234093475025468,
      "loss": 0.4417,
      "step": 943
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.11132175475358963,
      "learning_rate": 0.00019232380265080375,
      "loss": 0.4749,
      "step": 944
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10491162538528442,
      "learning_rate": 0.00019230665217660528,
      "loss": 0.4248,
      "step": 945
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.08477230370044708,
      "learning_rate": 0.00019228948333107265,
      "loss": 0.3375,
      "step": 946
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10698311030864716,
      "learning_rate": 0.00019227229611762289,
      "loss": 0.4055,
      "step": 947
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.09287930279970169,
      "learning_rate": 0.00019225509053967668,
      "loss": 0.3504,
      "step": 948
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.09634559601545334,
      "learning_rate": 0.00019223786660065836,
      "loss": 0.3,
      "step": 949
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10366722196340561,
      "learning_rate": 0.00019222062430399595,
      "loss": 0.406,
      "step": 950
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1351160854101181,
      "learning_rate": 0.00019220336365312107,
      "loss": 0.4422,
      "step": 951
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10576096922159195,
      "learning_rate": 0.000192186084651469,
      "loss": 0.3923,
      "step": 952
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.12591487169265747,
      "learning_rate": 0.00019216878730247877,
      "loss": 0.3722,
      "step": 953
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.09682486951351166,
      "learning_rate": 0.0001921514716095929,
      "loss": 0.31,
      "step": 954
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10374541580677032,
      "learning_rate": 0.0001921341375762577,
      "loss": 0.3392,
      "step": 955
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.11192578077316284,
      "learning_rate": 0.00019211678520592306,
      "loss": 0.4501,
      "step": 956
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10123610496520996,
      "learning_rate": 0.00019209941450204254,
      "loss": 0.3493,
      "step": 957
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.12819920480251312,
      "learning_rate": 0.00019208202546807334,
      "loss": 0.3822,
      "step": 958
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.08528844267129898,
      "learning_rate": 0.00019206461810747632,
      "loss": 0.3812,
      "step": 959
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1013895645737648,
      "learning_rate": 0.00019204719242371597,
      "loss": 0.3507,
      "step": 960
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.11038652062416077,
      "learning_rate": 0.00019202974842026045,
      "loss": 0.3304,
      "step": 961
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.13772208988666534,
      "learning_rate": 0.00019201228610058152,
      "loss": 0.3854,
      "step": 962
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10728990286588669,
      "learning_rate": 0.00019199480546815468,
      "loss": 0.4205,
      "step": 963
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.11505201458930969,
      "learning_rate": 0.00019197730652645897,
      "loss": 0.3858,
      "step": 964
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10237988084554672,
      "learning_rate": 0.00019195978927897712,
      "loss": 0.3345,
      "step": 965
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.13973066210746765,
      "learning_rate": 0.0001919422537291955,
      "loss": 0.503,
      "step": 966
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1131230816245079,
      "learning_rate": 0.00019192469988060413,
      "loss": 0.4109,
      "step": 967
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.08566392213106155,
      "learning_rate": 0.00019190712773669666,
      "loss": 0.2924,
      "step": 968
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10351484268903732,
      "learning_rate": 0.00019188953730097042,
      "loss": 0.3357,
      "step": 969
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.0858227089047432,
      "learning_rate": 0.0001918719285769263,
      "loss": 0.2838,
      "step": 970
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10008786618709564,
      "learning_rate": 0.0001918543015680689,
      "loss": 0.3618,
      "step": 971
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.10882529616355896,
      "learning_rate": 0.00019183665627790642,
      "loss": 0.4583,
      "step": 972
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.09251123666763306,
      "learning_rate": 0.0001918189927099507,
      "loss": 0.3319,
      "step": 973
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.09831300377845764,
      "learning_rate": 0.0001918013108677173,
      "loss": 0.4447,
      "step": 974
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.085174560546875,
      "learning_rate": 0.0001917836107547253,
      "loss": 0.2737,
      "step": 975
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1347580850124359,
      "learning_rate": 0.00019176589237449748,
      "loss": 0.359,
      "step": 976
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0957188531756401,
      "learning_rate": 0.00019174815573056022,
      "loss": 0.4474,
      "step": 977
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12532447278499603,
      "learning_rate": 0.00019173040082644355,
      "loss": 0.3674,
      "step": 978
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.11846289783716202,
      "learning_rate": 0.0001917126276656812,
      "loss": 0.3535,
      "step": 979
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.09384065121412277,
      "learning_rate": 0.0001916948362518104,
      "loss": 0.3014,
      "step": 980
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.08546987920999527,
      "learning_rate": 0.00019167702658837214,
      "loss": 0.2996,
      "step": 981
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.088336281478405,
      "learning_rate": 0.00019165919867891095,
      "loss": 0.2855,
      "step": 982
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.13962426781654358,
      "learning_rate": 0.00019164135252697508,
      "loss": 0.4003,
      "step": 983
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.11194971948862076,
      "learning_rate": 0.0001916234881361163,
      "loss": 0.3326,
      "step": 984
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.10831250250339508,
      "learning_rate": 0.00019160560550989013,
      "loss": 0.4008,
      "step": 985
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.10773955285549164,
      "learning_rate": 0.00019158770465185562,
      "loss": 0.3907,
      "step": 986
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12509289383888245,
      "learning_rate": 0.0001915697855655755,
      "loss": 0.4713,
      "step": 987
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1103108823299408,
      "learning_rate": 0.0001915518482546161,
      "loss": 0.3555,
      "step": 988
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.10095924884080887,
      "learning_rate": 0.0001915338927225474,
      "loss": 0.3961,
      "step": 989
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.10800380259752274,
      "learning_rate": 0.00019151591897294306,
      "loss": 0.3818,
      "step": 990
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0973094031214714,
      "learning_rate": 0.00019149792700938023,
      "loss": 0.3271,
      "step": 991
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.06728720664978027,
      "learning_rate": 0.0001914799168354398,
      "loss": 0.2467,
      "step": 992
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.08619693666696548,
      "learning_rate": 0.0001914618884547062,
      "loss": 0.291,
      "step": 993
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12844477593898773,
      "learning_rate": 0.0001914438418707676,
      "loss": 0.3733,
      "step": 994
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0898325964808464,
      "learning_rate": 0.00019142577708721565,
      "loss": 0.3355,
      "step": 995
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0792539194226265,
      "learning_rate": 0.00019140769410764576,
      "loss": 0.2823,
      "step": 996
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0850394144654274,
      "learning_rate": 0.00019138959293565685,
      "loss": 0.2798,
      "step": 997
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.10697845369577408,
      "learning_rate": 0.00019137147357485153,
      "loss": 0.4131,
      "step": 998
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.09594596177339554,
      "learning_rate": 0.00019135333602883598,
      "loss": 0.3655,
      "step": 999
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.10417148470878601,
      "learning_rate": 0.00019133518030122005,
      "loss": 0.3622,
      "step": 1000
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.09461657702922821,
      "learning_rate": 0.00019131700639561717,
      "loss": 0.2995,
      "step": 1001
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1139669120311737,
      "learning_rate": 0.00019129881431564444,
      "loss": 0.4139,
      "step": 1002
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.13431157171726227,
      "learning_rate": 0.00019128060406492248,
      "loss": 0.4179,
      "step": 1003
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.11944972723722458,
      "learning_rate": 0.00019126237564707563,
      "loss": 0.4121,
      "step": 1004
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1333748698234558,
      "learning_rate": 0.00019124412906573176,
      "loss": 0.3747,
      "step": 1005
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.11969165503978729,
      "learning_rate": 0.00019122586432452244,
      "loss": 0.4064,
      "step": 1006
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.11751555651426315,
      "learning_rate": 0.0001912075814270828,
      "loss": 0.3492,
      "step": 1007
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.09024353325366974,
      "learning_rate": 0.00019118928037705155,
      "loss": 0.3122,
      "step": 1008
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.09915587306022644,
      "learning_rate": 0.0001911709611780711,
      "loss": 0.4317,
      "step": 1009
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.09901371598243713,
      "learning_rate": 0.00019115262383378746,
      "loss": 0.3248,
      "step": 1010
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.17863045632839203,
      "learning_rate": 0.00019113426834785016,
      "loss": 0.3868,
      "step": 1011
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12547755241394043,
      "learning_rate": 0.00019111589472391242,
      "loss": 0.3738,
      "step": 1012
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1045336201786995,
      "learning_rate": 0.00019109750296563105,
      "loss": 0.3691,
      "step": 1013
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10851600021123886,
      "learning_rate": 0.0001910790930766665,
      "loss": 0.3984,
      "step": 1014
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.12057916074991226,
      "learning_rate": 0.00019106066506068277,
      "loss": 0.3538,
      "step": 1015
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10305196791887283,
      "learning_rate": 0.00019104221892134749,
      "loss": 0.537,
      "step": 1016
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10694577544927597,
      "learning_rate": 0.0001910237546623319,
      "loss": 0.3148,
      "step": 1017
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.11927560716867447,
      "learning_rate": 0.0001910052722873109,
      "loss": 0.3824,
      "step": 1018
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.09840627014636993,
      "learning_rate": 0.00019098677179996284,
      "loss": 0.3212,
      "step": 1019
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10388251394033432,
      "learning_rate": 0.0001909682532039699,
      "loss": 0.3355,
      "step": 1020
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.0917932391166687,
      "learning_rate": 0.0001909497165030177,
      "loss": 0.3133,
      "step": 1021
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10698262602090836,
      "learning_rate": 0.00019093116170079547,
      "loss": 0.3651,
      "step": 1022
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10357680916786194,
      "learning_rate": 0.00019091258880099614,
      "loss": 0.2848,
      "step": 1023
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.11415887624025345,
      "learning_rate": 0.00019089399780731613,
      "loss": 0.4096,
      "step": 1024
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10151797533035278,
      "learning_rate": 0.00019087538872345557,
      "loss": 0.3503,
      "step": 1025
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10939513891935349,
      "learning_rate": 0.00019085676155311806,
      "loss": 0.3644,
      "step": 1026
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10017262399196625,
      "learning_rate": 0.0001908381163000109,
      "loss": 0.3666,
      "step": 1027
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.09353199601173401,
      "learning_rate": 0.000190819452967845,
      "loss": 0.3665,
      "step": 1028
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1267353892326355,
      "learning_rate": 0.00019080077156033483,
      "loss": 0.371,
      "step": 1029
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.12865319848060608,
      "learning_rate": 0.0001907820720811984,
      "loss": 0.4475,
      "step": 1030
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.08865723758935928,
      "learning_rate": 0.0001907633545341574,
      "loss": 0.3259,
      "step": 1031
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10410608351230621,
      "learning_rate": 0.00019074461892293711,
      "loss": 0.3682,
      "step": 1032
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.13538789749145508,
      "learning_rate": 0.00019072586525126637,
      "loss": 0.4139,
      "step": 1033
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10394371300935745,
      "learning_rate": 0.00019070709352287762,
      "loss": 0.3785,
      "step": 1034
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.13381822407245636,
      "learning_rate": 0.00019068830374150694,
      "loss": 0.4647,
      "step": 1035
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10884661972522736,
      "learning_rate": 0.00019066949591089395,
      "loss": 0.4334,
      "step": 1036
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10397923737764359,
      "learning_rate": 0.00019065067003478183,
      "loss": 0.3634,
      "step": 1037
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.11610950529575348,
      "learning_rate": 0.00019063182611691747,
      "loss": 0.3749,
      "step": 1038
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.09239829331636429,
      "learning_rate": 0.00019061296416105123,
      "loss": 0.3315,
      "step": 1039
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.11310568451881409,
      "learning_rate": 0.00019059408417093719,
      "loss": 0.3771,
      "step": 1040
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.10565008968114853,
      "learning_rate": 0.00019057518615033282,
      "loss": 0.3906,
      "step": 1041
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.09313619136810303,
      "learning_rate": 0.00019055627010299938,
      "loss": 0.3371,
      "step": 1042
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.12189450114965439,
      "learning_rate": 0.00019053733603270167,
      "loss": 0.4711,
      "step": 1043
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.11379766464233398,
      "learning_rate": 0.00019051838394320796,
      "loss": 0.3659,
      "step": 1044
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.0921301394701004,
      "learning_rate": 0.00019049941383829022,
      "loss": 0.3322,
      "step": 1045
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.13039925694465637,
      "learning_rate": 0.000190480425721724,
      "loss": 0.3743,
      "step": 1046
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1081857681274414,
      "learning_rate": 0.00019046141959728837,
      "loss": 0.3572,
      "step": 1047
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.09252160787582397,
      "learning_rate": 0.00019044239546876606,
      "loss": 0.3164,
      "step": 1048
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.12075044959783554,
      "learning_rate": 0.00019042335333994333,
      "loss": 0.4273,
      "step": 1049
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1065279096364975,
      "learning_rate": 0.00019040429321461004,
      "loss": 0.4029,
      "step": 1050
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.08130793273448944,
      "learning_rate": 0.00019038521509655962,
      "loss": 0.2433,
      "step": 1051
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.13593462109565735,
      "learning_rate": 0.00019036611898958915,
      "loss": 0.3761,
      "step": 1052
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1283407360315323,
      "learning_rate": 0.00019034700489749918,
      "loss": 0.3426,
      "step": 1053
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10405127704143524,
      "learning_rate": 0.00019032787282409388,
      "loss": 0.3498,
      "step": 1054
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.11606742441654205,
      "learning_rate": 0.00019030872277318105,
      "loss": 0.3881,
      "step": 1055
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1071452721953392,
      "learning_rate": 0.00019028955474857204,
      "loss": 0.3996,
      "step": 1056
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.13541965186595917,
      "learning_rate": 0.00019027036875408172,
      "loss": 0.4134,
      "step": 1057
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10809806734323502,
      "learning_rate": 0.0001902511647935286,
      "loss": 0.3648,
      "step": 1058
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1081930622458458,
      "learning_rate": 0.00019023194287073476,
      "loss": 0.3125,
      "step": 1059
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.12349840253591537,
      "learning_rate": 0.00019021270298952585,
      "loss": 0.3731,
      "step": 1060
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.09164782613515854,
      "learning_rate": 0.00019019344515373106,
      "loss": 0.3119,
      "step": 1061
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.14807523787021637,
      "learning_rate": 0.0001901741693671832,
      "loss": 0.3941,
      "step": 1062
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10019677132368088,
      "learning_rate": 0.00019015487563371863,
      "loss": 0.3223,
      "step": 1063
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10335902869701385,
      "learning_rate": 0.0001901355639571773,
      "loss": 0.3347,
      "step": 1064
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.12048111855983734,
      "learning_rate": 0.00019011623434140272,
      "loss": 0.3946,
      "step": 1065
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.08067143708467484,
      "learning_rate": 0.0001900968867902419,
      "loss": 0.2856,
      "step": 1066
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1330951601266861,
      "learning_rate": 0.00019007752130754558,
      "loss": 0.3606,
      "step": 1067
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.08089874684810638,
      "learning_rate": 0.00019005813789716794,
      "loss": 0.3029,
      "step": 1068
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1324445903301239,
      "learning_rate": 0.00019003873656296675,
      "loss": 0.4136,
      "step": 1069
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.12275524437427521,
      "learning_rate": 0.00019001931730880335,
      "loss": 0.4435,
      "step": 1070
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.0909956619143486,
      "learning_rate": 0.00018999988013854272,
      "loss": 0.2755,
      "step": 1071
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.0863477885723114,
      "learning_rate": 0.00018998042505605326,
      "loss": 0.3054,
      "step": 1072
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.12006866186857224,
      "learning_rate": 0.00018996095206520708,
      "loss": 0.4044,
      "step": 1073
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.09093015640974045,
      "learning_rate": 0.00018994146116987974,
      "loss": 0.3695,
      "step": 1074
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10790169984102249,
      "learning_rate": 0.00018992195237395047,
      "loss": 0.3538,
      "step": 1075
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.13216102123260498,
      "learning_rate": 0.000189902425681302,
      "loss": 0.4129,
      "step": 1076
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.0987233817577362,
      "learning_rate": 0.0001898828810958206,
      "loss": 0.3882,
      "step": 1077
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10252645611763,
      "learning_rate": 0.00018986331862139613,
      "loss": 0.2994,
      "step": 1078
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10902216285467148,
      "learning_rate": 0.00018984373826192209,
      "loss": 0.3697,
      "step": 1079
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.08400193601846695,
      "learning_rate": 0.00018982414002129534,
      "loss": 0.2968,
      "step": 1080
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10869309306144714,
      "learning_rate": 0.00018980452390341649,
      "loss": 0.3696,
      "step": 1081
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.10496065020561218,
      "learning_rate": 0.00018978488991218965,
      "loss": 0.3,
      "step": 1082
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.11507370322942734,
      "learning_rate": 0.00018976523805152247,
      "loss": 0.378,
      "step": 1083
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10185782611370087,
      "learning_rate": 0.00018974556832532612,
      "loss": 0.3845,
      "step": 1084
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.08510474860668182,
      "learning_rate": 0.00018972588073751543,
      "loss": 0.2882,
      "step": 1085
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10172919183969498,
      "learning_rate": 0.00018970617529200868,
      "loss": 0.3129,
      "step": 1086
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17206037044525146,
      "learning_rate": 0.00018968645199272772,
      "loss": 0.3256,
      "step": 1087
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.09498221427202225,
      "learning_rate": 0.00018966671084359805,
      "loss": 0.3674,
      "step": 1088
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10086227208375931,
      "learning_rate": 0.0001896469518485486,
      "loss": 0.3443,
      "step": 1089
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.09197288006544113,
      "learning_rate": 0.00018962717501151195,
      "loss": 0.2994,
      "step": 1090
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.12418445199728012,
      "learning_rate": 0.00018960738033642414,
      "loss": 0.3511,
      "step": 1091
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1026315912604332,
      "learning_rate": 0.00018958756782722481,
      "loss": 0.4066,
      "step": 1092
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1442829966545105,
      "learning_rate": 0.00018956773748785718,
      "loss": 0.379,
      "step": 1093
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10811402648687363,
      "learning_rate": 0.00018954788932226796,
      "loss": 0.383,
      "step": 1094
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.15204346179962158,
      "learning_rate": 0.00018952802333440744,
      "loss": 0.4013,
      "step": 1095
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.15110638737678528,
      "learning_rate": 0.00018950813952822948,
      "loss": 0.3943,
      "step": 1096
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.06969477236270905,
      "learning_rate": 0.00018948823790769138,
      "loss": 0.2155,
      "step": 1097
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.11348151415586472,
      "learning_rate": 0.0001894683184767541,
      "loss": 0.368,
      "step": 1098
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.11060921102762222,
      "learning_rate": 0.00018944838123938212,
      "loss": 0.4745,
      "step": 1099
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.12518849968910217,
      "learning_rate": 0.0001894284261995434,
      "loss": 0.3861,
      "step": 1100
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.12141077220439911,
      "learning_rate": 0.0001894084533612096,
      "loss": 0.3695,
      "step": 1101
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.12976926565170288,
      "learning_rate": 0.00018938846272835566,
      "loss": 0.4322,
      "step": 1102
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.08787018060684204,
      "learning_rate": 0.00018936845430496036,
      "loss": 0.3242,
      "step": 1103
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10172366350889206,
      "learning_rate": 0.0001893484280950058,
      "loss": 0.2971,
      "step": 1104
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.12392531335353851,
      "learning_rate": 0.0001893283841024777,
      "loss": 0.3411,
      "step": 1105
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.13144490122795105,
      "learning_rate": 0.00018930832233136533,
      "loss": 0.5197,
      "step": 1106
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10267987847328186,
      "learning_rate": 0.0001892882427856615,
      "loss": 0.3265,
      "step": 1107
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.09073802083730698,
      "learning_rate": 0.00018926814546936247,
      "loss": 0.3498,
      "step": 1108
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1063522920012474,
      "learning_rate": 0.00018924803038646823,
      "loss": 0.3856,
      "step": 1109
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.13223537802696228,
      "learning_rate": 0.00018922789754098208,
      "loss": 0.2999,
      "step": 1110
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10642914474010468,
      "learning_rate": 0.00018920774693691102,
      "loss": 0.3735,
      "step": 1111
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.0921744704246521,
      "learning_rate": 0.00018918757857826551,
      "loss": 0.2841,
      "step": 1112
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1304224282503128,
      "learning_rate": 0.00018916739246905952,
      "loss": 0.3917,
      "step": 1113
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.11337674409151077,
      "learning_rate": 0.00018914718861331068,
      "loss": 0.3265,
      "step": 1114
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1259385496377945,
      "learning_rate": 0.00018912696701503995,
      "loss": 0.3839,
      "step": 1115
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.16206759214401245,
      "learning_rate": 0.00018910672767827202,
      "loss": 0.3797,
      "step": 1116
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.18751154839992523,
      "learning_rate": 0.000189086470607035,
      "loss": 0.4422,
      "step": 1117
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.10790019482374191,
      "learning_rate": 0.00018906619580536053,
      "loss": 0.3265,
      "step": 1118
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.14049412310123444,
      "learning_rate": 0.00018904590327728382,
      "loss": 0.3916,
      "step": 1119
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.12789995968341827,
      "learning_rate": 0.00018902559302684362,
      "loss": 0.4193,
      "step": 1120
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10839364677667618,
      "learning_rate": 0.0001890052650580821,
      "loss": 0.3612,
      "step": 1121
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0927065759897232,
      "learning_rate": 0.00018898491937504517,
      "loss": 0.336,
      "step": 1122
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09084980189800262,
      "learning_rate": 0.00018896455598178198,
      "loss": 0.2895,
      "step": 1123
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09654691815376282,
      "learning_rate": 0.00018894417488234545,
      "loss": 0.3606,
      "step": 1124
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.12690843641757965,
      "learning_rate": 0.00018892377608079188,
      "loss": 0.3772,
      "step": 1125
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.08480408042669296,
      "learning_rate": 0.0001889033595811812,
      "loss": 0.3325,
      "step": 1126
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09184834361076355,
      "learning_rate": 0.0001888829253875767,
      "loss": 0.3399,
      "step": 1127
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10559610277414322,
      "learning_rate": 0.00018886247350404542,
      "loss": 0.3483,
      "step": 1128
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.12105224281549454,
      "learning_rate": 0.0001888420039346577,
      "loss": 0.3663,
      "step": 1129
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09958678483963013,
      "learning_rate": 0.00018882151668348757,
      "loss": 0.4003,
      "step": 1130
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10069328546524048,
      "learning_rate": 0.00018880101175461247,
      "loss": 0.3857,
      "step": 1131
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10918834060430527,
      "learning_rate": 0.0001887804891521134,
      "loss": 0.3319,
      "step": 1132
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.08912821859121323,
      "learning_rate": 0.00018875994888007481,
      "loss": 0.292,
      "step": 1133
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1082548201084137,
      "learning_rate": 0.00018873939094258483,
      "loss": 0.2907,
      "step": 1134
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.11608398705720901,
      "learning_rate": 0.00018871881534373496,
      "loss": 0.3843,
      "step": 1135
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10529033839702606,
      "learning_rate": 0.0001886982220876203,
      "loss": 0.3393,
      "step": 1136
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.11061841249465942,
      "learning_rate": 0.0001886776111783393,
      "loss": 0.3868,
      "step": 1137
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.11411905288696289,
      "learning_rate": 0.00018865698261999418,
      "loss": 0.3465,
      "step": 1138
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10262023657560349,
      "learning_rate": 0.00018863633641669049,
      "loss": 0.3746,
      "step": 1139
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10132978856563568,
      "learning_rate": 0.00018861567257253735,
      "loss": 0.3776,
      "step": 1140
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.15687458217144012,
      "learning_rate": 0.0001885949910916473,
      "loss": 0.3981,
      "step": 1141
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09328915923833847,
      "learning_rate": 0.00018857429197813663,
      "loss": 0.2867,
      "step": 1142
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09943961352109909,
      "learning_rate": 0.00018855357523612484,
      "loss": 0.3336,
      "step": 1143
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09995663166046143,
      "learning_rate": 0.00018853284086973516,
      "loss": 0.3629,
      "step": 1144
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.10194186866283417,
      "learning_rate": 0.00018851208888309424,
      "loss": 0.3538,
      "step": 1145
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.11509378254413605,
      "learning_rate": 0.0001884913192803322,
      "loss": 0.3229,
      "step": 1146
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09059866517782211,
      "learning_rate": 0.00018847053206558277,
      "loss": 0.3104,
      "step": 1147
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09662867337465286,
      "learning_rate": 0.00018844972724298305,
      "loss": 0.342,
      "step": 1148
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1288442760705948,
      "learning_rate": 0.0001884289048166738,
      "loss": 0.4019,
      "step": 1149
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.12920443713665009,
      "learning_rate": 0.00018840806479079915,
      "loss": 0.4,
      "step": 1150
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1256144940853119,
      "learning_rate": 0.00018838720716950682,
      "loss": 0.3894,
      "step": 1151
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09024802595376968,
      "learning_rate": 0.00018836633195694797,
      "loss": 0.2884,
      "step": 1152
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1233355700969696,
      "learning_rate": 0.00018834543915727733,
      "loss": 0.3439,
      "step": 1153
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.13677601516246796,
      "learning_rate": 0.00018832452877465307,
      "loss": 0.3412,
      "step": 1154
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12313586473464966,
      "learning_rate": 0.00018830360081323685,
      "loss": 0.4063,
      "step": 1155
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1276191771030426,
      "learning_rate": 0.0001882826552771939,
      "loss": 0.4562,
      "step": 1156
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.09979527443647385,
      "learning_rate": 0.00018826169217069287,
      "loss": 0.3559,
      "step": 1157
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.11484860628843307,
      "learning_rate": 0.00018824071149790598,
      "loss": 0.4203,
      "step": 1158
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.090604268014431,
      "learning_rate": 0.0001882197132630089,
      "loss": 0.3218,
      "step": 1159
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12448903918266296,
      "learning_rate": 0.00018819869747018078,
      "loss": 0.3698,
      "step": 1160
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.0963209718465805,
      "learning_rate": 0.0001881776641236043,
      "loss": 0.3401,
      "step": 1161
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10047037154436111,
      "learning_rate": 0.00018815661322746564,
      "loss": 0.3503,
      "step": 1162
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.11816819757223129,
      "learning_rate": 0.00018813554478595444,
      "loss": 0.3844,
      "step": 1163
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10918360948562622,
      "learning_rate": 0.00018811445880326382,
      "loss": 0.3613,
      "step": 1164
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.09697275608778,
      "learning_rate": 0.00018809335528359046,
      "loss": 0.3201,
      "step": 1165
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.14845936000347137,
      "learning_rate": 0.0001880722342311345,
      "loss": 0.5119,
      "step": 1166
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.0924372598528862,
      "learning_rate": 0.0001880510956500995,
      "loss": 0.3289,
      "step": 1167
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1315954476594925,
      "learning_rate": 0.00018802993954469263,
      "loss": 0.4747,
      "step": 1168
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.13196228444576263,
      "learning_rate": 0.00018800876591912444,
      "loss": 0.3908,
      "step": 1169
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.09980036318302155,
      "learning_rate": 0.00018798757477760905,
      "loss": 0.4203,
      "step": 1170
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10222426801919937,
      "learning_rate": 0.00018796636612436398,
      "loss": 0.2979,
      "step": 1171
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10533398389816284,
      "learning_rate": 0.0001879451399636103,
      "loss": 0.292,
      "step": 1172
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10563963651657104,
      "learning_rate": 0.0001879238962995726,
      "loss": 0.4024,
      "step": 1173
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10214684158563614,
      "learning_rate": 0.0001879026351364788,
      "loss": 0.3614,
      "step": 1174
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.0952034443616867,
      "learning_rate": 0.00018788135647856047,
      "loss": 0.2638,
      "step": 1175
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1134958267211914,
      "learning_rate": 0.00018786006033005262,
      "loss": 0.374,
      "step": 1176
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.09175308048725128,
      "learning_rate": 0.00018783874669519365,
      "loss": 0.2787,
      "step": 1177
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.08974765986204147,
      "learning_rate": 0.0001878174155782255,
      "loss": 0.3068,
      "step": 1178
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12714293599128723,
      "learning_rate": 0.00018779606698339371,
      "loss": 0.392,
      "step": 1179
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12339433282613754,
      "learning_rate": 0.00018777470091494708,
      "loss": 0.4513,
      "step": 1180
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12435469776391983,
      "learning_rate": 0.00018775331737713803,
      "loss": 0.3669,
      "step": 1181
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12438105791807175,
      "learning_rate": 0.0001877319163742224,
      "loss": 0.4486,
      "step": 1182
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10389876365661621,
      "learning_rate": 0.0001877104979104595,
      "loss": 0.3292,
      "step": 1183
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.09464842081069946,
      "learning_rate": 0.00018768906199011223,
      "loss": 0.2546,
      "step": 1184
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12879694998264313,
      "learning_rate": 0.00018766760861744678,
      "loss": 0.3966,
      "step": 1185
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12549464404582977,
      "learning_rate": 0.00018764613779673298,
      "loss": 0.3725,
      "step": 1186
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.10723524540662766,
      "learning_rate": 0.00018762464953224402,
      "loss": 0.2971,
      "step": 1187
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1154346838593483,
      "learning_rate": 0.00018760314382825662,
      "loss": 0.447,
      "step": 1188
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.15516938269138336,
      "learning_rate": 0.00018758162068905092,
      "loss": 0.4437,
      "step": 1189
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09574083238840103,
      "learning_rate": 0.0001875600801189106,
      "loss": 0.3167,
      "step": 1190
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.10738249868154526,
      "learning_rate": 0.00018753852212212278,
      "loss": 0.3291,
      "step": 1191
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.12739567458629608,
      "learning_rate": 0.00018751694670297799,
      "loss": 0.4035,
      "step": 1192
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09381289780139923,
      "learning_rate": 0.00018749535386577032,
      "loss": 0.3127,
      "step": 1193
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09220244735479355,
      "learning_rate": 0.0001874737436147973,
      "loss": 0.3037,
      "step": 1194
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.06915169209241867,
      "learning_rate": 0.00018745211595435986,
      "loss": 0.2481,
      "step": 1195
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1036364957690239,
      "learning_rate": 0.00018743047088876248,
      "loss": 0.4453,
      "step": 1196
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.08712315559387207,
      "learning_rate": 0.00018740880842231308,
      "loss": 0.2831,
      "step": 1197
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.10752114653587341,
      "learning_rate": 0.00018738712855932298,
      "loss": 0.3024,
      "step": 1198
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.11465814709663391,
      "learning_rate": 0.00018736543130410706,
      "loss": 0.4421,
      "step": 1199
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.10198263823986053,
      "learning_rate": 0.00018734371666098362,
      "loss": 0.3931,
      "step": 1200
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.10958383977413177,
      "learning_rate": 0.00018732198463427443,
      "loss": 0.3369,
      "step": 1201
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09957507252693176,
      "learning_rate": 0.00018730023522830463,
      "loss": 0.3171,
      "step": 1202
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.0862436592578888,
      "learning_rate": 0.00018727846844740297,
      "loss": 0.2848,
      "step": 1203
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09388160705566406,
      "learning_rate": 0.00018725668429590158,
      "loss": 0.3318,
      "step": 1204
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09846656024456024,
      "learning_rate": 0.000187234882778136,
      "loss": 0.3182,
      "step": 1205
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.08889170736074448,
      "learning_rate": 0.00018721306389844533,
      "loss": 0.2905,
      "step": 1206
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1200849786400795,
      "learning_rate": 0.00018719122766117205,
      "loss": 0.3492,
      "step": 1207
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09703271090984344,
      "learning_rate": 0.00018716937407066214,
      "loss": 0.3086,
      "step": 1208
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1044919416308403,
      "learning_rate": 0.00018714750313126498,
      "loss": 0.4299,
      "step": 1209
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1464831680059433,
      "learning_rate": 0.00018712561484733343,
      "loss": 0.409,
      "step": 1210
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.10104365646839142,
      "learning_rate": 0.00018710370922322384,
      "loss": 0.3839,
      "step": 1211
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.08957383036613464,
      "learning_rate": 0.00018708178626329597,
      "loss": 0.2594,
      "step": 1212
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.12233632057905197,
      "learning_rate": 0.00018705984597191302,
      "loss": 0.4535,
      "step": 1213
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09667368233203888,
      "learning_rate": 0.0001870378883534417,
      "loss": 0.3468,
      "step": 1214
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.11373239010572433,
      "learning_rate": 0.00018701591341225204,
      "loss": 0.3609,
      "step": 1215
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.14034579694271088,
      "learning_rate": 0.00018699392115271768,
      "loss": 0.4382,
      "step": 1216
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.12275052070617676,
      "learning_rate": 0.00018697191157921562,
      "loss": 0.3435,
      "step": 1217
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.11533983051776886,
      "learning_rate": 0.00018694988469612626,
      "loss": 0.3197,
      "step": 1218
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.12666773796081543,
      "learning_rate": 0.0001869278405078336,
      "loss": 0.4388,
      "step": 1219
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.11983907967805862,
      "learning_rate": 0.00018690577901872487,
      "loss": 0.4785,
      "step": 1220
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.10977104306221008,
      "learning_rate": 0.00018688370023319098,
      "loss": 0.375,
      "step": 1221
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09191672503948212,
      "learning_rate": 0.00018686160415562605,
      "loss": 0.3044,
      "step": 1222
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1176590546965599,
      "learning_rate": 0.0001868394907904278,
      "loss": 0.3731,
      "step": 1223
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.14698928594589233,
      "learning_rate": 0.00018681736014199737,
      "loss": 0.4531,
      "step": 1224
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.09850738942623138,
      "learning_rate": 0.0001867952122147393,
      "loss": 0.3117,
      "step": 1225
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.0975097119808197,
      "learning_rate": 0.00018677304701306154,
      "loss": 0.3267,
      "step": 1226
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.11082661151885986,
      "learning_rate": 0.00018675086454137554,
      "loss": 0.2491,
      "step": 1227
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1032148078083992,
      "learning_rate": 0.00018672866480409618,
      "loss": 0.3431,
      "step": 1228
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10375431180000305,
      "learning_rate": 0.00018670644780564177,
      "loss": 0.3825,
      "step": 1229
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.12863823771476746,
      "learning_rate": 0.00018668421355043404,
      "loss": 0.4164,
      "step": 1230
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.08340641111135483,
      "learning_rate": 0.00018666196204289814,
      "loss": 0.2819,
      "step": 1231
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.11205897480249405,
      "learning_rate": 0.0001866396932874627,
      "loss": 0.3489,
      "step": 1232
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.09609492868185043,
      "learning_rate": 0.0001866174072885598,
      "loss": 0.326,
      "step": 1233
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.12240613251924515,
      "learning_rate": 0.00018659510405062482,
      "loss": 0.3031,
      "step": 1234
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10553009063005447,
      "learning_rate": 0.00018657278357809672,
      "loss": 0.3538,
      "step": 1235
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10461068153381348,
      "learning_rate": 0.00018655044587541784,
      "loss": 0.387,
      "step": 1236
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10082567483186722,
      "learning_rate": 0.0001865280909470339,
      "loss": 0.2923,
      "step": 1237
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1464022547006607,
      "learning_rate": 0.00018650571879739417,
      "loss": 0.4341,
      "step": 1238
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.12009703367948532,
      "learning_rate": 0.00018648332943095117,
      "loss": 0.4269,
      "step": 1239
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.21829535067081451,
      "learning_rate": 0.00018646092285216098,
      "loss": 0.3743,
      "step": 1240
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1204008162021637,
      "learning_rate": 0.0001864384990654831,
      "loss": 0.3249,
      "step": 1241
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.09979058057069778,
      "learning_rate": 0.00018641605807538043,
      "loss": 0.3689,
      "step": 1242
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.09624109417200089,
      "learning_rate": 0.00018639359988631922,
      "loss": 0.3554,
      "step": 1243
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10753492265939713,
      "learning_rate": 0.00018637112450276927,
      "loss": 0.3589,
      "step": 1244
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.09014839679002762,
      "learning_rate": 0.0001863486319292037,
      "loss": 0.3506,
      "step": 1245
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1395254135131836,
      "learning_rate": 0.00018632612217009916,
      "loss": 0.3371,
      "step": 1246
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.11106585711240768,
      "learning_rate": 0.00018630359522993562,
      "loss": 0.3735,
      "step": 1247
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.09997449815273285,
      "learning_rate": 0.00018628105111319647,
      "loss": 0.3504,
      "step": 1248
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10751426219940186,
      "learning_rate": 0.0001862584898243686,
      "loss": 0.4,
      "step": 1249
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.11405704915523529,
      "learning_rate": 0.00018623591136794228,
      "loss": 0.2935,
      "step": 1250
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.11334224045276642,
      "learning_rate": 0.00018621331574841116,
      "loss": 0.3576,
      "step": 1251
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1282757818698883,
      "learning_rate": 0.0001861907029702723,
      "loss": 0.4525,
      "step": 1252
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.089210145175457,
      "learning_rate": 0.0001861680730380263,
      "loss": 0.2932,
      "step": 1253
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.08340036123991013,
      "learning_rate": 0.000186145425956177,
      "loss": 0.3163,
      "step": 1254
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.160518079996109,
      "learning_rate": 0.00018612276172923177,
      "loss": 0.4403,
      "step": 1255
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10355688631534576,
      "learning_rate": 0.00018610008036170137,
      "loss": 0.3427,
      "step": 1256
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.14002954959869385,
      "learning_rate": 0.00018607738185809992,
      "loss": 0.3469,
      "step": 1257
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10498889535665512,
      "learning_rate": 0.00018605466622294503,
      "loss": 0.2943,
      "step": 1258
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.11662737280130386,
      "learning_rate": 0.0001860319334607577,
      "loss": 0.4125,
      "step": 1259
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.10643903911113739,
      "learning_rate": 0.00018600918357606223,
      "loss": 0.4036,
      "step": 1260
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10071388632059097,
      "learning_rate": 0.00018598641657338648,
      "loss": 0.3969,
      "step": 1261
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.07932871580123901,
      "learning_rate": 0.00018596363245726167,
      "loss": 0.2748,
      "step": 1262
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.12503032386302948,
      "learning_rate": 0.0001859408312322224,
      "loss": 0.4661,
      "step": 1263
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.11807159334421158,
      "learning_rate": 0.00018591801290280665,
      "loss": 0.4278,
      "step": 1264
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.11373947560787201,
      "learning_rate": 0.00018589517747355584,
      "loss": 0.347,
      "step": 1265
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.08344254642724991,
      "learning_rate": 0.0001858723249490148,
      "loss": 0.2479,
      "step": 1266
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.09887919574975967,
      "learning_rate": 0.00018584945533373177,
      "loss": 0.3733,
      "step": 1267
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.09329685568809509,
      "learning_rate": 0.0001858265686322584,
      "loss": 0.3288,
      "step": 1268
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.13039450347423553,
      "learning_rate": 0.00018580366484914965,
      "loss": 0.3978,
      "step": 1269
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.13422967493534088,
      "learning_rate": 0.00018578074398896402,
      "loss": 0.347,
      "step": 1270
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.12032876908779144,
      "learning_rate": 0.00018575780605626326,
      "loss": 0.3443,
      "step": 1271
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10933142900466919,
      "learning_rate": 0.00018573485105561263,
      "loss": 0.3309,
      "step": 1272
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.11240829527378082,
      "learning_rate": 0.00018571187899158077,
      "loss": 0.3719,
      "step": 1273
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10722413659095764,
      "learning_rate": 0.00018568888986873966,
      "loss": 0.3763,
      "step": 1274
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.11482305824756622,
      "learning_rate": 0.00018566588369166474,
      "loss": 0.4025,
      "step": 1275
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.13046562671661377,
      "learning_rate": 0.00018564286046493481,
      "loss": 0.3334,
      "step": 1276
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10299721360206604,
      "learning_rate": 0.00018561982019313204,
      "loss": 0.3407,
      "step": 1277
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.14881271123886108,
      "learning_rate": 0.00018559676288084208,
      "loss": 0.334,
      "step": 1278
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.09943878650665283,
      "learning_rate": 0.00018557368853265382,
      "loss": 0.2714,
      "step": 1279
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1116781011223793,
      "learning_rate": 0.0001855505971531597,
      "loss": 0.3211,
      "step": 1280
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.09736765176057816,
      "learning_rate": 0.00018552748874695548,
      "loss": 0.3311,
      "step": 1281
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.11371411383152008,
      "learning_rate": 0.00018550436331864027,
      "loss": 0.3758,
      "step": 1282
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1107805073261261,
      "learning_rate": 0.00018548122087281668,
      "loss": 0.3368,
      "step": 1283
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.16938026249408722,
      "learning_rate": 0.00018545806141409055,
      "loss": 0.4766,
      "step": 1284
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.08697892725467682,
      "learning_rate": 0.00018543488494707124,
      "loss": 0.2896,
      "step": 1285
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.12178158015012741,
      "learning_rate": 0.00018541169147637146,
      "loss": 0.4279,
      "step": 1286
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10556834936141968,
      "learning_rate": 0.00018538848100660727,
      "loss": 0.3055,
      "step": 1287
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.11919587850570679,
      "learning_rate": 0.00018536525354239815,
      "loss": 0.3545,
      "step": 1288
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10966961830854416,
      "learning_rate": 0.00018534200908836693,
      "loss": 0.3704,
      "step": 1289
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.12420876324176788,
      "learning_rate": 0.00018531874764913983,
      "loss": 0.3239,
      "step": 1290
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.08617323637008667,
      "learning_rate": 0.0001852954692293465,
      "loss": 0.335,
      "step": 1291
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10673634707927704,
      "learning_rate": 0.0001852721738336199,
      "loss": 0.3836,
      "step": 1292
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.11602270603179932,
      "learning_rate": 0.00018524886146659635,
      "loss": 0.4218,
      "step": 1293
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10275815427303314,
      "learning_rate": 0.00018522553213291566,
      "loss": 0.317,
      "step": 1294
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.13063868880271912,
      "learning_rate": 0.00018520218583722094,
      "loss": 0.3229,
      "step": 1295
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.12479196488857269,
      "learning_rate": 0.00018517882258415867,
      "loss": 0.378,
      "step": 1296
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.12950585782527924,
      "learning_rate": 0.00018515544237837877,
      "loss": 0.337,
      "step": 1297
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11025837808847427,
      "learning_rate": 0.00018513204522453442,
      "loss": 0.3261,
      "step": 1298
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.10275893658399582,
      "learning_rate": 0.00018510863112728226,
      "loss": 0.2854,
      "step": 1299
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.10776616632938385,
      "learning_rate": 0.0001850852000912823,
      "loss": 0.2999,
      "step": 1300
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11234559118747711,
      "learning_rate": 0.0001850617521211979,
      "loss": 0.4266,
      "step": 1301
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.10999099165201187,
      "learning_rate": 0.00018503828722169575,
      "loss": 0.352,
      "step": 1302
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.12818790972232819,
      "learning_rate": 0.00018501480539744603,
      "loss": 0.4045,
      "step": 1303
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.08416040986776352,
      "learning_rate": 0.00018499130665312213,
      "loss": 0.3004,
      "step": 1304
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.09278489649295807,
      "learning_rate": 0.00018496779099340095,
      "loss": 0.2999,
      "step": 1305
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11458314210176468,
      "learning_rate": 0.00018494425842296267,
      "loss": 0.4658,
      "step": 1306
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.09859441220760345,
      "learning_rate": 0.00018492070894649085,
      "loss": 0.3797,
      "step": 1307
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.10210665315389633,
      "learning_rate": 0.00018489714256867245,
      "loss": 0.3504,
      "step": 1308
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.12009266018867493,
      "learning_rate": 0.00018487355929419774,
      "loss": 0.351,
      "step": 1309
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11456922441720963,
      "learning_rate": 0.00018484995912776043,
      "loss": 0.3484,
      "step": 1310
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11614828556776047,
      "learning_rate": 0.00018482634207405747,
      "loss": 0.4269,
      "step": 1311
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11439870297908783,
      "learning_rate": 0.00018480270813778932,
      "loss": 0.3635,
      "step": 1312
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.14754121005535126,
      "learning_rate": 0.00018477905732365967,
      "loss": 0.4107,
      "step": 1313
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11677946895360947,
      "learning_rate": 0.00018475538963637562,
      "loss": 0.362,
      "step": 1314
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.12708383798599243,
      "learning_rate": 0.00018473170508064767,
      "loss": 0.3926,
      "step": 1315
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11420592665672302,
      "learning_rate": 0.00018470800366118966,
      "loss": 0.4092,
      "step": 1316
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1352943778038025,
      "learning_rate": 0.00018468428538271871,
      "loss": 0.3319,
      "step": 1317
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.105924092233181,
      "learning_rate": 0.0001846605502499554,
      "loss": 0.4017,
      "step": 1318
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.10567544400691986,
      "learning_rate": 0.00018463679826762354,
      "loss": 0.346,
      "step": 1319
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11120550334453583,
      "learning_rate": 0.00018461302944045046,
      "loss": 0.3816,
      "step": 1320
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.09033095091581345,
      "learning_rate": 0.00018458924377316667,
      "loss": 0.3045,
      "step": 1321
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.10666269809007645,
      "learning_rate": 0.00018456544127050617,
      "loss": 0.3827,
      "step": 1322
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.13166846334934235,
      "learning_rate": 0.00018454162193720625,
      "loss": 0.3319,
      "step": 1323
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.15399731695652008,
      "learning_rate": 0.0001845177857780075,
      "loss": 0.404,
      "step": 1324
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.15679413080215454,
      "learning_rate": 0.000184493932797654,
      "loss": 0.356,
      "step": 1325
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11075889319181442,
      "learning_rate": 0.00018447006300089302,
      "loss": 0.3591,
      "step": 1326
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.11014965176582336,
      "learning_rate": 0.00018444617639247528,
      "loss": 0.3355,
      "step": 1327
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.12877728044986725,
      "learning_rate": 0.0001844222729771548,
      "loss": 0.4007,
      "step": 1328
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.09888969361782074,
      "learning_rate": 0.00018439835275968895,
      "loss": 0.3068,
      "step": 1329
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.16686685383319855,
      "learning_rate": 0.00018437441574483844,
      "loss": 0.4521,
      "step": 1330
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.12971369922161102,
      "learning_rate": 0.0001843504619373674,
      "loss": 0.394,
      "step": 1331
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.11682478338479996,
      "learning_rate": 0.00018432649134204318,
      "loss": 0.3066,
      "step": 1332
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.09082973748445511,
      "learning_rate": 0.00018430250396363654,
      "loss": 0.3151,
      "step": 1333
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.08901599049568176,
      "learning_rate": 0.00018427849980692156,
      "loss": 0.3409,
      "step": 1334
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.13218246400356293,
      "learning_rate": 0.0001842544788766757,
      "loss": 0.4068,
      "step": 1335
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10869528353214264,
      "learning_rate": 0.00018423044117767966,
      "loss": 0.294,
      "step": 1336
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.11110565811395645,
      "learning_rate": 0.00018420638671471764,
      "loss": 0.3278,
      "step": 1337
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1326451599597931,
      "learning_rate": 0.00018418231549257702,
      "loss": 0.3804,
      "step": 1338
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.11468725651502609,
      "learning_rate": 0.00018415822751604858,
      "loss": 0.385,
      "step": 1339
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.08665390312671661,
      "learning_rate": 0.00018413412278992644,
      "loss": 0.2933,
      "step": 1340
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.11901368200778961,
      "learning_rate": 0.00018411000131900802,
      "loss": 0.3928,
      "step": 1341
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1169077530503273,
      "learning_rate": 0.00018408586310809412,
      "loss": 0.4164,
      "step": 1342
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1351500302553177,
      "learning_rate": 0.00018406170816198886,
      "loss": 0.4249,
      "step": 1343
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10902586579322815,
      "learning_rate": 0.00018403753648549965,
      "loss": 0.3582,
      "step": 1344
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10337718576192856,
      "learning_rate": 0.00018401334808343725,
      "loss": 0.3855,
      "step": 1345
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.09705562144517899,
      "learning_rate": 0.00018398914296061586,
      "loss": 0.3654,
      "step": 1346
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.12719210982322693,
      "learning_rate": 0.00018396492112185273,
      "loss": 0.3703,
      "step": 1347
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1007733941078186,
      "learning_rate": 0.00018394068257196876,
      "loss": 0.3687,
      "step": 1348
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10581708699464798,
      "learning_rate": 0.00018391642731578798,
      "loss": 0.3291,
      "step": 1349
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.08651982247829437,
      "learning_rate": 0.00018389215535813774,
      "loss": 0.2506,
      "step": 1350
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.09137991070747375,
      "learning_rate": 0.00018386786670384885,
      "loss": 0.3039,
      "step": 1351
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1294584721326828,
      "learning_rate": 0.0001838435613577553,
      "loss": 0.4829,
      "step": 1352
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1618448942899704,
      "learning_rate": 0.00018381923932469453,
      "loss": 0.4489,
      "step": 1353
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10369604080915451,
      "learning_rate": 0.00018379490060950715,
      "loss": 0.3546,
      "step": 1354
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.13343879580497742,
      "learning_rate": 0.00018377054521703722,
      "loss": 0.4325,
      "step": 1355
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.09431963413953781,
      "learning_rate": 0.00018374617315213208,
      "loss": 0.2773,
      "step": 1356
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.15215462446212769,
      "learning_rate": 0.00018372178441964236,
      "loss": 0.5093,
      "step": 1357
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.132584348320961,
      "learning_rate": 0.00018369737902442204,
      "loss": 0.3939,
      "step": 1358
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10831427574157715,
      "learning_rate": 0.0001836729569713284,
      "loss": 0.4319,
      "step": 1359
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10379618406295776,
      "learning_rate": 0.000183648518265222,
      "loss": 0.3118,
      "step": 1360
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.06435869634151459,
      "learning_rate": 0.00018362406291096684,
      "loss": 0.1967,
      "step": 1361
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.11284680664539337,
      "learning_rate": 0.00018359959091343011,
      "loss": 0.3805,
      "step": 1362
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.12038127332925797,
      "learning_rate": 0.0001835751022774823,
      "loss": 0.3696,
      "step": 1363
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1130613386631012,
      "learning_rate": 0.00018355059700799736,
      "loss": 0.4075,
      "step": 1364
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10248155146837234,
      "learning_rate": 0.00018352607510985233,
      "loss": 0.3286,
      "step": 1365
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1188468337059021,
      "learning_rate": 0.0001835015365879278,
      "loss": 0.3688,
      "step": 1366
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.13497602939605713,
      "learning_rate": 0.00018347698144710747,
      "loss": 0.3841,
      "step": 1367
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.11338791996240616,
      "learning_rate": 0.00018345240969227847,
      "loss": 0.442,
      "step": 1368
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12087877094745636,
      "learning_rate": 0.0001834278213283312,
      "loss": 0.329,
      "step": 1369
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12125813215970993,
      "learning_rate": 0.0001834032163601593,
      "loss": 0.3984,
      "step": 1370
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.15834170579910278,
      "learning_rate": 0.0001833785947926598,
      "loss": 0.4199,
      "step": 1371
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.13975057005882263,
      "learning_rate": 0.00018335395663073305,
      "loss": 0.3129,
      "step": 1372
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.09215500205755234,
      "learning_rate": 0.00018332930187928262,
      "loss": 0.2821,
      "step": 1373
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.11894688755273819,
      "learning_rate": 0.00018330463054321542,
      "loss": 0.363,
      "step": 1374
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.17513452470302582,
      "learning_rate": 0.0001832799426274417,
      "loss": 0.3144,
      "step": 1375
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.10706616193056107,
      "learning_rate": 0.00018325523813687494,
      "loss": 0.3759,
      "step": 1376
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12036166340112686,
      "learning_rate": 0.00018323051707643198,
      "loss": 0.3295,
      "step": 1377
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.13431236147880554,
      "learning_rate": 0.0001832057794510329,
      "loss": 0.3241,
      "step": 1378
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.13561102747917175,
      "learning_rate": 0.00018318102526560111,
      "loss": 0.3673,
      "step": 1379
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.13307805359363556,
      "learning_rate": 0.00018315625452506334,
      "loss": 0.4089,
      "step": 1380
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1366024762392044,
      "learning_rate": 0.00018313146723434958,
      "loss": 0.447,
      "step": 1381
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.09403257071971893,
      "learning_rate": 0.0001831066633983931,
      "loss": 0.2695,
      "step": 1382
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12241064012050629,
      "learning_rate": 0.00018308184302213046,
      "loss": 0.322,
      "step": 1383
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1282539814710617,
      "learning_rate": 0.0001830570061105016,
      "loss": 0.3136,
      "step": 1384
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.10938847064971924,
      "learning_rate": 0.00018303215266844965,
      "loss": 0.3679,
      "step": 1385
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.10584475100040436,
      "learning_rate": 0.0001830072827009211,
      "loss": 0.3266,
      "step": 1386
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.10970057547092438,
      "learning_rate": 0.00018298239621286565,
      "loss": 0.3572,
      "step": 1387
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1100362241268158,
      "learning_rate": 0.0001829574932092364,
      "loss": 0.365,
      "step": 1388
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.23577992618083954,
      "learning_rate": 0.00018293257369498956,
      "loss": 0.4026,
      "step": 1389
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.10177012532949448,
      "learning_rate": 0.00018290763767508483,
      "loss": 0.3188,
      "step": 1390
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.10019377619028091,
      "learning_rate": 0.00018288268515448508,
      "loss": 0.3608,
      "step": 1391
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.09568960964679718,
      "learning_rate": 0.00018285771613815648,
      "loss": 0.2637,
      "step": 1392
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12728667259216309,
      "learning_rate": 0.00018283273063106846,
      "loss": 0.3645,
      "step": 1393
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.11256596446037292,
      "learning_rate": 0.00018280772863819383,
      "loss": 0.3531,
      "step": 1394
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1282634437084198,
      "learning_rate": 0.00018278271016450857,
      "loss": 0.4169,
      "step": 1395
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.09935203939676285,
      "learning_rate": 0.000182757675214992,
      "loss": 0.339,
      "step": 1396
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.14976783096790314,
      "learning_rate": 0.00018273262379462667,
      "loss": 0.4689,
      "step": 1397
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.11671630293130875,
      "learning_rate": 0.00018270755590839844,
      "loss": 0.3504,
      "step": 1398
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.13485956192016602,
      "learning_rate": 0.00018268247156129648,
      "loss": 0.4265,
      "step": 1399
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12132010608911514,
      "learning_rate": 0.0001826573707583132,
      "loss": 0.3058,
      "step": 1400
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.09847119450569153,
      "learning_rate": 0.00018263225350444425,
      "loss": 0.3408,
      "step": 1401
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12120286375284195,
      "learning_rate": 0.00018260711980468863,
      "loss": 0.3302,
      "step": 1402
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.07963350415229797,
      "learning_rate": 0.00018258196966404857,
      "loss": 0.3182,
      "step": 1403
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.09493370354175568,
      "learning_rate": 0.0001825568030875296,
      "loss": 0.3761,
      "step": 1404
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10916756838560104,
      "learning_rate": 0.0001825316200801404,
      "loss": 0.4551,
      "step": 1405
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13431915640830994,
      "learning_rate": 0.0001825064206468931,
      "loss": 0.4736,
      "step": 1406
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10073388367891312,
      "learning_rate": 0.00018248120479280307,
      "loss": 0.3316,
      "step": 1407
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.09929900616407394,
      "learning_rate": 0.00018245597252288879,
      "loss": 0.3821,
      "step": 1408
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1070781722664833,
      "learning_rate": 0.00018243072384217215,
      "loss": 0.3249,
      "step": 1409
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10247600823640823,
      "learning_rate": 0.00018240545875567826,
      "loss": 0.3468,
      "step": 1410
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10319569706916809,
      "learning_rate": 0.00018238017726843558,
      "loss": 0.3615,
      "step": 1411
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11447329819202423,
      "learning_rate": 0.00018235487938547565,
      "loss": 0.3225,
      "step": 1412
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10292262583971024,
      "learning_rate": 0.00018232956511183342,
      "loss": 0.3603,
      "step": 1413
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.09121594578027725,
      "learning_rate": 0.0001823042344525471,
      "loss": 0.3417,
      "step": 1414
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10151584446430206,
      "learning_rate": 0.0001822788874126581,
      "loss": 0.3359,
      "step": 1415
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1262013018131256,
      "learning_rate": 0.0001822535239972111,
      "loss": 0.3942,
      "step": 1416
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11611178517341614,
      "learning_rate": 0.0001822281442112541,
      "loss": 0.3912,
      "step": 1417
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11171121150255203,
      "learning_rate": 0.00018220274805983826,
      "loss": 0.3299,
      "step": 1418
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11002642661333084,
      "learning_rate": 0.00018217733554801806,
      "loss": 0.3717,
      "step": 1419
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.121502585709095,
      "learning_rate": 0.00018215190668085125,
      "loss": 0.3551,
      "step": 1420
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1306340992450714,
      "learning_rate": 0.0001821264614633988,
      "loss": 0.3177,
      "step": 1421
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.12407000362873077,
      "learning_rate": 0.00018210099990072494,
      "loss": 0.3764,
      "step": 1422
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1303221881389618,
      "learning_rate": 0.00018207552199789716,
      "loss": 0.2765,
      "step": 1423
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1189129501581192,
      "learning_rate": 0.00018205002775998624,
      "loss": 0.4565,
      "step": 1424
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11153800040483475,
      "learning_rate": 0.0001820245171920661,
      "loss": 0.3261,
      "step": 1425
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.09996207803487778,
      "learning_rate": 0.000181998990299214,
      "loss": 0.3094,
      "step": 1426
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.134795680642128,
      "learning_rate": 0.00018197344708651046,
      "loss": 0.3635,
      "step": 1427
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.12537430226802826,
      "learning_rate": 0.0001819478875590392,
      "loss": 0.3617,
      "step": 1428
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10683771967887878,
      "learning_rate": 0.0001819223117218872,
      "loss": 0.3065,
      "step": 1429
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11559782177209854,
      "learning_rate": 0.00018189671958014473,
      "loss": 0.3342,
      "step": 1430
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1517263799905777,
      "learning_rate": 0.00018187111113890522,
      "loss": 0.3337,
      "step": 1431
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11324695497751236,
      "learning_rate": 0.00018184548640326543,
      "loss": 0.3477,
      "step": 1432
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1066446378827095,
      "learning_rate": 0.00018181984537832531,
      "loss": 0.292,
      "step": 1433
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11685407906770706,
      "learning_rate": 0.00018179418806918803,
      "loss": 0.3033,
      "step": 1434
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.28920993208885193,
      "learning_rate": 0.00018176851448096007,
      "loss": 0.3205,
      "step": 1435
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13010171055793762,
      "learning_rate": 0.0001817428246187511,
      "loss": 0.3788,
      "step": 1436
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.09232502430677414,
      "learning_rate": 0.00018171711848767407,
      "loss": 0.2902,
      "step": 1437
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.11836932599544525,
      "learning_rate": 0.00018169139609284515,
      "loss": 0.3628,
      "step": 1438
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.12588469684123993,
      "learning_rate": 0.0001816656574393837,
      "loss": 0.3431,
      "step": 1439
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.09970539808273315,
      "learning_rate": 0.0001816399025324124,
      "loss": 0.3947,
      "step": 1440
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.10159885138273239,
      "learning_rate": 0.0001816141313770571,
      "loss": 0.3397,
      "step": 1441
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.10459578037261963,
      "learning_rate": 0.00018158834397844688,
      "loss": 0.3026,
      "step": 1442
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11997316777706146,
      "learning_rate": 0.00018156254034171413,
      "loss": 0.3495,
      "step": 1443
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1055743619799614,
      "learning_rate": 0.00018153672047199434,
      "loss": 0.3356,
      "step": 1444
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.10994529724121094,
      "learning_rate": 0.00018151088437442644,
      "loss": 0.2882,
      "step": 1445
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.09535212069749832,
      "learning_rate": 0.0001814850320541523,
      "loss": 0.2684,
      "step": 1446
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.09795723110437393,
      "learning_rate": 0.00018145916351631732,
      "loss": 0.3367,
      "step": 1447
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.10329826176166534,
      "learning_rate": 0.0001814332787660699,
      "loss": 0.3395,
      "step": 1448
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.10965302586555481,
      "learning_rate": 0.00018140737780856177,
      "loss": 0.3751,
      "step": 1449
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.13968466222286224,
      "learning_rate": 0.00018138146064894793,
      "loss": 0.3424,
      "step": 1450
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.09012889862060547,
      "learning_rate": 0.00018135552729238645,
      "loss": 0.318,
      "step": 1451
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.12887531518936157,
      "learning_rate": 0.0001813295777440388,
      "loss": 0.3391,
      "step": 1452
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.08874377608299255,
      "learning_rate": 0.0001813036120090695,
      "loss": 0.3275,
      "step": 1453
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.16190578043460846,
      "learning_rate": 0.0001812776300926464,
      "loss": 0.4233,
      "step": 1454
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11368488520383835,
      "learning_rate": 0.00018125163199994067,
      "loss": 0.3676,
      "step": 1455
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.0989135131239891,
      "learning_rate": 0.00018122561773612644,
      "loss": 0.3294,
      "step": 1456
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11297992616891861,
      "learning_rate": 0.0001811995873063813,
      "loss": 0.3868,
      "step": 1457
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11128684878349304,
      "learning_rate": 0.00018117354071588585,
      "loss": 0.428,
      "step": 1458
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11378898471593857,
      "learning_rate": 0.0001811474779698241,
      "loss": 0.3913,
      "step": 1459
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.10115909576416016,
      "learning_rate": 0.0001811213990733832,
      "loss": 0.2848,
      "step": 1460
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.12516503036022186,
      "learning_rate": 0.0001810953040317534,
      "loss": 0.3807,
      "step": 1461
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.12514744699001312,
      "learning_rate": 0.00018106919285012837,
      "loss": 0.4643,
      "step": 1462
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.14014433324337006,
      "learning_rate": 0.00018104306553370485,
      "loss": 0.3271,
      "step": 1463
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11574740707874298,
      "learning_rate": 0.0001810169220876828,
      "loss": 0.3716,
      "step": 1464
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.08973167836666107,
      "learning_rate": 0.0001809907625172655,
      "loss": 0.2847,
      "step": 1465
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11931485682725906,
      "learning_rate": 0.00018096458682765926,
      "loss": 0.3041,
      "step": 1466
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11746934056282043,
      "learning_rate": 0.0001809383950240738,
      "loss": 0.3435,
      "step": 1467
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.10529693216085434,
      "learning_rate": 0.00018091218711172185,
      "loss": 0.3752,
      "step": 1468
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.12096302956342697,
      "learning_rate": 0.0001808859630958195,
      "loss": 0.3673,
      "step": 1469
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11738783866167068,
      "learning_rate": 0.00018085972298158596,
      "loss": 0.2999,
      "step": 1470
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1475694328546524,
      "learning_rate": 0.0001808334667742437,
      "loss": 0.368,
      "step": 1471
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.0823182612657547,
      "learning_rate": 0.00018080719447901832,
      "loss": 0.2755,
      "step": 1472
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.11324389278888702,
      "learning_rate": 0.00018078090610113866,
      "loss": 0.4459,
      "step": 1473
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1168639212846756,
      "learning_rate": 0.00018075460164583679,
      "loss": 0.3843,
      "step": 1474
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10760831832885742,
      "learning_rate": 0.000180728281118348,
      "loss": 0.3335,
      "step": 1475
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10323239862918854,
      "learning_rate": 0.00018070194452391065,
      "loss": 0.3518,
      "step": 1476
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.11989807337522507,
      "learning_rate": 0.00018067559186776645,
      "loss": 0.3628,
      "step": 1477
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.13484938442707062,
      "learning_rate": 0.0001806492231551602,
      "loss": 0.5067,
      "step": 1478
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16403385996818542,
      "learning_rate": 0.00018062283839133993,
      "loss": 0.2717,
      "step": 1479
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.11386776715517044,
      "learning_rate": 0.0001805964375815569,
      "loss": 0.4111,
      "step": 1480
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.09130716323852539,
      "learning_rate": 0.00018057002073106548,
      "loss": 0.3031,
      "step": 1481
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10346627980470657,
      "learning_rate": 0.00018054358784512332,
      "loss": 0.3573,
      "step": 1482
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17672060430049896,
      "learning_rate": 0.00018051713892899124,
      "loss": 0.5431,
      "step": 1483
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10265620052814484,
      "learning_rate": 0.00018049067398793323,
      "loss": 0.3577,
      "step": 1484
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.12223223596811295,
      "learning_rate": 0.00018046419302721644,
      "loss": 0.3232,
      "step": 1485
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.0997682437300682,
      "learning_rate": 0.0001804376960521113,
      "loss": 0.3776,
      "step": 1486
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.14820069074630737,
      "learning_rate": 0.0001804111830678913,
      "loss": 0.3925,
      "step": 1487
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1054140254855156,
      "learning_rate": 0.00018038465407983325,
      "loss": 0.3108,
      "step": 1488
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.08518117666244507,
      "learning_rate": 0.00018035810909321705,
      "loss": 0.2918,
      "step": 1489
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.153651624917984,
      "learning_rate": 0.00018033154811332582,
      "loss": 0.4084,
      "step": 1490
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.14969994127750397,
      "learning_rate": 0.00018030497114544585,
      "loss": 0.3633,
      "step": 1491
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.12804661691188812,
      "learning_rate": 0.00018027837819486667,
      "loss": 0.4029,
      "step": 1492
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1304250955581665,
      "learning_rate": 0.00018025176926688091,
      "loss": 0.39,
      "step": 1493
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.144698828458786,
      "learning_rate": 0.00018022514436678443,
      "loss": 0.3861,
      "step": 1494
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.13195128738880157,
      "learning_rate": 0.0001801985034998762,
      "loss": 0.4278,
      "step": 1495
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10808944702148438,
      "learning_rate": 0.00018017184667145847,
      "loss": 0.3136,
      "step": 1496
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.13366419076919556,
      "learning_rate": 0.0001801451738868366,
      "loss": 0.4166,
      "step": 1497
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.12403640896081924,
      "learning_rate": 0.00018011848515131913,
      "loss": 0.4137,
      "step": 1498
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.08538796007633209,
      "learning_rate": 0.00018009178047021779,
      "loss": 0.2871,
      "step": 1499
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1467355340719223,
      "learning_rate": 0.0001800650598488475,
      "loss": 0.3536,
      "step": 1500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.14990800619125366,
      "learning_rate": 0.00018003832329252634,
      "loss": 0.3624,
      "step": 1501
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.11421491950750351,
      "learning_rate": 0.0001800115708065755,
      "loss": 0.3201,
      "step": 1502
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.12016959488391876,
      "learning_rate": 0.00017998480239631945,
      "loss": 0.3401,
      "step": 1503
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.15151940286159515,
      "learning_rate": 0.00017995801806708578,
      "loss": 0.3405,
      "step": 1504
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.11812727153301239,
      "learning_rate": 0.00017993121782420513,
      "loss": 0.3528,
      "step": 1505
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.08292370289564133,
      "learning_rate": 0.0001799044016730116,
      "loss": 0.2624,
      "step": 1506
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.11702446639537811,
      "learning_rate": 0.0001798775696188421,
      "loss": 0.4007,
      "step": 1507
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10395041853189468,
      "learning_rate": 0.00017985072166703704,
      "loss": 0.3435,
      "step": 1508
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10870212316513062,
      "learning_rate": 0.00017982385782293968,
      "loss": 0.3858,
      "step": 1509
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.09800420701503754,
      "learning_rate": 0.0001797969780918967,
      "loss": 0.3122,
      "step": 1510
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1035100668668747,
      "learning_rate": 0.00017977008247925782,
      "loss": 0.3915,
      "step": 1511
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.08863136917352676,
      "learning_rate": 0.00017974317099037591,
      "loss": 0.2989,
      "step": 1512
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1116231381893158,
      "learning_rate": 0.00017971624363060707,
      "loss": 0.383,
      "step": 1513
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.12018470466136932,
      "learning_rate": 0.00017968930040531048,
      "loss": 0.389,
      "step": 1514
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.09886188805103302,
      "learning_rate": 0.00017966234131984855,
      "loss": 0.3245,
      "step": 1515
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11342859268188477,
      "learning_rate": 0.0001796353663795868,
      "loss": 0.4745,
      "step": 1516
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11483815312385559,
      "learning_rate": 0.00017960837558989392,
      "loss": 0.3595,
      "step": 1517
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.13362187147140503,
      "learning_rate": 0.00017958136895614174,
      "loss": 0.4416,
      "step": 1518
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.13170720636844635,
      "learning_rate": 0.00017955434648370526,
      "loss": 0.2993,
      "step": 1519
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.10418843477964401,
      "learning_rate": 0.0001795273081779626,
      "loss": 0.3031,
      "step": 1520
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.10112835466861725,
      "learning_rate": 0.00017950025404429515,
      "loss": 0.3635,
      "step": 1521
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1332915872335434,
      "learning_rate": 0.0001794731840880873,
      "loss": 0.4248,
      "step": 1522
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1291879415512085,
      "learning_rate": 0.00017944609831472663,
      "loss": 0.3551,
      "step": 1523
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.10764008015394211,
      "learning_rate": 0.00017941899672960392,
      "loss": 0.4495,
      "step": 1524
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1245196983218193,
      "learning_rate": 0.00017939187933811303,
      "loss": 0.3917,
      "step": 1525
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1647011786699295,
      "learning_rate": 0.00017936474614565104,
      "loss": 0.3703,
      "step": 1526
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.0973033756017685,
      "learning_rate": 0.00017933759715761812,
      "loss": 0.316,
      "step": 1527
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1864875853061676,
      "learning_rate": 0.00017931043237941755,
      "loss": 0.3717,
      "step": 1528
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.12233292311429977,
      "learning_rate": 0.00017928325181645592,
      "loss": 0.4063,
      "step": 1529
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11356430500745773,
      "learning_rate": 0.0001792560554741427,
      "loss": 0.3685,
      "step": 1530
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.137358158826828,
      "learning_rate": 0.00017922884335789076,
      "loss": 0.3764,
      "step": 1531
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1156955286860466,
      "learning_rate": 0.0001792016154731159,
      "loss": 0.3745,
      "step": 1532
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.12242241948843002,
      "learning_rate": 0.00017917437182523723,
      "loss": 0.2933,
      "step": 1533
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11486910283565521,
      "learning_rate": 0.00017914711241967686,
      "loss": 0.343,
      "step": 1534
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.108644038438797,
      "learning_rate": 0.0001791198372618601,
      "loss": 0.331,
      "step": 1535
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.10343213379383087,
      "learning_rate": 0.0001790925463572154,
      "loss": 0.3128,
      "step": 1536
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.09816283732652664,
      "learning_rate": 0.0001790652397111744,
      "loss": 0.2911,
      "step": 1537
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.13496892154216766,
      "learning_rate": 0.0001790379173291717,
      "loss": 0.3692,
      "step": 1538
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11271271109580994,
      "learning_rate": 0.00017901057921664517,
      "loss": 0.3368,
      "step": 1539
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11957454681396484,
      "learning_rate": 0.00017898322537903582,
      "loss": 0.4429,
      "step": 1540
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11676300317049026,
      "learning_rate": 0.0001789558558217877,
      "loss": 0.3571,
      "step": 1541
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11455120146274567,
      "learning_rate": 0.00017892847055034805,
      "loss": 0.37,
      "step": 1542
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11477352678775787,
      "learning_rate": 0.00017890106957016723,
      "loss": 0.3403,
      "step": 1543
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.11201687902212143,
      "learning_rate": 0.00017887365288669872,
      "loss": 0.3849,
      "step": 1544
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10688436776399612,
      "learning_rate": 0.00017884622050539915,
      "loss": 0.3625,
      "step": 1545
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11135364323854446,
      "learning_rate": 0.0001788187724317282,
      "loss": 0.4147,
      "step": 1546
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11407122015953064,
      "learning_rate": 0.00017879130867114876,
      "loss": 0.3539,
      "step": 1547
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.14267726242542267,
      "learning_rate": 0.0001787638292291268,
      "loss": 0.4092,
      "step": 1548
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10062309354543686,
      "learning_rate": 0.0001787363341111314,
      "loss": 0.3337,
      "step": 1549
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.14971381425857544,
      "learning_rate": 0.00017870882332263478,
      "loss": 0.3805,
      "step": 1550
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.09223338216543198,
      "learning_rate": 0.00017868129686911233,
      "loss": 0.2477,
      "step": 1551
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.13443739712238312,
      "learning_rate": 0.0001786537547560424,
      "loss": 0.3142,
      "step": 1552
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.12433169782161713,
      "learning_rate": 0.00017862619698890667,
      "loss": 0.3405,
      "step": 1553
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11041899025440216,
      "learning_rate": 0.00017859862357318975,
      "loss": 0.3504,
      "step": 1554
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11071007698774338,
      "learning_rate": 0.00017857103451437945,
      "loss": 0.3929,
      "step": 1555
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10190840810537338,
      "learning_rate": 0.00017854342981796673,
      "loss": 0.3578,
      "step": 1556
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.126723974943161,
      "learning_rate": 0.00017851580948944555,
      "loss": 0.3644,
      "step": 1557
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10320495069026947,
      "learning_rate": 0.00017848817353431312,
      "loss": 0.3043,
      "step": 1558
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11060352623462677,
      "learning_rate": 0.0001784605219580696,
      "loss": 0.3217,
      "step": 1559
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10177254676818848,
      "learning_rate": 0.0001784328547662184,
      "loss": 0.3284,
      "step": 1560
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.13704106211662292,
      "learning_rate": 0.000178405171964266,
      "loss": 0.2871,
      "step": 1561
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.08702030777931213,
      "learning_rate": 0.00017837747355772194,
      "loss": 0.3524,
      "step": 1562
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11363361030817032,
      "learning_rate": 0.0001783497595520989,
      "loss": 0.3068,
      "step": 1563
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.0853041261434555,
      "learning_rate": 0.00017832202995291265,
      "loss": 0.2917,
      "step": 1564
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11452649533748627,
      "learning_rate": 0.0001782942847656821,
      "loss": 0.313,
      "step": 1565
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1307966262102127,
      "learning_rate": 0.00017826652399592922,
      "loss": 0.3927,
      "step": 1566
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.06968724727630615,
      "learning_rate": 0.00017823874764917908,
      "loss": 0.2489,
      "step": 1567
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.08884329348802567,
      "learning_rate": 0.0001782109557309599,
      "loss": 0.2752,
      "step": 1568
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.14445629715919495,
      "learning_rate": 0.000178183148246803,
      "loss": 0.4068,
      "step": 1569
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.16455943882465363,
      "learning_rate": 0.00017815532520224268,
      "loss": 0.3388,
      "step": 1570
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.12362454831600189,
      "learning_rate": 0.00017812748660281646,
      "loss": 0.3533,
      "step": 1571
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.12490454316139221,
      "learning_rate": 0.00017809963245406495,
      "loss": 0.3889,
      "step": 1572
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10778511315584183,
      "learning_rate": 0.00017807176276153178,
      "loss": 0.3367,
      "step": 1573
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.13481499254703522,
      "learning_rate": 0.00017804387753076376,
      "loss": 0.4361,
      "step": 1574
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11714246869087219,
      "learning_rate": 0.00017801597676731068,
      "loss": 0.3993,
      "step": 1575
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10202709585428238,
      "learning_rate": 0.00017798806047672553,
      "loss": 0.3195,
      "step": 1576
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.13659755885601044,
      "learning_rate": 0.00017796012866456436,
      "loss": 0.3804,
      "step": 1577
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.14607912302017212,
      "learning_rate": 0.00017793218133638634,
      "loss": 0.3811,
      "step": 1578
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11418796330690384,
      "learning_rate": 0.00017790421849775358,
      "loss": 0.4042,
      "step": 1579
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.10522028803825378,
      "learning_rate": 0.00017787624015423145,
      "loss": 0.3626,
      "step": 1580
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.13153798878192902,
      "learning_rate": 0.00017784824631138837,
      "loss": 0.4314,
      "step": 1581
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10590030997991562,
      "learning_rate": 0.00017782023697479575,
      "loss": 0.3295,
      "step": 1582
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.11637008190155029,
      "learning_rate": 0.0001777922121500282,
      "loss": 0.2943,
      "step": 1583
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10666946321725845,
      "learning_rate": 0.00017776417184266335,
      "loss": 0.345,
      "step": 1584
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.09869476407766342,
      "learning_rate": 0.00017773611605828186,
      "loss": 0.2859,
      "step": 1585
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.0983775407075882,
      "learning_rate": 0.00017770804480246764,
      "loss": 0.3993,
      "step": 1586
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10595313459634781,
      "learning_rate": 0.00017767995808080748,
      "loss": 0.3189,
      "step": 1587
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1043817549943924,
      "learning_rate": 0.00017765185589889142,
      "loss": 0.3551,
      "step": 1588
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.12136685848236084,
      "learning_rate": 0.0001776237382623124,
      "loss": 0.3675,
      "step": 1589
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.11421531438827515,
      "learning_rate": 0.00017759560517666666,
      "loss": 0.3754,
      "step": 1590
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.146129310131073,
      "learning_rate": 0.00017756745664755327,
      "loss": 0.4357,
      "step": 1591
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.09826137125492096,
      "learning_rate": 0.00017753929268057457,
      "loss": 0.3351,
      "step": 1592
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.09349244832992554,
      "learning_rate": 0.00017751111328133585,
      "loss": 0.2793,
      "step": 1593
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1216839849948883,
      "learning_rate": 0.00017748291845544553,
      "loss": 0.3172,
      "step": 1594
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.08948248624801636,
      "learning_rate": 0.0001774547082085151,
      "loss": 0.3009,
      "step": 1595
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.13489466905593872,
      "learning_rate": 0.00017742648254615907,
      "loss": 0.3373,
      "step": 1596
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.15327902138233185,
      "learning_rate": 0.00017739824147399512,
      "loss": 0.4124,
      "step": 1597
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.15290318429470062,
      "learning_rate": 0.00017736998499764384,
      "loss": 0.546,
      "step": 1598
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10283338278532028,
      "learning_rate": 0.00017734171312272905,
      "loss": 0.2877,
      "step": 1599
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.12880121171474457,
      "learning_rate": 0.0001773134258548775,
      "loss": 0.442,
      "step": 1600
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.11233607679605484,
      "learning_rate": 0.00017728512319971915,
      "loss": 0.411,
      "step": 1601
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.12894116342067719,
      "learning_rate": 0.00017725680516288684,
      "loss": 0.3851,
      "step": 1602
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.11037945747375488,
      "learning_rate": 0.00017722847175001663,
      "loss": 0.3406,
      "step": 1603
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10017132759094238,
      "learning_rate": 0.00017720012296674757,
      "loss": 0.3109,
      "step": 1604
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10499175637960434,
      "learning_rate": 0.00017717175881872175,
      "loss": 0.3131,
      "step": 1605
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.11231164634227753,
      "learning_rate": 0.0001771433793115844,
      "loss": 0.2958,
      "step": 1606
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.09835965186357498,
      "learning_rate": 0.00017711498445098365,
      "loss": 0.3094,
      "step": 1607
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10286623984575272,
      "learning_rate": 0.00017708657424257086,
      "loss": 0.3363,
      "step": 1608
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.10062514990568161,
      "learning_rate": 0.0001770581486920004,
      "loss": 0.335,
      "step": 1609
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.12627096474170685,
      "learning_rate": 0.00017702970780492965,
      "loss": 0.2968,
      "step": 1610
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.11309679597616196,
      "learning_rate": 0.00017700125158701902,
      "loss": 0.2868,
      "step": 1611
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.120238296687603,
      "learning_rate": 0.00017697278004393202,
      "loss": 0.3573,
      "step": 1612
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.09467598795890808,
      "learning_rate": 0.0001769442931813352,
      "loss": 0.2834,
      "step": 1613
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.11250912398099899,
      "learning_rate": 0.0001769157910048982,
      "loss": 0.3285,
      "step": 1614
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1281065046787262,
      "learning_rate": 0.00017688727352029363,
      "loss": 0.3637,
      "step": 1615
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1147850826382637,
      "learning_rate": 0.00017685874073319714,
      "loss": 0.3918,
      "step": 1616
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.12880158424377441,
      "learning_rate": 0.00017683019264928758,
      "loss": 0.3249,
      "step": 1617
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10157907009124756,
      "learning_rate": 0.00017680162927424665,
      "loss": 0.3185,
      "step": 1618
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.13269343972206116,
      "learning_rate": 0.00017677305061375917,
      "loss": 0.3137,
      "step": 1619
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11678031086921692,
      "learning_rate": 0.00017674445667351308,
      "loss": 0.3585,
      "step": 1620
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1313018649816513,
      "learning_rate": 0.0001767158474591992,
      "loss": 0.3643,
      "step": 1621
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1432977169752121,
      "learning_rate": 0.00017668722297651157,
      "loss": 0.3674,
      "step": 1622
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10259398072957993,
      "learning_rate": 0.0001766585832311471,
      "loss": 0.3122,
      "step": 1623
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.09011361002922058,
      "learning_rate": 0.00017662992822880584,
      "loss": 0.3683,
      "step": 1624
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10275968909263611,
      "learning_rate": 0.0001766012579751909,
      "loss": 0.3373,
      "step": 1625
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10126303881406784,
      "learning_rate": 0.0001765725724760083,
      "loss": 0.3382,
      "step": 1626
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.16319891810417175,
      "learning_rate": 0.00017654387173696726,
      "loss": 0.3524,
      "step": 1627
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11313381791114807,
      "learning_rate": 0.00017651515576377986,
      "loss": 0.344,
      "step": 1628
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.12056194990873337,
      "learning_rate": 0.00017648642456216136,
      "loss": 0.3834,
      "step": 1629
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1229514554142952,
      "learning_rate": 0.00017645767813782994,
      "loss": 0.362,
      "step": 1630
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10297301411628723,
      "learning_rate": 0.0001764289164965069,
      "loss": 0.33,
      "step": 1631
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11224599182605743,
      "learning_rate": 0.0001764001396439165,
      "loss": 0.3444,
      "step": 1632
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10537690669298172,
      "learning_rate": 0.00017637134758578606,
      "loss": 0.3665,
      "step": 1633
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.09660334885120392,
      "learning_rate": 0.00017634254032784593,
      "loss": 0.2733,
      "step": 1634
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.172719344496727,
      "learning_rate": 0.00017631371787582946,
      "loss": 0.3148,
      "step": 1635
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.136999249458313,
      "learning_rate": 0.00017628488023547307,
      "loss": 0.3816,
      "step": 1636
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.17127478122711182,
      "learning_rate": 0.00017625602741251612,
      "loss": 0.3793,
      "step": 1637
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.12963399291038513,
      "learning_rate": 0.0001762271594127011,
      "loss": 0.3577,
      "step": 1638
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.14866268634796143,
      "learning_rate": 0.0001761982762417734,
      "loss": 0.4789,
      "step": 1639
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10500819236040115,
      "learning_rate": 0.00017616937790548157,
      "loss": 0.365,
      "step": 1640
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11596862971782684,
      "learning_rate": 0.00017614046440957704,
      "loss": 0.3601,
      "step": 1641
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1153968796133995,
      "learning_rate": 0.00017611153575981434,
      "loss": 0.3158,
      "step": 1642
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1100998967885971,
      "learning_rate": 0.00017608259196195101,
      "loss": 0.3489,
      "step": 1643
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.13268515467643738,
      "learning_rate": 0.00017605363302174759,
      "loss": 0.3361,
      "step": 1644
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11201373487710953,
      "learning_rate": 0.00017602465894496762,
      "loss": 0.337,
      "step": 1645
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.09543894976377487,
      "learning_rate": 0.00017599566973737764,
      "loss": 0.3872,
      "step": 1646
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.12026344239711761,
      "learning_rate": 0.00017596666540474728,
      "loss": 0.419,
      "step": 1647
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11211555451154709,
      "learning_rate": 0.0001759376459528491,
      "loss": 0.3335,
      "step": 1648
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.12231959402561188,
      "learning_rate": 0.0001759086113874587,
      "loss": 0.3716,
      "step": 1649
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11636540293693542,
      "learning_rate": 0.0001758795617143547,
      "loss": 0.3614,
      "step": 1650
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.10046426951885223,
      "learning_rate": 0.0001758504969393187,
      "loss": 0.3081,
      "step": 1651
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11749548465013504,
      "learning_rate": 0.00017582141706813534,
      "loss": 0.3182,
      "step": 1652
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10873885452747345,
      "learning_rate": 0.00017579232210659219,
      "loss": 0.3763,
      "step": 1653
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1432945430278778,
      "learning_rate": 0.0001757632120604799,
      "loss": 0.3766,
      "step": 1654
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.15740345418453217,
      "learning_rate": 0.0001757340869355921,
      "loss": 0.3249,
      "step": 1655
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12708452343940735,
      "learning_rate": 0.00017570494673772543,
      "loss": 0.4045,
      "step": 1656
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10484876483678818,
      "learning_rate": 0.00017567579147267952,
      "loss": 0.2678,
      "step": 1657
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11404378712177277,
      "learning_rate": 0.000175646621146257,
      "loss": 0.3767,
      "step": 1658
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10659288614988327,
      "learning_rate": 0.00017561743576426344,
      "loss": 0.3806,
      "step": 1659
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.13231594860553741,
      "learning_rate": 0.0001755882353325075,
      "loss": 0.4317,
      "step": 1660
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12431154400110245,
      "learning_rate": 0.00017555901985680085,
      "loss": 0.2971,
      "step": 1661
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12263079732656479,
      "learning_rate": 0.00017552978934295805,
      "loss": 0.3795,
      "step": 1662
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11794834583997726,
      "learning_rate": 0.0001755005437967967,
      "loss": 0.4107,
      "step": 1663
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12475059181451797,
      "learning_rate": 0.00017547128322413738,
      "loss": 0.3678,
      "step": 1664
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12017983198165894,
      "learning_rate": 0.00017544200763080372,
      "loss": 0.3252,
      "step": 1665
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.09191033244132996,
      "learning_rate": 0.00017541271702262225,
      "loss": 0.2388,
      "step": 1666
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12381541728973389,
      "learning_rate": 0.00017538341140542257,
      "loss": 0.3076,
      "step": 1667
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11982053518295288,
      "learning_rate": 0.00017535409078503725,
      "loss": 0.2364,
      "step": 1668
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.09584946185350418,
      "learning_rate": 0.00017532475516730177,
      "loss": 0.3779,
      "step": 1669
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10480742156505585,
      "learning_rate": 0.00017529540455805465,
      "loss": 0.326,
      "step": 1670
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.0978224128484726,
      "learning_rate": 0.00017526603896313747,
      "loss": 0.3038,
      "step": 1671
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12577930092811584,
      "learning_rate": 0.00017523665838839464,
      "loss": 0.402,
      "step": 1672
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.12388330698013306,
      "learning_rate": 0.0001752072628396737,
      "loss": 0.3593,
      "step": 1673
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10973227024078369,
      "learning_rate": 0.00017517785232282505,
      "loss": 0.3078,
      "step": 1674
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10720078647136688,
      "learning_rate": 0.00017514842684370212,
      "loss": 0.3544,
      "step": 1675
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10793936997652054,
      "learning_rate": 0.00017511898640816133,
      "loss": 0.3051,
      "step": 1676
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.120241180062294,
      "learning_rate": 0.00017508953102206206,
      "loss": 0.3222,
      "step": 1677
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.14659282565116882,
      "learning_rate": 0.00017506006069126668,
      "loss": 0.4754,
      "step": 1678
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11998473107814789,
      "learning_rate": 0.00017503057542164055,
      "loss": 0.4578,
      "step": 1679
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11151035875082016,
      "learning_rate": 0.0001750010752190519,
      "loss": 0.3426,
      "step": 1680
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1249084621667862,
      "learning_rate": 0.00017497156008937205,
      "loss": 0.3882,
      "step": 1681
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11565227806568146,
      "learning_rate": 0.00017494203003847524,
      "loss": 0.4001,
      "step": 1682
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.0998338982462883,
      "learning_rate": 0.00017491248507223875,
      "loss": 0.3049,
      "step": 1683
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10904170572757721,
      "learning_rate": 0.00017488292519654265,
      "loss": 0.3446,
      "step": 1684
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.11195902526378632,
      "learning_rate": 0.0001748533504172702,
      "loss": 0.3671,
      "step": 1685
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.10406693071126938,
      "learning_rate": 0.00017482376074030748,
      "loss": 0.323,
      "step": 1686
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12585678696632385,
      "learning_rate": 0.00017479415617154359,
      "loss": 0.3673,
      "step": 1687
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12566539645195007,
      "learning_rate": 0.00017476453671687057,
      "loss": 0.4256,
      "step": 1688
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.10408950597047806,
      "learning_rate": 0.00017473490238218342,
      "loss": 0.3648,
      "step": 1689
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1114833801984787,
      "learning_rate": 0.00017470525317338012,
      "loss": 0.388,
      "step": 1690
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.10401240736246109,
      "learning_rate": 0.00017467558909636162,
      "loss": 0.3575,
      "step": 1691
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1152929812669754,
      "learning_rate": 0.0001746459101570318,
      "loss": 0.3921,
      "step": 1692
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11567544937133789,
      "learning_rate": 0.00017461621636129753,
      "loss": 0.3586,
      "step": 1693
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.09369594603776932,
      "learning_rate": 0.00017458650771506862,
      "loss": 0.3281,
      "step": 1694
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11676707863807678,
      "learning_rate": 0.0001745567842242578,
      "loss": 0.3225,
      "step": 1695
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11046070605516434,
      "learning_rate": 0.0001745270458947808,
      "loss": 0.3684,
      "step": 1696
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.09101502597332001,
      "learning_rate": 0.0001744972927325563,
      "loss": 0.283,
      "step": 1697
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.102754145860672,
      "learning_rate": 0.00017446752474350593,
      "loss": 0.3592,
      "step": 1698
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11921937018632889,
      "learning_rate": 0.00017443774193355428,
      "loss": 0.3414,
      "step": 1699
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.09419535845518112,
      "learning_rate": 0.00017440794430862884,
      "loss": 0.3041,
      "step": 1700
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2642562985420227,
      "learning_rate": 0.00017437813187466008,
      "loss": 0.4588,
      "step": 1701
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.10515999048948288,
      "learning_rate": 0.00017434830463758144,
      "loss": 0.3598,
      "step": 1702
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11271286755800247,
      "learning_rate": 0.0001743184626033293,
      "loss": 0.3745,
      "step": 1703
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1193004921078682,
      "learning_rate": 0.00017428860577784296,
      "loss": 0.4252,
      "step": 1704
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1317516714334488,
      "learning_rate": 0.00017425873416706465,
      "loss": 0.3293,
      "step": 1705
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.117654949426651,
      "learning_rate": 0.00017422884777693965,
      "loss": 0.3002,
      "step": 1706
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.10750757902860641,
      "learning_rate": 0.000174198946613416,
      "loss": 0.3241,
      "step": 1707
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11386019736528397,
      "learning_rate": 0.0001741690306824448,
      "loss": 0.3846,
      "step": 1708
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15086328983306885,
      "learning_rate": 0.00017413909998998008,
      "loss": 0.3834,
      "step": 1709
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17621666193008423,
      "learning_rate": 0.00017410915454197886,
      "loss": 0.4486,
      "step": 1710
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.14085881412029266,
      "learning_rate": 0.00017407919434440095,
      "loss": 0.2839,
      "step": 1711
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11655130237340927,
      "learning_rate": 0.00017404921940320918,
      "loss": 0.3568,
      "step": 1712
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11909297108650208,
      "learning_rate": 0.00017401922972436936,
      "loss": 0.4227,
      "step": 1713
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.10137944668531418,
      "learning_rate": 0.0001739892253138502,
      "loss": 0.3806,
      "step": 1714
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12510253489017487,
      "learning_rate": 0.00017395920617762327,
      "loss": 0.3501,
      "step": 1715
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12455502152442932,
      "learning_rate": 0.00017392917232166317,
      "loss": 0.4187,
      "step": 1716
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.09716039896011353,
      "learning_rate": 0.00017389912375194737,
      "loss": 0.2622,
      "step": 1717
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11661958694458008,
      "learning_rate": 0.0001738690604744563,
      "loss": 0.3859,
      "step": 1718
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1463143229484558,
      "learning_rate": 0.0001738389824951733,
      "loss": 0.3228,
      "step": 1719
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1286306232213974,
      "learning_rate": 0.0001738088898200846,
      "loss": 0.4131,
      "step": 1720
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1269696205854416,
      "learning_rate": 0.00017377878245517948,
      "loss": 0.4171,
      "step": 1721
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12394875288009644,
      "learning_rate": 0.00017374866040645,
      "loss": 0.3889,
      "step": 1722
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11048490554094315,
      "learning_rate": 0.00017371852367989123,
      "loss": 0.3448,
      "step": 1723
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1430826485157013,
      "learning_rate": 0.00017368837228150109,
      "loss": 0.4066,
      "step": 1724
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.10807797312736511,
      "learning_rate": 0.0001736582062172805,
      "loss": 0.3384,
      "step": 1725
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.09643642604351044,
      "learning_rate": 0.00017362802549323326,
      "loss": 0.32,
      "step": 1726
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.13098517060279846,
      "learning_rate": 0.0001735978301153661,
      "loss": 0.3898,
      "step": 1727
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11509711295366287,
      "learning_rate": 0.00017356762008968862,
      "loss": 0.4279,
      "step": 1728
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.10801098495721817,
      "learning_rate": 0.00017353739542221337,
      "loss": 0.3318,
      "step": 1729
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11604401469230652,
      "learning_rate": 0.00017350715611895586,
      "loss": 0.3309,
      "step": 1730
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.15227776765823364,
      "learning_rate": 0.00017347690218593443,
      "loss": 0.5355,
      "step": 1731
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.08957637846469879,
      "learning_rate": 0.00017344663362917038,
      "loss": 0.3245,
      "step": 1732
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.13973699510097504,
      "learning_rate": 0.00017341635045468791,
      "loss": 0.4322,
      "step": 1733
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.06312297284603119,
      "learning_rate": 0.00017338605266851417,
      "loss": 0.1722,
      "step": 1734
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.14516445994377136,
      "learning_rate": 0.0001733557402766791,
      "loss": 0.3718,
      "step": 1735
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.08926516026258469,
      "learning_rate": 0.0001733254132852157,
      "loss": 0.2824,
      "step": 1736
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.12242384254932404,
      "learning_rate": 0.00017329507170015974,
      "loss": 0.422,
      "step": 1737
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.10269638895988464,
      "learning_rate": 0.00017326471552755,
      "loss": 0.3339,
      "step": 1738
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.14233556389808655,
      "learning_rate": 0.0001732343447734281,
      "loss": 0.317,
      "step": 1739
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11993616074323654,
      "learning_rate": 0.00017320395944383856,
      "loss": 0.3382,
      "step": 1740
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.08773251622915268,
      "learning_rate": 0.00017317355954482886,
      "loss": 0.3158,
      "step": 1741
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.13750603795051575,
      "learning_rate": 0.0001731431450824493,
      "loss": 0.3807,
      "step": 1742
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.10725067555904388,
      "learning_rate": 0.00017311271606275315,
      "loss": 0.3319,
      "step": 1743
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.12769442796707153,
      "learning_rate": 0.0001730822724917965,
      "loss": 0.411,
      "step": 1744
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11257798969745636,
      "learning_rate": 0.00017305181437563848,
      "loss": 0.3811,
      "step": 1745
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1038261353969574,
      "learning_rate": 0.00017302134172034094,
      "loss": 0.3126,
      "step": 1746
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.10797976702451706,
      "learning_rate": 0.00017299085453196871,
      "loss": 0.3083,
      "step": 1747
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.09995542466640472,
      "learning_rate": 0.0001729603528165895,
      "loss": 0.2666,
      "step": 1748
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11849681288003922,
      "learning_rate": 0.00017292983658027397,
      "loss": 0.3275,
      "step": 1749
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11584685742855072,
      "learning_rate": 0.00017289930582909551,
      "loss": 0.3508,
      "step": 1750
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.09338850528001785,
      "learning_rate": 0.0001728687605691306,
      "loss": 0.2554,
      "step": 1751
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.12128554284572601,
      "learning_rate": 0.00017283820080645848,
      "loss": 0.3256,
      "step": 1752
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1287328004837036,
      "learning_rate": 0.0001728076265471613,
      "loss": 0.4017,
      "step": 1753
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.09234647452831268,
      "learning_rate": 0.00017277703779732412,
      "loss": 0.2637,
      "step": 1754
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.10982686281204224,
      "learning_rate": 0.00017274643456303482,
      "loss": 0.3731,
      "step": 1755
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.10934562236070633,
      "learning_rate": 0.00017271581685038428,
      "loss": 0.3689,
      "step": 1756
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.11869701743125916,
      "learning_rate": 0.00017268518466546614,
      "loss": 0.345,
      "step": 1757
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11618447303771973,
      "learning_rate": 0.00017265453801437698,
      "loss": 0.3606,
      "step": 1758
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11584267020225525,
      "learning_rate": 0.00017262387690321625,
      "loss": 0.4096,
      "step": 1759
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.17503942549228668,
      "learning_rate": 0.0001725932013380863,
      "loss": 0.3711,
      "step": 1760
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11962595582008362,
      "learning_rate": 0.0001725625113250923,
      "loss": 0.3309,
      "step": 1761
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.17464084923267365,
      "learning_rate": 0.00017253180687034237,
      "loss": 0.4347,
      "step": 1762
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.15992143750190735,
      "learning_rate": 0.00017250108797994745,
      "loss": 0.4375,
      "step": 1763
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1487414836883545,
      "learning_rate": 0.00017247035466002136,
      "loss": 0.352,
      "step": 1764
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12021131068468094,
      "learning_rate": 0.0001724396069166808,
      "loss": 0.3365,
      "step": 1765
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.08504694700241089,
      "learning_rate": 0.00017240884475604534,
      "loss": 0.2765,
      "step": 1766
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12322793155908585,
      "learning_rate": 0.00017237806818423744,
      "loss": 0.4507,
      "step": 1767
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11287570744752884,
      "learning_rate": 0.00017234727720738237,
      "loss": 0.3957,
      "step": 1768
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.10509108752012253,
      "learning_rate": 0.00017231647183160834,
      "loss": 0.2712,
      "step": 1769
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.09916170686483383,
      "learning_rate": 0.00017228565206304637,
      "loss": 0.2888,
      "step": 1770
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12855176627635956,
      "learning_rate": 0.00017225481790783038,
      "loss": 0.3322,
      "step": 1771
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1246248409152031,
      "learning_rate": 0.00017222396937209715,
      "loss": 0.4091,
      "step": 1772
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12529893219470978,
      "learning_rate": 0.00017219310646198626,
      "loss": 0.3806,
      "step": 1773
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11110204458236694,
      "learning_rate": 0.00017216222918364026,
      "loss": 0.3326,
      "step": 1774
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.14308467507362366,
      "learning_rate": 0.00017213133754320444,
      "loss": 0.3783,
      "step": 1775
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2001328319311142,
      "learning_rate": 0.0001721004315468271,
      "loss": 0.3656,
      "step": 1776
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.09152114391326904,
      "learning_rate": 0.0001720695112006592,
      "loss": 0.3099,
      "step": 1777
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11771384626626968,
      "learning_rate": 0.00017203857651085474,
      "loss": 0.3838,
      "step": 1778
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.10141478478908539,
      "learning_rate": 0.0001720076274835705,
      "loss": 0.3122,
      "step": 1779
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12390196323394775,
      "learning_rate": 0.00017197666412496605,
      "loss": 0.4902,
      "step": 1780
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.10111285001039505,
      "learning_rate": 0.00017194568644120394,
      "loss": 0.3774,
      "step": 1781
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.09492283314466476,
      "learning_rate": 0.00017191469443844943,
      "loss": 0.3578,
      "step": 1782
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.13337190449237823,
      "learning_rate": 0.00017188368812287079,
      "loss": 0.3662,
      "step": 1783
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.10837318748235703,
      "learning_rate": 0.00017185266750063897,
      "loss": 0.3822,
      "step": 1784
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12859849631786346,
      "learning_rate": 0.0001718216325779279,
      "loss": 0.3626,
      "step": 1785
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.14843423664569855,
      "learning_rate": 0.00017179058336091432,
      "loss": 0.4238,
      "step": 1786
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.15141503512859344,
      "learning_rate": 0.0001717595198557777,
      "loss": 0.4085,
      "step": 1787
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.10488402098417282,
      "learning_rate": 0.00017172844206870064,
      "loss": 0.3637,
      "step": 1788
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11885213851928711,
      "learning_rate": 0.0001716973500058682,
      "loss": 0.3664,
      "step": 1789
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1287459135055542,
      "learning_rate": 0.00017166624367346862,
      "loss": 0.3314,
      "step": 1790
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1662192940711975,
      "learning_rate": 0.00017163512307769276,
      "loss": 0.3039,
      "step": 1791
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1199912428855896,
      "learning_rate": 0.00017160398822473446,
      "loss": 0.3561,
      "step": 1792
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12032821029424667,
      "learning_rate": 0.00017157283912079026,
      "loss": 0.3857,
      "step": 1793
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12841103971004486,
      "learning_rate": 0.00017154167577205967,
      "loss": 0.3814,
      "step": 1794
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.19609394669532776,
      "learning_rate": 0.00017151049818474494,
      "loss": 0.3952,
      "step": 1795
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12299039959907532,
      "learning_rate": 0.00017147930636505124,
      "loss": 0.323,
      "step": 1796
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.10260078310966492,
      "learning_rate": 0.00017144810031918643,
      "loss": 0.2987,
      "step": 1797
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1271284818649292,
      "learning_rate": 0.00017141688005336143,
      "loss": 0.3934,
      "step": 1798
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1381721943616867,
      "learning_rate": 0.00017138564557378974,
      "loss": 0.3948,
      "step": 1799
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12074995785951614,
      "learning_rate": 0.00017135439688668785,
      "loss": 0.3965,
      "step": 1800
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.11197847872972488,
      "learning_rate": 0.00017132313399827499,
      "loss": 0.3729,
      "step": 1801
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1289457380771637,
      "learning_rate": 0.0001712918569147733,
      "loss": 0.3878,
      "step": 1802
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12431266903877258,
      "learning_rate": 0.00017126056564240773,
      "loss": 0.4097,
      "step": 1803
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.0993679091334343,
      "learning_rate": 0.00017122926018740597,
      "loss": 0.287,
      "step": 1804
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.11566605418920517,
      "learning_rate": 0.0001711979405559986,
      "loss": 0.3819,
      "step": 1805
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.115850530564785,
      "learning_rate": 0.00017116660675441905,
      "loss": 0.354,
      "step": 1806
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.14054472744464874,
      "learning_rate": 0.00017113525878890347,
      "loss": 0.391,
      "step": 1807
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1834619790315628,
      "learning_rate": 0.00017110389666569092,
      "loss": 0.3313,
      "step": 1808
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1266697645187378,
      "learning_rate": 0.00017107252039102325,
      "loss": 0.3717,
      "step": 1809
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.08935990184545517,
      "learning_rate": 0.00017104112997114512,
      "loss": 0.2813,
      "step": 1810
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.07971537113189697,
      "learning_rate": 0.000171009725412304,
      "loss": 0.2395,
      "step": 1811
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.11299449950456619,
      "learning_rate": 0.0001709783067207502,
      "loss": 0.3735,
      "step": 1812
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12995247542858124,
      "learning_rate": 0.00017094687390273685,
      "loss": 0.3713,
      "step": 1813
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.10115548968315125,
      "learning_rate": 0.0001709154269645198,
      "loss": 0.2993,
      "step": 1814
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.14324574172496796,
      "learning_rate": 0.0001708839659123578,
      "loss": 0.38,
      "step": 1815
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.10234800726175308,
      "learning_rate": 0.00017085249075251245,
      "loss": 0.3373,
      "step": 1816
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.10515189170837402,
      "learning_rate": 0.000170821001491248,
      "loss": 0.3034,
      "step": 1817
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.10825292021036148,
      "learning_rate": 0.0001707894981348317,
      "loss": 0.3438,
      "step": 1818
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1123007982969284,
      "learning_rate": 0.0001707579806895334,
      "loss": 0.3193,
      "step": 1819
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.11374085396528244,
      "learning_rate": 0.00017072644916162592,
      "loss": 0.4068,
      "step": 1820
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.10066479444503784,
      "learning_rate": 0.00017069490355738485,
      "loss": 0.2929,
      "step": 1821
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.08912532776594162,
      "learning_rate": 0.00017066334388308852,
      "loss": 0.2887,
      "step": 1822
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12559179961681366,
      "learning_rate": 0.00017063177014501804,
      "loss": 0.3118,
      "step": 1823
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1278374344110489,
      "learning_rate": 0.0001706001823494575,
      "loss": 0.5253,
      "step": 1824
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1111014112830162,
      "learning_rate": 0.0001705685805026936,
      "loss": 0.3263,
      "step": 1825
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.11249566823244095,
      "learning_rate": 0.00017053696461101581,
      "loss": 0.3174,
      "step": 1826
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1431344747543335,
      "learning_rate": 0.00017050533468071662,
      "loss": 0.228,
      "step": 1827
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.12315735220909119,
      "learning_rate": 0.00017047369071809113,
      "loss": 0.3351,
      "step": 1828
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.10925856232643127,
      "learning_rate": 0.00017044203272943725,
      "loss": 0.3447,
      "step": 1829
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.09867826104164124,
      "learning_rate": 0.00017041036072105574,
      "loss": 0.3326,
      "step": 1830
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.13591019809246063,
      "learning_rate": 0.00017037867469925014,
      "loss": 0.4128,
      "step": 1831
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.13551579415798187,
      "learning_rate": 0.0001703469746703267,
      "loss": 0.4033,
      "step": 1832
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.09918715059757233,
      "learning_rate": 0.00017031526064059457,
      "loss": 0.3219,
      "step": 1833
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.09813570976257324,
      "learning_rate": 0.00017028353261636564,
      "loss": 0.3074,
      "step": 1834
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.12193585932254791,
      "learning_rate": 0.0001702517906039546,
      "loss": 0.3522,
      "step": 1835
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.109669029712677,
      "learning_rate": 0.00017022003460967882,
      "loss": 0.3186,
      "step": 1836
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14078228175640106,
      "learning_rate": 0.0001701882646398586,
      "loss": 0.41,
      "step": 1837
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.12952792644500732,
      "learning_rate": 0.00017015648070081696,
      "loss": 0.3966,
      "step": 1838
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14027710258960724,
      "learning_rate": 0.00017012468279887965,
      "loss": 0.4129,
      "step": 1839
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.11462529003620148,
      "learning_rate": 0.00017009287094037534,
      "loss": 0.2984,
      "step": 1840
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1197345182299614,
      "learning_rate": 0.00017006104513163527,
      "loss": 0.331,
      "step": 1841
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.12496758997440338,
      "learning_rate": 0.00017002920537899366,
      "loss": 0.4069,
      "step": 1842
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.10831049829721451,
      "learning_rate": 0.0001699973516887874,
      "loss": 0.3719,
      "step": 1843
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.11725310236215591,
      "learning_rate": 0.00016996548406735616,
      "loss": 0.2959,
      "step": 1844
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.12457410246133804,
      "learning_rate": 0.00016993360252104243,
      "loss": 0.3047,
      "step": 1845
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14750640094280243,
      "learning_rate": 0.00016990170705619137,
      "loss": 0.4774,
      "step": 1846
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.08746971189975739,
      "learning_rate": 0.00016986979767915099,
      "loss": 0.315,
      "step": 1847
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.09918583929538727,
      "learning_rate": 0.0001698378743962721,
      "loss": 0.3111,
      "step": 1848
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3960433900356293,
      "learning_rate": 0.0001698059372139082,
      "loss": 0.4404,
      "step": 1849
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.12353476136922836,
      "learning_rate": 0.0001697739861384156,
      "loss": 0.3868,
      "step": 1850
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.0959688052535057,
      "learning_rate": 0.00016974202117615335,
      "loss": 0.247,
      "step": 1851
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14759154617786407,
      "learning_rate": 0.0001697100423334833,
      "loss": 0.327,
      "step": 1852
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.10849101096391678,
      "learning_rate": 0.00016967804961677,
      "loss": 0.3423,
      "step": 1853
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1194528266787529,
      "learning_rate": 0.00016964604303238085,
      "loss": 0.3772,
      "step": 1854
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.11884871125221252,
      "learning_rate": 0.00016961402258668592,
      "loss": 0.3765,
      "step": 1855
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.10156980901956558,
      "learning_rate": 0.0001695819882860581,
      "loss": 0.3444,
      "step": 1856
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.11611797660589218,
      "learning_rate": 0.00016954994013687304,
      "loss": 0.401,
      "step": 1857
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.12024842202663422,
      "learning_rate": 0.00016951787814550908,
      "loss": 0.3111,
      "step": 1858
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.2132711559534073,
      "learning_rate": 0.00016948580231834737,
      "loss": 0.4095,
      "step": 1859
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.12920701503753662,
      "learning_rate": 0.00016945371266177185,
      "loss": 0.4496,
      "step": 1860
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.14460168778896332,
      "learning_rate": 0.00016942160918216912,
      "loss": 0.4605,
      "step": 1861
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1345536708831787,
      "learning_rate": 0.00016938949188592854,
      "loss": 0.4718,
      "step": 1862
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.08361200243234634,
      "learning_rate": 0.00016935736077944234,
      "loss": 0.2942,
      "step": 1863
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.10897993296384811,
      "learning_rate": 0.00016932521586910534,
      "loss": 0.3509,
      "step": 1864
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.17056293785572052,
      "learning_rate": 0.00016929305716131525,
      "loss": 0.3909,
      "step": 1865
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1328822374343872,
      "learning_rate": 0.00016926088466247242,
      "loss": 0.3375,
      "step": 1866
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.16599445044994354,
      "learning_rate": 0.00016922869837897994,
      "loss": 0.4488,
      "step": 1867
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11840397864580154,
      "learning_rate": 0.0001691964983172438,
      "loss": 0.385,
      "step": 1868
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10038098692893982,
      "learning_rate": 0.00016916428448367248,
      "loss": 0.2573,
      "step": 1869
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10552521049976349,
      "learning_rate": 0.00016913205688467745,
      "loss": 0.3258,
      "step": 1870
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10429473221302032,
      "learning_rate": 0.00016909981552667272,
      "loss": 0.3084,
      "step": 1871
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11018881946802139,
      "learning_rate": 0.00016906756041607524,
      "loss": 0.3817,
      "step": 1872
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10860694199800491,
      "learning_rate": 0.00016903529155930447,
      "loss": 0.3622,
      "step": 1873
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11653906852006912,
      "learning_rate": 0.00016900300896278278,
      "loss": 0.3536,
      "step": 1874
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10043604671955109,
      "learning_rate": 0.0001689707126329352,
      "loss": 0.3311,
      "step": 1875
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.16034220159053802,
      "learning_rate": 0.00016893840257618955,
      "loss": 0.4233,
      "step": 1876
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.09432338923215866,
      "learning_rate": 0.00016890607879897624,
      "loss": 0.3163,
      "step": 1877
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10831227153539658,
      "learning_rate": 0.0001688737413077286,
      "loss": 0.3148,
      "step": 1878
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.09662546962499619,
      "learning_rate": 0.00016884139010888257,
      "loss": 0.2875,
      "step": 1879
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1192319467663765,
      "learning_rate": 0.00016880902520887686,
      "loss": 0.4156,
      "step": 1880
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.09361769258975983,
      "learning_rate": 0.00016877664661415289,
      "loss": 0.2905,
      "step": 1881
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.12666410207748413,
      "learning_rate": 0.00016874425433115482,
      "loss": 0.3268,
      "step": 1882
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.12119393050670624,
      "learning_rate": 0.00016871184836632946,
      "loss": 0.3945,
      "step": 1883
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11166708916425705,
      "learning_rate": 0.0001686794287261265,
      "loss": 0.3772,
      "step": 1884
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.12527622282505035,
      "learning_rate": 0.0001686469954169982,
      "loss": 0.33,
      "step": 1885
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.09491878002882004,
      "learning_rate": 0.00016861454844539965,
      "loss": 0.2756,
      "step": 1886
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10090143978595734,
      "learning_rate": 0.00016858208781778854,
      "loss": 0.197,
      "step": 1887
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.12619182467460632,
      "learning_rate": 0.00016854961354062538,
      "loss": 0.3528,
      "step": 1888
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10282236337661743,
      "learning_rate": 0.00016851712562037342,
      "loss": 0.3959,
      "step": 1889
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10904429852962494,
      "learning_rate": 0.0001684846240634985,
      "loss": 0.3673,
      "step": 1890
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.12151867896318436,
      "learning_rate": 0.00016845210887646926,
      "loss": 0.3391,
      "step": 1891
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1114334985613823,
      "learning_rate": 0.00016841958006575704,
      "loss": 0.2663,
      "step": 1892
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.12540565431118011,
      "learning_rate": 0.00016838703763783587,
      "loss": 0.3227,
      "step": 1893
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10796088725328445,
      "learning_rate": 0.00016835448159918255,
      "loss": 0.3026,
      "step": 1894
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1494649052619934,
      "learning_rate": 0.0001683219119562765,
      "loss": 0.397,
      "step": 1895
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1291244477033615,
      "learning_rate": 0.00016828932871559992,
      "loss": 0.3632,
      "step": 1896
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11057741940021515,
      "learning_rate": 0.00016825673188363772,
      "loss": 0.3623,
      "step": 1897
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11992838233709335,
      "learning_rate": 0.00016822412146687738,
      "loss": 0.3785,
      "step": 1898
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1530032604932785,
      "learning_rate": 0.00016819149747180934,
      "loss": 0.4057,
      "step": 1899
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1278637796640396,
      "learning_rate": 0.00016815885990492646,
      "loss": 0.394,
      "step": 1900
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.13209037482738495,
      "learning_rate": 0.0001681262087727245,
      "loss": 0.3568,
      "step": 1901
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.09172412008047104,
      "learning_rate": 0.0001680935440817018,
      "loss": 0.285,
      "step": 1902
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11771465837955475,
      "learning_rate": 0.00016806086583835955,
      "loss": 0.3736,
      "step": 1903
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1406763643026352,
      "learning_rate": 0.00016802817404920143,
      "loss": 0.395,
      "step": 1904
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1374635249376297,
      "learning_rate": 0.00016799546872073399,
      "loss": 0.4151,
      "step": 1905
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11759959161281586,
      "learning_rate": 0.0001679627498594664,
      "loss": 0.3784,
      "step": 1906
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.12478438764810562,
      "learning_rate": 0.0001679300174719105,
      "loss": 0.3365,
      "step": 1907
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11973313987255096,
      "learning_rate": 0.00016789727156458088,
      "loss": 0.314,
      "step": 1908
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.10576432943344116,
      "learning_rate": 0.00016786451214399482,
      "loss": 0.3185,
      "step": 1909
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11167708784341812,
      "learning_rate": 0.0001678317392166722,
      "loss": 0.3652,
      "step": 1910
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.13893413543701172,
      "learning_rate": 0.0001677989527891357,
      "loss": 0.3269,
      "step": 1911
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.10263565927743912,
      "learning_rate": 0.00016776615286791065,
      "loss": 0.3664,
      "step": 1912
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1416660100221634,
      "learning_rate": 0.00016773333945952504,
      "loss": 0.4325,
      "step": 1913
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1409655213356018,
      "learning_rate": 0.0001677005125705095,
      "loss": 0.3448,
      "step": 1914
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.13207228481769562,
      "learning_rate": 0.0001676676722073975,
      "loss": 0.3507,
      "step": 1915
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.10631933808326721,
      "learning_rate": 0.00016763481837672503,
      "loss": 0.3164,
      "step": 1916
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11898331344127655,
      "learning_rate": 0.00016760195108503085,
      "loss": 0.2799,
      "step": 1917
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1580609828233719,
      "learning_rate": 0.00016756907033885638,
      "loss": 0.4224,
      "step": 1918
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11316581070423126,
      "learning_rate": 0.00016753617614474568,
      "loss": 0.3118,
      "step": 1919
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.07208000868558884,
      "learning_rate": 0.00016750326850924557,
      "loss": 0.1836,
      "step": 1920
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11251979321241379,
      "learning_rate": 0.00016747034743890544,
      "loss": 0.4166,
      "step": 1921
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.10286465287208557,
      "learning_rate": 0.00016743741294027742,
      "loss": 0.3313,
      "step": 1922
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1195400282740593,
      "learning_rate": 0.0001674044650199163,
      "loss": 0.3305,
      "step": 1923
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1508331596851349,
      "learning_rate": 0.00016737150368437956,
      "loss": 0.3669,
      "step": 1924
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.14678068459033966,
      "learning_rate": 0.00016733852894022734,
      "loss": 0.391,
      "step": 1925
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.09943485260009766,
      "learning_rate": 0.0001673055407940224,
      "loss": 0.3269,
      "step": 1926
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.09202472120523453,
      "learning_rate": 0.00016727253925233023,
      "loss": 0.2466,
      "step": 1927
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.08881119638681412,
      "learning_rate": 0.00016723952432171895,
      "loss": 0.2698,
      "step": 1928
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11885479837656021,
      "learning_rate": 0.00016720649600875936,
      "loss": 0.3413,
      "step": 1929
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11333014816045761,
      "learning_rate": 0.00016717345432002497,
      "loss": 0.4281,
      "step": 1930
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.10472338646650314,
      "learning_rate": 0.00016714039926209181,
      "loss": 0.3558,
      "step": 1931
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.09829236567020416,
      "learning_rate": 0.00016710733084153873,
      "loss": 0.2938,
      "step": 1932
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.09782233089208603,
      "learning_rate": 0.00016707424906494718,
      "loss": 0.2636,
      "step": 1933
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11947358399629593,
      "learning_rate": 0.00016704115393890122,
      "loss": 0.3455,
      "step": 1934
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.11864858120679855,
      "learning_rate": 0.0001670080454699876,
      "loss": 0.3265,
      "step": 1935
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.09965687245130539,
      "learning_rate": 0.00016697492366479582,
      "loss": 0.3455,
      "step": 1936
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.12320756912231445,
      "learning_rate": 0.00016694178852991783,
      "loss": 0.3937,
      "step": 1937
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11759105324745178,
      "learning_rate": 0.00016690864007194844,
      "loss": 0.3424,
      "step": 1938
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10353174060583115,
      "learning_rate": 0.000166875478297485,
      "loss": 0.3572,
      "step": 1939
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11053541302680969,
      "learning_rate": 0.0001668423032131275,
      "loss": 0.3101,
      "step": 1940
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.13792693614959717,
      "learning_rate": 0.00016680911482547868,
      "loss": 0.4261,
      "step": 1941
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10734246671199799,
      "learning_rate": 0.00016677591314114378,
      "loss": 0.33,
      "step": 1942
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11506402492523193,
      "learning_rate": 0.00016674269816673083,
      "loss": 0.2657,
      "step": 1943
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10802154988050461,
      "learning_rate": 0.0001667094699088504,
      "loss": 0.3102,
      "step": 1944
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11681544780731201,
      "learning_rate": 0.00016667622837411575,
      "loss": 0.3771,
      "step": 1945
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.15003857016563416,
      "learning_rate": 0.00016664297356914283,
      "loss": 0.3892,
      "step": 1946
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.13154147565364838,
      "learning_rate": 0.00016660970550055011,
      "loss": 0.3481,
      "step": 1947
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.09039132297039032,
      "learning_rate": 0.0001665764241749588,
      "loss": 0.2746,
      "step": 1948
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10472429543733597,
      "learning_rate": 0.00016654312959899273,
      "loss": 0.3657,
      "step": 1949
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.14540815353393555,
      "learning_rate": 0.0001665098217792783,
      "loss": 0.5262,
      "step": 1950
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1165979877114296,
      "learning_rate": 0.00016647650072244464,
      "loss": 0.3713,
      "step": 1951
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11883535236120224,
      "learning_rate": 0.0001664431664351235,
      "loss": 0.3719,
      "step": 1952
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11651775985956192,
      "learning_rate": 0.00016640981892394917,
      "loss": 0.3564,
      "step": 1953
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.13584241271018982,
      "learning_rate": 0.0001663764581955587,
      "loss": 0.3967,
      "step": 1954
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10753151774406433,
      "learning_rate": 0.0001663430842565917,
      "loss": 0.2707,
      "step": 1955
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.12524624168872833,
      "learning_rate": 0.00016630969711369038,
      "loss": 0.4142,
      "step": 1956
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.09510782361030579,
      "learning_rate": 0.00016627629677349966,
      "loss": 0.3352,
      "step": 1957
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.14486676454544067,
      "learning_rate": 0.000166242883242667,
      "loss": 0.3776,
      "step": 1958
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.13256850838661194,
      "learning_rate": 0.00016620945652784256,
      "loss": 0.3771,
      "step": 1959
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.09856701642274857,
      "learning_rate": 0.0001661760166356791,
      "loss": 0.4119,
      "step": 1960
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1137491762638092,
      "learning_rate": 0.00016614256357283202,
      "loss": 0.3257,
      "step": 1961
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.13585405051708221,
      "learning_rate": 0.00016610909734595923,
      "loss": 0.4588,
      "step": 1962
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10221884399652481,
      "learning_rate": 0.0001660756179617214,
      "loss": 0.351,
      "step": 1963
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11955512315034866,
      "learning_rate": 0.0001660421254267818,
      "loss": 0.3688,
      "step": 1964
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.11545667052268982,
      "learning_rate": 0.00016600861974780623,
      "loss": 0.351,
      "step": 1965
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1606285721063614,
      "learning_rate": 0.00016597510093146317,
      "loss": 0.3173,
      "step": 1966
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.09541342407464981,
      "learning_rate": 0.00016594156898442372,
      "loss": 0.2906,
      "step": 1967
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.10626693069934845,
      "learning_rate": 0.00016590802391336156,
      "loss": 0.3001,
      "step": 1968
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.12282346189022064,
      "learning_rate": 0.000165874465724953,
      "loss": 0.413,
      "step": 1969
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1576402336359024,
      "learning_rate": 0.00016584089442587695,
      "loss": 0.4372,
      "step": 1970
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11788780987262726,
      "learning_rate": 0.00016580731002281498,
      "loss": 0.3109,
      "step": 1971
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.09626170247793198,
      "learning_rate": 0.00016577371252245117,
      "loss": 0.3173,
      "step": 1972
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13131166994571686,
      "learning_rate": 0.0001657401019314723,
      "loss": 0.3339,
      "step": 1973
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.10727494210004807,
      "learning_rate": 0.00016570647825656773,
      "loss": 0.2359,
      "step": 1974
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13486024737358093,
      "learning_rate": 0.00016567284150442938,
      "loss": 0.4298,
      "step": 1975
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11082731187343597,
      "learning_rate": 0.00016563919168175183,
      "loss": 0.3328,
      "step": 1976
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.17377503216266632,
      "learning_rate": 0.00016560552879523222,
      "loss": 0.3538,
      "step": 1977
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11787591874599457,
      "learning_rate": 0.0001655718528515703,
      "loss": 0.3176,
      "step": 1978
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.09002994000911713,
      "learning_rate": 0.00016553816385746846,
      "loss": 0.278,
      "step": 1979
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1778406947851181,
      "learning_rate": 0.00016550446181963163,
      "loss": 0.3683,
      "step": 1980
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1629987210035324,
      "learning_rate": 0.0001654707467447673,
      "loss": 0.4443,
      "step": 1981
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11663981527090073,
      "learning_rate": 0.00016543701863958577,
      "loss": 0.3501,
      "step": 1982
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16061627864837646,
      "learning_rate": 0.00016540327751079966,
      "loss": 0.3931,
      "step": 1983
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.15678350627422333,
      "learning_rate": 0.00016536952336512428,
      "loss": 0.3395,
      "step": 1984
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1472875475883484,
      "learning_rate": 0.0001653357562092776,
      "loss": 0.3716,
      "step": 1985
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11891048401594162,
      "learning_rate": 0.00016530197604998015,
      "loss": 0.3579,
      "step": 1986
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.10968131572008133,
      "learning_rate": 0.000165268182893955,
      "loss": 0.3778,
      "step": 1987
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11444341391324997,
      "learning_rate": 0.0001652343767479278,
      "loss": 0.3507,
      "step": 1988
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.133339524269104,
      "learning_rate": 0.00016520055761862684,
      "loss": 0.4185,
      "step": 1989
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.10511058568954468,
      "learning_rate": 0.00016516672551278303,
      "loss": 0.3167,
      "step": 1990
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11058049649000168,
      "learning_rate": 0.00016513288043712971,
      "loss": 0.3731,
      "step": 1991
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11047988384962082,
      "learning_rate": 0.00016509902239840297,
      "loss": 0.3797,
      "step": 1992
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.10251277685165405,
      "learning_rate": 0.0001650651514033414,
      "loss": 0.3825,
      "step": 1993
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13734149932861328,
      "learning_rate": 0.00016503126745868617,
      "loss": 0.4483,
      "step": 1994
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11315692216157913,
      "learning_rate": 0.000164997370571181,
      "loss": 0.3273,
      "step": 1995
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1220388188958168,
      "learning_rate": 0.00016496346074757224,
      "loss": 0.4276,
      "step": 1996
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11650997400283813,
      "learning_rate": 0.0001649295379946088,
      "loss": 0.3912,
      "step": 1997
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13574513792991638,
      "learning_rate": 0.00016489560231904214,
      "loss": 0.3878,
      "step": 1998
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.14038731157779694,
      "learning_rate": 0.00016486165372762635,
      "loss": 0.4723,
      "step": 1999
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.14836342632770538,
      "learning_rate": 0.000164827692227118,
      "loss": 0.4407,
      "step": 2000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13243229687213898,
      "learning_rate": 0.0001647937178242763,
      "loss": 0.4445,
      "step": 2001
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11324409395456314,
      "learning_rate": 0.000164759730525863,
      "loss": 0.3696,
      "step": 2002
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.15246152877807617,
      "learning_rate": 0.00016472573033864246,
      "loss": 0.3661,
      "step": 2003
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11343985050916672,
      "learning_rate": 0.00016469171726938152,
      "loss": 0.3892,
      "step": 2004
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.11825722455978394,
      "learning_rate": 0.00016465769132484963,
      "loss": 0.3939,
      "step": 2005
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.12339004129171371,
      "learning_rate": 0.00016462365251181885,
      "loss": 0.3599,
      "step": 2006
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1425759643316269,
      "learning_rate": 0.00016458960083706373,
      "loss": 0.3696,
      "step": 2007
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13163815438747406,
      "learning_rate": 0.00016455553630736138,
      "loss": 0.4469,
      "step": 2008
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.12602034211158752,
      "learning_rate": 0.00016452145892949154,
      "loss": 0.3318,
      "step": 2009
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13849644362926483,
      "learning_rate": 0.00016448736871023641,
      "loss": 0.4182,
      "step": 2010
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.14377906918525696,
      "learning_rate": 0.00016445326565638085,
      "loss": 0.4083,
      "step": 2011
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13060341775417328,
      "learning_rate": 0.0001644191497747122,
      "loss": 0.434,
      "step": 2012
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1479429304599762,
      "learning_rate": 0.0001643850210720204,
      "loss": 0.3557,
      "step": 2013
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.14229798316955566,
      "learning_rate": 0.00016435087955509785,
      "loss": 0.4053,
      "step": 2014
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.12673890590667725,
      "learning_rate": 0.0001643167252307396,
      "loss": 0.3874,
      "step": 2015
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.09462446719408035,
      "learning_rate": 0.00016428255810574326,
      "loss": 0.2687,
      "step": 2016
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.11283478140830994,
      "learning_rate": 0.00016424837818690885,
      "loss": 0.3759,
      "step": 2017
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.10798042267560959,
      "learning_rate": 0.00016421418548103915,
      "loss": 0.311,
      "step": 2018
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.15253835916519165,
      "learning_rate": 0.00016417997999493923,
      "loss": 0.3587,
      "step": 2019
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.12765605747699738,
      "learning_rate": 0.00016414576173541697,
      "loss": 0.3987,
      "step": 2020
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13732314109802246,
      "learning_rate": 0.00016411153070928255,
      "loss": 0.3937,
      "step": 2021
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13775575160980225,
      "learning_rate": 0.00016407728692334884,
      "loss": 0.387,
      "step": 2022
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.11343642324209213,
      "learning_rate": 0.00016404303038443125,
      "loss": 0.2923,
      "step": 2023
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13521189987659454,
      "learning_rate": 0.00016400876109934765,
      "loss": 0.3936,
      "step": 2024
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.09368500113487244,
      "learning_rate": 0.00016397447907491846,
      "loss": 0.2378,
      "step": 2025
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.12450776249170303,
      "learning_rate": 0.00016394018431796674,
      "loss": 0.368,
      "step": 2026
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.2302698940038681,
      "learning_rate": 0.00016390587683531792,
      "loss": 0.3392,
      "step": 2027
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1132052019238472,
      "learning_rate": 0.0001638715566338001,
      "loss": 0.2747,
      "step": 2028
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.17187832295894623,
      "learning_rate": 0.00016383722372024387,
      "loss": 0.4468,
      "step": 2029
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.14255347847938538,
      "learning_rate": 0.00016380287810148226,
      "loss": 0.3268,
      "step": 2030
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13680727779865265,
      "learning_rate": 0.00016376851978435099,
      "loss": 0.4443,
      "step": 2031
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.12812167406082153,
      "learning_rate": 0.00016373414877568818,
      "loss": 0.252,
      "step": 2032
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1282844841480255,
      "learning_rate": 0.00016369976508233454,
      "loss": 0.3393,
      "step": 2033
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1409836858510971,
      "learning_rate": 0.0001636653687111333,
      "loss": 0.4225,
      "step": 2034
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8162317276000977,
      "learning_rate": 0.00016363095966893018,
      "loss": 0.4849,
      "step": 2035
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.13340745866298676,
      "learning_rate": 0.00016359653796257345,
      "loss": 0.3916,
      "step": 2036
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.16469062864780426,
      "learning_rate": 0.0001635621035989139,
      "loss": 0.4983,
      "step": 2037
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.11516322940587997,
      "learning_rate": 0.00016352765658480476,
      "loss": 0.3624,
      "step": 2038
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1396704465150833,
      "learning_rate": 0.0001634931969271019,
      "loss": 0.3996,
      "step": 2039
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.12058892846107483,
      "learning_rate": 0.0001634587246326637,
      "loss": 0.3488,
      "step": 2040
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.14494234323501587,
      "learning_rate": 0.00016342423970835092,
      "loss": 0.3101,
      "step": 2041
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14542868733406067,
      "learning_rate": 0.000163389742161027,
      "loss": 0.4202,
      "step": 2042
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11948263645172119,
      "learning_rate": 0.00016335523199755779,
      "loss": 0.3981,
      "step": 2043
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1067240834236145,
      "learning_rate": 0.00016332070922481164,
      "loss": 0.2847,
      "step": 2044
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1331961750984192,
      "learning_rate": 0.0001632861738496595,
      "loss": 0.3574,
      "step": 2045
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.12094812840223312,
      "learning_rate": 0.00016325162587897473,
      "loss": 0.3667,
      "step": 2046
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.09151126444339752,
      "learning_rate": 0.00016321706531963328,
      "loss": 0.3073,
      "step": 2047
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11578798294067383,
      "learning_rate": 0.00016318249217851355,
      "loss": 0.3218,
      "step": 2048
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.13880814611911774,
      "learning_rate": 0.00016314790646249641,
      "loss": 0.4089,
      "step": 2049
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14018824696540833,
      "learning_rate": 0.0001631133081784654,
      "loss": 0.3473,
      "step": 2050
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.12531036138534546,
      "learning_rate": 0.00016307869733330632,
      "loss": 0.3672,
      "step": 2051
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1013171449303627,
      "learning_rate": 0.00016304407393390768,
      "loss": 0.3405,
      "step": 2052
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11078048497438431,
      "learning_rate": 0.00016300943798716039,
      "loss": 0.2923,
      "step": 2053
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11758942157030106,
      "learning_rate": 0.00016297478949995782,
      "loss": 0.3404,
      "step": 2054
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14011943340301514,
      "learning_rate": 0.0001629401284791959,
      "loss": 0.4164,
      "step": 2055
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14111055433750153,
      "learning_rate": 0.0001629054549317731,
      "loss": 0.508,
      "step": 2056
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.13535760343074799,
      "learning_rate": 0.00016287076886459026,
      "loss": 0.3831,
      "step": 2057
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.12652795016765594,
      "learning_rate": 0.0001628360702845508,
      "loss": 0.3348,
      "step": 2058
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.10822674632072449,
      "learning_rate": 0.00016280135919856061,
      "loss": 0.3415,
      "step": 2059
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11238878965377808,
      "learning_rate": 0.00016276663561352807,
      "loss": 0.3128,
      "step": 2060
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1415816992521286,
      "learning_rate": 0.00016273189953636404,
      "loss": 0.4287,
      "step": 2061
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11043884605169296,
      "learning_rate": 0.00016269715097398183,
      "loss": 0.3059,
      "step": 2062
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11277639865875244,
      "learning_rate": 0.00016266238993329732,
      "loss": 0.4111,
      "step": 2063
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.11274953931570053,
      "learning_rate": 0.00016262761642122883,
      "loss": 0.2901,
      "step": 2064
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.09422565996646881,
      "learning_rate": 0.00016259283044469712,
      "loss": 0.2798,
      "step": 2065
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.09572041779756546,
      "learning_rate": 0.0001625580320106255,
      "loss": 0.3129,
      "step": 2066
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.12172695249319077,
      "learning_rate": 0.00016252322112593972,
      "loss": 0.3452,
      "step": 2067
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.13305771350860596,
      "learning_rate": 0.00016248839779756802,
      "loss": 0.3816,
      "step": 2068
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.13349615037441254,
      "learning_rate": 0.00016245356203244108,
      "loss": 0.3797,
      "step": 2069
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.13127487897872925,
      "learning_rate": 0.00016241871383749216,
      "loss": 0.3625,
      "step": 2070
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.10421496629714966,
      "learning_rate": 0.00016238385321965687,
      "loss": 0.3275,
      "step": 2071
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.14187127351760864,
      "learning_rate": 0.00016234898018587337,
      "loss": 0.3839,
      "step": 2072
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.13178277015686035,
      "learning_rate": 0.00016231409474308227,
      "loss": 0.3669,
      "step": 2073
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.12825177609920502,
      "learning_rate": 0.0001622791968982266,
      "loss": 0.3537,
      "step": 2074
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.13712362945079803,
      "learning_rate": 0.00016224428665825193,
      "loss": 0.3923,
      "step": 2075
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.10717079043388367,
      "learning_rate": 0.0001622093640301063,
      "loss": 0.2838,
      "step": 2076
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.15104587376117706,
      "learning_rate": 0.00016217442902074017,
      "loss": 0.3438,
      "step": 2077
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1326591819524765,
      "learning_rate": 0.00016213948163710647,
      "loss": 0.3745,
      "step": 2078
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.10695898532867432,
      "learning_rate": 0.00016210452188616058,
      "loss": 0.3283,
      "step": 2079
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.07605679333209991,
      "learning_rate": 0.00016206954977486047,
      "loss": 0.2135,
      "step": 2080
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.13263507187366486,
      "learning_rate": 0.00016203456531016635,
      "loss": 0.2346,
      "step": 2081
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.10666503757238388,
      "learning_rate": 0.00016199956849904102,
      "loss": 0.2379,
      "step": 2082
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.18292485177516937,
      "learning_rate": 0.00016196455934844978,
      "loss": 0.4088,
      "step": 2083
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.14494481682777405,
      "learning_rate": 0.0001619295378653603,
      "loss": 0.4103,
      "step": 2084
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.12071926146745682,
      "learning_rate": 0.00016189450405674268,
      "loss": 0.3247,
      "step": 2085
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.144143208861351,
      "learning_rate": 0.00016185945792956963,
      "loss": 0.4498,
      "step": 2086
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.13770294189453125,
      "learning_rate": 0.0001618243994908161,
      "loss": 0.3453,
      "step": 2087
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.12544026970863342,
      "learning_rate": 0.00016178932874745967,
      "loss": 0.3243,
      "step": 2088
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.09355073422193527,
      "learning_rate": 0.0001617542457064803,
      "loss": 0.2515,
      "step": 2089
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.12509852647781372,
      "learning_rate": 0.0001617191503748603,
      "loss": 0.3688,
      "step": 2090
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.12132246792316437,
      "learning_rate": 0.00016168404275958463,
      "loss": 0.2779,
      "step": 2091
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11932683736085892,
      "learning_rate": 0.0001616489228676405,
      "loss": 0.3569,
      "step": 2092
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.13188697397708893,
      "learning_rate": 0.0001616137907060177,
      "loss": 0.3682,
      "step": 2093
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11956774443387985,
      "learning_rate": 0.0001615786462817084,
      "loss": 0.3634,
      "step": 2094
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11779983341693878,
      "learning_rate": 0.00016154348960170723,
      "loss": 0.3525,
      "step": 2095
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11651404201984406,
      "learning_rate": 0.00016150832067301122,
      "loss": 0.3222,
      "step": 2096
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1081485003232956,
      "learning_rate": 0.00016147313950261988,
      "loss": 0.4296,
      "step": 2097
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11683442443609238,
      "learning_rate": 0.00016143794609753512,
      "loss": 0.3992,
      "step": 2098
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11622165888547897,
      "learning_rate": 0.0001614027404647614,
      "loss": 0.3789,
      "step": 2099
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.12663008272647858,
      "learning_rate": 0.00016136752261130538,
      "loss": 0.3406,
      "step": 2100
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.12390351295471191,
      "learning_rate": 0.00016133229254417642,
      "loss": 0.4122,
      "step": 2101
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.13360224664211273,
      "learning_rate": 0.0001612970502703861,
      "loss": 0.401,
      "step": 2102
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.12348685413599014,
      "learning_rate": 0.00016126179579694855,
      "loss": 0.367,
      "step": 2103
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1184137687087059,
      "learning_rate": 0.00016122652913088032,
      "loss": 0.3595,
      "step": 2104
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11958616971969604,
      "learning_rate": 0.00016119125027920031,
      "loss": 0.3344,
      "step": 2105
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.14617066085338593,
      "learning_rate": 0.0001611559592489299,
      "loss": 0.3276,
      "step": 2106
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1183183416724205,
      "learning_rate": 0.00016112065604709296,
      "loss": 0.2924,
      "step": 2107
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.11690012365579605,
      "learning_rate": 0.00016108534068071557,
      "loss": 0.3592,
      "step": 2108
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.09931230545043945,
      "learning_rate": 0.00016105001315682652,
      "loss": 0.3188,
      "step": 2109
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.10595601052045822,
      "learning_rate": 0.00016101467348245677,
      "loss": 0.3218,
      "step": 2110
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.13883163034915924,
      "learning_rate": 0.00016097932166463986,
      "loss": 0.2929,
      "step": 2111
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1045011430978775,
      "learning_rate": 0.00016094395771041166,
      "loss": 0.3002,
      "step": 2112
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1378602385520935,
      "learning_rate": 0.0001609085816268105,
      "loss": 0.3549,
      "step": 2113
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.13846424221992493,
      "learning_rate": 0.00016087319342087704,
      "loss": 0.3926,
      "step": 2114
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.12071985751390457,
      "learning_rate": 0.00016083779309965452,
      "loss": 0.3395,
      "step": 2115
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.09839537739753723,
      "learning_rate": 0.00016080238067018841,
      "loss": 0.3042,
      "step": 2116
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11041319370269775,
      "learning_rate": 0.00016076695613952672,
      "loss": 0.2893,
      "step": 2117
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11127011477947235,
      "learning_rate": 0.00016073151951471982,
      "loss": 0.3446,
      "step": 2118
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1239214688539505,
      "learning_rate": 0.00016069607080282044,
      "loss": 0.3507,
      "step": 2119
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1379854530096054,
      "learning_rate": 0.00016066061001088376,
      "loss": 0.3395,
      "step": 2120
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.19929511845111847,
      "learning_rate": 0.00016062513714596742,
      "loss": 0.3757,
      "step": 2121
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1267772912979126,
      "learning_rate": 0.0001605896522151314,
      "loss": 0.3627,
      "step": 2122
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11478438228368759,
      "learning_rate": 0.000160554155225438,
      "loss": 0.3135,
      "step": 2123
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10575732588768005,
      "learning_rate": 0.00016051864618395217,
      "loss": 0.3603,
      "step": 2124
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.17675518989562988,
      "learning_rate": 0.0001604831250977409,
      "loss": 0.3165,
      "step": 2125
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10193076729774475,
      "learning_rate": 0.00016044759197387395,
      "loss": 0.3029,
      "step": 2126
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11746607720851898,
      "learning_rate": 0.00016041204681942322,
      "loss": 0.3905,
      "step": 2127
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11137069016695023,
      "learning_rate": 0.00016037648964146311,
      "loss": 0.3445,
      "step": 2128
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11374373733997345,
      "learning_rate": 0.00016034092044707034,
      "loss": 0.3344,
      "step": 2129
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.13287921249866486,
      "learning_rate": 0.00016030533924332412,
      "loss": 0.354,
      "step": 2130
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1258814036846161,
      "learning_rate": 0.00016026974603730598,
      "loss": 0.3884,
      "step": 2131
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1427268236875534,
      "learning_rate": 0.00016023414083609987,
      "loss": 0.4293,
      "step": 2132
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.09653009474277496,
      "learning_rate": 0.0001601985236467921,
      "loss": 0.3111,
      "step": 2133
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11251824349164963,
      "learning_rate": 0.0001601628944764714,
      "loss": 0.3771,
      "step": 2134
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.15779559314250946,
      "learning_rate": 0.00016012725333222885,
      "loss": 0.3804,
      "step": 2135
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10974971950054169,
      "learning_rate": 0.00016009160022115797,
      "loss": 0.3462,
      "step": 2136
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10546170920133591,
      "learning_rate": 0.00016005593515035454,
      "loss": 0.2756,
      "step": 2137
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.12528486549854279,
      "learning_rate": 0.00016002025812691687,
      "loss": 0.3661,
      "step": 2138
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11506935954093933,
      "learning_rate": 0.00015998456915794558,
      "loss": 0.3157,
      "step": 2139
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10764600336551666,
      "learning_rate": 0.00015994886825054365,
      "loss": 0.2721,
      "step": 2140
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10336314886808395,
      "learning_rate": 0.00015991315541181644,
      "loss": 0.2797,
      "step": 2141
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1453503519296646,
      "learning_rate": 0.00015987743064887173,
      "loss": 0.4794,
      "step": 2142
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.12122286111116409,
      "learning_rate": 0.00015984169396881961,
      "loss": 0.3966,
      "step": 2143
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.14854103326797485,
      "learning_rate": 0.00015980594537877259,
      "loss": 0.4617,
      "step": 2144
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.12973009049892426,
      "learning_rate": 0.00015977018488584554,
      "loss": 0.3229,
      "step": 2145
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10424675047397614,
      "learning_rate": 0.00015973441249715568,
      "loss": 0.334,
      "step": 2146
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.08596445620059967,
      "learning_rate": 0.00015969862821982263,
      "loss": 0.2362,
      "step": 2147
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.11783364415168762,
      "learning_rate": 0.00015966283206096833,
      "loss": 0.333,
      "step": 2148
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1149614155292511,
      "learning_rate": 0.00015962702402771712,
      "loss": 0.3856,
      "step": 2149
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11013655364513397,
      "learning_rate": 0.00015959120412719572,
      "loss": 0.3793,
      "step": 2150
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.10170182585716248,
      "learning_rate": 0.00015955537236653314,
      "loss": 0.3773,
      "step": 2151
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.13110768795013428,
      "learning_rate": 0.00015951952875286086,
      "loss": 0.3461,
      "step": 2152
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11686035990715027,
      "learning_rate": 0.00015948367329331263,
      "loss": 0.367,
      "step": 2153
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.09735414385795593,
      "learning_rate": 0.00015944780599502453,
      "loss": 0.2855,
      "step": 2154
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1377243548631668,
      "learning_rate": 0.0001594119268651351,
      "loss": 0.3569,
      "step": 2155
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11272239685058594,
      "learning_rate": 0.0001593760359107852,
      "loss": 0.3131,
      "step": 2156
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.14107461273670197,
      "learning_rate": 0.000159340133139118,
      "loss": 0.4097,
      "step": 2157
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1317196786403656,
      "learning_rate": 0.00015930421855727908,
      "loss": 0.374,
      "step": 2158
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.118023581802845,
      "learning_rate": 0.0001592682921724163,
      "loss": 0.3567,
      "step": 2159
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11710908263921738,
      "learning_rate": 0.00015923235399167992,
      "loss": 0.2858,
      "step": 2160
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1129293218255043,
      "learning_rate": 0.00015919640402222256,
      "loss": 0.3375,
      "step": 2161
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11782549321651459,
      "learning_rate": 0.00015916044227119914,
      "loss": 0.298,
      "step": 2162
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.16090647876262665,
      "learning_rate": 0.00015912446874576696,
      "loss": 0.3056,
      "step": 2163
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.10302618891000748,
      "learning_rate": 0.00015908848345308563,
      "loss": 0.2795,
      "step": 2164
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11077247560024261,
      "learning_rate": 0.0001590524864003172,
      "loss": 0.296,
      "step": 2165
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1342843770980835,
      "learning_rate": 0.0001590164775946259,
      "loss": 0.3861,
      "step": 2166
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.12348823249340057,
      "learning_rate": 0.00015898045704317842,
      "loss": 0.3086,
      "step": 2167
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.12023252993822098,
      "learning_rate": 0.0001589444247531437,
      "loss": 0.3556,
      "step": 2168
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.10318348556756973,
      "learning_rate": 0.00015890838073169317,
      "loss": 0.291,
      "step": 2169
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.12654699385166168,
      "learning_rate": 0.0001588723249860004,
      "loss": 0.3481,
      "step": 2170
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.10773304104804993,
      "learning_rate": 0.00015883625752324143,
      "loss": 0.3087,
      "step": 2171
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1317320168018341,
      "learning_rate": 0.00015880017835059458,
      "loss": 0.4545,
      "step": 2172
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.20112279057502747,
      "learning_rate": 0.00015876408747524047,
      "loss": 0.4191,
      "step": 2173
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.12987568974494934,
      "learning_rate": 0.00015872798490436217,
      "loss": 0.3771,
      "step": 2174
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11280974000692368,
      "learning_rate": 0.00015869187064514493,
      "loss": 0.3375,
      "step": 2175
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.13736583292484283,
      "learning_rate": 0.00015865574470477642,
      "loss": 0.3968,
      "step": 2176
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11595883220434189,
      "learning_rate": 0.00015861960709044655,
      "loss": 0.3785,
      "step": 2177
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11780896037817001,
      "learning_rate": 0.00015858345780934773,
      "loss": 0.3487,
      "step": 2178
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1317235827445984,
      "learning_rate": 0.00015854729686867446,
      "loss": 0.4417,
      "step": 2179
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1620243638753891,
      "learning_rate": 0.0001585111242756237,
      "loss": 0.4671,
      "step": 2180
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.08480839431285858,
      "learning_rate": 0.00015847494003739474,
      "loss": 0.2408,
      "step": 2181
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.13864336907863617,
      "learning_rate": 0.00015843874416118908,
      "loss": 0.4446,
      "step": 2182
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.11806381493806839,
      "learning_rate": 0.00015840253665421069,
      "loss": 0.3257,
      "step": 2183
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11683552712202072,
      "learning_rate": 0.00015836631752366568,
      "loss": 0.3628,
      "step": 2184
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1261538416147232,
      "learning_rate": 0.00015833008677676265,
      "loss": 0.4202,
      "step": 2185
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11674309521913528,
      "learning_rate": 0.0001582938444207124,
      "loss": 0.2833,
      "step": 2186
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.09384864568710327,
      "learning_rate": 0.000158257590462728,
      "loss": 0.2963,
      "step": 2187
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1340123414993286,
      "learning_rate": 0.00015822132491002497,
      "loss": 0.4089,
      "step": 2188
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11445935815572739,
      "learning_rate": 0.00015818504776982106,
      "loss": 0.3013,
      "step": 2189
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.10128863900899887,
      "learning_rate": 0.0001581487590493363,
      "loss": 0.3217,
      "step": 2190
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1396293193101883,
      "learning_rate": 0.000158112458755793,
      "loss": 0.2994,
      "step": 2191
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1611517071723938,
      "learning_rate": 0.00015807614689641595,
      "loss": 0.3981,
      "step": 2192
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1201988086104393,
      "learning_rate": 0.00015803982347843205,
      "loss": 0.3692,
      "step": 2193
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11579541862010956,
      "learning_rate": 0.00015800348850907056,
      "loss": 0.3471,
      "step": 2194
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.0897984653711319,
      "learning_rate": 0.00015796714199556305,
      "loss": 0.2492,
      "step": 2195
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1303194761276245,
      "learning_rate": 0.00015793078394514348,
      "loss": 0.4403,
      "step": 2196
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.14420188963413239,
      "learning_rate": 0.00015789441436504787,
      "loss": 0.4621,
      "step": 2197
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11660484224557877,
      "learning_rate": 0.0001578580332625147,
      "loss": 0.3254,
      "step": 2198
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11621712148189545,
      "learning_rate": 0.00015782164064478483,
      "loss": 0.3964,
      "step": 2199
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15994472801685333,
      "learning_rate": 0.00015778523651910123,
      "loss": 0.4623,
      "step": 2200
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.10961616039276123,
      "learning_rate": 0.0001577488208927092,
      "loss": 0.3461,
      "step": 2201
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11532068252563477,
      "learning_rate": 0.0001577123937728564,
      "loss": 0.3683,
      "step": 2202
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.14493735134601593,
      "learning_rate": 0.00015767595516679274,
      "loss": 0.3738,
      "step": 2203
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.10273855179548264,
      "learning_rate": 0.0001576395050817704,
      "loss": 0.3065,
      "step": 2204
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.10354836285114288,
      "learning_rate": 0.00015760304352504387,
      "loss": 0.3641,
      "step": 2205
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.13578663766384125,
      "learning_rate": 0.00015756657050386994,
      "loss": 0.3753,
      "step": 2206
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1179385632276535,
      "learning_rate": 0.0001575300860255076,
      "loss": 0.3702,
      "step": 2207
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.11095136404037476,
      "learning_rate": 0.0001574935900972182,
      "loss": 0.3269,
      "step": 2208
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.10086981952190399,
      "learning_rate": 0.00015745708272626533,
      "loss": 0.368,
      "step": 2209
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.0980776846408844,
      "learning_rate": 0.00015742056391991488,
      "loss": 0.3177,
      "step": 2210
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.09094483405351639,
      "learning_rate": 0.00015738403368543505,
      "loss": 0.2719,
      "step": 2211
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.10617964714765549,
      "learning_rate": 0.00015734749203009617,
      "loss": 0.3531,
      "step": 2212
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.12437251955270767,
      "learning_rate": 0.00015731093896117102,
      "loss": 0.3758,
      "step": 2213
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1364401876926422,
      "learning_rate": 0.00015727437448593458,
      "loss": 0.3427,
      "step": 2214
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.09666910022497177,
      "learning_rate": 0.0001572377986116641,
      "loss": 0.316,
      "step": 2215
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.14338520169258118,
      "learning_rate": 0.000157201211345639,
      "loss": 0.3445,
      "step": 2216
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1607491374015808,
      "learning_rate": 0.00015716461269514115,
      "loss": 0.3455,
      "step": 2217
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.12195237725973129,
      "learning_rate": 0.00015712800266745459,
      "loss": 0.3336,
      "step": 2218
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.159025177359581,
      "learning_rate": 0.00015709138126986563,
      "loss": 0.4509,
      "step": 2219
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.11868032813072205,
      "learning_rate": 0.00015705474850966287,
      "loss": 0.3048,
      "step": 2220
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.11512510478496552,
      "learning_rate": 0.00015701810439413703,
      "loss": 0.3612,
      "step": 2221
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.13082240521907806,
      "learning_rate": 0.00015698144893058134,
      "loss": 0.273,
      "step": 2222
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14904797077178955,
      "learning_rate": 0.0001569447821262911,
      "loss": 0.4215,
      "step": 2223
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.10848384350538254,
      "learning_rate": 0.0001569081039885639,
      "loss": 0.362,
      "step": 2224
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.12328439950942993,
      "learning_rate": 0.00015687141452469966,
      "loss": 0.407,
      "step": 2225
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1222040206193924,
      "learning_rate": 0.00015683471374200046,
      "loss": 0.3322,
      "step": 2226
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14541959762573242,
      "learning_rate": 0.00015679800164777066,
      "loss": 0.3356,
      "step": 2227
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14321190118789673,
      "learning_rate": 0.00015676127824931695,
      "loss": 0.3893,
      "step": 2228
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.16664107143878937,
      "learning_rate": 0.00015672454355394817,
      "loss": 0.4622,
      "step": 2229
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.09167739748954773,
      "learning_rate": 0.00015668779756897544,
      "loss": 0.2691,
      "step": 2230
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14332549273967743,
      "learning_rate": 0.0001566510403017121,
      "loss": 0.4697,
      "step": 2231
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.10205167531967163,
      "learning_rate": 0.00015661427175947383,
      "loss": 0.2922,
      "step": 2232
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1492902636528015,
      "learning_rate": 0.00015657749194957846,
      "loss": 0.4478,
      "step": 2233
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14026828110218048,
      "learning_rate": 0.00015654070087934606,
      "loss": 0.2946,
      "step": 2234
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.10021869838237762,
      "learning_rate": 0.00015650389855609902,
      "loss": 0.2779,
      "step": 2235
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.08667446672916412,
      "learning_rate": 0.00015646708498716193,
      "loss": 0.2665,
      "step": 2236
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1411975473165512,
      "learning_rate": 0.0001564302601798616,
      "loss": 0.3937,
      "step": 2237
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.12569408118724823,
      "learning_rate": 0.00015639342414152703,
      "loss": 0.3999,
      "step": 2238
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.11401882767677307,
      "learning_rate": 0.0001563565768794896,
      "loss": 0.3233,
      "step": 2239
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.10842853784561157,
      "learning_rate": 0.0001563197184010828,
      "loss": 0.312,
      "step": 2240
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.08609028160572052,
      "learning_rate": 0.00015628284871364238,
      "loss": 0.3424,
      "step": 2241
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.17188729345798492,
      "learning_rate": 0.00015624596782450633,
      "loss": 0.3961,
      "step": 2242
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.10186583548784256,
      "learning_rate": 0.0001562090757410149,
      "loss": 0.2937,
      "step": 2243
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.15063820779323578,
      "learning_rate": 0.00015617217247051052,
      "loss": 0.3223,
      "step": 2244
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.13388380408287048,
      "learning_rate": 0.00015613525802033782,
      "loss": 0.4101,
      "step": 2245
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.11356321722269058,
      "learning_rate": 0.0001560983323978438,
      "loss": 0.3163,
      "step": 2246
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.11110525578260422,
      "learning_rate": 0.0001560613956103775,
      "loss": 0.3212,
      "step": 2247
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.12417750060558319,
      "learning_rate": 0.0001560244476652903,
      "loss": 0.3593,
      "step": 2248
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.10873993486166,
      "learning_rate": 0.00015598748856993574,
      "loss": 0.3766,
      "step": 2249
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.11638818681240082,
      "learning_rate": 0.00015595051833166968,
      "loss": 0.422,
      "step": 2250
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.12777064740657806,
      "learning_rate": 0.00015591353695785,
      "loss": 0.408,
      "step": 2251
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.10527970641851425,
      "learning_rate": 0.000155876544455837,
      "loss": 0.3966,
      "step": 2252
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.17471201717853546,
      "learning_rate": 0.0001558395408329931,
      "loss": 0.2706,
      "step": 2253
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1070169061422348,
      "learning_rate": 0.00015580252609668295,
      "loss": 0.3372,
      "step": 2254
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10921548306941986,
      "learning_rate": 0.0001557655002542734,
      "loss": 0.3242,
      "step": 2255
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1313667744398117,
      "learning_rate": 0.00015572846331313352,
      "loss": 0.2851,
      "step": 2256
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.13008753955364227,
      "learning_rate": 0.00015569141528063457,
      "loss": 0.5604,
      "step": 2257
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11637274920940399,
      "learning_rate": 0.0001556543561641501,
      "loss": 0.3189,
      "step": 2258
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15226182341575623,
      "learning_rate": 0.00015561728597105574,
      "loss": 0.4131,
      "step": 2259
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11170899868011475,
      "learning_rate": 0.0001555802047087294,
      "loss": 0.3208,
      "step": 2260
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10715249925851822,
      "learning_rate": 0.0001555431123845512,
      "loss": 0.2707,
      "step": 2261
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11581014096736908,
      "learning_rate": 0.00015550600900590342,
      "loss": 0.3188,
      "step": 2262
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15634101629257202,
      "learning_rate": 0.00015546889458017054,
      "loss": 0.3138,
      "step": 2263
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11230652779340744,
      "learning_rate": 0.00015543176911473933,
      "loss": 0.305,
      "step": 2264
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.14014722406864166,
      "learning_rate": 0.0001553946326169986,
      "loss": 0.3002,
      "step": 2265
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11524820327758789,
      "learning_rate": 0.00015535748509433952,
      "loss": 0.3165,
      "step": 2266
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.12108808010816574,
      "learning_rate": 0.00015532032655415532,
      "loss": 0.4133,
      "step": 2267
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1396346241235733,
      "learning_rate": 0.0001552831570038415,
      "loss": 0.4343,
      "step": 2268
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10238825529813766,
      "learning_rate": 0.00015524597645079574,
      "loss": 0.3161,
      "step": 2269
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.0816355049610138,
      "learning_rate": 0.00015520878490241793,
      "loss": 0.2572,
      "step": 2270
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.12119825184345245,
      "learning_rate": 0.00015517158236611002,
      "loss": 0.3174,
      "step": 2271
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1090465784072876,
      "learning_rate": 0.00015513436884927634,
      "loss": 0.3068,
      "step": 2272
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1433386206626892,
      "learning_rate": 0.00015509714435932328,
      "loss": 0.3861,
      "step": 2273
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.14631956815719604,
      "learning_rate": 0.00015505990890365946,
      "loss": 0.3732,
      "step": 2274
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.09460253268480301,
      "learning_rate": 0.0001550226624896956,
      "loss": 0.2776,
      "step": 2275
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.12565605342388153,
      "learning_rate": 0.00015498540512484476,
      "loss": 0.3936,
      "step": 2276
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15060991048812866,
      "learning_rate": 0.00015494813681652205,
      "loss": 0.4032,
      "step": 2277
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10606779903173447,
      "learning_rate": 0.00015491085757214477,
      "loss": 0.3201,
      "step": 2278
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11012489348649979,
      "learning_rate": 0.00015487356739913249,
      "loss": 0.3031,
      "step": 2279
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.09966420382261276,
      "learning_rate": 0.00015483626630490683,
      "loss": 0.3307,
      "step": 2280
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.12527675926685333,
      "learning_rate": 0.00015479895429689164,
      "loss": 0.3795,
      "step": 2281
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.14220772683620453,
      "learning_rate": 0.00015476163138251295,
      "loss": 0.3935,
      "step": 2282
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1173463985323906,
      "learning_rate": 0.000154724297569199,
      "loss": 0.3171,
      "step": 2283
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7268038988113403,
      "learning_rate": 0.00015468695286438013,
      "loss": 0.599,
      "step": 2284
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2617550492286682,
      "learning_rate": 0.00015464959727548884,
      "loss": 0.3291,
      "step": 2285
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1618100106716156,
      "learning_rate": 0.0001546122308099598,
      "loss": 0.3918,
      "step": 2286
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.09094899147748947,
      "learning_rate": 0.00015457485347522998,
      "loss": 0.2737,
      "step": 2287
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.10255604982376099,
      "learning_rate": 0.0001545374652787383,
      "loss": 0.2732,
      "step": 2288
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11761117726564407,
      "learning_rate": 0.00015450006622792604,
      "loss": 0.3277,
      "step": 2289
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.11764032393693924,
      "learning_rate": 0.00015446265633023646,
      "loss": 0.2734,
      "step": 2290
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.13750319182872772,
      "learning_rate": 0.0001544252355931151,
      "loss": 0.3946,
      "step": 2291
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.14789941906929016,
      "learning_rate": 0.00015438780402400964,
      "loss": 0.3717,
      "step": 2292
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.10505657643079758,
      "learning_rate": 0.0001543503616303699,
      "loss": 0.3478,
      "step": 2293
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1122703030705452,
      "learning_rate": 0.00015431290841964784,
      "loss": 0.3106,
      "step": 2294
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.13454151153564453,
      "learning_rate": 0.00015427544439929752,
      "loss": 0.419,
      "step": 2295
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.09850460290908813,
      "learning_rate": 0.00015423796957677536,
      "loss": 0.3369,
      "step": 2296
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12674947082996368,
      "learning_rate": 0.0001542004839595397,
      "loss": 0.3387,
      "step": 2297
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.14262159168720245,
      "learning_rate": 0.0001541629875550511,
      "loss": 0.4633,
      "step": 2298
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1516323834657669,
      "learning_rate": 0.0001541254803707723,
      "loss": 0.2856,
      "step": 2299
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1480933278799057,
      "learning_rate": 0.0001540879624141682,
      "loss": 0.3486,
      "step": 2300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.10236111283302307,
      "learning_rate": 0.00015405043369270578,
      "loss": 0.2873,
      "step": 2301
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.14705318212509155,
      "learning_rate": 0.0001540128942138542,
      "loss": 0.5672,
      "step": 2302
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.11236076802015305,
      "learning_rate": 0.00015397534398508482,
      "loss": 0.3344,
      "step": 2303
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12046843767166138,
      "learning_rate": 0.00015393778301387096,
      "loss": 0.3796,
      "step": 2304
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12560522556304932,
      "learning_rate": 0.00015390021130768825,
      "loss": 0.3866,
      "step": 2305
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.10170743614435196,
      "learning_rate": 0.0001538626288740144,
      "loss": 0.3713,
      "step": 2306
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.11951354891061783,
      "learning_rate": 0.00015382503572032932,
      "loss": 0.3259,
      "step": 2307
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12277264893054962,
      "learning_rate": 0.00015378743185411487,
      "loss": 0.3545,
      "step": 2308
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1127345860004425,
      "learning_rate": 0.00015374981728285522,
      "loss": 0.3092,
      "step": 2309
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.11658083647489548,
      "learning_rate": 0.00015371219201403658,
      "loss": 0.385,
      "step": 2310
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1141277551651001,
      "learning_rate": 0.0001536745560551474,
      "loss": 0.3502,
      "step": 2311
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4293893575668335,
      "learning_rate": 0.00015363690941367812,
      "loss": 0.3468,
      "step": 2312
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.11672957986593246,
      "learning_rate": 0.0001535992520971213,
      "loss": 0.3401,
      "step": 2313
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.11171195656061172,
      "learning_rate": 0.00015356158411297183,
      "loss": 0.2939,
      "step": 2314
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.16273830831050873,
      "learning_rate": 0.00015352390546872645,
      "loss": 0.3822,
      "step": 2315
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1031661406159401,
      "learning_rate": 0.00015348621617188428,
      "loss": 0.2807,
      "step": 2316
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12201614677906036,
      "learning_rate": 0.00015344851622994628,
      "loss": 0.3468,
      "step": 2317
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1310112625360489,
      "learning_rate": 0.0001534108056504158,
      "loss": 0.4177,
      "step": 2318
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.13737799227237701,
      "learning_rate": 0.00015337308444079818,
      "loss": 0.3649,
      "step": 2319
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.10347041487693787,
      "learning_rate": 0.00015333535260860087,
      "loss": 0.3467,
      "step": 2320
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1283188909292221,
      "learning_rate": 0.0001532976101613334,
      "loss": 0.353,
      "step": 2321
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.12076476216316223,
      "learning_rate": 0.00015325985710650753,
      "loss": 0.3654,
      "step": 2322
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.11730577796697617,
      "learning_rate": 0.000153222093451637,
      "loss": 0.318,
      "step": 2323
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.11055292189121246,
      "learning_rate": 0.00015318431920423778,
      "loss": 0.312,
      "step": 2324
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.14491471648216248,
      "learning_rate": 0.00015314653437182787,
      "loss": 0.4079,
      "step": 2325
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11699750274419785,
      "learning_rate": 0.0001531087389619274,
      "loss": 0.4065,
      "step": 2326
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.1320602297782898,
      "learning_rate": 0.00015307093298205858,
      "loss": 0.3401,
      "step": 2327
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.109426349401474,
      "learning_rate": 0.0001530331164397458,
      "loss": 0.3163,
      "step": 2328
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11226971447467804,
      "learning_rate": 0.00015299528934251542,
      "loss": 0.3209,
      "step": 2329
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.10509756952524185,
      "learning_rate": 0.00015295745169789603,
      "loss": 0.3045,
      "step": 2330
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15258100628852844,
      "learning_rate": 0.00015291960351341825,
      "loss": 0.3022,
      "step": 2331
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11410060524940491,
      "learning_rate": 0.00015288174479661485,
      "loss": 0.2948,
      "step": 2332
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11334361881017685,
      "learning_rate": 0.00015284387555502066,
      "loss": 0.3209,
      "step": 2333
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.150467649102211,
      "learning_rate": 0.00015280599579617252,
      "loss": 0.3528,
      "step": 2334
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.13644669950008392,
      "learning_rate": 0.00015276810552760953,
      "loss": 0.4067,
      "step": 2335
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.10373184084892273,
      "learning_rate": 0.00015273020475687282,
      "loss": 0.2796,
      "step": 2336
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.10839692503213882,
      "learning_rate": 0.00015269229349150555,
      "loss": 0.3248,
      "step": 2337
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11300953477621078,
      "learning_rate": 0.00015265437173905298,
      "loss": 0.3208,
      "step": 2338
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.14850351214408875,
      "learning_rate": 0.0001526164395070626,
      "loss": 0.3731,
      "step": 2339
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.1453491896390915,
      "learning_rate": 0.00015257849680308375,
      "loss": 0.3693,
      "step": 2340
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11665968596935272,
      "learning_rate": 0.00015254054363466807,
      "loss": 0.3617,
      "step": 2341
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.14731445908546448,
      "learning_rate": 0.0001525025800093691,
      "loss": 0.4501,
      "step": 2342
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.12034174799919128,
      "learning_rate": 0.00015246460593474264,
      "loss": 0.3731,
      "step": 2343
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.13645011186599731,
      "learning_rate": 0.00015242662141834643,
      "loss": 0.4178,
      "step": 2344
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11273551732301712,
      "learning_rate": 0.00015238862646774033,
      "loss": 0.3094,
      "step": 2345
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.13339130580425262,
      "learning_rate": 0.0001523506210904863,
      "loss": 0.3691,
      "step": 2346
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15697544813156128,
      "learning_rate": 0.0001523126052941484,
      "loss": 0.4228,
      "step": 2347
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11546620726585388,
      "learning_rate": 0.00015227457908629268,
      "loss": 0.3356,
      "step": 2348
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11182724684476852,
      "learning_rate": 0.00015223654247448732,
      "loss": 0.3578,
      "step": 2349
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.11950428783893585,
      "learning_rate": 0.00015219849546630257,
      "loss": 0.3568,
      "step": 2350
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.10693211108446121,
      "learning_rate": 0.0001521604380693107,
      "loss": 0.3165,
      "step": 2351
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.10151724517345428,
      "learning_rate": 0.00015212237029108616,
      "loss": 0.265,
      "step": 2352
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.13212287425994873,
      "learning_rate": 0.0001520842921392053,
      "loss": 0.3217,
      "step": 2353
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.10175658762454987,
      "learning_rate": 0.00015204620362124666,
      "loss": 0.274,
      "step": 2354
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.12327655404806137,
      "learning_rate": 0.00015200810474479083,
      "loss": 0.3372,
      "step": 2355
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.12289895117282867,
      "learning_rate": 0.00015196999551742043,
      "loss": 0.3643,
      "step": 2356
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.13029170036315918,
      "learning_rate": 0.00015193187594672017,
      "loss": 0.3965,
      "step": 2357
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.10867387801408768,
      "learning_rate": 0.00015189374604027673,
      "loss": 0.4094,
      "step": 2358
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.1307060867547989,
      "learning_rate": 0.00015185560580567898,
      "loss": 0.3024,
      "step": 2359
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.19478701055049896,
      "learning_rate": 0.00015181745525051776,
      "loss": 0.3731,
      "step": 2360
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.13335010409355164,
      "learning_rate": 0.00015177929438238595,
      "loss": 0.4558,
      "step": 2361
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.12079527974128723,
      "learning_rate": 0.00015174112320887862,
      "loss": 0.4176,
      "step": 2362
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11677658557891846,
      "learning_rate": 0.00015170294173759267,
      "loss": 0.3181,
      "step": 2363
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.10281167924404144,
      "learning_rate": 0.00015166474997612724,
      "loss": 0.3009,
      "step": 2364
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.14827652275562286,
      "learning_rate": 0.00015162654793208344,
      "loss": 0.4153,
      "step": 2365
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11560071259737015,
      "learning_rate": 0.00015158833561306438,
      "loss": 0.3474,
      "step": 2366
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11466191709041595,
      "learning_rate": 0.00015155011302667534,
      "loss": 0.3514,
      "step": 2367
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.15364423394203186,
      "learning_rate": 0.00015151188018052355,
      "loss": 0.2954,
      "step": 2368
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.14850696921348572,
      "learning_rate": 0.00015147363708221828,
      "loss": 0.4475,
      "step": 2369
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11945443600416183,
      "learning_rate": 0.00015143538373937088,
      "loss": 0.2898,
      "step": 2370
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11426766961812973,
      "learning_rate": 0.0001513971201595947,
      "loss": 0.3117,
      "step": 2371
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.13416559994220734,
      "learning_rate": 0.0001513588463505052,
      "loss": 0.3241,
      "step": 2372
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.12579120695590973,
      "learning_rate": 0.0001513205623197198,
      "loss": 0.3843,
      "step": 2373
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.14482973515987396,
      "learning_rate": 0.00015128226807485797,
      "loss": 0.4964,
      "step": 2374
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11428749561309814,
      "learning_rate": 0.00015124396362354122,
      "loss": 0.3308,
      "step": 2375
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.13436062633991241,
      "learning_rate": 0.00015120564897339308,
      "loss": 0.3852,
      "step": 2376
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.12364480644464493,
      "learning_rate": 0.00015116732413203917,
      "loss": 0.347,
      "step": 2377
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1140577495098114,
      "learning_rate": 0.00015112898910710706,
      "loss": 0.35,
      "step": 2378
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.13391707837581635,
      "learning_rate": 0.0001510906439062264,
      "loss": 0.3164,
      "step": 2379
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.14277030527591705,
      "learning_rate": 0.00015105228853702887,
      "loss": 0.4496,
      "step": 2380
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.14109733700752258,
      "learning_rate": 0.00015101392300714806,
      "loss": 0.4272,
      "step": 2381
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.13229449093341827,
      "learning_rate": 0.00015097554732421974,
      "loss": 0.3388,
      "step": 2382
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1184777319431305,
      "learning_rate": 0.00015093716149588163,
      "loss": 0.3864,
      "step": 2383
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.09411395341157913,
      "learning_rate": 0.00015089876552977345,
      "loss": 0.3292,
      "step": 2384
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1310156136751175,
      "learning_rate": 0.00015086035943353695,
      "loss": 0.4001,
      "step": 2385
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.18932582437992096,
      "learning_rate": 0.00015082194321481594,
      "loss": 0.3056,
      "step": 2386
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11916181445121765,
      "learning_rate": 0.00015078351688125615,
      "loss": 0.3817,
      "step": 2387
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11743152886629105,
      "learning_rate": 0.00015074508044050545,
      "loss": 0.322,
      "step": 2388
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1310560256242752,
      "learning_rate": 0.00015070663390021364,
      "loss": 0.4,
      "step": 2389
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.11618620902299881,
      "learning_rate": 0.00015066817726803252,
      "loss": 0.3368,
      "step": 2390
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1257624477148056,
      "learning_rate": 0.0001506297105516159,
      "loss": 0.4702,
      "step": 2391
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1297888159751892,
      "learning_rate": 0.0001505912337586197,
      "loss": 0.3455,
      "step": 2392
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.15560315549373627,
      "learning_rate": 0.00015055274689670166,
      "loss": 0.4045,
      "step": 2393
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.10845326632261276,
      "learning_rate": 0.0001505142499735217,
      "loss": 0.2973,
      "step": 2394
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.10678733885288239,
      "learning_rate": 0.00015047574299674164,
      "loss": 0.3534,
      "step": 2395
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.15512636303901672,
      "learning_rate": 0.00015043722597402542,
      "loss": 0.4438,
      "step": 2396
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11871043592691422,
      "learning_rate": 0.00015039869891303876,
      "loss": 0.3257,
      "step": 2397
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.09778399020433426,
      "learning_rate": 0.00015036016182144957,
      "loss": 0.2604,
      "step": 2398
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11439589411020279,
      "learning_rate": 0.0001503216147069277,
      "loss": 0.3177,
      "step": 2399
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11599685996770859,
      "learning_rate": 0.000150283057577145,
      "loss": 0.3376,
      "step": 2400
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.10173042118549347,
      "learning_rate": 0.00015024449043977525,
      "loss": 0.2767,
      "step": 2401
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13312441110610962,
      "learning_rate": 0.00015020591330249433,
      "loss": 0.3896,
      "step": 2402
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13845205307006836,
      "learning_rate": 0.00015016732617298005,
      "loss": 0.3434,
      "step": 2403
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.09512943774461746,
      "learning_rate": 0.00015012872905891222,
      "loss": 0.3216,
      "step": 2404
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.15003694593906403,
      "learning_rate": 0.00015009012196797258,
      "loss": 0.3497,
      "step": 2405
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13405506312847137,
      "learning_rate": 0.00015005150490784498,
      "loss": 0.3429,
      "step": 2406
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14171773195266724,
      "learning_rate": 0.0001500128778862151,
      "loss": 0.3767,
      "step": 2407
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13924787938594818,
      "learning_rate": 0.00014997424091077075,
      "loss": 0.3642,
      "step": 2408
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1455443948507309,
      "learning_rate": 0.00014993559398920165,
      "loss": 0.341,
      "step": 2409
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.17607326805591583,
      "learning_rate": 0.00014989693712919947,
      "loss": 0.4723,
      "step": 2410
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.09328805655241013,
      "learning_rate": 0.00014985827033845792,
      "loss": 0.2703,
      "step": 2411
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.12729692459106445,
      "learning_rate": 0.00014981959362467265,
      "loss": 0.3837,
      "step": 2412
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14555372297763824,
      "learning_rate": 0.00014978090699554127,
      "loss": 0.3781,
      "step": 2413
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1087900921702385,
      "learning_rate": 0.00014974221045876344,
      "loss": 0.3342,
      "step": 2414
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1310376226902008,
      "learning_rate": 0.0001497035040220407,
      "loss": 0.3315,
      "step": 2415
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.12450606375932693,
      "learning_rate": 0.00014966478769307663,
      "loss": 0.3834,
      "step": 2416
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11683768033981323,
      "learning_rate": 0.00014962606147957673,
      "loss": 0.3908,
      "step": 2417
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.10360388457775116,
      "learning_rate": 0.00014958732538924847,
      "loss": 0.3353,
      "step": 2418
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13754524290561676,
      "learning_rate": 0.0001495485794298013,
      "loss": 0.4089,
      "step": 2419
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13523536920547485,
      "learning_rate": 0.00014950982360894668,
      "loss": 0.298,
      "step": 2420
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.15122416615486145,
      "learning_rate": 0.00014947105793439795,
      "loss": 0.4529,
      "step": 2421
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1391495019197464,
      "learning_rate": 0.0001494322824138705,
      "loss": 0.3611,
      "step": 2422
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11851044744253159,
      "learning_rate": 0.00014939349705508153,
      "loss": 0.3659,
      "step": 2423
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11693298071622849,
      "learning_rate": 0.0001493547018657504,
      "loss": 0.3336,
      "step": 2424
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11820188164710999,
      "learning_rate": 0.00014931589685359824,
      "loss": 0.2974,
      "step": 2425
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14183248579502106,
      "learning_rate": 0.00014927708202634827,
      "loss": 0.4297,
      "step": 2426
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.12065547704696655,
      "learning_rate": 0.0001492382573917256,
      "loss": 0.4403,
      "step": 2427
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.13129004836082458,
      "learning_rate": 0.00014919942295745737,
      "loss": 0.3757,
      "step": 2428
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14146028459072113,
      "learning_rate": 0.00014916057873127247,
      "loss": 0.3515,
      "step": 2429
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.12070736289024353,
      "learning_rate": 0.00014912172472090197,
      "loss": 0.3091,
      "step": 2430
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.12670361995697021,
      "learning_rate": 0.00014908286093407873,
      "loss": 0.2938,
      "step": 2431
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11477334797382355,
      "learning_rate": 0.0001490439873785377,
      "loss": 0.3728,
      "step": 2432
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.12357359379529953,
      "learning_rate": 0.00014900510406201564,
      "loss": 0.3594,
      "step": 2433
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15272784233093262,
      "learning_rate": 0.00014896621099225128,
      "loss": 0.4193,
      "step": 2434
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.09766755998134613,
      "learning_rate": 0.00014892730817698532,
      "loss": 0.2786,
      "step": 2435
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.14238427579402924,
      "learning_rate": 0.00014888839562396045,
      "loss": 0.3202,
      "step": 2436
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.11596722155809402,
      "learning_rate": 0.0001488494733409212,
      "loss": 0.3295,
      "step": 2437
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1310322880744934,
      "learning_rate": 0.00014881054133561406,
      "loss": 0.4105,
      "step": 2438
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.12260923534631729,
      "learning_rate": 0.00014877159961578749,
      "loss": 0.3898,
      "step": 2439
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.11328110843896866,
      "learning_rate": 0.00014873264818919188,
      "loss": 0.3285,
      "step": 2440
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.0936122015118599,
      "learning_rate": 0.00014869368706357957,
      "loss": 0.3052,
      "step": 2441
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.10805179923772812,
      "learning_rate": 0.0001486547162467047,
      "loss": 0.3773,
      "step": 2442
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1258978247642517,
      "learning_rate": 0.00014861573574632354,
      "loss": 0.3208,
      "step": 2443
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.12418656796216965,
      "learning_rate": 0.00014857674557019413,
      "loss": 0.4756,
      "step": 2444
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.09302731603384018,
      "learning_rate": 0.00014853774572607653,
      "loss": 0.2796,
      "step": 2445
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1437099725008011,
      "learning_rate": 0.00014849873622173264,
      "loss": 0.546,
      "step": 2446
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.16427333652973175,
      "learning_rate": 0.00014845971706492633,
      "loss": 0.3589,
      "step": 2447
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.11340708285570145,
      "learning_rate": 0.0001484206882634234,
      "loss": 0.338,
      "step": 2448
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.12556049227714539,
      "learning_rate": 0.00014838164982499164,
      "loss": 0.3532,
      "step": 2449
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.13854408264160156,
      "learning_rate": 0.00014834260175740054,
      "loss": 0.3866,
      "step": 2450
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.12708425521850586,
      "learning_rate": 0.0001483035440684217,
      "loss": 0.2842,
      "step": 2451
    },
    {
      "epoch": 0.69,
      "grad_norm": 10.752204895019531,
      "learning_rate": 0.0001482644767658286,
      "loss": 0.5781,
      "step": 2452
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.12835900485515594,
      "learning_rate": 0.0001482253998573966,
      "loss": 0.3763,
      "step": 2453
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.11266501992940903,
      "learning_rate": 0.00014818631335090297,
      "loss": 0.4172,
      "step": 2454
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.21039240062236786,
      "learning_rate": 0.0001481472172541269,
      "loss": 0.3831,
      "step": 2455
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1921265572309494,
      "learning_rate": 0.00014810811157484952,
      "loss": 0.33,
      "step": 2456
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.18254725635051727,
      "learning_rate": 0.00014806899632085381,
      "loss": 0.2733,
      "step": 2457
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.19132880866527557,
      "learning_rate": 0.0001480298714999247,
      "loss": 0.2722,
      "step": 2458
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.18059128522872925,
      "learning_rate": 0.00014799073711984902,
      "loss": 0.2856,
      "step": 2459
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.14955802261829376,
      "learning_rate": 0.00014795159318841541,
      "loss": 0.3232,
      "step": 2460
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.12386705726385117,
      "learning_rate": 0.00014791243971341462,
      "loss": 0.3321,
      "step": 2461
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.11618870496749878,
      "learning_rate": 0.0001478732767026391,
      "loss": 0.3344,
      "step": 2462
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1548176407814026,
      "learning_rate": 0.00014783410416388326,
      "loss": 0.3908,
      "step": 2463
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.09668000042438507,
      "learning_rate": 0.00014779492210494343,
      "loss": 0.2719,
      "step": 2464
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1295880675315857,
      "learning_rate": 0.00014775573053361788,
      "loss": 0.3796,
      "step": 2465
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1256762146949768,
      "learning_rate": 0.00014771652945770657,
      "loss": 0.3697,
      "step": 2466
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1307634711265564,
      "learning_rate": 0.0001476773188850116,
      "loss": 0.3585,
      "step": 2467
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13213373720645905,
      "learning_rate": 0.00014763809882333687,
      "loss": 0.3404,
      "step": 2468
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13190534710884094,
      "learning_rate": 0.00014759886928048815,
      "loss": 0.3764,
      "step": 2469
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11607154458761215,
      "learning_rate": 0.00014755963026427302,
      "loss": 0.3171,
      "step": 2470
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.12986041605472565,
      "learning_rate": 0.0001475203817825011,
      "loss": 0.4252,
      "step": 2471
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13861356675624847,
      "learning_rate": 0.00014748112384298375,
      "loss": 0.3937,
      "step": 2472
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1296699345111847,
      "learning_rate": 0.00014744185645353442,
      "loss": 0.3698,
      "step": 2473
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.15649457275867462,
      "learning_rate": 0.00014740257962196816,
      "loss": 0.3663,
      "step": 2474
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.10657430440187454,
      "learning_rate": 0.00014736329335610207,
      "loss": 0.2866,
      "step": 2475
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.10441870987415314,
      "learning_rate": 0.00014732399766375517,
      "loss": 0.2933,
      "step": 2476
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.22788555920124054,
      "learning_rate": 0.00014728469255274827,
      "loss": 0.3765,
      "step": 2477
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.10854069143533707,
      "learning_rate": 0.000147245378030904,
      "loss": 0.322,
      "step": 2478
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11708997935056686,
      "learning_rate": 0.00014720605410604697,
      "loss": 0.3977,
      "step": 2479
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.09131869673728943,
      "learning_rate": 0.00014716672078600367,
      "loss": 0.2583,
      "step": 2480
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.12359242886304855,
      "learning_rate": 0.00014712737807860238,
      "loss": 0.3525,
      "step": 2481
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.12554123997688293,
      "learning_rate": 0.00014708802599167325,
      "loss": 0.4376,
      "step": 2482
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13289007544517517,
      "learning_rate": 0.0001470486645330484,
      "loss": 0.4426,
      "step": 2483
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.16526339948177338,
      "learning_rate": 0.00014700929371056168,
      "loss": 0.4365,
      "step": 2484
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13483206927776337,
      "learning_rate": 0.0001469699135320489,
      "loss": 0.4236,
      "step": 2485
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.08370977640151978,
      "learning_rate": 0.00014693052400534772,
      "loss": 0.236,
      "step": 2486
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.12365514785051346,
      "learning_rate": 0.0001468911251382976,
      "loss": 0.4108,
      "step": 2487
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.15188024938106537,
      "learning_rate": 0.00014685171693873994,
      "loss": 0.4057,
      "step": 2488
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11533138900995255,
      "learning_rate": 0.00014681229941451794,
      "loss": 0.2794,
      "step": 2489
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13580194115638733,
      "learning_rate": 0.00014677287257347665,
      "loss": 0.3766,
      "step": 2490
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11587629467248917,
      "learning_rate": 0.00014673343642346303,
      "loss": 0.3866,
      "step": 2491
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11994737386703491,
      "learning_rate": 0.00014669399097232586,
      "loss": 0.3761,
      "step": 2492
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.14022991061210632,
      "learning_rate": 0.00014665453622791577,
      "loss": 0.4365,
      "step": 2493
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1461440473794937,
      "learning_rate": 0.00014661507219808522,
      "loss": 0.3808,
      "step": 2494
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1583508402109146,
      "learning_rate": 0.00014657559889068856,
      "loss": 0.4751,
      "step": 2495
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13137856125831604,
      "learning_rate": 0.00014653611631358198,
      "loss": 0.364,
      "step": 2496
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11120520532131195,
      "learning_rate": 0.00014649662447462346,
      "loss": 0.2822,
      "step": 2497
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.13893598318099976,
      "learning_rate": 0.0001464571233816729,
      "loss": 0.3888,
      "step": 2498
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11484641581773758,
      "learning_rate": 0.000146417613042592,
      "loss": 0.2979,
      "step": 2499
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1390400230884552,
      "learning_rate": 0.0001463780934652443,
      "loss": 0.4068,
      "step": 2500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11854614317417145,
      "learning_rate": 0.00014633856465749517,
      "loss": 0.3221,
      "step": 2501
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.18102394044399261,
      "learning_rate": 0.00014629902662721185,
      "loss": 0.3886,
      "step": 2502
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.11099083721637726,
      "learning_rate": 0.0001462594793822634,
      "loss": 0.2773,
      "step": 2503
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.11631561070680618,
      "learning_rate": 0.0001462199229305207,
      "loss": 0.3426,
      "step": 2504
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.14931729435920715,
      "learning_rate": 0.00014618035727985646,
      "loss": 0.3427,
      "step": 2505
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.11610694229602814,
      "learning_rate": 0.00014614078243814531,
      "loss": 0.2711,
      "step": 2506
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.13744238018989563,
      "learning_rate": 0.00014610119841326354,
      "loss": 0.3654,
      "step": 2507
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.14256185293197632,
      "learning_rate": 0.0001460616052130894,
      "loss": 0.3871,
      "step": 2508
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.10174870491027832,
      "learning_rate": 0.00014602200284550296,
      "loss": 0.283,
      "step": 2509
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.12113643437623978,
      "learning_rate": 0.00014598239131838602,
      "loss": 0.2699,
      "step": 2510
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1219487264752388,
      "learning_rate": 0.0001459427706396223,
      "loss": 0.3464,
      "step": 2511
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.10764291882514954,
      "learning_rate": 0.0001459031408170973,
      "loss": 0.2802,
      "step": 2512
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.11160159111022949,
      "learning_rate": 0.00014586350185869838,
      "loss": 0.3226,
      "step": 2513
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.14229172468185425,
      "learning_rate": 0.00014582385377231462,
      "loss": 0.3068,
      "step": 2514
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.10927250236272812,
      "learning_rate": 0.00014578419656583705,
      "loss": 0.2599,
      "step": 2515
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.11382801830768585,
      "learning_rate": 0.00014574453024715836,
      "loss": 0.2737,
      "step": 2516
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.13654597103595734,
      "learning_rate": 0.00014570485482417325,
      "loss": 0.319,
      "step": 2517
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1330697387456894,
      "learning_rate": 0.00014566517030477805,
      "loss": 0.405,
      "step": 2518
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1020815297961235,
      "learning_rate": 0.00014562547669687097,
      "loss": 0.2868,
      "step": 2519
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.14966866374015808,
      "learning_rate": 0.00014558577400835204,
      "loss": 0.435,
      "step": 2520
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.11701486259698868,
      "learning_rate": 0.00014554606224712315,
      "loss": 0.3789,
      "step": 2521
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.11340118199586868,
      "learning_rate": 0.00014550634142108785,
      "loss": 0.3647,
      "step": 2522
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.116429403424263,
      "learning_rate": 0.0001454666115381516,
      "loss": 0.3633,
      "step": 2523
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.12150628119707108,
      "learning_rate": 0.00014542687260622164,
      "loss": 0.3493,
      "step": 2524
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.10519719868898392,
      "learning_rate": 0.00014538712463320707,
      "loss": 0.3371,
      "step": 2525
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.12489475309848785,
      "learning_rate": 0.0001453473676270187,
      "loss": 0.3116,
      "step": 2526
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1303483247756958,
      "learning_rate": 0.0001453076015955691,
      "loss": 0.334,
      "step": 2527
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.10439743101596832,
      "learning_rate": 0.0001452678265467728,
      "loss": 0.2707,
      "step": 2528
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.37956711649894714,
      "learning_rate": 0.00014522804248854595,
      "loss": 0.3906,
      "step": 2529
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.11016064882278442,
      "learning_rate": 0.00014518824942880666,
      "loss": 0.3146,
      "step": 2530
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.12838101387023926,
      "learning_rate": 0.0001451484473754747,
      "loss": 0.4246,
      "step": 2531
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.10854892432689667,
      "learning_rate": 0.00014510863633647163,
      "loss": 0.345,
      "step": 2532
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.13736622035503387,
      "learning_rate": 0.0001450688163197209,
      "loss": 0.2976,
      "step": 2533
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1066339835524559,
      "learning_rate": 0.0001450289873331477,
      "loss": 0.2488,
      "step": 2534
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1045856699347496,
      "learning_rate": 0.00014498914938467896,
      "loss": 0.3121,
      "step": 2535
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.12059549242258072,
      "learning_rate": 0.00014494930248224342,
      "loss": 0.3621,
      "step": 2536
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.09832891076803207,
      "learning_rate": 0.00014490944663377167,
      "loss": 0.2694,
      "step": 2537
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.08982501924037933,
      "learning_rate": 0.00014486958184719596,
      "loss": 0.2495,
      "step": 2538
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.14531883597373962,
      "learning_rate": 0.00014482970813045043,
      "loss": 0.3214,
      "step": 2539
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11876362562179565,
      "learning_rate": 0.0001447898254914709,
      "loss": 0.3748,
      "step": 2540
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.14661958813667297,
      "learning_rate": 0.00014474993393819502,
      "loss": 0.4268,
      "step": 2541
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11347313970327377,
      "learning_rate": 0.00014471003347856228,
      "loss": 0.2756,
      "step": 2542
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11670216172933578,
      "learning_rate": 0.00014467012412051376,
      "loss": 0.2563,
      "step": 2543
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13663484156131744,
      "learning_rate": 0.00014463020587199247,
      "loss": 0.4104,
      "step": 2544
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11064174026250839,
      "learning_rate": 0.00014459027874094317,
      "loss": 0.3986,
      "step": 2545
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12333814054727554,
      "learning_rate": 0.00014455034273531234,
      "loss": 0.3608,
      "step": 2546
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.14293266832828522,
      "learning_rate": 0.0001445103978630482,
      "loss": 0.3645,
      "step": 2547
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13029956817626953,
      "learning_rate": 0.00014447044413210084,
      "loss": 0.3334,
      "step": 2548
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1141626238822937,
      "learning_rate": 0.00014443048155042204,
      "loss": 0.3383,
      "step": 2549
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.15422990918159485,
      "learning_rate": 0.00014439051012596536,
      "loss": 0.4645,
      "step": 2550
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12032318115234375,
      "learning_rate": 0.00014435052986668608,
      "loss": 0.3556,
      "step": 2551
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13177303969860077,
      "learning_rate": 0.00014431054078054126,
      "loss": 0.4202,
      "step": 2552
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12850971519947052,
      "learning_rate": 0.0001442705428754898,
      "loss": 0.3606,
      "step": 2553
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1516302227973938,
      "learning_rate": 0.00014423053615949223,
      "loss": 0.4321,
      "step": 2554
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.19486215710639954,
      "learning_rate": 0.0001441905206405109,
      "loss": 0.3708,
      "step": 2555
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13415302336215973,
      "learning_rate": 0.0001441504963265099,
      "loss": 0.4126,
      "step": 2556
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.15007621049880981,
      "learning_rate": 0.00014411046322545504,
      "loss": 0.4457,
      "step": 2557
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12022018432617188,
      "learning_rate": 0.000144070421345314,
      "loss": 0.2679,
      "step": 2558
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12675055861473083,
      "learning_rate": 0.000144030370694056,
      "loss": 0.3978,
      "step": 2559
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11364421248435974,
      "learning_rate": 0.0001439903112796522,
      "loss": 0.3831,
      "step": 2560
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1322319209575653,
      "learning_rate": 0.00014395024311007542,
      "loss": 0.3532,
      "step": 2561
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.10536915808916092,
      "learning_rate": 0.00014391016619330022,
      "loss": 0.2693,
      "step": 2562
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13620084524154663,
      "learning_rate": 0.0001438700805373029,
      "loss": 0.3161,
      "step": 2563
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1236896961927414,
      "learning_rate": 0.00014382998615006148,
      "loss": 0.3446,
      "step": 2564
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.08685430139303207,
      "learning_rate": 0.00014378988303955577,
      "loss": 0.3457,
      "step": 2565
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11835359781980515,
      "learning_rate": 0.00014374977121376736,
      "loss": 0.3846,
      "step": 2566
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13944654166698456,
      "learning_rate": 0.0001437096506806794,
      "loss": 0.4064,
      "step": 2567
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.14605660736560822,
      "learning_rate": 0.00014366952144827694,
      "loss": 0.383,
      "step": 2568
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13373009860515594,
      "learning_rate": 0.0001436293835245467,
      "loss": 0.366,
      "step": 2569
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.09432432055473328,
      "learning_rate": 0.00014358923691747713,
      "loss": 0.2988,
      "step": 2570
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11985223740339279,
      "learning_rate": 0.0001435490816350584,
      "loss": 0.5354,
      "step": 2571
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.31885215640068054,
      "learning_rate": 0.00014350891768528237,
      "loss": 0.4212,
      "step": 2572
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1190575361251831,
      "learning_rate": 0.00014346874507614277,
      "loss": 0.3111,
      "step": 2573
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12370625138282776,
      "learning_rate": 0.0001434285638156349,
      "loss": 0.339,
      "step": 2574
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11934451758861542,
      "learning_rate": 0.00014338837391175582,
      "loss": 0.4123,
      "step": 2575
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.07986517250537872,
      "learning_rate": 0.00014334817537250434,
      "loss": 0.2498,
      "step": 2576
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.08785174041986465,
      "learning_rate": 0.00014330796820588102,
      "loss": 0.2768,
      "step": 2577
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11563211679458618,
      "learning_rate": 0.00014326775241988804,
      "loss": 0.3493,
      "step": 2578
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.14540962874889374,
      "learning_rate": 0.00014322752802252935,
      "loss": 0.3303,
      "step": 2579
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.14206436276435852,
      "learning_rate": 0.00014318729502181063,
      "loss": 0.4187,
      "step": 2580
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11965020000934601,
      "learning_rate": 0.00014314705342573925,
      "loss": 0.3431,
      "step": 2581
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.14498983323574066,
      "learning_rate": 0.0001431068032423243,
      "loss": 0.3793,
      "step": 2582
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1218947172164917,
      "learning_rate": 0.00014306654447957657,
      "loss": 0.3697,
      "step": 2583
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1781078577041626,
      "learning_rate": 0.00014302627714550854,
      "loss": 0.3237,
      "step": 2584
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.15782034397125244,
      "learning_rate": 0.00014298600124813447,
      "loss": 0.4092,
      "step": 2585
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.20993320643901825,
      "learning_rate": 0.0001429457167954702,
      "loss": 0.3211,
      "step": 2586
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.10158684104681015,
      "learning_rate": 0.00014290542379553342,
      "loss": 0.2731,
      "step": 2587
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1534455567598343,
      "learning_rate": 0.0001428651222563434,
      "loss": 0.4052,
      "step": 2588
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1230013370513916,
      "learning_rate": 0.00014282481218592114,
      "loss": 0.3134,
      "step": 2589
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.12845398485660553,
      "learning_rate": 0.00014278449359228938,
      "loss": 0.3864,
      "step": 2590
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.12364261597394943,
      "learning_rate": 0.00014274416648347256,
      "loss": 0.3274,
      "step": 2591
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1290283054113388,
      "learning_rate": 0.0001427038308674967,
      "loss": 0.4101,
      "step": 2592
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.12815257906913757,
      "learning_rate": 0.00014266348675238968,
      "loss": 0.384,
      "step": 2593
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1344844549894333,
      "learning_rate": 0.00014262313414618096,
      "loss": 0.3359,
      "step": 2594
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11958035826683044,
      "learning_rate": 0.00014258277305690168,
      "loss": 0.3055,
      "step": 2595
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13825225830078125,
      "learning_rate": 0.00014254240349258475,
      "loss": 0.3658,
      "step": 2596
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.09913687407970428,
      "learning_rate": 0.00014250202546126474,
      "loss": 0.3279,
      "step": 2597
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11286880075931549,
      "learning_rate": 0.00014246163897097786,
      "loss": 0.3063,
      "step": 2598
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.14639964699745178,
      "learning_rate": 0.000142421244029762,
      "loss": 0.3018,
      "step": 2599
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.10288848727941513,
      "learning_rate": 0.00014238084064565685,
      "loss": 0.325,
      "step": 2600
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13499249517917633,
      "learning_rate": 0.0001423404288267036,
      "loss": 0.3645,
      "step": 2601
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11140492558479309,
      "learning_rate": 0.0001423000085809453,
      "loss": 0.3006,
      "step": 2602
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13806883990764618,
      "learning_rate": 0.0001422595799164265,
      "loss": 0.3443,
      "step": 2603
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13235127925872803,
      "learning_rate": 0.0001422191428411936,
      "loss": 0.3376,
      "step": 2604
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11469985544681549,
      "learning_rate": 0.00014217869736329454,
      "loss": 0.3537,
      "step": 2605
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11253850907087326,
      "learning_rate": 0.000142138243490779,
      "loss": 0.3269,
      "step": 2606
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13088910281658173,
      "learning_rate": 0.00014209778123169836,
      "loss": 0.3446,
      "step": 2607
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.13489098846912384,
      "learning_rate": 0.0001420573105941055,
      "loss": 0.3839,
      "step": 2608
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.11273559182882309,
      "learning_rate": 0.0001420168315860552,
      "loss": 0.3376,
      "step": 2609
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.16927722096443176,
      "learning_rate": 0.00014197634421560379,
      "loss": 0.3715,
      "step": 2610
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.14706647396087646,
      "learning_rate": 0.00014193584849080918,
      "loss": 0.4288,
      "step": 2611
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1123233363032341,
      "learning_rate": 0.00014189534441973108,
      "loss": 0.2802,
      "step": 2612
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.13749630749225616,
      "learning_rate": 0.00014185483201043086,
      "loss": 0.3784,
      "step": 2613
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11229594051837921,
      "learning_rate": 0.0001418143112709715,
      "loss": 0.3108,
      "step": 2614
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.17884789407253265,
      "learning_rate": 0.00014177378220941759,
      "loss": 0.3523,
      "step": 2615
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.09999676793813705,
      "learning_rate": 0.00014173324483383542,
      "loss": 0.2862,
      "step": 2616
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11627721786499023,
      "learning_rate": 0.00014169269915229298,
      "loss": 0.3161,
      "step": 2617
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.13057151436805725,
      "learning_rate": 0.00014165214517285988,
      "loss": 0.3334,
      "step": 2618
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.10978918522596359,
      "learning_rate": 0.00014161158290360736,
      "loss": 0.2962,
      "step": 2619
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1335679292678833,
      "learning_rate": 0.00014157101235260833,
      "loss": 0.3807,
      "step": 2620
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11938752979040146,
      "learning_rate": 0.00014153043352793733,
      "loss": 0.3318,
      "step": 2621
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.09862005710601807,
      "learning_rate": 0.0001414898464376706,
      "loss": 0.325,
      "step": 2622
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.12944729626178741,
      "learning_rate": 0.00014144925108988592,
      "loss": 0.3276,
      "step": 2623
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1117788702249527,
      "learning_rate": 0.00014140864749266288,
      "loss": 0.383,
      "step": 2624
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.12213293462991714,
      "learning_rate": 0.00014136803565408253,
      "loss": 0.3693,
      "step": 2625
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.10330744087696075,
      "learning_rate": 0.00014132741558222763,
      "loss": 0.2665,
      "step": 2626
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.13384093344211578,
      "learning_rate": 0.0001412867872851827,
      "loss": 0.4079,
      "step": 2627
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11090879887342453,
      "learning_rate": 0.0001412461507710337,
      "loss": 0.318,
      "step": 2628
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11016860604286194,
      "learning_rate": 0.0001412055060478683,
      "loss": 0.3123,
      "step": 2629
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.13225407898426056,
      "learning_rate": 0.00014116485312377585,
      "loss": 0.3438,
      "step": 2630
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11447630822658539,
      "learning_rate": 0.0001411241920068473,
      "loss": 0.2692,
      "step": 2631
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.12888890504837036,
      "learning_rate": 0.00014108352270517528,
      "loss": 0.3895,
      "step": 2632
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.10485076159238815,
      "learning_rate": 0.00014104284522685386,
      "loss": 0.3091,
      "step": 2633
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1495143622159958,
      "learning_rate": 0.00014100215957997902,
      "loss": 0.3667,
      "step": 2634
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.12870417535305023,
      "learning_rate": 0.00014096146577264817,
      "loss": 0.3481,
      "step": 2635
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.12219163775444031,
      "learning_rate": 0.0001409207638129604,
      "loss": 0.302,
      "step": 2636
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.14435842633247375,
      "learning_rate": 0.00014088005370901634,
      "loss": 0.4383,
      "step": 2637
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11566953361034393,
      "learning_rate": 0.00014083933546891846,
      "loss": 0.3474,
      "step": 2638
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.12748588621616364,
      "learning_rate": 0.0001407986091007706,
      "loss": 0.4098,
      "step": 2639
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1013001948595047,
      "learning_rate": 0.00014075787461267835,
      "loss": 0.2839,
      "step": 2640
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.16213704645633698,
      "learning_rate": 0.00014071713201274893,
      "loss": 0.3827,
      "step": 2641
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11219048500061035,
      "learning_rate": 0.00014067638130909113,
      "loss": 0.3088,
      "step": 2642
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1423276960849762,
      "learning_rate": 0.00014063562250981535,
      "loss": 0.3538,
      "step": 2643
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.11817294359207153,
      "learning_rate": 0.00014059485562303357,
      "loss": 0.3778,
      "step": 2644
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.09237394481897354,
      "learning_rate": 0.00014055408065685946,
      "loss": 0.2731,
      "step": 2645
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.13085806369781494,
      "learning_rate": 0.0001405132976194083,
      "loss": 0.3468,
      "step": 2646
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1395091414451599,
      "learning_rate": 0.00014047250651879684,
      "loss": 0.3821,
      "step": 2647
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.10733753442764282,
      "learning_rate": 0.00014043170736314362,
      "loss": 0.2725,
      "step": 2648
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.09361658245325089,
      "learning_rate": 0.00014039090016056865,
      "loss": 0.2785,
      "step": 2649
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11309819668531418,
      "learning_rate": 0.00014035008491919355,
      "loss": 0.3077,
      "step": 2650
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.12973777949810028,
      "learning_rate": 0.00014030926164714164,
      "loss": 0.3865,
      "step": 2651
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.13255247473716736,
      "learning_rate": 0.00014026843035253776,
      "loss": 0.3997,
      "step": 2652
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.12702108919620514,
      "learning_rate": 0.0001402275910435083,
      "loss": 0.3673,
      "step": 2653
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11536728590726852,
      "learning_rate": 0.00014018674372818138,
      "loss": 0.3084,
      "step": 2654
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.14762406051158905,
      "learning_rate": 0.00014014588841468662,
      "loss": 0.4693,
      "step": 2655
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11124391108751297,
      "learning_rate": 0.00014010502511115522,
      "loss": 0.2991,
      "step": 2656
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.09359107911586761,
      "learning_rate": 0.00014006415382572003,
      "loss": 0.3204,
      "step": 2657
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1541118323802948,
      "learning_rate": 0.00014002327456651544,
      "loss": 0.4375,
      "step": 2658
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.12062984704971313,
      "learning_rate": 0.00013998238734167745,
      "loss": 0.3548,
      "step": 2659
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11496468633413315,
      "learning_rate": 0.00013994149215934364,
      "loss": 0.2729,
      "step": 2660
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11387491971254349,
      "learning_rate": 0.0001399005890276532,
      "loss": 0.3305,
      "step": 2661
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11490769684314728,
      "learning_rate": 0.00013985967795474683,
      "loss": 0.314,
      "step": 2662
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.12729361653327942,
      "learning_rate": 0.00013981875894876692,
      "loss": 0.3146,
      "step": 2663
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1364259421825409,
      "learning_rate": 0.00013977783201785733,
      "loss": 0.371,
      "step": 2664
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1102059930562973,
      "learning_rate": 0.00013973689717016352,
      "loss": 0.2846,
      "step": 2665
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11874580383300781,
      "learning_rate": 0.0001396959544138326,
      "loss": 0.333,
      "step": 2666
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.14480119943618774,
      "learning_rate": 0.0001396550037570132,
      "loss": 0.4145,
      "step": 2667
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.619956910610199,
      "learning_rate": 0.0001396140452078555,
      "loss": 0.4031,
      "step": 2668
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1329483687877655,
      "learning_rate": 0.0001395730787745113,
      "loss": 0.3839,
      "step": 2669
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.10408446937799454,
      "learning_rate": 0.0001395321044651339,
      "loss": 0.2575,
      "step": 2670
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.14231295883655548,
      "learning_rate": 0.0001394911222878783,
      "loss": 0.3491,
      "step": 2671
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1407695859670639,
      "learning_rate": 0.00013945013225090088,
      "loss": 0.3225,
      "step": 2672
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.13533222675323486,
      "learning_rate": 0.00013940913436235976,
      "loss": 0.3507,
      "step": 2673
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1321430504322052,
      "learning_rate": 0.0001393681286304145,
      "loss": 0.3183,
      "step": 2674
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.12795384228229523,
      "learning_rate": 0.0001393271150632263,
      "loss": 0.3573,
      "step": 2675
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.1426069438457489,
      "learning_rate": 0.00013928609366895784,
      "loss": 0.4204,
      "step": 2676
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.14785230159759521,
      "learning_rate": 0.00013924506445577345,
      "loss": 0.3784,
      "step": 2677
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11472661048173904,
      "learning_rate": 0.00013920402743183895,
      "loss": 0.2626,
      "step": 2678
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.14946439862251282,
      "learning_rate": 0.00013916298260532175,
      "loss": 0.4625,
      "step": 2679
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.15217991173267365,
      "learning_rate": 0.00013912192998439076,
      "loss": 0.3655,
      "step": 2680
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.11099566519260406,
      "learning_rate": 0.00013908086957721652,
      "loss": 0.3812,
      "step": 2681
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1524876058101654,
      "learning_rate": 0.00013903980139197108,
      "loss": 0.4068,
      "step": 2682
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11750238388776779,
      "learning_rate": 0.00013899872543682803,
      "loss": 0.3499,
      "step": 2683
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.15491460263729095,
      "learning_rate": 0.00013895764171996245,
      "loss": 0.3491,
      "step": 2684
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.10835450142621994,
      "learning_rate": 0.00013891655024955113,
      "loss": 0.3007,
      "step": 2685
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.13848033547401428,
      "learning_rate": 0.0001388754510337722,
      "loss": 0.3626,
      "step": 2686
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12173416465520859,
      "learning_rate": 0.00013883434408080555,
      "loss": 0.3638,
      "step": 2687
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12025794386863708,
      "learning_rate": 0.00013879322939883238,
      "loss": 0.3171,
      "step": 2688
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12630611658096313,
      "learning_rate": 0.00013875210699603564,
      "loss": 0.4151,
      "step": 2689
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.0979769304394722,
      "learning_rate": 0.00013871097688059958,
      "loss": 0.291,
      "step": 2690
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1961345672607422,
      "learning_rate": 0.0001386698390607103,
      "loss": 0.3398,
      "step": 2691
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.14722056686878204,
      "learning_rate": 0.00013862869354455513,
      "loss": 0.3779,
      "step": 2692
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.135354682803154,
      "learning_rate": 0.0001385875403403231,
      "loss": 0.4021,
      "step": 2693
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11117563396692276,
      "learning_rate": 0.00013854637945620468,
      "loss": 0.3395,
      "step": 2694
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12912124395370483,
      "learning_rate": 0.000138505210900392,
      "loss": 0.333,
      "step": 2695
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11580722033977509,
      "learning_rate": 0.00013846403468107855,
      "loss": 0.2775,
      "step": 2696
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1524641513824463,
      "learning_rate": 0.0001384228508064595,
      "loss": 0.3822,
      "step": 2697
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.10641877353191376,
      "learning_rate": 0.0001383816592847314,
      "loss": 0.2962,
      "step": 2698
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12119148671627045,
      "learning_rate": 0.0001383404601240925,
      "loss": 0.3576,
      "step": 2699
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12403684109449387,
      "learning_rate": 0.00013829925333274233,
      "loss": 0.3474,
      "step": 2700
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.13090267777442932,
      "learning_rate": 0.00013825803891888219,
      "loss": 0.3676,
      "step": 2701
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11296145617961884,
      "learning_rate": 0.00013821681689071472,
      "loss": 0.2782,
      "step": 2702
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12319397181272507,
      "learning_rate": 0.00013817558725644414,
      "loss": 0.3392,
      "step": 2703
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.14460700750350952,
      "learning_rate": 0.00013813435002427618,
      "loss": 0.4237,
      "step": 2704
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11665034294128418,
      "learning_rate": 0.00013809310520241806,
      "loss": 0.3431,
      "step": 2705
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.15942564606666565,
      "learning_rate": 0.00013805185279907857,
      "loss": 0.4263,
      "step": 2706
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.15706530213356018,
      "learning_rate": 0.000138010592822468,
      "loss": 0.3694,
      "step": 2707
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.13257192075252533,
      "learning_rate": 0.00013796932528079806,
      "loss": 0.3766,
      "step": 2708
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12534336745738983,
      "learning_rate": 0.00013792805018228202,
      "loss": 0.3845,
      "step": 2709
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1538817286491394,
      "learning_rate": 0.00013788676753513467,
      "loss": 0.4047,
      "step": 2710
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1455671340227127,
      "learning_rate": 0.00013784547734757232,
      "loss": 0.4111,
      "step": 2711
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.11808063834905624,
      "learning_rate": 0.00013780417962781273,
      "loss": 0.3123,
      "step": 2712
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.14584682881832123,
      "learning_rate": 0.00013776287438407517,
      "loss": 0.4478,
      "step": 2713
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.2459235042333603,
      "learning_rate": 0.00013772156162458044,
      "loss": 0.2263,
      "step": 2714
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12251347303390503,
      "learning_rate": 0.00013768024135755075,
      "loss": 0.3432,
      "step": 2715
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12087830156087875,
      "learning_rate": 0.00013763891359120997,
      "loss": 0.2995,
      "step": 2716
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13002997636795044,
      "learning_rate": 0.00013759757833378328,
      "loss": 0.3668,
      "step": 2717
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1049499362707138,
      "learning_rate": 0.00013755623559349748,
      "loss": 0.3085,
      "step": 2718
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11397320032119751,
      "learning_rate": 0.00013751488537858077,
      "loss": 0.3171,
      "step": 2719
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11786045879125595,
      "learning_rate": 0.0001374735276972629,
      "loss": 0.3836,
      "step": 2720
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.10310933738946915,
      "learning_rate": 0.00013743216255777507,
      "loss": 0.3707,
      "step": 2721
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.09801148623228073,
      "learning_rate": 0.00013739078996835,
      "loss": 0.3507,
      "step": 2722
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11734841018915176,
      "learning_rate": 0.00013734940993722185,
      "loss": 0.3266,
      "step": 2723
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11760096251964569,
      "learning_rate": 0.0001373080224726263,
      "loss": 0.2698,
      "step": 2724
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13695034384727478,
      "learning_rate": 0.00013726662758280046,
      "loss": 0.3952,
      "step": 2725
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11440974473953247,
      "learning_rate": 0.000137225225275983,
      "loss": 0.333,
      "step": 2726
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.09973017871379852,
      "learning_rate": 0.00013718381556041397,
      "loss": 0.2671,
      "step": 2727
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.179139643907547,
      "learning_rate": 0.00013714239844433494,
      "loss": 0.4495,
      "step": 2728
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1527051329612732,
      "learning_rate": 0.00013710097393598898,
      "loss": 0.3668,
      "step": 2729
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.12962907552719116,
      "learning_rate": 0.0001370595420436206,
      "loss": 0.3842,
      "step": 2730
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.14197802543640137,
      "learning_rate": 0.00013701810277547577,
      "loss": 0.4216,
      "step": 2731
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.12300349771976471,
      "learning_rate": 0.00013697665613980194,
      "loss": 0.4154,
      "step": 2732
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.10967046767473221,
      "learning_rate": 0.00013693520214484804,
      "loss": 0.3757,
      "step": 2733
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.15463660657405853,
      "learning_rate": 0.00013689374079886444,
      "loss": 0.32,
      "step": 2734
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.12952788174152374,
      "learning_rate": 0.000136852272110103,
      "loss": 0.4162,
      "step": 2735
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1272936761379242,
      "learning_rate": 0.00013681079608681703,
      "loss": 0.3434,
      "step": 2736
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11575566977262497,
      "learning_rate": 0.0001367693127372613,
      "loss": 0.296,
      "step": 2737
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.10211581736803055,
      "learning_rate": 0.00013672782206969198,
      "loss": 0.2994,
      "step": 2738
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13445694744586945,
      "learning_rate": 0.00013668632409236683,
      "loss": 0.3736,
      "step": 2739
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11359302699565887,
      "learning_rate": 0.00013664481881354496,
      "loss": 0.3416,
      "step": 2740
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.12912435829639435,
      "learning_rate": 0.00013660330624148693,
      "loss": 0.3077,
      "step": 2741
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1851814240217209,
      "learning_rate": 0.00013656178638445476,
      "loss": 0.3749,
      "step": 2742
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13323257863521576,
      "learning_rate": 0.00013652025925071202,
      "loss": 0.3148,
      "step": 2743
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.15497761964797974,
      "learning_rate": 0.00013647872484852361,
      "loss": 0.348,
      "step": 2744
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.15470097959041595,
      "learning_rate": 0.0001364371831861559,
      "loss": 0.4079,
      "step": 2745
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11738632619380951,
      "learning_rate": 0.00013639563427187673,
      "loss": 0.3049,
      "step": 2746
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.10575411468744278,
      "learning_rate": 0.0001363540781139554,
      "loss": 0.325,
      "step": 2747
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.10070128738880157,
      "learning_rate": 0.0001363125147206626,
      "loss": 0.2535,
      "step": 2748
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11567752808332443,
      "learning_rate": 0.00013627094410027048,
      "loss": 0.3629,
      "step": 2749
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.16023418307304382,
      "learning_rate": 0.00013622936626105268,
      "loss": 0.3901,
      "step": 2750
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13472290337085724,
      "learning_rate": 0.00013618778121128415,
      "loss": 0.3753,
      "step": 2751
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.11740284413099289,
      "learning_rate": 0.00013614618895924142,
      "loss": 0.3307,
      "step": 2752
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.10473700612783432,
      "learning_rate": 0.00013610458951320237,
      "loss": 0.2678,
      "step": 2753
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.10629487782716751,
      "learning_rate": 0.00013606298288144632,
      "loss": 0.3099,
      "step": 2754
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.09019447863101959,
      "learning_rate": 0.00013602136907225405,
      "loss": 0.2628,
      "step": 2755
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1187773197889328,
      "learning_rate": 0.00013597974809390778,
      "loss": 0.4015,
      "step": 2756
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.11312542110681534,
      "learning_rate": 0.00013593811995469104,
      "loss": 0.3094,
      "step": 2757
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.14036716520786285,
      "learning_rate": 0.0001358964846628889,
      "loss": 0.3456,
      "step": 2758
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.18961367011070251,
      "learning_rate": 0.00013585484222678788,
      "loss": 0.4985,
      "step": 2759
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.11765611171722412,
      "learning_rate": 0.00013581319265467586,
      "loss": 0.3042,
      "step": 2760
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.17415350675582886,
      "learning_rate": 0.00013577153595484208,
      "loss": 0.3075,
      "step": 2761
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.10762780159711838,
      "learning_rate": 0.0001357298721355773,
      "loss": 0.3486,
      "step": 2762
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.13007064163684845,
      "learning_rate": 0.0001356882012051737,
      "loss": 0.409,
      "step": 2763
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1411915272474289,
      "learning_rate": 0.0001356465231719248,
      "loss": 0.373,
      "step": 2764
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.10316445678472519,
      "learning_rate": 0.00013560483804412555,
      "loss": 0.247,
      "step": 2765
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.10342201590538025,
      "learning_rate": 0.00013556314583007239,
      "loss": 0.33,
      "step": 2766
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.09888525307178497,
      "learning_rate": 0.00013552144653806306,
      "loss": 0.3345,
      "step": 2767
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1049465611577034,
      "learning_rate": 0.00013547974017639683,
      "loss": 0.3171,
      "step": 2768
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.11081960052251816,
      "learning_rate": 0.00013543802675337421,
      "loss": 0.2823,
      "step": 2769
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1429765373468399,
      "learning_rate": 0.00013539630627729734,
      "loss": 0.4178,
      "step": 2770
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.13898101449012756,
      "learning_rate": 0.00013535457875646953,
      "loss": 0.3176,
      "step": 2771
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.11208690702915192,
      "learning_rate": 0.00013531284419919566,
      "loss": 0.3024,
      "step": 2772
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.11849170178174973,
      "learning_rate": 0.00013527110261378193,
      "loss": 0.3515,
      "step": 2773
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1221713125705719,
      "learning_rate": 0.00013522935400853595,
      "loss": 0.3037,
      "step": 2774
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.14538998901844025,
      "learning_rate": 0.00013518759839176677,
      "loss": 0.391,
      "step": 2775
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.15064571797847748,
      "learning_rate": 0.00013514583577178482,
      "loss": 0.4111,
      "step": 2776
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.47543737292289734,
      "learning_rate": 0.00013510406615690183,
      "loss": 0.2497,
      "step": 2777
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.09937893599271774,
      "learning_rate": 0.00013506228955543104,
      "loss": 0.3189,
      "step": 2778
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.12575803697109222,
      "learning_rate": 0.00013502050597568704,
      "loss": 0.3449,
      "step": 2779
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.11937063187360764,
      "learning_rate": 0.00013497871542598582,
      "loss": 0.3003,
      "step": 2780
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.11214549094438553,
      "learning_rate": 0.00013493691791464474,
      "loss": 0.3077,
      "step": 2781
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1763727366924286,
      "learning_rate": 0.00013489511344998254,
      "loss": 0.381,
      "step": 2782
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.09929210692644119,
      "learning_rate": 0.00013485330204031937,
      "loss": 0.2682,
      "step": 2783
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.09896949678659439,
      "learning_rate": 0.00013481148369397672,
      "loss": 0.2353,
      "step": 2784
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.10853298008441925,
      "learning_rate": 0.0001347696584192775,
      "loss": 0.278,
      "step": 2785
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.13584795594215393,
      "learning_rate": 0.00013472782622454601,
      "loss": 0.4145,
      "step": 2786
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2832220792770386,
      "learning_rate": 0.00013468598711810788,
      "loss": 0.2718,
      "step": 2787
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.11459361016750336,
      "learning_rate": 0.00013464414110829015,
      "loss": 0.3679,
      "step": 2788
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1222747415304184,
      "learning_rate": 0.0001346022882034212,
      "loss": 0.3188,
      "step": 2789
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.09901140630245209,
      "learning_rate": 0.00013456042841183082,
      "loss": 0.396,
      "step": 2790
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12808427214622498,
      "learning_rate": 0.00013451856174185017,
      "loss": 0.3672,
      "step": 2791
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.10451734811067581,
      "learning_rate": 0.00013447668820181177,
      "loss": 0.2633,
      "step": 2792
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.16102315485477448,
      "learning_rate": 0.00013443480780004946,
      "loss": 0.4665,
      "step": 2793
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1435876190662384,
      "learning_rate": 0.00013439292054489852,
      "loss": 0.3267,
      "step": 2794
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12391100078821182,
      "learning_rate": 0.00013435102644469558,
      "loss": 0.3123,
      "step": 2795
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.11840909719467163,
      "learning_rate": 0.00013430912550777859,
      "loss": 0.364,
      "step": 2796
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12014975398778915,
      "learning_rate": 0.0001342672177424869,
      "loss": 0.3364,
      "step": 2797
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12774403393268585,
      "learning_rate": 0.00013422530315716115,
      "loss": 0.396,
      "step": 2798
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.10592558979988098,
      "learning_rate": 0.00013418338176014345,
      "loss": 0.2594,
      "step": 2799
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12532763183116913,
      "learning_rate": 0.00013414145355977722,
      "loss": 0.3533,
      "step": 2800
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.13890601694583893,
      "learning_rate": 0.00013409951856440717,
      "loss": 0.3378,
      "step": 2801
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.14229854941368103,
      "learning_rate": 0.00013405757678237943,
      "loss": 0.389,
      "step": 2802
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.09855758398771286,
      "learning_rate": 0.00013401562822204147,
      "loss": 0.2973,
      "step": 2803
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12935371696949005,
      "learning_rate": 0.0001339736728917421,
      "loss": 0.3187,
      "step": 2804
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.16106100380420685,
      "learning_rate": 0.00013393171079983149,
      "loss": 0.324,
      "step": 2805
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.13995453715324402,
      "learning_rate": 0.00013388974195466114,
      "loss": 0.3904,
      "step": 2806
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.13809742033481598,
      "learning_rate": 0.0001338477663645839,
      "loss": 0.3973,
      "step": 2807
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.11533736437559128,
      "learning_rate": 0.000133805784037954,
      "loss": 0.3283,
      "step": 2808
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.145400270819664,
      "learning_rate": 0.00013376379498312687,
      "loss": 0.435,
      "step": 2809
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1313246488571167,
      "learning_rate": 0.00013372179920845948,
      "loss": 0.4351,
      "step": 2810
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12137874215841293,
      "learning_rate": 0.00013367979672231003,
      "loss": 0.3621,
      "step": 2811
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.15101902186870575,
      "learning_rate": 0.00013363778753303803,
      "loss": 0.3777,
      "step": 2812
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.10658324509859085,
      "learning_rate": 0.00013359577164900438,
      "loss": 0.3483,
      "step": 2813
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12108197808265686,
      "learning_rate": 0.0001335537490785713,
      "loss": 0.3793,
      "step": 2814
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12446969747543335,
      "learning_rate": 0.00013351171983010232,
      "loss": 0.3425,
      "step": 2815
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.11350889503955841,
      "learning_rate": 0.00013346968391196232,
      "loss": 0.3398,
      "step": 2816
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.13601362705230713,
      "learning_rate": 0.00013342764133251748,
      "loss": 0.3517,
      "step": 2817
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1065860241651535,
      "learning_rate": 0.00013338559210013536,
      "loss": 0.2849,
      "step": 2818
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.11897393316030502,
      "learning_rate": 0.00013334353622318477,
      "loss": 0.442,
      "step": 2819
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.11028219014406204,
      "learning_rate": 0.0001333014737100359,
      "loss": 0.3106,
      "step": 2820
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.11029545217752457,
      "learning_rate": 0.00013325940456906027,
      "loss": 0.3103,
      "step": 2821
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.09846553206443787,
      "learning_rate": 0.00013321732880863067,
      "loss": 0.3044,
      "step": 2822
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.14973625540733337,
      "learning_rate": 0.0001331752464371212,
      "loss": 0.4119,
      "step": 2823
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.11951275169849396,
      "learning_rate": 0.00013313315746290737,
      "loss": 0.3044,
      "step": 2824
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.09186115115880966,
      "learning_rate": 0.00013309106189436588,
      "loss": 0.2346,
      "step": 2825
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.11193370074033737,
      "learning_rate": 0.00013304895973987482,
      "loss": 0.2513,
      "step": 2826
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.15366528928279877,
      "learning_rate": 0.00013300685100781358,
      "loss": 0.4017,
      "step": 2827
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.11864794045686722,
      "learning_rate": 0.00013296473570656287,
      "loss": 0.3459,
      "step": 2828
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1175108253955841,
      "learning_rate": 0.00013292261384450463,
      "loss": 0.3511,
      "step": 2829
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.11524687707424164,
      "learning_rate": 0.00013288048543002223,
      "loss": 0.3503,
      "step": 2830
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13158784806728363,
      "learning_rate": 0.00013283835047150024,
      "loss": 0.3535,
      "step": 2831
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.11474944651126862,
      "learning_rate": 0.0001327962089773246,
      "loss": 0.2741,
      "step": 2832
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.10659368336200714,
      "learning_rate": 0.0001327540609558825,
      "loss": 0.3517,
      "step": 2833
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12817589938640594,
      "learning_rate": 0.00013271190641556244,
      "loss": 0.3686,
      "step": 2834
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.11848441511392593,
      "learning_rate": 0.00013266974536475424,
      "loss": 0.3265,
      "step": 2835
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13749603927135468,
      "learning_rate": 0.000132627577811849,
      "loss": 0.3703,
      "step": 2836
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.14155589044094086,
      "learning_rate": 0.00013258540376523916,
      "loss": 0.3336,
      "step": 2837
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13987965881824493,
      "learning_rate": 0.00013254322323331835,
      "loss": 0.3466,
      "step": 2838
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13311339914798737,
      "learning_rate": 0.0001325010362244816,
      "loss": 0.3486,
      "step": 2839
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12185709178447723,
      "learning_rate": 0.00013245884274712513,
      "loss": 0.3934,
      "step": 2840
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12901097536087036,
      "learning_rate": 0.00013241664280964658,
      "loss": 0.3494,
      "step": 2841
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12303212285041809,
      "learning_rate": 0.00013237443642044472,
      "loss": 0.3421,
      "step": 2842
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12640170753002167,
      "learning_rate": 0.00013233222358791967,
      "loss": 0.3678,
      "step": 2843
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.11397187411785126,
      "learning_rate": 0.0001322900043204729,
      "loss": 0.3108,
      "step": 2844
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1360647827386856,
      "learning_rate": 0.00013224777862650707,
      "loss": 0.3567,
      "step": 2845
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.09192819148302078,
      "learning_rate": 0.00013220554651442615,
      "loss": 0.2586,
      "step": 2846
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12426251918077469,
      "learning_rate": 0.00013216330799263536,
      "loss": 0.2886,
      "step": 2847
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1276102215051651,
      "learning_rate": 0.00013212106306954128,
      "loss": 0.3158,
      "step": 2848
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13672614097595215,
      "learning_rate": 0.00013207881175355168,
      "loss": 0.3383,
      "step": 2849
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12850749492645264,
      "learning_rate": 0.00013203655405307562,
      "loss": 0.3464,
      "step": 2850
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.120547816157341,
      "learning_rate": 0.00013199428997652345,
      "loss": 0.3285,
      "step": 2851
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.10813362896442413,
      "learning_rate": 0.00013195201953230677,
      "loss": 0.4074,
      "step": 2852
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12499286234378815,
      "learning_rate": 0.0001319097427288385,
      "loss": 0.3149,
      "step": 2853
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1204647496342659,
      "learning_rate": 0.0001318674595745327,
      "loss": 0.3183,
      "step": 2854
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13602353632450104,
      "learning_rate": 0.00013182517007780483,
      "loss": 0.34,
      "step": 2855
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.14296002686023712,
      "learning_rate": 0.0001317828742470716,
      "loss": 0.3464,
      "step": 2856
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13000799715518951,
      "learning_rate": 0.00013174057209075084,
      "loss": 0.3302,
      "step": 2857
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12025338411331177,
      "learning_rate": 0.00013169826361726175,
      "loss": 0.2614,
      "step": 2858
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12414049357175827,
      "learning_rate": 0.00013165594883502487,
      "loss": 0.3389,
      "step": 2859
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1332802027463913,
      "learning_rate": 0.00013161362775246184,
      "loss": 0.3514,
      "step": 2860
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12921912968158722,
      "learning_rate": 0.00013157130037799562,
      "loss": 0.3222,
      "step": 2861
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1541261076927185,
      "learning_rate": 0.00013152896672005042,
      "loss": 0.4015,
      "step": 2862
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.13048648834228516,
      "learning_rate": 0.00013148662678705167,
      "loss": 0.3562,
      "step": 2863
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1417718380689621,
      "learning_rate": 0.00013144428058742608,
      "loss": 0.3257,
      "step": 2864
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.09784549474716187,
      "learning_rate": 0.00013140192812960167,
      "loss": 0.2289,
      "step": 2865
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.13254395127296448,
      "learning_rate": 0.00013135956942200757,
      "loss": 0.2896,
      "step": 2866
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.0953526496887207,
      "learning_rate": 0.0001313172044730742,
      "loss": 0.2926,
      "step": 2867
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1088702604174614,
      "learning_rate": 0.00013127483329123334,
      "loss": 0.3158,
      "step": 2868
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12686464190483093,
      "learning_rate": 0.00013123245588491785,
      "loss": 0.3957,
      "step": 2869
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.10312388092279434,
      "learning_rate": 0.00013119007226256192,
      "loss": 0.2699,
      "step": 2870
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.10762985050678253,
      "learning_rate": 0.00013114768243260093,
      "loss": 0.3216,
      "step": 2871
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.13623781502246857,
      "learning_rate": 0.00013110528640347154,
      "loss": 0.3981,
      "step": 2872
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.13890008628368378,
      "learning_rate": 0.00013106288418361162,
      "loss": 0.4023,
      "step": 2873
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12391013652086258,
      "learning_rate": 0.00013102047578146024,
      "loss": 0.4357,
      "step": 2874
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12152808159589767,
      "learning_rate": 0.00013097806120545774,
      "loss": 0.3383,
      "step": 2875
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1568964272737503,
      "learning_rate": 0.00013093564046404572,
      "loss": 0.4083,
      "step": 2876
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.11085821688175201,
      "learning_rate": 0.00013089321356566695,
      "loss": 0.3074,
      "step": 2877
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.15295369923114777,
      "learning_rate": 0.00013085078051876546,
      "loss": 0.3267,
      "step": 2878
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12426290661096573,
      "learning_rate": 0.00013080834133178643,
      "loss": 0.3469,
      "step": 2879
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.10340774059295654,
      "learning_rate": 0.00013076589601317636,
      "loss": 0.3026,
      "step": 2880
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.15716367959976196,
      "learning_rate": 0.000130723444571383,
      "loss": 0.4431,
      "step": 2881
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1094411313533783,
      "learning_rate": 0.00013068098701485512,
      "loss": 0.3487,
      "step": 2882
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1263858824968338,
      "learning_rate": 0.0001306385233520429,
      "loss": 0.3402,
      "step": 2883
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12304920703172684,
      "learning_rate": 0.00013059605359139767,
      "loss": 0.3327,
      "step": 2884
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12793594598770142,
      "learning_rate": 0.000130553577741372,
      "loss": 0.3564,
      "step": 2885
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.10626115649938583,
      "learning_rate": 0.00013051109581041961,
      "loss": 0.283,
      "step": 2886
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.11734813451766968,
      "learning_rate": 0.00013046860780699547,
      "loss": 0.3244,
      "step": 2887
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12812687456607819,
      "learning_rate": 0.00013042611373955578,
      "loss": 0.3243,
      "step": 2888
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.12152495235204697,
      "learning_rate": 0.0001303836136165579,
      "loss": 0.3922,
      "step": 2889
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.13928739726543427,
      "learning_rate": 0.00013034110744646044,
      "loss": 0.3462,
      "step": 2890
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.18323862552642822,
      "learning_rate": 0.00013029859523772314,
      "loss": 0.3275,
      "step": 2891
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.15989424288272858,
      "learning_rate": 0.00013025607699880705,
      "loss": 0.5626,
      "step": 2892
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.13406267762184143,
      "learning_rate": 0.0001302135527381744,
      "loss": 0.2818,
      "step": 2893
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1288495510816574,
      "learning_rate": 0.00013017102246428848,
      "loss": 0.3582,
      "step": 2894
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.13112236559391022,
      "learning_rate": 0.00013012848618561396,
      "loss": 0.383,
      "step": 2895
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.10596097260713577,
      "learning_rate": 0.00013008594391061655,
      "loss": 0.3361,
      "step": 2896
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.11191631853580475,
      "learning_rate": 0.0001300433956477633,
      "loss": 0.2431,
      "step": 2897
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.11542452126741409,
      "learning_rate": 0.0001300008414055223,
      "loss": 0.3573,
      "step": 2898
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.09529159963130951,
      "learning_rate": 0.000129958281192363,
      "loss": 0.2706,
      "step": 2899
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1558651477098465,
      "learning_rate": 0.0001299157150167559,
      "loss": 0.3414,
      "step": 2900
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.0989769995212555,
      "learning_rate": 0.00012987314288717274,
      "loss": 0.3065,
      "step": 2901
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1166750118136406,
      "learning_rate": 0.00012983056481208642,
      "loss": 0.3243,
      "step": 2902
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1307125985622406,
      "learning_rate": 0.00012978798079997108,
      "loss": 0.334,
      "step": 2903
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.10816087573766708,
      "learning_rate": 0.00012974539085930197,
      "loss": 0.3111,
      "step": 2904
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12945488095283508,
      "learning_rate": 0.0001297027949985556,
      "loss": 0.3161,
      "step": 2905
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.11282220482826233,
      "learning_rate": 0.00012966019322620956,
      "loss": 0.3752,
      "step": 2906
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.0973336473107338,
      "learning_rate": 0.0001296175855507427,
      "loss": 0.3083,
      "step": 2907
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.11570346355438232,
      "learning_rate": 0.000129574971980635,
      "loss": 0.322,
      "step": 2908
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12932443618774414,
      "learning_rate": 0.00012953235252436763,
      "loss": 0.3011,
      "step": 2909
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12830416858196259,
      "learning_rate": 0.00012948972719042294,
      "loss": 0.3704,
      "step": 2910
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12603585422039032,
      "learning_rate": 0.00012944709598728443,
      "loss": 0.3265,
      "step": 2911
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.13436086475849152,
      "learning_rate": 0.00012940445892343675,
      "loss": 0.4,
      "step": 2912
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.15934672951698303,
      "learning_rate": 0.0001293618160073658,
      "loss": 0.4041,
      "step": 2913
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12018200755119324,
      "learning_rate": 0.00012931916724755852,
      "loss": 0.3147,
      "step": 2914
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.129129096865654,
      "learning_rate": 0.00012927651265250316,
      "loss": 0.3064,
      "step": 2915
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12189725041389465,
      "learning_rate": 0.000129233852230689,
      "loss": 0.3728,
      "step": 2916
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.13171161711215973,
      "learning_rate": 0.00012919118599060653,
      "loss": 0.3155,
      "step": 2917
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.10098274797201157,
      "learning_rate": 0.00012914851394074737,
      "loss": 0.2762,
      "step": 2918
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.13092052936553955,
      "learning_rate": 0.00012910583608960442,
      "loss": 0.3615,
      "step": 2919
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12995855510234833,
      "learning_rate": 0.00012906315244567157,
      "loss": 0.361,
      "step": 2920
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12576833367347717,
      "learning_rate": 0.00012902046301744397,
      "loss": 0.2837,
      "step": 2921
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.18976759910583496,
      "learning_rate": 0.00012897776781341786,
      "loss": 0.4554,
      "step": 2922
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.11308881640434265,
      "learning_rate": 0.00012893506684209064,
      "loss": 0.3726,
      "step": 2923
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.13646532595157623,
      "learning_rate": 0.00012889236011196092,
      "loss": 0.3096,
      "step": 2924
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.12553934752941132,
      "learning_rate": 0.00012884964763152835,
      "loss": 0.3056,
      "step": 2925
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.13309180736541748,
      "learning_rate": 0.00012880692940929383,
      "loss": 0.357,
      "step": 2926
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.11934027820825577,
      "learning_rate": 0.00012876420545375933,
      "loss": 0.3217,
      "step": 2927
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.11458948254585266,
      "learning_rate": 0.000128721475773428,
      "loss": 0.2912,
      "step": 2928
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.137134850025177,
      "learning_rate": 0.0001286787403768041,
      "loss": 0.314,
      "step": 2929
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1429494470357895,
      "learning_rate": 0.00012863599927239307,
      "loss": 0.4102,
      "step": 2930
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.11390439420938492,
      "learning_rate": 0.00012859325246870142,
      "loss": 0.3312,
      "step": 2931
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1340116262435913,
      "learning_rate": 0.00012855049997423688,
      "loss": 0.2858,
      "step": 2932
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.11448991298675537,
      "learning_rate": 0.00012850774179750822,
      "loss": 0.3049,
      "step": 2933
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.14283619821071625,
      "learning_rate": 0.00012846497794702543,
      "loss": 0.4694,
      "step": 2934
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.13529172539710999,
      "learning_rate": 0.00012842220843129956,
      "loss": 0.3694,
      "step": 2935
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1336676925420761,
      "learning_rate": 0.0001283794332588428,
      "loss": 0.3342,
      "step": 2936
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.14226415753364563,
      "learning_rate": 0.00012833665243816854,
      "loss": 0.4609,
      "step": 2937
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.17775112390518188,
      "learning_rate": 0.00012829386597779118,
      "loss": 0.3548,
      "step": 2938
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.14605724811553955,
      "learning_rate": 0.00012825107388622634,
      "loss": 0.3333,
      "step": 2939
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.16963708400726318,
      "learning_rate": 0.00012820827617199062,
      "loss": 0.3509,
      "step": 2940
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.10810703039169312,
      "learning_rate": 0.00012816547284360196,
      "loss": 0.4169,
      "step": 2941
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1273089051246643,
      "learning_rate": 0.00012812266390957924,
      "loss": 0.3603,
      "step": 2942
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.14609673619270325,
      "learning_rate": 0.0001280798493784425,
      "loss": 0.3221,
      "step": 2943
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.13427849113941193,
      "learning_rate": 0.0001280370292587129,
      "loss": 0.4294,
      "step": 2944
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1621641218662262,
      "learning_rate": 0.00012799420355891274,
      "loss": 0.4794,
      "step": 2945
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.12979665398597717,
      "learning_rate": 0.0001279513722875654,
      "loss": 0.2985,
      "step": 2946
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.08973594754934311,
      "learning_rate": 0.00012790853545319536,
      "loss": 0.2924,
      "step": 2947
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1563631296157837,
      "learning_rate": 0.00012786569306432821,
      "loss": 0.4278,
      "step": 2948
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.15171648561954498,
      "learning_rate": 0.00012782284512949073,
      "loss": 0.3545,
      "step": 2949
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.14541034400463104,
      "learning_rate": 0.00012777999165721062,
      "loss": 0.3415,
      "step": 2950
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.11659256368875504,
      "learning_rate": 0.00012773713265601687,
      "loss": 0.3094,
      "step": 2951
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.13613155484199524,
      "learning_rate": 0.0001276942681344395,
      "loss": 0.426,
      "step": 2952
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.11777213960886002,
      "learning_rate": 0.00012765139810100962,
      "loss": 0.2922,
      "step": 2953
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1294386088848114,
      "learning_rate": 0.00012760852256425942,
      "loss": 0.2826,
      "step": 2954
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.09905717521905899,
      "learning_rate": 0.00012756564153272216,
      "loss": 0.2927,
      "step": 2955
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.15034063160419464,
      "learning_rate": 0.0001275227550149323,
      "loss": 0.3213,
      "step": 2956
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.12976323068141937,
      "learning_rate": 0.00012747986301942532,
      "loss": 0.4164,
      "step": 2957
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.131028950214386,
      "learning_rate": 0.00012743696555473779,
      "loss": 0.4255,
      "step": 2958
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.2014232724905014,
      "learning_rate": 0.00012739406262940738,
      "loss": 0.3509,
      "step": 2959
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.12759482860565186,
      "learning_rate": 0.00012735115425197287,
      "loss": 0.3471,
      "step": 2960
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.17111928761005402,
      "learning_rate": 0.00012730824043097403,
      "loss": 0.4786,
      "step": 2961
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.17460761964321136,
      "learning_rate": 0.00012726532117495192,
      "loss": 0.499,
      "step": 2962
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.11359966546297073,
      "learning_rate": 0.0001272223964924484,
      "loss": 0.2959,
      "step": 2963
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1335337609052658,
      "learning_rate": 0.00012717946639200664,
      "loss": 0.3718,
      "step": 2964
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.12033198028802872,
      "learning_rate": 0.00012713653088217077,
      "loss": 0.3222,
      "step": 2965
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.13792312145233154,
      "learning_rate": 0.00012709358997148605,
      "loss": 0.3988,
      "step": 2966
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1189785972237587,
      "learning_rate": 0.0001270506436684988,
      "loss": 0.2927,
      "step": 2967
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12793436646461487,
      "learning_rate": 0.00012700769198175637,
      "loss": 0.3723,
      "step": 2968
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.13272304832935333,
      "learning_rate": 0.00012696473491980727,
      "loss": 0.2987,
      "step": 2969
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.13217857480049133,
      "learning_rate": 0.00012692177249120102,
      "loss": 0.3184,
      "step": 2970
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12410245835781097,
      "learning_rate": 0.00012687880470448818,
      "loss": 0.3292,
      "step": 2971
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12104583531618118,
      "learning_rate": 0.00012683583156822045,
      "loss": 0.359,
      "step": 2972
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.09823555499315262,
      "learning_rate": 0.00012679285309095056,
      "loss": 0.2308,
      "step": 2973
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12539619207382202,
      "learning_rate": 0.00012674986928123234,
      "loss": 0.3612,
      "step": 2974
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.2192031890153885,
      "learning_rate": 0.00012670688014762056,
      "loss": 0.4202,
      "step": 2975
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.124782495200634,
      "learning_rate": 0.00012666388569867115,
      "loss": 0.3342,
      "step": 2976
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1510152816772461,
      "learning_rate": 0.00012662088594294114,
      "loss": 0.376,
      "step": 2977
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.11618467420339584,
      "learning_rate": 0.00012657788088898852,
      "loss": 0.5301,
      "step": 2978
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.11489689350128174,
      "learning_rate": 0.00012653487054537237,
      "loss": 0.3047,
      "step": 2979
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.09436320513486862,
      "learning_rate": 0.0001264918549206528,
      "loss": 0.2614,
      "step": 2980
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.11926918476819992,
      "learning_rate": 0.00012644883402339105,
      "loss": 0.2759,
      "step": 2981
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1280820071697235,
      "learning_rate": 0.00012640580786214936,
      "loss": 0.392,
      "step": 2982
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.11065082997083664,
      "learning_rate": 0.00012636277644549094,
      "loss": 0.3016,
      "step": 2983
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.09728299826383591,
      "learning_rate": 0.00012631973978198023,
      "loss": 0.3359,
      "step": 2984
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12378765642642975,
      "learning_rate": 0.00012627669788018247,
      "loss": 0.3448,
      "step": 2985
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.13496333360671997,
      "learning_rate": 0.00012623365074866417,
      "loss": 0.2817,
      "step": 2986
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12343041598796844,
      "learning_rate": 0.00012619059839599273,
      "loss": 0.3566,
      "step": 2987
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.26487603783607483,
      "learning_rate": 0.0001261475408307367,
      "loss": 0.4905,
      "step": 2988
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12297090142965317,
      "learning_rate": 0.00012610447806146556,
      "loss": 0.3186,
      "step": 2989
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.10386490821838379,
      "learning_rate": 0.00012606141009674997,
      "loss": 0.2681,
      "step": 2990
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.11877301335334778,
      "learning_rate": 0.00012601833694516143,
      "loss": 0.2793,
      "step": 2991
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.10442501306533813,
      "learning_rate": 0.0001259752586152726,
      "loss": 0.3133,
      "step": 2992
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.15399813652038574,
      "learning_rate": 0.00012593217511565715,
      "loss": 0.4007,
      "step": 2993
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.14302381873130798,
      "learning_rate": 0.00012588908645488984,
      "loss": 0.2951,
      "step": 2994
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.10650520026683807,
      "learning_rate": 0.0001258459926415463,
      "loss": 0.3249,
      "step": 2995
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.13642220199108124,
      "learning_rate": 0.00012580289368420333,
      "loss": 0.3518,
      "step": 2996
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.11297234892845154,
      "learning_rate": 0.00012575978959143865,
      "loss": 0.4069,
      "step": 2997
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.13270603120326996,
      "learning_rate": 0.00012571668037183114,
      "loss": 0.387,
      "step": 2998
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.13299375772476196,
      "learning_rate": 0.00012567356603396054,
      "loss": 0.2973,
      "step": 2999
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.15257978439331055,
      "learning_rate": 0.0001256304465864077,
      "loss": 0.3614,
      "step": 3000
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.09679766744375229,
      "learning_rate": 0.00012558732203775448,
      "loss": 0.2721,
      "step": 3001
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.08757179230451584,
      "learning_rate": 0.00012554419239658375,
      "loss": 0.2196,
      "step": 3002
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1569366306066513,
      "learning_rate": 0.00012550105767147938,
      "loss": 0.4668,
      "step": 3003
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.0853314995765686,
      "learning_rate": 0.00012545791787102624,
      "loss": 0.2271,
      "step": 3004
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1352589875459671,
      "learning_rate": 0.00012541477300381023,
      "loss": 0.3591,
      "step": 3005
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11670073866844177,
      "learning_rate": 0.00012537162307841833,
      "loss": 0.3557,
      "step": 3006
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.13605326414108276,
      "learning_rate": 0.00012532846810343838,
      "loss": 0.3813,
      "step": 3007
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.12353791296482086,
      "learning_rate": 0.0001252853080874593,
      "loss": 0.3388,
      "step": 3008
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1259748786687851,
      "learning_rate": 0.00012524214303907103,
      "loss": 0.3203,
      "step": 3009
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11352185904979706,
      "learning_rate": 0.00012519897296686452,
      "loss": 0.3055,
      "step": 3010
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.10684739053249359,
      "learning_rate": 0.0001251557978794317,
      "loss": 0.317,
      "step": 3011
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11293568462133408,
      "learning_rate": 0.00012511261778536543,
      "loss": 0.34,
      "step": 3012
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1443215012550354,
      "learning_rate": 0.00012506943269325964,
      "loss": 0.3322,
      "step": 3013
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.12121085822582245,
      "learning_rate": 0.00012502624261170935,
      "loss": 0.3123,
      "step": 3014
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.14099130034446716,
      "learning_rate": 0.00012498304754931036,
      "loss": 0.3657,
      "step": 3015
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11682083457708359,
      "learning_rate": 0.00012493984751465957,
      "loss": 0.3985,
      "step": 3016
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.13458216190338135,
      "learning_rate": 0.00012489664251635492,
      "loss": 0.3492,
      "step": 3017
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.12990061938762665,
      "learning_rate": 0.0001248534325629952,
      "loss": 0.4063,
      "step": 3018
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.13709813356399536,
      "learning_rate": 0.00012481021766318044,
      "loss": 0.3757,
      "step": 3019
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.169806107878685,
      "learning_rate": 0.00012476699782551132,
      "loss": 0.3561,
      "step": 3020
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1269216537475586,
      "learning_rate": 0.00012472377305858972,
      "loss": 0.3614,
      "step": 3021
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1038849800825119,
      "learning_rate": 0.0001246805433710185,
      "loss": 0.3009,
      "step": 3022
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.09886439889669418,
      "learning_rate": 0.00012463730877140138,
      "loss": 0.3052,
      "step": 3023
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1416258066892624,
      "learning_rate": 0.00012459406926834316,
      "loss": 0.2967,
      "step": 3024
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11479969322681427,
      "learning_rate": 0.00012455082487044958,
      "loss": 0.3693,
      "step": 3025
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.1284959763288498,
      "learning_rate": 0.00012450757558632737,
      "loss": 0.3318,
      "step": 3026
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.12535010278224945,
      "learning_rate": 0.0001244643214245842,
      "loss": 0.3846,
      "step": 3027
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.12317298352718353,
      "learning_rate": 0.00012442106239382873,
      "loss": 0.3161,
      "step": 3028
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.12130091339349747,
      "learning_rate": 0.00012437779850267062,
      "loss": 0.3396,
      "step": 3029
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11225864291191101,
      "learning_rate": 0.00012433452975972045,
      "loss": 0.2674,
      "step": 3030
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.13138195872306824,
      "learning_rate": 0.00012429125617358975,
      "loss": 0.3594,
      "step": 3031
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.10535600781440735,
      "learning_rate": 0.0001242479777528911,
      "loss": 0.2887,
      "step": 3032
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.15469682216644287,
      "learning_rate": 0.00012420469450623794,
      "loss": 0.3327,
      "step": 3033
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11060837656259537,
      "learning_rate": 0.0001241614064422448,
      "loss": 0.3639,
      "step": 3034
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11379745602607727,
      "learning_rate": 0.00012411811356952699,
      "loss": 0.3056,
      "step": 3035
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.11141130328178406,
      "learning_rate": 0.0001240748158967009,
      "loss": 0.3081,
      "step": 3036
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12340639531612396,
      "learning_rate": 0.0001240315134323839,
      "loss": 0.3003,
      "step": 3037
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12958937883377075,
      "learning_rate": 0.00012398820618519425,
      "loss": 0.3705,
      "step": 3038
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12059169262647629,
      "learning_rate": 0.00012394489416375112,
      "loss": 0.2832,
      "step": 3039
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12083779275417328,
      "learning_rate": 0.00012390157737667473,
      "loss": 0.3615,
      "step": 3040
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.11506403237581253,
      "learning_rate": 0.0001238582558325862,
      "loss": 0.3163,
      "step": 3041
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.13563895225524902,
      "learning_rate": 0.00012381492954010765,
      "loss": 0.4007,
      "step": 3042
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.131173238158226,
      "learning_rate": 0.000123771598507862,
      "loss": 0.4076,
      "step": 3043
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1368420571088791,
      "learning_rate": 0.00012372826274447326,
      "loss": 0.3757,
      "step": 3044
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1088833138346672,
      "learning_rate": 0.00012368492225856633,
      "loss": 0.2839,
      "step": 3045
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12386122345924377,
      "learning_rate": 0.00012364157705876708,
      "loss": 0.3509,
      "step": 3046
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.13100990653038025,
      "learning_rate": 0.00012359822715370225,
      "loss": 0.3617,
      "step": 3047
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.13516603410243988,
      "learning_rate": 0.00012355487255199957,
      "loss": 0.4133,
      "step": 3048
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1162167340517044,
      "learning_rate": 0.00012351151326228768,
      "loss": 0.2732,
      "step": 3049
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12001889199018478,
      "learning_rate": 0.00012346814929319614,
      "loss": 0.328,
      "step": 3050
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1170392632484436,
      "learning_rate": 0.00012342478065335556,
      "loss": 0.3316,
      "step": 3051
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.13935880362987518,
      "learning_rate": 0.00012338140735139726,
      "loss": 0.348,
      "step": 3052
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12028544396162033,
      "learning_rate": 0.0001233380293959537,
      "loss": 0.3313,
      "step": 3053
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.10377062857151031,
      "learning_rate": 0.00012329464679565816,
      "loss": 0.2825,
      "step": 3054
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.11294175684452057,
      "learning_rate": 0.00012325125955914488,
      "loss": 0.2822,
      "step": 3055
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1423214226961136,
      "learning_rate": 0.00012320786769504894,
      "loss": 0.3311,
      "step": 3056
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12226887047290802,
      "learning_rate": 0.00012316447121200647,
      "loss": 0.3139,
      "step": 3057
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.16819588840007782,
      "learning_rate": 0.00012312107011865444,
      "loss": 0.4191,
      "step": 3058
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.11014644056558609,
      "learning_rate": 0.00012307766442363075,
      "loss": 0.2983,
      "step": 3059
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.13909411430358887,
      "learning_rate": 0.0001230342541355742,
      "loss": 0.4417,
      "step": 3060
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1338677704334259,
      "learning_rate": 0.00012299083926312456,
      "loss": 0.3262,
      "step": 3061
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.11750645190477371,
      "learning_rate": 0.00012294741981492245,
      "loss": 0.3548,
      "step": 3062
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.16116830706596375,
      "learning_rate": 0.00012290399579960946,
      "loss": 0.3538,
      "step": 3063
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.151260107755661,
      "learning_rate": 0.00012286056722582802,
      "loss": 0.33,
      "step": 3064
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1365063190460205,
      "learning_rate": 0.00012281713410222151,
      "loss": 0.3433,
      "step": 3065
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.08506003022193909,
      "learning_rate": 0.00012277369643743418,
      "loss": 0.2123,
      "step": 3066
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.10452805459499359,
      "learning_rate": 0.00012273025424011134,
      "loss": 0.3125,
      "step": 3067
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.10448811948299408,
      "learning_rate": 0.00012268680751889891,
      "loss": 0.2687,
      "step": 3068
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.13879233598709106,
      "learning_rate": 0.00012264335628244397,
      "loss": 0.378,
      "step": 3069
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.11079749464988708,
      "learning_rate": 0.0001225999005393944,
      "loss": 0.3896,
      "step": 3070
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12342563271522522,
      "learning_rate": 0.0001225564402983989,
      "loss": 0.3205,
      "step": 3071
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11727197468280792,
      "learning_rate": 0.00012251297556810722,
      "loss": 0.2895,
      "step": 3072
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.12100572884082794,
      "learning_rate": 0.00012246950635716995,
      "loss": 0.2969,
      "step": 3073
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.12322495877742767,
      "learning_rate": 0.00012242603267423853,
      "loss": 0.3489,
      "step": 3074
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1256372630596161,
      "learning_rate": 0.00012238255452796528,
      "loss": 0.3308,
      "step": 3075
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.14640973508358002,
      "learning_rate": 0.00012233907192700345,
      "loss": 0.3894,
      "step": 3076
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13941331207752228,
      "learning_rate": 0.00012229558488000716,
      "loss": 0.3767,
      "step": 3077
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.10923560708761215,
      "learning_rate": 0.00012225209339563145,
      "loss": 0.3458,
      "step": 3078
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1269744485616684,
      "learning_rate": 0.0001222085974825322,
      "loss": 0.3246,
      "step": 3079
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11173268407583237,
      "learning_rate": 0.0001221650971493662,
      "loss": 0.3115,
      "step": 3080
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11414293944835663,
      "learning_rate": 0.00012212159240479104,
      "loss": 0.2981,
      "step": 3081
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13566097617149353,
      "learning_rate": 0.0001220780832574653,
      "loss": 0.3372,
      "step": 3082
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11634138971567154,
      "learning_rate": 0.00012203456971604847,
      "loss": 0.32,
      "step": 3083
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13818855583667755,
      "learning_rate": 0.0001219910517892007,
      "loss": 0.4036,
      "step": 3084
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.10735248029232025,
      "learning_rate": 0.00012194752948558319,
      "loss": 0.3135,
      "step": 3085
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11453410983085632,
      "learning_rate": 0.00012190400281385801,
      "loss": 0.2991,
      "step": 3086
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.14433494210243225,
      "learning_rate": 0.00012186047178268802,
      "loss": 0.3629,
      "step": 3087
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11529262363910675,
      "learning_rate": 0.00012181693640073697,
      "loss": 0.2802,
      "step": 3088
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1509987860918045,
      "learning_rate": 0.00012177339667666951,
      "loss": 0.3845,
      "step": 3089
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.14149479568004608,
      "learning_rate": 0.00012172985261915116,
      "loss": 0.3452,
      "step": 3090
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1172659620642662,
      "learning_rate": 0.00012168630423684825,
      "loss": 0.3055,
      "step": 3091
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1320514678955078,
      "learning_rate": 0.00012164275153842799,
      "loss": 0.3232,
      "step": 3092
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13627348840236664,
      "learning_rate": 0.00012159919453255848,
      "loss": 0.413,
      "step": 3093
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.15311187505722046,
      "learning_rate": 0.00012155563322790864,
      "loss": 0.3564,
      "step": 3094
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.12717357277870178,
      "learning_rate": 0.00012151206763314827,
      "loss": 0.3077,
      "step": 3095
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13062803447246552,
      "learning_rate": 0.000121468497756948,
      "loss": 0.3513,
      "step": 3096
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11602406203746796,
      "learning_rate": 0.00012142492360797932,
      "loss": 0.3849,
      "step": 3097
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13496451079845428,
      "learning_rate": 0.0001213813451949146,
      "loss": 0.376,
      "step": 3098
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1563614159822464,
      "learning_rate": 0.00012133776252642703,
      "loss": 0.3449,
      "step": 3099
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1377994865179062,
      "learning_rate": 0.00012129417561119065,
      "loss": 0.3367,
      "step": 3100
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13701218366622925,
      "learning_rate": 0.00012125058445788033,
      "loss": 0.3456,
      "step": 3101
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1324457824230194,
      "learning_rate": 0.00012120698907517181,
      "loss": 0.3051,
      "step": 3102
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.11361777782440186,
      "learning_rate": 0.0001211633894717417,
      "loss": 0.2951,
      "step": 3103
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.13418807089328766,
      "learning_rate": 0.00012111978565626734,
      "loss": 0.3155,
      "step": 3104
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.20555570721626282,
      "learning_rate": 0.00012107617763742703,
      "loss": 0.3203,
      "step": 3105
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1262345165014267,
      "learning_rate": 0.00012103256542389984,
      "loss": 0.3522,
      "step": 3106
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.16225558519363403,
      "learning_rate": 0.00012098894902436575,
      "loss": 0.443,
      "step": 3107
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.15077097713947296,
      "learning_rate": 0.00012094532844750541,
      "loss": 0.4465,
      "step": 3108
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.12729768455028534,
      "learning_rate": 0.00012090170370200047,
      "loss": 0.358,
      "step": 3109
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.15770086646080017,
      "learning_rate": 0.00012085807479653332,
      "loss": 0.3558,
      "step": 3110
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.12230643630027771,
      "learning_rate": 0.00012081444173978727,
      "loss": 0.3776,
      "step": 3111
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.15267029404640198,
      "learning_rate": 0.00012077080454044632,
      "loss": 0.3056,
      "step": 3112
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.12605278193950653,
      "learning_rate": 0.00012072716320719534,
      "loss": 0.4216,
      "step": 3113
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.12479810416698456,
      "learning_rate": 0.00012068351774872013,
      "loss": 0.3598,
      "step": 3114
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.15273137390613556,
      "learning_rate": 0.00012063986817370722,
      "loss": 0.3615,
      "step": 3115
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.14908219873905182,
      "learning_rate": 0.0001205962144908439,
      "loss": 0.3638,
      "step": 3116
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.10506455600261688,
      "learning_rate": 0.0001205525567088184,
      "loss": 0.3536,
      "step": 3117
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.14198598265647888,
      "learning_rate": 0.00012050889483631969,
      "loss": 0.3145,
      "step": 3118
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.13424745202064514,
      "learning_rate": 0.0001204652288820376,
      "loss": 0.3856,
      "step": 3119
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1412402093410492,
      "learning_rate": 0.0001204215588546627,
      "loss": 0.3438,
      "step": 3120
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11858804523944855,
      "learning_rate": 0.00012037788476288647,
      "loss": 0.3235,
      "step": 3121
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.14293354749679565,
      "learning_rate": 0.00012033420661540112,
      "loss": 0.3745,
      "step": 3122
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.13119785487651825,
      "learning_rate": 0.00012029052442089972,
      "loss": 0.4046,
      "step": 3123
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1406807154417038,
      "learning_rate": 0.00012024683818807608,
      "loss": 0.3861,
      "step": 3124
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.15961159765720367,
      "learning_rate": 0.00012020314792562486,
      "loss": 0.4134,
      "step": 3125
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1401282399892807,
      "learning_rate": 0.00012015945364224155,
      "loss": 0.4203,
      "step": 3126
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.12948568165302277,
      "learning_rate": 0.0001201157553466224,
      "loss": 0.2931,
      "step": 3127
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.10665099322795868,
      "learning_rate": 0.00012007205304746442,
      "loss": 0.3107,
      "step": 3128
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1444029062986374,
      "learning_rate": 0.00012002834675346552,
      "loss": 0.4184,
      "step": 3129
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1273084133863449,
      "learning_rate": 0.0001199846364733243,
      "loss": 0.4138,
      "step": 3130
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.12677568197250366,
      "learning_rate": 0.00011994092221574025,
      "loss": 0.3506,
      "step": 3131
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.22315281629562378,
      "learning_rate": 0.00011989720398941353,
      "loss": 0.3756,
      "step": 3132
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11946514248847961,
      "learning_rate": 0.0001198534818030452,
      "loss": 0.3472,
      "step": 3133
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11670392006635666,
      "learning_rate": 0.0001198097556653371,
      "loss": 0.2929,
      "step": 3134
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11152230203151703,
      "learning_rate": 0.0001197660255849918,
      "loss": 0.328,
      "step": 3135
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.17434172332286835,
      "learning_rate": 0.00011972229157071266,
      "loss": 0.3432,
      "step": 3136
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11234916001558304,
      "learning_rate": 0.00011967855363120386,
      "loss": 0.3398,
      "step": 3137
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11169532686471939,
      "learning_rate": 0.00011963481177517036,
      "loss": 0.2815,
      "step": 3138
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.09675727784633636,
      "learning_rate": 0.00011959106601131785,
      "loss": 0.2758,
      "step": 3139
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11431199312210083,
      "learning_rate": 0.00011954731634835288,
      "loss": 0.3274,
      "step": 3140
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.14292268455028534,
      "learning_rate": 0.00011950356279498267,
      "loss": 0.3376,
      "step": 3141
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.12111978232860565,
      "learning_rate": 0.0001194598053599153,
      "loss": 0.2931,
      "step": 3142
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.08851335942745209,
      "learning_rate": 0.0001194160440518596,
      "loss": 0.2137,
      "step": 3143
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.12288561463356018,
      "learning_rate": 0.00011937227887952518,
      "loss": 0.3234,
      "step": 3144
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.10446619987487793,
      "learning_rate": 0.00011932850985162238,
      "loss": 0.2583,
      "step": 3145
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.15873385965824127,
      "learning_rate": 0.00011928473697686233,
      "loss": 0.4081,
      "step": 3146
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.11871228367090225,
      "learning_rate": 0.00011924096026395692,
      "loss": 0.2959,
      "step": 3147
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.10493919998407364,
      "learning_rate": 0.00011919717972161888,
      "loss": 0.2856,
      "step": 3148
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.16503356397151947,
      "learning_rate": 0.00011915339535856154,
      "loss": 0.4103,
      "step": 3149
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.15071198344230652,
      "learning_rate": 0.00011910960718349913,
      "loss": 0.4032,
      "step": 3150
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.14861980080604553,
      "learning_rate": 0.00011906581520514659,
      "loss": 0.3905,
      "step": 3151
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.10938827693462372,
      "learning_rate": 0.00011902201943221963,
      "loss": 0.238,
      "step": 3152
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.08981326222419739,
      "learning_rate": 0.0001189782198734347,
      "loss": 0.2661,
      "step": 3153
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.10938472300767899,
      "learning_rate": 0.00011893441653750896,
      "loss": 0.2845,
      "step": 3154
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.10839015990495682,
      "learning_rate": 0.00011889060943316047,
      "loss": 0.3015,
      "step": 3155
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.12959955632686615,
      "learning_rate": 0.00011884679856910783,
      "loss": 0.3238,
      "step": 3156
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.13520853221416473,
      "learning_rate": 0.00011880298395407057,
      "loss": 0.4458,
      "step": 3157
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.13047343492507935,
      "learning_rate": 0.00011875916559676887,
      "loss": 0.3635,
      "step": 3158
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.123379647731781,
      "learning_rate": 0.00011871534350592373,
      "loss": 0.31,
      "step": 3159
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1396961361169815,
      "learning_rate": 0.00011867151769025675,
      "loss": 0.3526,
      "step": 3160
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.11962253600358963,
      "learning_rate": 0.00011862768815849041,
      "loss": 0.359,
      "step": 3161
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.12147540599107742,
      "learning_rate": 0.00011858385491934792,
      "loss": 0.2989,
      "step": 3162
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.13647185266017914,
      "learning_rate": 0.00011854001798155314,
      "loss": 0.3221,
      "step": 3163
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.143599733710289,
      "learning_rate": 0.00011849617735383074,
      "loss": 0.3956,
      "step": 3164
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.12341295182704926,
      "learning_rate": 0.0001184523330449061,
      "loss": 0.3313,
      "step": 3165
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.14475159347057343,
      "learning_rate": 0.00011840848506350532,
      "loss": 0.1643,
      "step": 3166
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.10236180573701859,
      "learning_rate": 0.00011836463341835529,
      "loss": 0.2641,
      "step": 3167
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.13148903846740723,
      "learning_rate": 0.00011832077811818357,
      "loss": 0.373,
      "step": 3168
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.11710668355226517,
      "learning_rate": 0.0001182769191717184,
      "loss": 0.3229,
      "step": 3169
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.11859636008739471,
      "learning_rate": 0.00011823305658768884,
      "loss": 0.3183,
      "step": 3170
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.11887701600790024,
      "learning_rate": 0.00011818919037482467,
      "loss": 0.2831,
      "step": 3171
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1248173639178276,
      "learning_rate": 0.00011814532054185639,
      "loss": 0.3527,
      "step": 3172
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.14883625507354736,
      "learning_rate": 0.00011810144709751511,
      "loss": 0.4214,
      "step": 3173
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.12743178009986877,
      "learning_rate": 0.00011805757005053282,
      "loss": 0.3708,
      "step": 3174
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1327623873949051,
      "learning_rate": 0.00011801368940964211,
      "loss": 0.4014,
      "step": 3175
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.11385001242160797,
      "learning_rate": 0.00011796980518357634,
      "loss": 0.3148,
      "step": 3176
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1343928575515747,
      "learning_rate": 0.00011792591738106957,
      "loss": 0.3694,
      "step": 3177
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.13741017878055573,
      "learning_rate": 0.00011788202601085653,
      "loss": 0.2897,
      "step": 3178
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.10789309442043304,
      "learning_rate": 0.00011783813108167277,
      "loss": 0.3237,
      "step": 3179
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.13655215501785278,
      "learning_rate": 0.00011779423260225446,
      "loss": 0.3415,
      "step": 3180
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14703980088233948,
      "learning_rate": 0.00011775033058133847,
      "loss": 0.3635,
      "step": 3181
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12026488780975342,
      "learning_rate": 0.0001177064250276624,
      "loss": 0.348,
      "step": 3182
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12261195480823517,
      "learning_rate": 0.00011766251594996456,
      "loss": 0.2994,
      "step": 3183
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.10691538453102112,
      "learning_rate": 0.000117618603356984,
      "loss": 0.3391,
      "step": 3184
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.15298864245414734,
      "learning_rate": 0.00011757468725746037,
      "loss": 0.3917,
      "step": 3185
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12428945302963257,
      "learning_rate": 0.00011753076766013409,
      "loss": 0.3535,
      "step": 3186
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.10175148397684097,
      "learning_rate": 0.00011748684457374626,
      "loss": 0.2779,
      "step": 3187
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12366348505020142,
      "learning_rate": 0.0001174429180070387,
      "loss": 0.3182,
      "step": 3188
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.18017205595970154,
      "learning_rate": 0.00011739898796875383,
      "loss": 0.3967,
      "step": 3189
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.11113011091947556,
      "learning_rate": 0.0001173550544676349,
      "loss": 0.2957,
      "step": 3190
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.11297128349542618,
      "learning_rate": 0.00011731111751242572,
      "loss": 0.332,
      "step": 3191
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.13600896298885345,
      "learning_rate": 0.00011726717711187089,
      "loss": 0.4384,
      "step": 3192
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14389349520206451,
      "learning_rate": 0.00011722323327471562,
      "loss": 0.3122,
      "step": 3193
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14601770043373108,
      "learning_rate": 0.00011717928600970585,
      "loss": 0.3358,
      "step": 3194
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12853872776031494,
      "learning_rate": 0.00011713533532558816,
      "loss": 0.3331,
      "step": 3195
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12634533643722534,
      "learning_rate": 0.00011709138123110988,
      "loss": 0.3479,
      "step": 3196
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12895897030830383,
      "learning_rate": 0.00011704742373501891,
      "loss": 0.2588,
      "step": 3197
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.1402420848608017,
      "learning_rate": 0.00011700346284606394,
      "loss": 0.491,
      "step": 3198
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.11651721596717834,
      "learning_rate": 0.00011695949857299431,
      "loss": 0.3097,
      "step": 3199
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.10075423866510391,
      "learning_rate": 0.00011691553092455997,
      "loss": 0.2656,
      "step": 3200
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.13545233011245728,
      "learning_rate": 0.00011687155990951158,
      "loss": 0.4436,
      "step": 3201
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.15711598098278046,
      "learning_rate": 0.00011682758553660047,
      "loss": 0.3653,
      "step": 3202
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.11100436002016068,
      "learning_rate": 0.00011678360781457867,
      "loss": 0.2998,
      "step": 3203
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14982837438583374,
      "learning_rate": 0.00011673962675219883,
      "loss": 0.398,
      "step": 3204
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.11675211787223816,
      "learning_rate": 0.00011669564235821426,
      "loss": 0.2856,
      "step": 3205
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.130972221493721,
      "learning_rate": 0.00011665165464137899,
      "loss": 0.3942,
      "step": 3206
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.13898979127407074,
      "learning_rate": 0.00011660766361044768,
      "loss": 0.3891,
      "step": 3207
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12497640401124954,
      "learning_rate": 0.00011656366927417563,
      "loss": 0.3479,
      "step": 3208
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.13262107968330383,
      "learning_rate": 0.0001165196716413188,
      "loss": 0.3246,
      "step": 3209
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.12587471306324005,
      "learning_rate": 0.00011647567072063386,
      "loss": 0.4141,
      "step": 3210
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.30983829498291016,
      "learning_rate": 0.00011643166652087805,
      "loss": 0.259,
      "step": 3211
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14097477495670319,
      "learning_rate": 0.00011638765905080935,
      "loss": 0.3883,
      "step": 3212
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.17708085477352142,
      "learning_rate": 0.0001163436483191863,
      "loss": 0.3593,
      "step": 3213
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.11122884601354599,
      "learning_rate": 0.00011629963433476818,
      "loss": 0.3328,
      "step": 3214
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.16835477948188782,
      "learning_rate": 0.00011625561710631485,
      "loss": 0.3853,
      "step": 3215
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12653924524784088,
      "learning_rate": 0.00011621159664258685,
      "loss": 0.4855,
      "step": 3216
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.13056811690330505,
      "learning_rate": 0.00011616757295234535,
      "loss": 0.3451,
      "step": 3217
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.14858368039131165,
      "learning_rate": 0.00011612354604435216,
      "loss": 0.3949,
      "step": 3218
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.14978647232055664,
      "learning_rate": 0.00011607951592736977,
      "loss": 0.352,
      "step": 3219
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.13644544780254364,
      "learning_rate": 0.00011603548261016124,
      "loss": 0.3974,
      "step": 3220
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.10479755699634552,
      "learning_rate": 0.00011599144610149028,
      "loss": 0.2917,
      "step": 3221
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.11617744714021683,
      "learning_rate": 0.00011594740641012132,
      "loss": 0.3515,
      "step": 3222
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.13658283650875092,
      "learning_rate": 0.00011590336354481932,
      "loss": 0.3919,
      "step": 3223
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12668384611606598,
      "learning_rate": 0.00011585931751434995,
      "loss": 0.3188,
      "step": 3224
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.11388850212097168,
      "learning_rate": 0.00011581526832747942,
      "loss": 0.2958,
      "step": 3225
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.08255758136510849,
      "learning_rate": 0.00011577121599297465,
      "loss": 0.2055,
      "step": 3226
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1456460803747177,
      "learning_rate": 0.00011572716051960316,
      "loss": 0.3836,
      "step": 3227
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1403971165418625,
      "learning_rate": 0.00011568310191613307,
      "loss": 0.3958,
      "step": 3228
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.11289085447788239,
      "learning_rate": 0.00011563904019133321,
      "loss": 0.3019,
      "step": 3229
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1281822770833969,
      "learning_rate": 0.00011559497535397286,
      "loss": 0.4383,
      "step": 3230
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.09924667328596115,
      "learning_rate": 0.0001155509074128221,
      "loss": 0.2855,
      "step": 3231
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.11370521038770676,
      "learning_rate": 0.00011550683637665152,
      "loss": 0.2659,
      "step": 3232
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12074147164821625,
      "learning_rate": 0.0001154627622542324,
      "loss": 0.2845,
      "step": 3233
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12302330881357193,
      "learning_rate": 0.00011541868505433657,
      "loss": 0.3721,
      "step": 3234
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1525079905986786,
      "learning_rate": 0.00011537460478573648,
      "loss": 0.3463,
      "step": 3235
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12998883426189423,
      "learning_rate": 0.00011533052145720522,
      "loss": 0.394,
      "step": 3236
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12628380954265594,
      "learning_rate": 0.00011528643507751649,
      "loss": 0.3611,
      "step": 3237
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.13417096436023712,
      "learning_rate": 0.00011524234565544454,
      "loss": 0.3419,
      "step": 3238
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.13693176209926605,
      "learning_rate": 0.00011519825319976431,
      "loss": 0.3412,
      "step": 3239
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.19255094230175018,
      "learning_rate": 0.0001151541577192513,
      "loss": 0.4827,
      "step": 3240
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.10926489531993866,
      "learning_rate": 0.00011511005922268161,
      "loss": 0.3353,
      "step": 3241
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12660586833953857,
      "learning_rate": 0.00011506595771883193,
      "loss": 0.3175,
      "step": 3242
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1466444730758667,
      "learning_rate": 0.00011502185321647956,
      "loss": 0.3956,
      "step": 3243
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.12009776383638382,
      "learning_rate": 0.00011497774572440243,
      "loss": 0.3344,
      "step": 3244
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.15190760791301727,
      "learning_rate": 0.00011493363525137901,
      "loss": 0.3502,
      "step": 3245
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1501437872648239,
      "learning_rate": 0.00011488952180618839,
      "loss": 0.4242,
      "step": 3246
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.2002505511045456,
      "learning_rate": 0.00011484540539761026,
      "loss": 0.4562,
      "step": 3247
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.10632257908582687,
      "learning_rate": 0.0001148012860344249,
      "loss": 0.3003,
      "step": 3248
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1354396939277649,
      "learning_rate": 0.00011475716372541314,
      "loss": 0.3403,
      "step": 3249
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.14054174721240997,
      "learning_rate": 0.00011471303847935642,
      "loss": 0.3565,
      "step": 3250
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.09507903456687927,
      "learning_rate": 0.00011466891030503679,
      "loss": 0.2981,
      "step": 3251
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11736909300088882,
      "learning_rate": 0.00011462477921123688,
      "loss": 0.3228,
      "step": 3252
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12658001482486725,
      "learning_rate": 0.00011458064520673983,
      "loss": 0.3839,
      "step": 3253
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.10200705379247665,
      "learning_rate": 0.00011453650830032944,
      "loss": 0.2576,
      "step": 3254
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.15898722410202026,
      "learning_rate": 0.00011449236850079008,
      "loss": 0.3399,
      "step": 3255
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11152303218841553,
      "learning_rate": 0.00011444822581690666,
      "loss": 0.2676,
      "step": 3256
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17650136351585388,
      "learning_rate": 0.00011440408025746463,
      "loss": 0.3224,
      "step": 3257
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12416093796491623,
      "learning_rate": 0.00011435993183125014,
      "loss": 0.3335,
      "step": 3258
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11972218751907349,
      "learning_rate": 0.00011431578054704977,
      "loss": 0.2961,
      "step": 3259
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1543145775794983,
      "learning_rate": 0.00011427162641365079,
      "loss": 0.3763,
      "step": 3260
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.13004030287265778,
      "learning_rate": 0.00011422746943984093,
      "loss": 0.3536,
      "step": 3261
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11691512167453766,
      "learning_rate": 0.00011418330963440853,
      "loss": 0.3063,
      "step": 3262
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.15102235972881317,
      "learning_rate": 0.00011413914700614252,
      "loss": 0.4723,
      "step": 3263
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.10429224371910095,
      "learning_rate": 0.00011409498156383235,
      "loss": 0.2802,
      "step": 3264
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1378306746482849,
      "learning_rate": 0.0001140508133162681,
      "loss": 0.3184,
      "step": 3265
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1132841631770134,
      "learning_rate": 0.0001140066422722403,
      "loss": 0.3255,
      "step": 3266
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1205172911286354,
      "learning_rate": 0.00011396246844054008,
      "loss": 0.2911,
      "step": 3267
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11805058270692825,
      "learning_rate": 0.0001139182918299592,
      "loss": 0.3021,
      "step": 3268
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1322515457868576,
      "learning_rate": 0.00011387411244928987,
      "loss": 0.318,
      "step": 3269
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12446848303079605,
      "learning_rate": 0.00011382993030732489,
      "loss": 0.3281,
      "step": 3270
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1285049021244049,
      "learning_rate": 0.00011378574541285763,
      "loss": 0.3978,
      "step": 3271
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.15652813017368317,
      "learning_rate": 0.00011374155777468199,
      "loss": 0.4402,
      "step": 3272
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12949585914611816,
      "learning_rate": 0.00011369736740159243,
      "loss": 0.3692,
      "step": 3273
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12770774960517883,
      "learning_rate": 0.00011365317430238389,
      "loss": 0.351,
      "step": 3274
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12331131100654602,
      "learning_rate": 0.00011360897848585193,
      "loss": 0.294,
      "step": 3275
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11352135986089706,
      "learning_rate": 0.00011356477996079265,
      "loss": 0.2681,
      "step": 3276
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12371573597192764,
      "learning_rate": 0.00011352057873600264,
      "loss": 0.3584,
      "step": 3277
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.13010305166244507,
      "learning_rate": 0.00011347637482027902,
      "loss": 0.33,
      "step": 3278
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11587633192539215,
      "learning_rate": 0.00011343216822241954,
      "loss": 0.334,
      "step": 3279
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1283695101737976,
      "learning_rate": 0.00011338795895122233,
      "loss": 0.324,
      "step": 3280
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.11622313410043716,
      "learning_rate": 0.00011334374701548627,
      "loss": 0.3067,
      "step": 3281
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1006338894367218,
      "learning_rate": 0.00011329953242401052,
      "loss": 0.3119,
      "step": 3282
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.16563573479652405,
      "learning_rate": 0.00011325531518559496,
      "loss": 0.4017,
      "step": 3283
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.10244913399219513,
      "learning_rate": 0.0001132110953090399,
      "loss": 0.2831,
      "step": 3284
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.12618900835514069,
      "learning_rate": 0.00011316687280314622,
      "loss": 0.3369,
      "step": 3285
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1254071593284607,
      "learning_rate": 0.00011312264767671526,
      "loss": 0.3338,
      "step": 3286
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11576789617538452,
      "learning_rate": 0.00011307841993854897,
      "loss": 0.2959,
      "step": 3287
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.10423216223716736,
      "learning_rate": 0.0001130341895974498,
      "loss": 0.2571,
      "step": 3288
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.10630692541599274,
      "learning_rate": 0.00011298995666222063,
      "loss": 0.3122,
      "step": 3289
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11608847975730896,
      "learning_rate": 0.00011294572114166495,
      "loss": 0.3528,
      "step": 3290
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.12966766953468323,
      "learning_rate": 0.00011290148304458679,
      "loss": 0.2823,
      "step": 3291
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.10422695428133011,
      "learning_rate": 0.00011285724237979053,
      "loss": 0.2821,
      "step": 3292
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.12052935361862183,
      "learning_rate": 0.00011281299915608125,
      "loss": 0.3838,
      "step": 3293
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.09525644779205322,
      "learning_rate": 0.00011276875338226445,
      "loss": 0.3412,
      "step": 3294
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11231554299592972,
      "learning_rate": 0.00011272450506714612,
      "loss": 0.3472,
      "step": 3295
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.130063995718956,
      "learning_rate": 0.00011268025421953277,
      "loss": 0.2921,
      "step": 3296
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.12722061574459076,
      "learning_rate": 0.00011263600084823149,
      "loss": 0.3262,
      "step": 3297
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11338326334953308,
      "learning_rate": 0.00011259174496204974,
      "loss": 0.3508,
      "step": 3298
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1221948117017746,
      "learning_rate": 0.0001125474865697956,
      "loss": 0.2949,
      "step": 3299
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.09093806892633438,
      "learning_rate": 0.00011250322568027756,
      "loss": 0.2613,
      "step": 3300
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.13353168964385986,
      "learning_rate": 0.00011245896230230468,
      "loss": 0.3886,
      "step": 3301
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1851292997598648,
      "learning_rate": 0.00011241469644468645,
      "loss": 0.3313,
      "step": 3302
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1226472556591034,
      "learning_rate": 0.00011237042811623289,
      "loss": 0.3132,
      "step": 3303
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11853055655956268,
      "learning_rate": 0.00011232615732575451,
      "loss": 0.2849,
      "step": 3304
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11428271979093552,
      "learning_rate": 0.00011228188408206232,
      "loss": 0.3574,
      "step": 3305
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.12243890017271042,
      "learning_rate": 0.0001122376083939678,
      "loss": 0.3663,
      "step": 3306
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.10043976455926895,
      "learning_rate": 0.00011219333027028287,
      "loss": 0.312,
      "step": 3307
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.09195160120725632,
      "learning_rate": 0.00011214904971982006,
      "loss": 0.2072,
      "step": 3308
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.14331795275211334,
      "learning_rate": 0.00011210476675139227,
      "loss": 0.3768,
      "step": 3309
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.14810863137245178,
      "learning_rate": 0.0001120604813738129,
      "loss": 0.3337,
      "step": 3310
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11861484497785568,
      "learning_rate": 0.00011201619359589589,
      "loss": 0.2936,
      "step": 3311
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1168140396475792,
      "learning_rate": 0.00011197190342645556,
      "loss": 0.3167,
      "step": 3312
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.13944850862026215,
      "learning_rate": 0.00011192761087430686,
      "loss": 0.3954,
      "step": 3313
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.10103768110275269,
      "learning_rate": 0.000111883315948265,
      "loss": 0.3425,
      "step": 3314
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.14900663495063782,
      "learning_rate": 0.00011183901865714585,
      "loss": 0.3771,
      "step": 3315
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.14508911967277527,
      "learning_rate": 0.00011179471900976567,
      "loss": 0.3528,
      "step": 3316
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.15499015152454376,
      "learning_rate": 0.00011175041701494122,
      "loss": 0.3658,
      "step": 3317
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1342952847480774,
      "learning_rate": 0.00011170611268148965,
      "loss": 0.362,
      "step": 3318
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11479677259922028,
      "learning_rate": 0.00011166180601822864,
      "loss": 0.3052,
      "step": 3319
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1351994276046753,
      "learning_rate": 0.00011161749703397637,
      "loss": 0.3805,
      "step": 3320
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.10864780098199844,
      "learning_rate": 0.00011157318573755145,
      "loss": 0.3028,
      "step": 3321
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12037183344364166,
      "learning_rate": 0.00011152887213777283,
      "loss": 0.3237,
      "step": 3322
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.10931187123060226,
      "learning_rate": 0.00011148455624346012,
      "loss": 0.3084,
      "step": 3323
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12538617849349976,
      "learning_rate": 0.00011144023806343327,
      "loss": 0.3169,
      "step": 3324
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12291964143514633,
      "learning_rate": 0.0001113959176065127,
      "loss": 0.3411,
      "step": 3325
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.11549141258001328,
      "learning_rate": 0.0001113515948815193,
      "loss": 0.26,
      "step": 3326
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.14198000729084015,
      "learning_rate": 0.00011130726989727438,
      "loss": 0.4053,
      "step": 3327
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.0898672491312027,
      "learning_rate": 0.00011126294266259973,
      "loss": 0.2311,
      "step": 3328
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.11804616451263428,
      "learning_rate": 0.00011121861318631762,
      "loss": 0.3187,
      "step": 3329
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.10610849410295486,
      "learning_rate": 0.00011117428147725066,
      "loss": 0.3065,
      "step": 3330
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.13169701397418976,
      "learning_rate": 0.00011112994754422201,
      "loss": 0.2948,
      "step": 3331
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.10023462772369385,
      "learning_rate": 0.00011108561139605523,
      "loss": 0.2989,
      "step": 3332
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1663655787706375,
      "learning_rate": 0.0001110412730415743,
      "loss": 0.395,
      "step": 3333
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.11548499763011932,
      "learning_rate": 0.0001109969324896037,
      "loss": 0.3183,
      "step": 3334
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1438160389661789,
      "learning_rate": 0.00011095258974896827,
      "loss": 0.3967,
      "step": 3335
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12452390789985657,
      "learning_rate": 0.00011090824482849334,
      "loss": 0.3065,
      "step": 3336
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1182439774274826,
      "learning_rate": 0.0001108638977370047,
      "loss": 0.3219,
      "step": 3337
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.17635387182235718,
      "learning_rate": 0.00011081954848332845,
      "loss": 0.3466,
      "step": 3338
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.13151854276657104,
      "learning_rate": 0.00011077519707629125,
      "loss": 0.3146,
      "step": 3339
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12576064467430115,
      "learning_rate": 0.00011073084352472014,
      "loss": 0.2957,
      "step": 3340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.14871177077293396,
      "learning_rate": 0.00011068648783744259,
      "loss": 0.3769,
      "step": 3341
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.14845438301563263,
      "learning_rate": 0.00011064213002328649,
      "loss": 0.3776,
      "step": 3342
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1094040796160698,
      "learning_rate": 0.00011059777009108015,
      "loss": 0.2565,
      "step": 3343
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1351984441280365,
      "learning_rate": 0.00011055340804965229,
      "loss": 0.3026,
      "step": 3344
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.14449577033519745,
      "learning_rate": 0.0001105090439078321,
      "loss": 0.3391,
      "step": 3345
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12347462773323059,
      "learning_rate": 0.00011046467767444913,
      "loss": 0.3321,
      "step": 3346
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12148674577474594,
      "learning_rate": 0.00011042030935833336,
      "loss": 0.3678,
      "step": 3347
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12930893898010254,
      "learning_rate": 0.00011037593896831522,
      "loss": 0.3172,
      "step": 3348
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.12449990212917328,
      "learning_rate": 0.00011033156651322556,
      "loss": 0.2798,
      "step": 3349
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.11080178618431091,
      "learning_rate": 0.00011028719200189553,
      "loss": 0.2973,
      "step": 3350
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.10784269869327545,
      "learning_rate": 0.00011024281544315683,
      "loss": 0.2702,
      "step": 3351
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.11166398972272873,
      "learning_rate": 0.00011019843684584147,
      "loss": 0.2956,
      "step": 3352
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1369110494852066,
      "learning_rate": 0.00011015405621878194,
      "loss": 0.3405,
      "step": 3353
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.17372211813926697,
      "learning_rate": 0.00011010967357081105,
      "loss": 0.3663,
      "step": 3354
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.13318327069282532,
      "learning_rate": 0.00011006528891076209,
      "loss": 0.3718,
      "step": 3355
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.10745349526405334,
      "learning_rate": 0.0001100209022474687,
      "loss": 0.2762,
      "step": 3356
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1204940527677536,
      "learning_rate": 0.00010997651358976495,
      "loss": 0.3429,
      "step": 3357
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.14519409835338593,
      "learning_rate": 0.00010993212294648531,
      "loss": 0.3614,
      "step": 3358
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1136876791715622,
      "learning_rate": 0.0001098877303264646,
      "loss": 0.3161,
      "step": 3359
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1313234269618988,
      "learning_rate": 0.00010984333573853804,
      "loss": 0.3461,
      "step": 3360
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.11180219799280167,
      "learning_rate": 0.00010979893919154132,
      "loss": 0.2856,
      "step": 3361
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.12287681549787521,
      "learning_rate": 0.00010975454069431046,
      "loss": 0.3892,
      "step": 3362
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.13556547462940216,
      "learning_rate": 0.0001097101402556818,
      "loss": 0.2377,
      "step": 3363
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1377745419740677,
      "learning_rate": 0.00010966573788449224,
      "loss": 0.3709,
      "step": 3364
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.14322355389595032,
      "learning_rate": 0.00010962133358957887,
      "loss": 0.3511,
      "step": 3365
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.10644042491912842,
      "learning_rate": 0.00010957692737977934,
      "loss": 0.3107,
      "step": 3366
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.11760003864765167,
      "learning_rate": 0.00010953251926393153,
      "loss": 0.28,
      "step": 3367
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.10673103481531143,
      "learning_rate": 0.0001094881092508738,
      "loss": 0.3474,
      "step": 3368
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.11979353427886963,
      "learning_rate": 0.00010944369734944486,
      "loss": 0.3016,
      "step": 3369
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1198415607213974,
      "learning_rate": 0.00010939928356848377,
      "loss": 0.3516,
      "step": 3370
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.12917593121528625,
      "learning_rate": 0.00010935486791682998,
      "loss": 0.2999,
      "step": 3371
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1434590071439743,
      "learning_rate": 0.00010931045040332333,
      "loss": 0.388,
      "step": 3372
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1298467218875885,
      "learning_rate": 0.00010926603103680403,
      "loss": 0.2976,
      "step": 3373
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1123088151216507,
      "learning_rate": 0.00010922160982611263,
      "loss": 0.3137,
      "step": 3374
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.12201932072639465,
      "learning_rate": 0.00010917718678009005,
      "loss": 0.3492,
      "step": 3375
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.09503611922264099,
      "learning_rate": 0.0001091327619075776,
      "loss": 0.2628,
      "step": 3376
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.13405731320381165,
      "learning_rate": 0.00010908833521741697,
      "loss": 0.3549,
      "step": 3377
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.11514163017272949,
      "learning_rate": 0.00010904390671845012,
      "loss": 0.3391,
      "step": 3378
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.13646197319030762,
      "learning_rate": 0.00010899947641951948,
      "loss": 0.362,
      "step": 3379
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1441064178943634,
      "learning_rate": 0.00010895504432946779,
      "loss": 0.3388,
      "step": 3380
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.11827465891838074,
      "learning_rate": 0.00010891061045713815,
      "loss": 0.3192,
      "step": 3381
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1582757830619812,
      "learning_rate": 0.000108866174811374,
      "loss": 0.4336,
      "step": 3382
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.13459071516990662,
      "learning_rate": 0.00010882173740101913,
      "loss": 0.3918,
      "step": 3383
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1501353681087494,
      "learning_rate": 0.00010877729823491771,
      "loss": 0.303,
      "step": 3384
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1301032304763794,
      "learning_rate": 0.00010873285732191427,
      "loss": 0.3251,
      "step": 3385
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1264321357011795,
      "learning_rate": 0.00010868841467085364,
      "loss": 0.3118,
      "step": 3386
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.10104180127382278,
      "learning_rate": 0.00010864397029058102,
      "loss": 0.3027,
      "step": 3387
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.1153738722205162,
      "learning_rate": 0.00010859952418994195,
      "loss": 0.2391,
      "step": 3388
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.12717153131961823,
      "learning_rate": 0.00010855507637778233,
      "loss": 0.2974,
      "step": 3389
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.08836021274328232,
      "learning_rate": 0.00010851062686294842,
      "loss": 0.2689,
      "step": 3390
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.16065596044063568,
      "learning_rate": 0.00010846617565428669,
      "loss": 0.3731,
      "step": 3391
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1622801572084427,
      "learning_rate": 0.00010842172276064412,
      "loss": 0.465,
      "step": 3392
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.10485830157995224,
      "learning_rate": 0.00010837726819086793,
      "loss": 0.2676,
      "step": 3393
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.14492499828338623,
      "learning_rate": 0.00010833281195380574,
      "loss": 0.385,
      "step": 3394
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.13981938362121582,
      "learning_rate": 0.00010828835405830536,
      "loss": 0.4059,
      "step": 3395
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.13570371270179749,
      "learning_rate": 0.00010824389451321506,
      "loss": 0.2994,
      "step": 3396
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.09699752926826477,
      "learning_rate": 0.00010819943332738343,
      "loss": 0.2276,
      "step": 3397
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1335328221321106,
      "learning_rate": 0.00010815497050965935,
      "loss": 0.3314,
      "step": 3398
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.13186371326446533,
      "learning_rate": 0.00010811050606889199,
      "loss": 0.3649,
      "step": 3399
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11584560573101044,
      "learning_rate": 0.00010806604001393095,
      "loss": 0.2826,
      "step": 3400
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.12286384403705597,
      "learning_rate": 0.00010802157235362604,
      "loss": 0.3288,
      "step": 3401
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11078912019729614,
      "learning_rate": 0.00010797710309682749,
      "loss": 0.3301,
      "step": 3402
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1143413633108139,
      "learning_rate": 0.00010793263225238575,
      "loss": 0.2905,
      "step": 3403
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11470898240804672,
      "learning_rate": 0.00010788815982915162,
      "loss": 0.3055,
      "step": 3404
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11339712888002396,
      "learning_rate": 0.00010784368583597626,
      "loss": 0.278,
      "step": 3405
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.14700281620025635,
      "learning_rate": 0.00010779921028171111,
      "loss": 0.333,
      "step": 3406
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11405106633901596,
      "learning_rate": 0.0001077547331752079,
      "loss": 0.2512,
      "step": 3407
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.39358940720558167,
      "learning_rate": 0.00010771025452531867,
      "loss": 0.3976,
      "step": 3408
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11101086437702179,
      "learning_rate": 0.00010766577434089581,
      "loss": 0.2895,
      "step": 3409
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.37187260389328003,
      "learning_rate": 0.00010762129263079204,
      "loss": 0.4503,
      "step": 3410
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2143014371395111,
      "learning_rate": 0.00010757680940386021,
      "loss": 0.4796,
      "step": 3411
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11734836548566818,
      "learning_rate": 0.00010753232466895371,
      "loss": 0.3038,
      "step": 3412
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.12193527072668076,
      "learning_rate": 0.00010748783843492607,
      "loss": 0.3161,
      "step": 3413
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.12626247107982635,
      "learning_rate": 0.00010744335071063116,
      "loss": 0.3508,
      "step": 3414
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1327994018793106,
      "learning_rate": 0.00010739886150492315,
      "loss": 0.3493,
      "step": 3415
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.12077255547046661,
      "learning_rate": 0.0001073543708266565,
      "loss": 0.3274,
      "step": 3416
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.13188806176185608,
      "learning_rate": 0.00010730987868468598,
      "loss": 0.4091,
      "step": 3417
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.14335952699184418,
      "learning_rate": 0.00010726538508786668,
      "loss": 0.2979,
      "step": 3418
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11675172299146652,
      "learning_rate": 0.00010722089004505385,
      "loss": 0.3183,
      "step": 3419
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.12253574281930923,
      "learning_rate": 0.00010717639356510319,
      "loss": 0.3406,
      "step": 3420
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.13219088315963745,
      "learning_rate": 0.00010713189565687056,
      "loss": 0.299,
      "step": 3421
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.13403312861919403,
      "learning_rate": 0.00010708739632921223,
      "loss": 0.3161,
      "step": 3422
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.10447099059820175,
      "learning_rate": 0.00010704289559098462,
      "loss": 0.2519,
      "step": 3423
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.10855201631784439,
      "learning_rate": 0.0001069983934510445,
      "loss": 0.28,
      "step": 3424
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1311645656824112,
      "learning_rate": 0.00010695388991824893,
      "loss": 0.3588,
      "step": 3425
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.16263790428638458,
      "learning_rate": 0.00010690938500145523,
      "loss": 0.4513,
      "step": 3426
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.13220001757144928,
      "learning_rate": 0.00010686487870952093,
      "loss": 0.2997,
      "step": 3427
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1368684619665146,
      "learning_rate": 0.00010682037105130398,
      "loss": 0.3624,
      "step": 3428
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.11657000333070755,
      "learning_rate": 0.00010677586203566245,
      "loss": 0.2721,
      "step": 3429
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.15174876153469086,
      "learning_rate": 0.00010673135167145482,
      "loss": 0.3836,
      "step": 3430
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.10446935892105103,
      "learning_rate": 0.00010668683996753972,
      "loss": 0.2632,
      "step": 3431
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1427491456270218,
      "learning_rate": 0.00010664232693277607,
      "loss": 0.3501,
      "step": 3432
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.10407587140798569,
      "learning_rate": 0.00010659781257602312,
      "loss": 0.2957,
      "step": 3433
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1409834921360016,
      "learning_rate": 0.00010655329690614033,
      "loss": 0.3685,
      "step": 3434
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.11928880959749222,
      "learning_rate": 0.00010650877993198745,
      "loss": 0.366,
      "step": 3435
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12647607922554016,
      "learning_rate": 0.00010646426166242442,
      "loss": 0.381,
      "step": 3436
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1421336531639099,
      "learning_rate": 0.00010641974210631154,
      "loss": 0.3007,
      "step": 3437
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12468177080154419,
      "learning_rate": 0.00010637522127250929,
      "loss": 0.3209,
      "step": 3438
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.11015482991933823,
      "learning_rate": 0.00010633069916987845,
      "loss": 0.2648,
      "step": 3439
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.13540545105934143,
      "learning_rate": 0.00010628617580728,
      "loss": 0.3931,
      "step": 3440
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.15090414881706238,
      "learning_rate": 0.00010624165119357525,
      "loss": 0.3275,
      "step": 3441
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1274648904800415,
      "learning_rate": 0.0001061971253376257,
      "loss": 0.3975,
      "step": 3442
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.13708803057670593,
      "learning_rate": 0.00010615259824829306,
      "loss": 0.3454,
      "step": 3443
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12793639302253723,
      "learning_rate": 0.0001061080699344394,
      "loss": 0.2955,
      "step": 3444
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.11684535443782806,
      "learning_rate": 0.00010606354040492695,
      "loss": 0.3256,
      "step": 3445
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.131929412484169,
      "learning_rate": 0.00010601900966861815,
      "loss": 0.3431,
      "step": 3446
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1252647340297699,
      "learning_rate": 0.00010597447773437581,
      "loss": 0.3131,
      "step": 3447
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12729300558567047,
      "learning_rate": 0.00010592994461106285,
      "loss": 0.3325,
      "step": 3448
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12740983068943024,
      "learning_rate": 0.00010588541030754249,
      "loss": 0.2783,
      "step": 3449
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1471550613641739,
      "learning_rate": 0.00010584087483267814,
      "loss": 0.4159,
      "step": 3450
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.17381466925144196,
      "learning_rate": 0.00010579633819533357,
      "loss": 0.3812,
      "step": 3451
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.09985321760177612,
      "learning_rate": 0.00010575180040437258,
      "loss": 0.2673,
      "step": 3452
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.11660681664943695,
      "learning_rate": 0.00010570726146865934,
      "loss": 0.2761,
      "step": 3453
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.13462822139263153,
      "learning_rate": 0.00010566272139705827,
      "loss": 0.3112,
      "step": 3454
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.09584566950798035,
      "learning_rate": 0.00010561818019843384,
      "loss": 0.225,
      "step": 3455
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12152182310819626,
      "learning_rate": 0.00010557363788165096,
      "loss": 0.2951,
      "step": 3456
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.10897616297006607,
      "learning_rate": 0.00010552909445557464,
      "loss": 0.306,
      "step": 3457
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12984968721866608,
      "learning_rate": 0.00010548454992907013,
      "loss": 0.3638,
      "step": 3458
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.12537871301174164,
      "learning_rate": 0.00010544000431100291,
      "loss": 0.2768,
      "step": 3459
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.1137688159942627,
      "learning_rate": 0.00010539545761023866,
      "loss": 0.3315,
      "step": 3460
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.14189907908439636,
      "learning_rate": 0.00010535090983564331,
      "loss": 0.3987,
      "step": 3461
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.09675197303295135,
      "learning_rate": 0.00010530636099608297,
      "loss": 0.3048,
      "step": 3462
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11742454767227173,
      "learning_rate": 0.00010526181110042399,
      "loss": 0.3233,
      "step": 3463
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11608472466468811,
      "learning_rate": 0.00010521726015753288,
      "loss": 0.354,
      "step": 3464
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.16982249915599823,
      "learning_rate": 0.00010517270817627643,
      "loss": 0.4687,
      "step": 3465
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11756273359060287,
      "learning_rate": 0.00010512815516552159,
      "loss": 0.3867,
      "step": 3466
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1318272352218628,
      "learning_rate": 0.00010508360113413551,
      "loss": 0.3825,
      "step": 3467
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.14479605853557587,
      "learning_rate": 0.00010503904609098554,
      "loss": 0.3433,
      "step": 3468
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11830101907253265,
      "learning_rate": 0.00010499449004493928,
      "loss": 0.3044,
      "step": 3469
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.13351424038410187,
      "learning_rate": 0.00010494993300486453,
      "loss": 0.4611,
      "step": 3470
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1354232281446457,
      "learning_rate": 0.0001049053749796292,
      "loss": 0.2881,
      "step": 3471
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.125421404838562,
      "learning_rate": 0.00010486081597810146,
      "loss": 0.3152,
      "step": 3472
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.13140447437763214,
      "learning_rate": 0.00010481625600914968,
      "loss": 0.4033,
      "step": 3473
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.150976300239563,
      "learning_rate": 0.00010477169508164242,
      "loss": 0.411,
      "step": 3474
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.09332440048456192,
      "learning_rate": 0.0001047271332044484,
      "loss": 0.2594,
      "step": 3475
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.10671280324459076,
      "learning_rate": 0.00010468257038643657,
      "loss": 0.2416,
      "step": 3476
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.10926734656095505,
      "learning_rate": 0.00010463800663647598,
      "loss": 0.2911,
      "step": 3477
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11452896893024445,
      "learning_rate": 0.00010459344196343602,
      "loss": 0.3559,
      "step": 3478
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1215604767203331,
      "learning_rate": 0.00010454887637618616,
      "loss": 0.3313,
      "step": 3479
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1194634810090065,
      "learning_rate": 0.00010450430988359601,
      "loss": 0.3151,
      "step": 3480
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11620689183473587,
      "learning_rate": 0.00010445974249453546,
      "loss": 0.3058,
      "step": 3481
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1157345175743103,
      "learning_rate": 0.0001044151742178745,
      "loss": 0.317,
      "step": 3482
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.13276447355747223,
      "learning_rate": 0.00010437060506248341,
      "loss": 0.37,
      "step": 3483
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.14020374417304993,
      "learning_rate": 0.0001043260350372325,
      "loss": 0.2858,
      "step": 3484
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11880821734666824,
      "learning_rate": 0.00010428146415099234,
      "loss": 0.3124,
      "step": 3485
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1970590204000473,
      "learning_rate": 0.00010423689241263364,
      "loss": 0.4056,
      "step": 3486
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.10875198245048523,
      "learning_rate": 0.00010419231983102733,
      "loss": 0.2706,
      "step": 3487
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.12005267292261124,
      "learning_rate": 0.00010414774641504441,
      "loss": 0.311,
      "step": 3488
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.12514354288578033,
      "learning_rate": 0.00010410317217355616,
      "loss": 0.2985,
      "step": 3489
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1504417061805725,
      "learning_rate": 0.00010405859711543393,
      "loss": 0.3791,
      "step": 3490
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.12378194183111191,
      "learning_rate": 0.00010401402124954933,
      "loss": 0.3448,
      "step": 3491
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1312267929315567,
      "learning_rate": 0.000103969444584774,
      "loss": 0.3411,
      "step": 3492
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.16644616425037384,
      "learning_rate": 0.00010392486712997984,
      "loss": 0.364,
      "step": 3493
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.13803111016750336,
      "learning_rate": 0.00010388028889403889,
      "loss": 0.3534,
      "step": 3494
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.10079286992549896,
      "learning_rate": 0.00010383570988582334,
      "loss": 0.2239,
      "step": 3495
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.12090308964252472,
      "learning_rate": 0.00010379113011420551,
      "loss": 0.3275,
      "step": 3496
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.11021317541599274,
      "learning_rate": 0.00010374654958805789,
      "loss": 0.3176,
      "step": 3497
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.16148696839809418,
      "learning_rate": 0.00010370196831625316,
      "loss": 0.359,
      "step": 3498
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.18007104098796844,
      "learning_rate": 0.00010365738630766404,
      "loss": 0.3833,
      "step": 3499
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11104044318199158,
      "learning_rate": 0.00010361280357116352,
      "loss": 0.2677,
      "step": 3500
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1392820030450821,
      "learning_rate": 0.00010356822011562464,
      "loss": 0.3711,
      "step": 3501
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.14033594727516174,
      "learning_rate": 0.0001035236359499207,
      "loss": 0.3902,
      "step": 3502
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11132296174764633,
      "learning_rate": 0.00010347905108292495,
      "loss": 0.2672,
      "step": 3503
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1213158369064331,
      "learning_rate": 0.00010343446552351099,
      "loss": 0.3498,
      "step": 3504
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.12624144554138184,
      "learning_rate": 0.00010338987928055244,
      "loss": 0.2851,
      "step": 3505
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.18010590970516205,
      "learning_rate": 0.00010334529236292304,
      "loss": 0.4337,
      "step": 3506
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.13638785481452942,
      "learning_rate": 0.00010330070477949676,
      "loss": 0.3573,
      "step": 3507
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.10689269751310349,
      "learning_rate": 0.00010325611653914757,
      "loss": 0.2584,
      "step": 3508
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1450217366218567,
      "learning_rate": 0.00010321152765074971,
      "loss": 0.2968,
      "step": 3509
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.14403735101222992,
      "learning_rate": 0.00010316693812317746,
      "loss": 0.3615,
      "step": 3510
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11097247898578644,
      "learning_rate": 0.00010312234796530528,
      "loss": 0.3318,
      "step": 3511
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.147227942943573,
      "learning_rate": 0.00010307775718600768,
      "loss": 0.3919,
      "step": 3512
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1573915034532547,
      "learning_rate": 0.00010303316579415935,
      "loss": 0.4019,
      "step": 3513
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.14416587352752686,
      "learning_rate": 0.00010298857379863514,
      "loss": 0.3646,
      "step": 3514
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1541959047317505,
      "learning_rate": 0.00010294398120830995,
      "loss": 0.4324,
      "step": 3515
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11986971646547318,
      "learning_rate": 0.00010289938803205879,
      "loss": 0.2791,
      "step": 3516
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11143121123313904,
      "learning_rate": 0.00010285479427875686,
      "loss": 0.301,
      "step": 3517
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1696130782365799,
      "learning_rate": 0.00010281019995727939,
      "loss": 0.3776,
      "step": 3518
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.13549759984016418,
      "learning_rate": 0.00010276560507650181,
      "loss": 0.3499,
      "step": 3519
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.14194712042808533,
      "learning_rate": 0.00010272100964529961,
      "loss": 0.3142,
      "step": 3520
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.12565433979034424,
      "learning_rate": 0.00010267641367254834,
      "loss": 0.2896,
      "step": 3521
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.12465279549360275,
      "learning_rate": 0.0001026318171671238,
      "loss": 0.2854,
      "step": 3522
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.09819453209638596,
      "learning_rate": 0.00010258722013790176,
      "loss": 0.2699,
      "step": 3523
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11537513881921768,
      "learning_rate": 0.00010254262259375816,
      "loss": 0.3104,
      "step": 3524
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11010922491550446,
      "learning_rate": 0.00010249802454356901,
      "loss": 0.3136,
      "step": 3525
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1500394493341446,
      "learning_rate": 0.00010245342599621046,
      "loss": 0.3736,
      "step": 3526
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.12669630348682404,
      "learning_rate": 0.00010240882696055873,
      "loss": 0.3395,
      "step": 3527
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.15578214824199677,
      "learning_rate": 0.00010236422744549015,
      "loss": 0.3909,
      "step": 3528
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.14707189798355103,
      "learning_rate": 0.00010231962745988113,
      "loss": 0.3598,
      "step": 3529
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1261705905199051,
      "learning_rate": 0.00010227502701260817,
      "loss": 0.2965,
      "step": 3530
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.1508869230747223,
      "learning_rate": 0.00010223042611254792,
      "loss": 0.3267,
      "step": 3531
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.15397007763385773,
      "learning_rate": 0.00010218582476857703,
      "loss": 0.3674,
      "step": 3532
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.11895943433046341,
      "learning_rate": 0.00010214122298957229,
      "loss": 0.2589,
      "step": 3533
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.12862949073314667,
      "learning_rate": 0.0001020966207844106,
      "loss": 0.4105,
      "step": 3534
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.11670340597629547,
      "learning_rate": 0.0001020520181619689,
      "loss": 0.3046,
      "step": 3535
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.11973341554403305,
      "learning_rate": 0.00010200741513112423,
      "loss": 0.2759,
      "step": 3536
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.13139010965824127,
      "learning_rate": 0.0001019628117007537,
      "loss": 0.323,
      "step": 3537
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.14261595904827118,
      "learning_rate": 0.0001019182078797345,
      "loss": 0.3778,
      "step": 3538
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.14127117395401,
      "learning_rate": 0.00010187360367694394,
      "loss": 0.4285,
      "step": 3539
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.11970613896846771,
      "learning_rate": 0.00010182899910125931,
      "loss": 0.3681,
      "step": 3540
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.14950469136238098,
      "learning_rate": 0.00010178439416155812,
      "loss": 0.35,
      "step": 3541
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.144722580909729,
      "learning_rate": 0.0001017397888667178,
      "loss": 0.3271,
      "step": 3542
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.12607237696647644,
      "learning_rate": 0.000101695183225616,
      "loss": 0.2966,
      "step": 3543
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10752524435520172,
      "learning_rate": 0.00010165057724713027,
      "loss": 0.23,
      "step": 3544
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1313648670911789,
      "learning_rate": 0.00010160597094013835,
      "loss": 0.3411,
      "step": 3545
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.11710261553525925,
      "learning_rate": 0.00010156136431351802,
      "loss": 0.3416,
      "step": 3546
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10565914213657379,
      "learning_rate": 0.00010151675737614714,
      "loss": 0.3067,
      "step": 3547
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.11454033106565475,
      "learning_rate": 0.00010147215013690354,
      "loss": 0.3257,
      "step": 3548
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1354612410068512,
      "learning_rate": 0.00010142754260466525,
      "loss": 0.3687,
      "step": 3549
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1361936777830124,
      "learning_rate": 0.00010138293478831022,
      "loss": 0.3978,
      "step": 3550
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.14137786626815796,
      "learning_rate": 0.00010133832669671659,
      "loss": 0.3278,
      "step": 3551
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10887961089611053,
      "learning_rate": 0.00010129371833876242,
      "loss": 0.3216,
      "step": 3552
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1391039788722992,
      "learning_rate": 0.00010124910972332593,
      "loss": 0.3764,
      "step": 3553
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10894013941287994,
      "learning_rate": 0.00010120450085928532,
      "loss": 0.2745,
      "step": 3554
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1423017531633377,
      "learning_rate": 0.00010115989175551893,
      "loss": 0.4032,
      "step": 3555
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10578148812055588,
      "learning_rate": 0.00010111528242090502,
      "loss": 0.2726,
      "step": 3556
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09958996623754501,
      "learning_rate": 0.00010107067286432199,
      "loss": 0.2908,
      "step": 3557
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.15362954139709473,
      "learning_rate": 0.00010102606309464829,
      "loss": 0.3426,
      "step": 3558
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.141483336687088,
      "learning_rate": 0.00010098145312076235,
      "loss": 0.2867,
      "step": 3559
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1088445857167244,
      "learning_rate": 0.00010093684295154264,
      "loss": 0.281,
      "step": 3560
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.08598171174526215,
      "learning_rate": 0.00010089223259586775,
      "loss": 0.1968,
      "step": 3561
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09476586431264877,
      "learning_rate": 0.00010084762206261624,
      "loss": 0.203,
      "step": 3562
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.11147427558898926,
      "learning_rate": 0.00010080301136066674,
      "loss": 0.2605,
      "step": 3563
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1255599409341812,
      "learning_rate": 0.00010075840049889787,
      "loss": 0.259,
      "step": 3564
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09798401594161987,
      "learning_rate": 0.00010071378948618831,
      "loss": 0.2226,
      "step": 3565
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.13234055042266846,
      "learning_rate": 0.00010066917833141681,
      "loss": 0.3284,
      "step": 3566
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.16053716838359833,
      "learning_rate": 0.00010062456704346203,
      "loss": 0.3248,
      "step": 3567
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.11550289392471313,
      "learning_rate": 0.00010057995563120282,
      "loss": 0.251,
      "step": 3568
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.16423463821411133,
      "learning_rate": 0.00010053534410351788,
      "loss": 0.3436,
      "step": 3569
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.12763772904872894,
      "learning_rate": 0.00010049073246928609,
      "loss": 0.3451,
      "step": 3570
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1551070213317871,
      "learning_rate": 0.00010044612073738624,
      "loss": 0.2896,
      "step": 3571
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.13288648426532745,
      "learning_rate": 0.00010040150891669721,
      "loss": 0.2678,
      "step": 3572
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.13315293192863464,
      "learning_rate": 0.00010035689701609785,
      "loss": 0.2551,
      "step": 3573
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.12337003648281097,
      "learning_rate": 0.00010031228504446703,
      "loss": 0.2496,
      "step": 3574
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.15854917466640472,
      "learning_rate": 0.00010026767301068369,
      "loss": 0.2588,
      "step": 3575
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.13033369183540344,
      "learning_rate": 0.00010022306092362675,
      "loss": 0.2745,
      "step": 3576
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.14173176884651184,
      "learning_rate": 0.00010017844879217506,
      "loss": 0.2233,
      "step": 3577
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1662621945142746,
      "learning_rate": 0.00010013383662520761,
      "loss": 0.2918,
      "step": 3578
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.16826216876506805,
      "learning_rate": 0.00010008922443160332,
      "loss": 0.2961,
      "step": 3579
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.12919214367866516,
      "learning_rate": 0.00010004461222024116,
      "loss": 0.2346,
      "step": 3580
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.14978693425655365,
      "learning_rate": 0.0001,
      "loss": 0.2722,
      "step": 3581
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.16837221384048462,
      "learning_rate": 9.99553877797589e-05,
      "loss": 0.325,
      "step": 3582
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.15650947391986847,
      "learning_rate": 9.99107755683967e-05,
      "loss": 0.3108,
      "step": 3583
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1263018101453781,
      "learning_rate": 9.986616337479244e-05,
      "loss": 0.3087,
      "step": 3584
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1671440154314041,
      "learning_rate": 9.982155120782495e-05,
      "loss": 0.3193,
      "step": 3585
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.12650972604751587,
      "learning_rate": 9.97769390763733e-05,
      "loss": 0.245,
      "step": 3586
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.20311450958251953,
      "learning_rate": 9.973232698931632e-05,
      "loss": 0.4553,
      "step": 3587
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.14733129739761353,
      "learning_rate": 9.968771495553299e-05,
      "loss": 0.267,
      "step": 3588
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19193445146083832,
      "learning_rate": 9.964310298390218e-05,
      "loss": 0.2753,
      "step": 3589
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.13166549801826477,
      "learning_rate": 9.959849108330282e-05,
      "loss": 0.2794,
      "step": 3590
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.15206828713417053,
      "learning_rate": 9.95538792626138e-05,
      "loss": 0.3261,
      "step": 3591
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.17395085096359253,
      "learning_rate": 9.950926753071396e-05,
      "loss": 0.2953,
      "step": 3592
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1276782900094986,
      "learning_rate": 9.946465589648213e-05,
      "loss": 0.305,
      "step": 3593
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.13283178210258484,
      "learning_rate": 9.942004436879723e-05,
      "loss": 0.2675,
      "step": 3594
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.09612363576889038,
      "learning_rate": 9.937543295653799e-05,
      "loss": 0.23,
      "step": 3595
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.11733181774616241,
      "learning_rate": 9.933082166858324e-05,
      "loss": 0.2493,
      "step": 3596
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.12649056315422058,
      "learning_rate": 9.928621051381169e-05,
      "loss": 0.2867,
      "step": 3597
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.11888433992862701,
      "learning_rate": 9.924159950110216e-05,
      "loss": 0.2373,
      "step": 3598
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.10839924216270447,
      "learning_rate": 9.919698863933327e-05,
      "loss": 0.1955,
      "step": 3599
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.1605273187160492,
      "learning_rate": 9.915237793738378e-05,
      "loss": 0.3814,
      "step": 3600
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.11411048471927643,
      "learning_rate": 9.910776740413225e-05,
      "loss": 0.2899,
      "step": 3601
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.13237452507019043,
      "learning_rate": 9.906315704845738e-05,
      "loss": 0.2999,
      "step": 3602
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.206085667014122,
      "learning_rate": 9.901854687923769e-05,
      "loss": 0.4084,
      "step": 3603
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.13420984148979187,
      "learning_rate": 9.897393690535175e-05,
      "loss": 0.337,
      "step": 3604
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.12896929681301117,
      "learning_rate": 9.8929327135678e-05,
      "loss": 0.2783,
      "step": 3605
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.14808346331119537,
      "learning_rate": 9.8884717579095e-05,
      "loss": 0.3092,
      "step": 3606
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22116166353225708,
      "learning_rate": 9.884010824448108e-05,
      "loss": 0.3366,
      "step": 3607
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.14088238775730133,
      "learning_rate": 9.87954991407147e-05,
      "loss": 0.373,
      "step": 3608
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.14949393272399902,
      "learning_rate": 9.875089027667408e-05,
      "loss": 0.2989,
      "step": 3609
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.14761404693126678,
      "learning_rate": 9.870628166123761e-05,
      "loss": 0.3328,
      "step": 3610
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.11709729582071304,
      "learning_rate": 9.866167330328344e-05,
      "loss": 0.292,
      "step": 3611
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.13625676929950714,
      "learning_rate": 9.86170652116898e-05,
      "loss": 0.3054,
      "step": 3612
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1560734659433365,
      "learning_rate": 9.85724573953348e-05,
      "loss": 0.3588,
      "step": 3613
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1449439525604248,
      "learning_rate": 9.852784986309647e-05,
      "loss": 0.263,
      "step": 3614
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.12224457412958145,
      "learning_rate": 9.84832426238529e-05,
      "loss": 0.2159,
      "step": 3615
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.183817520737648,
      "learning_rate": 9.843863568648199e-05,
      "loss": 0.3328,
      "step": 3616
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1386132836341858,
      "learning_rate": 9.839402905986169e-05,
      "loss": 0.235,
      "step": 3617
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.14740024507045746,
      "learning_rate": 9.834942275286976e-05,
      "loss": 0.367,
      "step": 3618
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.17833511531352997,
      "learning_rate": 9.830481677438405e-05,
      "loss": 0.3527,
      "step": 3619
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1588057577610016,
      "learning_rate": 9.826021113328221e-05,
      "loss": 0.2744,
      "step": 3620
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.17291799187660217,
      "learning_rate": 9.821560583844192e-05,
      "loss": 0.2584,
      "step": 3621
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1819913387298584,
      "learning_rate": 9.81710008987407e-05,
      "loss": 0.3321,
      "step": 3622
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.14118097722530365,
      "learning_rate": 9.812639632305611e-05,
      "loss": 0.3383,
      "step": 3623
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.160840705037117,
      "learning_rate": 9.808179212026554e-05,
      "loss": 0.3398,
      "step": 3624
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1538943648338318,
      "learning_rate": 9.803718829924635e-05,
      "loss": 0.286,
      "step": 3625
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2883816361427307,
      "learning_rate": 9.799258486887579e-05,
      "loss": 0.3942,
      "step": 3626
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.17084211111068726,
      "learning_rate": 9.794798183803113e-05,
      "loss": 0.3234,
      "step": 3627
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.18293353915214539,
      "learning_rate": 9.79033792155894e-05,
      "loss": 0.2884,
      "step": 3628
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.14595390856266022,
      "learning_rate": 9.785877701042773e-05,
      "loss": 0.3126,
      "step": 3629
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1487446427345276,
      "learning_rate": 9.781417523142298e-05,
      "loss": 0.3071,
      "step": 3630
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.11157886683940887,
      "learning_rate": 9.77695738874521e-05,
      "loss": 0.1981,
      "step": 3631
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.15643467009067535,
      "learning_rate": 9.772497298739183e-05,
      "loss": 0.3974,
      "step": 3632
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.12406180053949356,
      "learning_rate": 9.76803725401189e-05,
      "loss": 0.2034,
      "step": 3633
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.17067870497703552,
      "learning_rate": 9.763577255450985e-05,
      "loss": 0.3553,
      "step": 3634
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1695781946182251,
      "learning_rate": 9.759117303944128e-05,
      "loss": 0.3128,
      "step": 3635
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.12540309131145477,
      "learning_rate": 9.754657400378955e-05,
      "loss": 0.2856,
      "step": 3636
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.1210203617811203,
      "learning_rate": 9.750197545643102e-05,
      "loss": 0.2995,
      "step": 3637
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.16670264303684235,
      "learning_rate": 9.745737740624185e-05,
      "loss": 0.309,
      "step": 3638
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.13014039397239685,
      "learning_rate": 9.741277986209826e-05,
      "loss": 0.26,
      "step": 3639
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.14011788368225098,
      "learning_rate": 9.73681828328762e-05,
      "loss": 0.3205,
      "step": 3640
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.1287657618522644,
      "learning_rate": 9.732358632745168e-05,
      "loss": 0.2322,
      "step": 3641
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.19894850254058838,
      "learning_rate": 9.72789903547004e-05,
      "loss": 0.2935,
      "step": 3642
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.12911513447761536,
      "learning_rate": 9.723439492349821e-05,
      "loss": 0.2893,
      "step": 3643
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.14237958192825317,
      "learning_rate": 9.718980004272064e-05,
      "loss": 0.2695,
      "step": 3644
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.140425905585289,
      "learning_rate": 9.714520572124317e-05,
      "loss": 0.292,
      "step": 3645
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.1467091292142868,
      "learning_rate": 9.710061196794125e-05,
      "loss": 0.3942,
      "step": 3646
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.12158884108066559,
      "learning_rate": 9.705601879169006e-05,
      "loss": 0.2407,
      "step": 3647
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.14510679244995117,
      "learning_rate": 9.701142620136487e-05,
      "loss": 0.2303,
      "step": 3648
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.12615083158016205,
      "learning_rate": 9.696683420584066e-05,
      "loss": 0.1835,
      "step": 3649
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.15436884760856628,
      "learning_rate": 9.692224281399236e-05,
      "loss": 0.2758,
      "step": 3650
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.16908536851406097,
      "learning_rate": 9.687765203469474e-05,
      "loss": 0.3252,
      "step": 3651
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.15682333707809448,
      "learning_rate": 9.683306187682257e-05,
      "loss": 0.3422,
      "step": 3652
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.14149242639541626,
      "learning_rate": 9.678847234925031e-05,
      "loss": 0.3425,
      "step": 3653
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.1349678635597229,
      "learning_rate": 9.674388346085247e-05,
      "loss": 0.2673,
      "step": 3654
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.13951566815376282,
      "learning_rate": 9.669929522050327e-05,
      "loss": 0.3808,
      "step": 3655
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2222098708152771,
      "learning_rate": 9.665470763707699e-05,
      "loss": 0.291,
      "step": 3656
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.13967786729335785,
      "learning_rate": 9.661012071944758e-05,
      "loss": 0.324,
      "step": 3657
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.1587650179862976,
      "learning_rate": 9.656553447648904e-05,
      "loss": 0.2889,
      "step": 3658
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.11620043218135834,
      "learning_rate": 9.652094891707503e-05,
      "loss": 0.2254,
      "step": 3659
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.14102570712566376,
      "learning_rate": 9.647636405007934e-05,
      "loss": 0.2303,
      "step": 3660
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.30243152379989624,
      "learning_rate": 9.643177988437535e-05,
      "loss": 0.2376,
      "step": 3661
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.11573264002799988,
      "learning_rate": 9.638719642883652e-05,
      "loss": 0.2261,
      "step": 3662
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.13365612924098969,
      "learning_rate": 9.634261369233596e-05,
      "loss": 0.2926,
      "step": 3663
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.12232840061187744,
      "learning_rate": 9.629803168374687e-05,
      "loss": 0.2435,
      "step": 3664
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.16708114743232727,
      "learning_rate": 9.62534504119421e-05,
      "loss": 0.3177,
      "step": 3665
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.14102748036384583,
      "learning_rate": 9.620886988579451e-05,
      "loss": 0.3035,
      "step": 3666
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.10700120776891708,
      "learning_rate": 9.616429011417664e-05,
      "loss": 0.2628,
      "step": 3667
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.13353221118450165,
      "learning_rate": 9.611971110596114e-05,
      "loss": 0.2769,
      "step": 3668
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.13391496241092682,
      "learning_rate": 9.607513287002015e-05,
      "loss": 0.288,
      "step": 3669
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.1477053016424179,
      "learning_rate": 9.603055541522603e-05,
      "loss": 0.2666,
      "step": 3670
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.13957151770591736,
      "learning_rate": 9.598597875045068e-05,
      "loss": 0.3055,
      "step": 3671
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.18482327461242676,
      "learning_rate": 9.594140288456608e-05,
      "loss": 0.2674,
      "step": 3672
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.15899509191513062,
      "learning_rate": 9.589682782644387e-05,
      "loss": 0.3679,
      "step": 3673
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.12747399508953094,
      "learning_rate": 9.58522535849556e-05,
      "loss": 0.247,
      "step": 3674
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.13686147332191467,
      "learning_rate": 9.580768016897271e-05,
      "loss": 0.3278,
      "step": 3675
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.14180414378643036,
      "learning_rate": 9.576310758736638e-05,
      "loss": 0.2602,
      "step": 3676
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1833547055721283,
      "learning_rate": 9.571853584900771e-05,
      "loss": 0.3578,
      "step": 3677
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.11896096915006638,
      "learning_rate": 9.567396496276753e-05,
      "loss": 0.2328,
      "step": 3678
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.14463981986045837,
      "learning_rate": 9.562939493751663e-05,
      "loss": 0.3057,
      "step": 3679
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.12613490223884583,
      "learning_rate": 9.558482578212551e-05,
      "loss": 0.2861,
      "step": 3680
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1315310299396515,
      "learning_rate": 9.554025750546461e-05,
      "loss": 0.2968,
      "step": 3681
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.09920462220907211,
      "learning_rate": 9.549569011640403e-05,
      "loss": 0.1917,
      "step": 3682
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.18762607872486115,
      "learning_rate": 9.54511236238139e-05,
      "loss": 0.3644,
      "step": 3683
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.15050609409809113,
      "learning_rate": 9.540655803656401e-05,
      "loss": 0.3089,
      "step": 3684
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1749631017446518,
      "learning_rate": 9.536199336352404e-05,
      "loss": 0.2737,
      "step": 3685
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.13780219852924347,
      "learning_rate": 9.531742961356347e-05,
      "loss": 0.2818,
      "step": 3686
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.14618317782878876,
      "learning_rate": 9.527286679555163e-05,
      "loss": 0.2603,
      "step": 3687
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.10959108918905258,
      "learning_rate": 9.52283049183576e-05,
      "loss": 0.2393,
      "step": 3688
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.16266250610351562,
      "learning_rate": 9.518374399085035e-05,
      "loss": 0.2778,
      "step": 3689
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1289333552122116,
      "learning_rate": 9.513918402189855e-05,
      "loss": 0.3192,
      "step": 3690
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.13746269047260284,
      "learning_rate": 9.509462502037082e-05,
      "loss": 0.3267,
      "step": 3691
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.14864474534988403,
      "learning_rate": 9.505006699513548e-05,
      "loss": 0.3285,
      "step": 3692
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.13501250743865967,
      "learning_rate": 9.500550995506073e-05,
      "loss": 0.2821,
      "step": 3693
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.13710016012191772,
      "learning_rate": 9.496095390901445e-05,
      "loss": 0.2546,
      "step": 3694
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.13103953003883362,
      "learning_rate": 9.491639886586452e-05,
      "loss": 0.2861,
      "step": 3695
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.15708675980567932,
      "learning_rate": 9.487184483447842e-05,
      "loss": 0.302,
      "step": 3696
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.12269335240125656,
      "learning_rate": 9.48272918237236e-05,
      "loss": 0.2505,
      "step": 3697
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.12632761895656586,
      "learning_rate": 9.478273984246712e-05,
      "loss": 0.2272,
      "step": 3698
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1590888500213623,
      "learning_rate": 9.473818889957603e-05,
      "loss": 0.2741,
      "step": 3699
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.111342653632164,
      "learning_rate": 9.469363900391704e-05,
      "loss": 0.2341,
      "step": 3700
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.133992537856102,
      "learning_rate": 9.464909016435672e-05,
      "loss": 0.2479,
      "step": 3701
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.11934305727481842,
      "learning_rate": 9.460454238976134e-05,
      "loss": 0.2775,
      "step": 3702
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.16982176899909973,
      "learning_rate": 9.455999568899711e-05,
      "loss": 0.3949,
      "step": 3703
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.13768194615840912,
      "learning_rate": 9.45154500709299e-05,
      "loss": 0.2934,
      "step": 3704
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1319182962179184,
      "learning_rate": 9.44709055444254e-05,
      "loss": 0.2741,
      "step": 3705
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1247592642903328,
      "learning_rate": 9.44263621183491e-05,
      "loss": 0.3186,
      "step": 3706
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.12931512296199799,
      "learning_rate": 9.438181980156617e-05,
      "loss": 0.2739,
      "step": 3707
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.08199585229158401,
      "learning_rate": 9.43372786029418e-05,
      "loss": 0.2011,
      "step": 3708
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.198468416929245,
      "learning_rate": 9.429273853134067e-05,
      "loss": 0.2875,
      "step": 3709
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.16777688264846802,
      "learning_rate": 9.424819959562746e-05,
      "loss": 0.2997,
      "step": 3710
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.12478423118591309,
      "learning_rate": 9.420366180466645e-05,
      "loss": 0.255,
      "step": 3711
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.11586320400238037,
      "learning_rate": 9.415912516732186e-05,
      "loss": 0.2448,
      "step": 3712
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1453351527452469,
      "learning_rate": 9.411458969245753e-05,
      "loss": 0.2483,
      "step": 3713
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1315794587135315,
      "learning_rate": 9.40700553889372e-05,
      "loss": 0.3459,
      "step": 3714
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.12944239377975464,
      "learning_rate": 9.402552226562422e-05,
      "loss": 0.274,
      "step": 3715
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.14791546761989594,
      "learning_rate": 9.398099033138187e-05,
      "loss": 0.2491,
      "step": 3716
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.14600872993469238,
      "learning_rate": 9.393645959507309e-05,
      "loss": 0.3,
      "step": 3717
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.15540839731693268,
      "learning_rate": 9.389193006556064e-05,
      "loss": 0.2892,
      "step": 3718
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.13201101124286652,
      "learning_rate": 9.384740175170695e-05,
      "loss": 0.2498,
      "step": 3719
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1596275418996811,
      "learning_rate": 9.380287466237433e-05,
      "loss": 0.371,
      "step": 3720
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.15318840742111206,
      "learning_rate": 9.375834880642476e-05,
      "loss": 0.3182,
      "step": 3721
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.16459551453590393,
      "learning_rate": 9.371382419272002e-05,
      "loss": 0.328,
      "step": 3722
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.14394430816173553,
      "learning_rate": 9.366930083012156e-05,
      "loss": 0.3128,
      "step": 3723
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1365162581205368,
      "learning_rate": 9.362477872749073e-05,
      "loss": 0.2642,
      "step": 3724
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1305464506149292,
      "learning_rate": 9.358025789368847e-05,
      "loss": 0.2566,
      "step": 3725
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.16316962242126465,
      "learning_rate": 9.353573833757561e-05,
      "loss": 0.2668,
      "step": 3726
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.13890261948108673,
      "learning_rate": 9.349122006801256e-05,
      "loss": 0.265,
      "step": 3727
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.18266476690769196,
      "learning_rate": 9.344670309385968e-05,
      "loss": 0.2705,
      "step": 3728
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.15288099646568298,
      "learning_rate": 9.340218742397689e-05,
      "loss": 0.3128,
      "step": 3729
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.11563874781131744,
      "learning_rate": 9.335767306722395e-05,
      "loss": 0.2163,
      "step": 3730
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1503235101699829,
      "learning_rate": 9.331316003246028e-05,
      "loss": 0.3315,
      "step": 3731
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.14086481928825378,
      "learning_rate": 9.326864832854519e-05,
      "loss": 0.2865,
      "step": 3732
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.17971864342689514,
      "learning_rate": 9.322413796433753e-05,
      "loss": 0.307,
      "step": 3733
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.16461710631847382,
      "learning_rate": 9.317962894869605e-05,
      "loss": 0.3203,
      "step": 3734
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1230386421084404,
      "learning_rate": 9.313512129047909e-05,
      "loss": 0.2469,
      "step": 3735
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.13992923498153687,
      "learning_rate": 9.30906149985448e-05,
      "loss": 0.3489,
      "step": 3736
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.12625151872634888,
      "learning_rate": 9.30461100817511e-05,
      "loss": 0.2446,
      "step": 3737
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1458716094493866,
      "learning_rate": 9.300160654895552e-05,
      "loss": 0.2733,
      "step": 3738
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.13620662689208984,
      "learning_rate": 9.295710440901542e-05,
      "loss": 0.4406,
      "step": 3739
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1356910914182663,
      "learning_rate": 9.291260367078778e-05,
      "loss": 0.2931,
      "step": 3740
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.1682107150554657,
      "learning_rate": 9.286810434312945e-05,
      "loss": 0.3466,
      "step": 3741
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.24100375175476074,
      "learning_rate": 9.282360643489685e-05,
      "loss": 0.2929,
      "step": 3742
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.17657087743282318,
      "learning_rate": 9.27791099549462e-05,
      "loss": 0.2636,
      "step": 3743
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.11999666690826416,
      "learning_rate": 9.273461491213336e-05,
      "loss": 0.2757,
      "step": 3744
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.13196295499801636,
      "learning_rate": 9.269012131531403e-05,
      "loss": 0.3259,
      "step": 3745
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.14341777563095093,
      "learning_rate": 9.264562917334353e-05,
      "loss": 0.3392,
      "step": 3746
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.13528954982757568,
      "learning_rate": 9.26011384950769e-05,
      "loss": 0.2498,
      "step": 3747
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.15170082449913025,
      "learning_rate": 9.255664928936885e-05,
      "loss": 0.3605,
      "step": 3748
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.09864368289709091,
      "learning_rate": 9.251216156507397e-05,
      "loss": 0.2655,
      "step": 3749
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.1557864546775818,
      "learning_rate": 9.24676753310463e-05,
      "loss": 0.3337,
      "step": 3750
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.11307454854249954,
      "learning_rate": 9.24231905961398e-05,
      "loss": 0.2616,
      "step": 3751
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.1662479192018509,
      "learning_rate": 9.237870736920797e-05,
      "loss": 0.3258,
      "step": 3752
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.14114166796207428,
      "learning_rate": 9.23342256591042e-05,
      "loss": 0.2772,
      "step": 3753
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.10259877890348434,
      "learning_rate": 9.228974547468132e-05,
      "loss": 0.2266,
      "step": 3754
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.12247057259082794,
      "learning_rate": 9.224526682479213e-05,
      "loss": 0.2542,
      "step": 3755
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.12615805864334106,
      "learning_rate": 9.220078971828888e-05,
      "loss": 0.2404,
      "step": 3756
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.12840361893177032,
      "learning_rate": 9.215631416402377e-05,
      "loss": 0.3051,
      "step": 3757
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.20241399109363556,
      "learning_rate": 9.211184017084838e-05,
      "loss": 0.3754,
      "step": 3758
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.17101773619651794,
      "learning_rate": 9.206736774761427e-05,
      "loss": 0.3841,
      "step": 3759
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.12786337733268738,
      "learning_rate": 9.202289690317253e-05,
      "loss": 0.2444,
      "step": 3760
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.13039307296276093,
      "learning_rate": 9.197842764637397e-05,
      "loss": 0.2876,
      "step": 3761
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.12639407813549042,
      "learning_rate": 9.193395998606905e-05,
      "loss": 0.2702,
      "step": 3762
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.13957121968269348,
      "learning_rate": 9.188949393110802e-05,
      "loss": 0.3396,
      "step": 3763
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.141874298453331,
      "learning_rate": 9.184502949034067e-05,
      "loss": 0.2749,
      "step": 3764
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.1263893097639084,
      "learning_rate": 9.180056667261661e-05,
      "loss": 0.2541,
      "step": 3765
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.15343831479549408,
      "learning_rate": 9.175610548678498e-05,
      "loss": 0.3459,
      "step": 3766
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.09877602010965347,
      "learning_rate": 9.171164594169468e-05,
      "loss": 0.2226,
      "step": 3767
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.1437024176120758,
      "learning_rate": 9.166718804619431e-05,
      "loss": 0.455,
      "step": 3768
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.19341114163398743,
      "learning_rate": 9.162273180913208e-05,
      "loss": 0.3176,
      "step": 3769
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.11713621765375137,
      "learning_rate": 9.157827723935591e-05,
      "loss": 0.2173,
      "step": 3770
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.1234605610370636,
      "learning_rate": 9.153382434571332e-05,
      "loss": 0.2875,
      "step": 3771
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.11662537604570389,
      "learning_rate": 9.148937313705164e-05,
      "loss": 0.2594,
      "step": 3772
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.16174040734767914,
      "learning_rate": 9.144492362221769e-05,
      "loss": 0.2927,
      "step": 3773
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.15837125480175018,
      "learning_rate": 9.140047581005809e-05,
      "loss": 0.4077,
      "step": 3774
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.11643055826425552,
      "learning_rate": 9.1356029709419e-05,
      "loss": 0.2428,
      "step": 3775
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.1381198614835739,
      "learning_rate": 9.131158532914639e-05,
      "loss": 0.3345,
      "step": 3776
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.1612958014011383,
      "learning_rate": 9.126714267808576e-05,
      "loss": 0.31,
      "step": 3777
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.14311610162258148,
      "learning_rate": 9.122270176508233e-05,
      "loss": 0.3497,
      "step": 3778
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.11677666008472443,
      "learning_rate": 9.117826259898089e-05,
      "loss": 0.2288,
      "step": 3779
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.11256442219018936,
      "learning_rate": 9.113382518862604e-05,
      "loss": 0.2833,
      "step": 3780
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.14041246473789215,
      "learning_rate": 9.108938954286187e-05,
      "loss": 0.3781,
      "step": 3781
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.14318779110908508,
      "learning_rate": 9.104495567053224e-05,
      "loss": 0.2468,
      "step": 3782
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.15434250235557556,
      "learning_rate": 9.100052358048052e-05,
      "loss": 0.3023,
      "step": 3783
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.11527493596076965,
      "learning_rate": 9.09560932815499e-05,
      "loss": 0.2501,
      "step": 3784
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.13269875943660736,
      "learning_rate": 9.091166478258306e-05,
      "loss": 0.3708,
      "step": 3785
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.13278110325336456,
      "learning_rate": 9.086723809242243e-05,
      "loss": 0.2927,
      "step": 3786
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.15888862311840057,
      "learning_rate": 9.082281321990996e-05,
      "loss": 0.2919,
      "step": 3787
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.12141788005828857,
      "learning_rate": 9.07783901738874e-05,
      "loss": 0.2422,
      "step": 3788
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.13859935104846954,
      "learning_rate": 9.073396896319598e-05,
      "loss": 0.2898,
      "step": 3789
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.18280643224716187,
      "learning_rate": 9.06895495966767e-05,
      "loss": 0.3269,
      "step": 3790
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.12217850983142853,
      "learning_rate": 9.064513208317001e-05,
      "loss": 0.2449,
      "step": 3791
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1499829888343811,
      "learning_rate": 9.060071643151625e-05,
      "loss": 0.276,
      "step": 3792
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.19162119925022125,
      "learning_rate": 9.055630265055516e-05,
      "loss": 0.2616,
      "step": 3793
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.13097217679023743,
      "learning_rate": 9.051189074912622e-05,
      "loss": 0.2619,
      "step": 3794
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1836005449295044,
      "learning_rate": 9.046748073606847e-05,
      "loss": 0.3301,
      "step": 3795
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.13145141303539276,
      "learning_rate": 9.042307262022068e-05,
      "loss": 0.2527,
      "step": 3796
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.12592865526676178,
      "learning_rate": 9.037866641042114e-05,
      "loss": 0.2764,
      "step": 3797
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.14124134182929993,
      "learning_rate": 9.03342621155078e-05,
      "loss": 0.3481,
      "step": 3798
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1724834442138672,
      "learning_rate": 9.028985974431823e-05,
      "loss": 0.3776,
      "step": 3799
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.14790073037147522,
      "learning_rate": 9.024545930568958e-05,
      "loss": 0.2634,
      "step": 3800
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.15508854389190674,
      "learning_rate": 9.02010608084587e-05,
      "loss": 0.3367,
      "step": 3801
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.13508884608745575,
      "learning_rate": 9.015666426146198e-05,
      "loss": 0.2874,
      "step": 3802
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1819620430469513,
      "learning_rate": 9.011226967353545e-05,
      "loss": 0.2936,
      "step": 3803
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.09850523620843887,
      "learning_rate": 9.006787705351471e-05,
      "loss": 0.2051,
      "step": 3804
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1813499480485916,
      "learning_rate": 9.002348641023506e-05,
      "loss": 0.3093,
      "step": 3805
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.11455398052930832,
      "learning_rate": 8.997909775253132e-05,
      "loss": 0.2802,
      "step": 3806
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.29358813166618347,
      "learning_rate": 8.993471108923794e-05,
      "loss": 0.4636,
      "step": 3807
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.12417355179786682,
      "learning_rate": 8.989032642918896e-05,
      "loss": 0.2219,
      "step": 3808
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.15442119538784027,
      "learning_rate": 8.984594378121808e-05,
      "loss": 0.2369,
      "step": 3809
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.10923387855291367,
      "learning_rate": 8.980156315415854e-05,
      "loss": 0.2407,
      "step": 3810
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.15329687297344208,
      "learning_rate": 8.975718455684321e-05,
      "loss": 0.237,
      "step": 3811
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.15575578808784485,
      "learning_rate": 8.971280799810447e-05,
      "loss": 0.3167,
      "step": 3812
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.16177459061145782,
      "learning_rate": 8.966843348677447e-05,
      "loss": 0.2791,
      "step": 3813
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.15069803595542908,
      "learning_rate": 8.962406103168477e-05,
      "loss": 0.3173,
      "step": 3814
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1513306349515915,
      "learning_rate": 8.957969064166666e-05,
      "loss": 0.3132,
      "step": 3815
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.22761794924736023,
      "learning_rate": 8.953532232555088e-05,
      "loss": 0.3128,
      "step": 3816
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.14241670072078705,
      "learning_rate": 8.949095609216792e-05,
      "loss": 0.3013,
      "step": 3817
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.14739300310611725,
      "learning_rate": 8.944659195034772e-05,
      "loss": 0.3092,
      "step": 3818
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.12413410097360611,
      "learning_rate": 8.940222990891989e-05,
      "loss": 0.2168,
      "step": 3819
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.17367315292358398,
      "learning_rate": 8.93578699767135e-05,
      "loss": 0.3967,
      "step": 3820
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.14277727901935577,
      "learning_rate": 8.931351216255742e-05,
      "loss": 0.3588,
      "step": 3821
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.10374879091978073,
      "learning_rate": 8.926915647527985e-05,
      "loss": 0.2051,
      "step": 3822
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15322376787662506,
      "learning_rate": 8.922480292370877e-05,
      "loss": 0.2534,
      "step": 3823
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.11735962331295013,
      "learning_rate": 8.918045151667155e-05,
      "loss": 0.2841,
      "step": 3824
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.12128729373216629,
      "learning_rate": 8.913610226299534e-05,
      "loss": 0.4252,
      "step": 3825
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15755192935466766,
      "learning_rate": 8.909175517150669e-05,
      "loss": 0.2653,
      "step": 3826
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.14371871948242188,
      "learning_rate": 8.904741025103176e-05,
      "loss": 0.3152,
      "step": 3827
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.161887988448143,
      "learning_rate": 8.900306751039635e-05,
      "loss": 0.2988,
      "step": 3828
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.1401275247335434,
      "learning_rate": 8.89587269584257e-05,
      "loss": 0.2467,
      "step": 3829
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.20632408559322357,
      "learning_rate": 8.891438860394481e-05,
      "loss": 0.3044,
      "step": 3830
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.09526859223842621,
      "learning_rate": 8.887005245577802e-05,
      "loss": 0.3157,
      "step": 3831
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15607482194900513,
      "learning_rate": 8.882571852274937e-05,
      "loss": 0.3134,
      "step": 3832
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15190519392490387,
      "learning_rate": 8.878138681368239e-05,
      "loss": 0.2717,
      "step": 3833
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.1548115760087967,
      "learning_rate": 8.873705733740029e-05,
      "loss": 0.3265,
      "step": 3834
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.16983477771282196,
      "learning_rate": 8.869273010272566e-05,
      "loss": 0.3288,
      "step": 3835
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.12780392169952393,
      "learning_rate": 8.864840511848075e-05,
      "loss": 0.246,
      "step": 3836
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.19308163225650787,
      "learning_rate": 8.860408239348732e-05,
      "loss": 0.415,
      "step": 3837
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15143916010856628,
      "learning_rate": 8.855976193656678e-05,
      "loss": 0.2257,
      "step": 3838
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.14181382954120636,
      "learning_rate": 8.85154437565399e-05,
      "loss": 0.2679,
      "step": 3839
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.16784211993217468,
      "learning_rate": 8.84711278622272e-05,
      "loss": 0.3181,
      "step": 3840
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.12120579183101654,
      "learning_rate": 8.842681426244859e-05,
      "loss": 0.2148,
      "step": 3841
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.1281541883945465,
      "learning_rate": 8.838250296602366e-05,
      "loss": 0.2115,
      "step": 3842
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.13447305560112,
      "learning_rate": 8.833819398177135e-05,
      "loss": 0.3155,
      "step": 3843
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15288609266281128,
      "learning_rate": 8.829388731851038e-05,
      "loss": 0.4202,
      "step": 3844
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.13757987320423126,
      "learning_rate": 8.824958298505882e-05,
      "loss": 0.2622,
      "step": 3845
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.147599458694458,
      "learning_rate": 8.820528099023435e-05,
      "loss": 0.2894,
      "step": 3846
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.1655796766281128,
      "learning_rate": 8.816098134285414e-05,
      "loss": 0.356,
      "step": 3847
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15354368090629578,
      "learning_rate": 8.811668405173501e-05,
      "loss": 0.291,
      "step": 3848
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.13853754103183746,
      "learning_rate": 8.807238912569317e-05,
      "loss": 0.2498,
      "step": 3849
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.13942258059978485,
      "learning_rate": 8.802809657354445e-05,
      "loss": 0.3071,
      "step": 3850
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.1412666141986847,
      "learning_rate": 8.798380640410412e-05,
      "loss": 0.2438,
      "step": 3851
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.14522893726825714,
      "learning_rate": 8.793951862618712e-05,
      "loss": 0.3006,
      "step": 3852
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1184769943356514,
      "learning_rate": 8.789523324860775e-05,
      "loss": 0.2734,
      "step": 3853
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1375696063041687,
      "learning_rate": 8.785095028017998e-05,
      "loss": 0.2692,
      "step": 3854
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.15277454257011414,
      "learning_rate": 8.780666972971712e-05,
      "loss": 0.2965,
      "step": 3855
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1390017569065094,
      "learning_rate": 8.776239160603223e-05,
      "loss": 0.2164,
      "step": 3856
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.10529715567827225,
      "learning_rate": 8.771811591793771e-05,
      "loss": 0.1961,
      "step": 3857
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.11054710298776627,
      "learning_rate": 8.767384267424551e-05,
      "loss": 0.2295,
      "step": 3858
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12036918848752975,
      "learning_rate": 8.762957188376716e-05,
      "loss": 0.2751,
      "step": 3859
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12829476594924927,
      "learning_rate": 8.758530355531359e-05,
      "loss": 0.2799,
      "step": 3860
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.15910065174102783,
      "learning_rate": 8.754103769769536e-05,
      "loss": 0.288,
      "step": 3861
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.13889053463935852,
      "learning_rate": 8.749677431972247e-05,
      "loss": 0.2901,
      "step": 3862
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12462147325277328,
      "learning_rate": 8.745251343020445e-05,
      "loss": 0.2471,
      "step": 3863
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.11734423786401749,
      "learning_rate": 8.740825503795027e-05,
      "loss": 0.2358,
      "step": 3864
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1728757619857788,
      "learning_rate": 8.736399915176856e-05,
      "loss": 0.2823,
      "step": 3865
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12056693434715271,
      "learning_rate": 8.731974578046726e-05,
      "loss": 0.2275,
      "step": 3866
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.14589686691761017,
      "learning_rate": 8.727549493285394e-05,
      "loss": 0.29,
      "step": 3867
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12122143059968948,
      "learning_rate": 8.723124661773558e-05,
      "loss": 0.2526,
      "step": 3868
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.11032849550247192,
      "learning_rate": 8.718700084391877e-05,
      "loss": 0.2316,
      "step": 3869
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.13624703884124756,
      "learning_rate": 8.714275762020949e-05,
      "loss": 0.2856,
      "step": 3870
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1635347306728363,
      "learning_rate": 8.709851695541326e-05,
      "loss": 0.3811,
      "step": 3871
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.19585278630256653,
      "learning_rate": 8.705427885833503e-05,
      "loss": 0.314,
      "step": 3872
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12102971971035004,
      "learning_rate": 8.701004333777939e-05,
      "loss": 0.2483,
      "step": 3873
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.17047998309135437,
      "learning_rate": 8.696581040255023e-05,
      "loss": 0.2889,
      "step": 3874
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.17858366668224335,
      "learning_rate": 8.692158006145105e-05,
      "loss": 0.3157,
      "step": 3875
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.14383456110954285,
      "learning_rate": 8.687735232328474e-05,
      "loss": 0.3151,
      "step": 3876
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1296171247959137,
      "learning_rate": 8.683312719685381e-05,
      "loss": 0.2458,
      "step": 3877
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1630410999059677,
      "learning_rate": 8.678890469096011e-05,
      "loss": 0.3112,
      "step": 3878
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1780889928340912,
      "learning_rate": 8.674468481440507e-05,
      "loss": 0.3608,
      "step": 3879
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.14947262406349182,
      "learning_rate": 8.670046757598948e-05,
      "loss": 0.3412,
      "step": 3880
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12077119201421738,
      "learning_rate": 8.665625298451375e-05,
      "loss": 0.2176,
      "step": 3881
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.15565980970859528,
      "learning_rate": 8.661204104877765e-05,
      "loss": 0.364,
      "step": 3882
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.11222857236862183,
      "learning_rate": 8.65678317775805e-05,
      "loss": 0.2292,
      "step": 3883
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.16494980454444885,
      "learning_rate": 8.652362517972097e-05,
      "loss": 0.3166,
      "step": 3884
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.13827893137931824,
      "learning_rate": 8.64794212639974e-05,
      "loss": 0.2716,
      "step": 3885
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.12883980572223663,
      "learning_rate": 8.643522003920736e-05,
      "loss": 0.2308,
      "step": 3886
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.1703018844127655,
      "learning_rate": 8.639102151414808e-05,
      "loss": 0.2908,
      "step": 3887
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.15640310943126678,
      "learning_rate": 8.634682569761616e-05,
      "loss": 0.2793,
      "step": 3888
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.13863438367843628,
      "learning_rate": 8.63026325984076e-05,
      "loss": 0.3047,
      "step": 3889
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.13091443479061127,
      "learning_rate": 8.625844222531804e-05,
      "loss": 0.2074,
      "step": 3890
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.13356520235538483,
      "learning_rate": 8.621425458714238e-05,
      "loss": 0.2813,
      "step": 3891
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.13087955117225647,
      "learning_rate": 8.617006969267514e-05,
      "loss": 0.2439,
      "step": 3892
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.1529085338115692,
      "learning_rate": 8.612588755071015e-05,
      "loss": 0.294,
      "step": 3893
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.13985532522201538,
      "learning_rate": 8.608170817004084e-05,
      "loss": 0.2948,
      "step": 3894
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.15842480957508087,
      "learning_rate": 8.603753155945994e-05,
      "loss": 0.2906,
      "step": 3895
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.20504586398601532,
      "learning_rate": 8.599335772775976e-05,
      "loss": 0.3257,
      "step": 3896
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.1653231978416443,
      "learning_rate": 8.594918668373192e-05,
      "loss": 0.3577,
      "step": 3897
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.19910365343093872,
      "learning_rate": 8.590501843616766e-05,
      "loss": 0.2503,
      "step": 3898
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.13665033876895905,
      "learning_rate": 8.58608529938575e-05,
      "loss": 0.2814,
      "step": 3899
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.16610977053642273,
      "learning_rate": 8.58166903655915e-05,
      "loss": 0.2988,
      "step": 3900
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.1705661565065384,
      "learning_rate": 8.57725305601591e-05,
      "loss": 0.3316,
      "step": 3901
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14529141783714294,
      "learning_rate": 8.572837358634924e-05,
      "loss": 0.2491,
      "step": 3902
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.19620992243289948,
      "learning_rate": 8.568421945295023e-05,
      "loss": 0.3307,
      "step": 3903
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.15727423131465912,
      "learning_rate": 8.564006816874989e-05,
      "loss": 0.3177,
      "step": 3904
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.1827707141637802,
      "learning_rate": 8.559591974253536e-05,
      "loss": 0.3042,
      "step": 3905
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.15147696435451508,
      "learning_rate": 8.555177418309337e-05,
      "loss": 0.3133,
      "step": 3906
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.19541503489017487,
      "learning_rate": 8.550763149920993e-05,
      "loss": 0.4026,
      "step": 3907
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.21324273943901062,
      "learning_rate": 8.546349169967057e-05,
      "loss": 0.3241,
      "step": 3908
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.17982512712478638,
      "learning_rate": 8.541935479326016e-05,
      "loss": 0.3187,
      "step": 3909
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14937067031860352,
      "learning_rate": 8.537522078876314e-05,
      "loss": 0.2636,
      "step": 3910
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14016298949718475,
      "learning_rate": 8.533108969496321e-05,
      "loss": 0.3166,
      "step": 3911
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.16948169469833374,
      "learning_rate": 8.52869615206436e-05,
      "loss": 0.3124,
      "step": 3912
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14761880040168762,
      "learning_rate": 8.524283627458687e-05,
      "loss": 0.3629,
      "step": 3913
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.15762758255004883,
      "learning_rate": 8.519871396557513e-05,
      "loss": 0.2525,
      "step": 3914
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14396730065345764,
      "learning_rate": 8.515459460238975e-05,
      "loss": 0.3194,
      "step": 3915
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.12833811342716217,
      "learning_rate": 8.511047819381163e-05,
      "loss": 0.2793,
      "step": 3916
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.16682219505310059,
      "learning_rate": 8.506636474862098e-05,
      "loss": 0.3576,
      "step": 3917
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14510762691497803,
      "learning_rate": 8.502225427559758e-05,
      "loss": 0.2506,
      "step": 3918
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.15166349709033966,
      "learning_rate": 8.497814678352049e-05,
      "loss": 0.3287,
      "step": 3919
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.18044881522655487,
      "learning_rate": 8.49340422811681e-05,
      "loss": 0.351,
      "step": 3920
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14538338780403137,
      "learning_rate": 8.488994077731843e-05,
      "loss": 0.3569,
      "step": 3921
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.19301283359527588,
      "learning_rate": 8.48458422807487e-05,
      "loss": 0.3258,
      "step": 3922
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.16462823748588562,
      "learning_rate": 8.480174680023574e-05,
      "loss": 0.3703,
      "step": 3923
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.1627679169178009,
      "learning_rate": 8.475765434455548e-05,
      "loss": 0.3464,
      "step": 3924
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.1365937888622284,
      "learning_rate": 8.471356492248356e-05,
      "loss": 0.2595,
      "step": 3925
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.15479347109794617,
      "learning_rate": 8.466947854279479e-05,
      "loss": 0.2935,
      "step": 3926
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.1581827998161316,
      "learning_rate": 8.462539521426357e-05,
      "loss": 0.2859,
      "step": 3927
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14798565208911896,
      "learning_rate": 8.458131494566346e-05,
      "loss": 0.3143,
      "step": 3928
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.16401049494743347,
      "learning_rate": 8.453723774576763e-05,
      "loss": 0.2973,
      "step": 3929
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.16145452857017517,
      "learning_rate": 8.449316362334849e-05,
      "loss": 0.3234,
      "step": 3930
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.13977663218975067,
      "learning_rate": 8.444909258717795e-05,
      "loss": 0.3183,
      "step": 3931
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14729377627372742,
      "learning_rate": 8.440502464602715e-05,
      "loss": 0.2761,
      "step": 3932
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14411702752113342,
      "learning_rate": 8.436095980866684e-05,
      "loss": 0.2387,
      "step": 3933
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.15250349044799805,
      "learning_rate": 8.431689808386694e-05,
      "loss": 0.3132,
      "step": 3934
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.15437699854373932,
      "learning_rate": 8.427283948039687e-05,
      "loss": 0.2631,
      "step": 3935
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14362089335918427,
      "learning_rate": 8.422878400702535e-05,
      "loss": 0.2811,
      "step": 3936
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.18503262102603912,
      "learning_rate": 8.41847316725206e-05,
      "loss": 0.3031,
      "step": 3937
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14584463834762573,
      "learning_rate": 8.414068248565007e-05,
      "loss": 0.2936,
      "step": 3938
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.128563791513443,
      "learning_rate": 8.409663645518069e-05,
      "loss": 0.274,
      "step": 3939
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.17182956635951996,
      "learning_rate": 8.405259358987867e-05,
      "loss": 0.2949,
      "step": 3940
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14242875576019287,
      "learning_rate": 8.400855389850973e-05,
      "loss": 0.3142,
      "step": 3941
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.13480991125106812,
      "learning_rate": 8.396451738983879e-05,
      "loss": 0.2484,
      "step": 3942
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.15177343785762787,
      "learning_rate": 8.392048407263027e-05,
      "loss": 0.2398,
      "step": 3943
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14888925850391388,
      "learning_rate": 8.387645395564783e-05,
      "loss": 0.275,
      "step": 3944
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.1999676376581192,
      "learning_rate": 8.383242704765468e-05,
      "loss": 0.3576,
      "step": 3945
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.16187016665935516,
      "learning_rate": 8.378840335741316e-05,
      "loss": 0.2627,
      "step": 3946
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14522498846054077,
      "learning_rate": 8.374438289368519e-05,
      "loss": 0.2881,
      "step": 3947
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.16561266779899597,
      "learning_rate": 8.370036566523183e-05,
      "loss": 0.3499,
      "step": 3948
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14956456422805786,
      "learning_rate": 8.365635168081372e-05,
      "loss": 0.3063,
      "step": 3949
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.11221186816692352,
      "learning_rate": 8.36123409491907e-05,
      "loss": 0.2142,
      "step": 3950
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.14815270900726318,
      "learning_rate": 8.356833347912197e-05,
      "loss": 0.2761,
      "step": 3951
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.11233501136302948,
      "learning_rate": 8.352432927936619e-05,
      "loss": 0.245,
      "step": 3952
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.15117247402668,
      "learning_rate": 8.348032835868121e-05,
      "loss": 0.2966,
      "step": 3953
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.1453501582145691,
      "learning_rate": 8.34363307258244e-05,
      "loss": 0.2869,
      "step": 3954
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.13501004874706268,
      "learning_rate": 8.339233638955235e-05,
      "loss": 0.3077,
      "step": 3955
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.11738140881061554,
      "learning_rate": 8.334834535862104e-05,
      "loss": 0.2385,
      "step": 3956
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.13813649117946625,
      "learning_rate": 8.330435764178575e-05,
      "loss": 0.2762,
      "step": 3957
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.12960880994796753,
      "learning_rate": 8.326037324780121e-05,
      "loss": 0.253,
      "step": 3958
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.17762471735477448,
      "learning_rate": 8.321639218542137e-05,
      "loss": 0.3054,
      "step": 3959
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.12345778942108154,
      "learning_rate": 8.317241446339958e-05,
      "loss": 0.2215,
      "step": 3960
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15269526839256287,
      "learning_rate": 8.312844009048845e-05,
      "loss": 0.3397,
      "step": 3961
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.10326570272445679,
      "learning_rate": 8.308446907544008e-05,
      "loss": 0.1593,
      "step": 3962
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15318560600280762,
      "learning_rate": 8.304050142700572e-05,
      "loss": 0.2718,
      "step": 3963
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1770147979259491,
      "learning_rate": 8.299653715393607e-05,
      "loss": 0.3212,
      "step": 3964
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.14443138241767883,
      "learning_rate": 8.295257626498109e-05,
      "loss": 0.2718,
      "step": 3965
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1350792497396469,
      "learning_rate": 8.290861876889016e-05,
      "loss": 0.2733,
      "step": 3966
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.17690913379192352,
      "learning_rate": 8.286466467441185e-05,
      "loss": 0.3499,
      "step": 3967
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.16796201467514038,
      "learning_rate": 8.282071399029418e-05,
      "loss": 0.2628,
      "step": 3968
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.13921333849430084,
      "learning_rate": 8.277676672528437e-05,
      "loss": 0.2913,
      "step": 3969
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.16679692268371582,
      "learning_rate": 8.273282288812913e-05,
      "loss": 0.3465,
      "step": 3970
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1738874763250351,
      "learning_rate": 8.268888248757429e-05,
      "loss": 0.285,
      "step": 3971
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1587752401828766,
      "learning_rate": 8.264494553236512e-05,
      "loss": 0.3167,
      "step": 3972
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15827235579490662,
      "learning_rate": 8.260101203124616e-05,
      "loss": 0.3976,
      "step": 3973
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.14634402096271515,
      "learning_rate": 8.255708199296133e-05,
      "loss": 0.2681,
      "step": 3974
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.17958182096481323,
      "learning_rate": 8.251315542625374e-05,
      "loss": 0.3219,
      "step": 3975
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.14725396037101746,
      "learning_rate": 8.246923233986593e-05,
      "loss": 0.2892,
      "step": 3976
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.17230641841888428,
      "learning_rate": 8.242531274253963e-05,
      "loss": 0.3357,
      "step": 3977
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.18610331416130066,
      "learning_rate": 8.238139664301602e-05,
      "loss": 0.3499,
      "step": 3978
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.14432932436466217,
      "learning_rate": 8.233748405003543e-05,
      "loss": 0.2965,
      "step": 3979
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15979579091072083,
      "learning_rate": 8.229357497233762e-05,
      "loss": 0.2266,
      "step": 3980
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.12965784966945648,
      "learning_rate": 8.224966941866158e-05,
      "loss": 0.258,
      "step": 3981
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15794889628887177,
      "learning_rate": 8.220576739774556e-05,
      "loss": 0.3219,
      "step": 3982
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15549127757549286,
      "learning_rate": 8.216186891832724e-05,
      "loss": 0.2534,
      "step": 3983
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1703457087278366,
      "learning_rate": 8.211797398914349e-05,
      "loss": 0.2572,
      "step": 3984
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.11283839493989944,
      "learning_rate": 8.207408261893048e-05,
      "loss": 0.215,
      "step": 3985
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1129942387342453,
      "learning_rate": 8.203019481642368e-05,
      "loss": 0.2181,
      "step": 3986
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1539694219827652,
      "learning_rate": 8.198631059035791e-05,
      "loss": 0.3133,
      "step": 3987
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15964695811271667,
      "learning_rate": 8.19424299494672e-05,
      "loss": 0.2606,
      "step": 3988
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.15374110639095306,
      "learning_rate": 8.189855290248491e-05,
      "loss": 0.3288,
      "step": 3989
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.16490906476974487,
      "learning_rate": 8.185467945814362e-05,
      "loss": 0.3019,
      "step": 3990
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.177124485373497,
      "learning_rate": 8.181080962517534e-05,
      "loss": 0.2989,
      "step": 3991
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1314302235841751,
      "learning_rate": 8.176694341231117e-05,
      "loss": 0.255,
      "step": 3992
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.12601996958255768,
      "learning_rate": 8.172308082828167e-05,
      "loss": 0.2473,
      "step": 3993
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.1308409720659256,
      "learning_rate": 8.167922188181647e-05,
      "loss": 0.245,
      "step": 3994
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.15605966746807098,
      "learning_rate": 8.163536658164473e-05,
      "loss": 0.2893,
      "step": 3995
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.1622372418642044,
      "learning_rate": 8.159151493649469e-05,
      "loss": 0.3342,
      "step": 3996
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.13669002056121826,
      "learning_rate": 8.154766695509392e-05,
      "loss": 0.2725,
      "step": 3997
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.13625355064868927,
      "learning_rate": 8.150382264616925e-05,
      "loss": 0.2632,
      "step": 3998
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.17211633920669556,
      "learning_rate": 8.145998201844687e-05,
      "loss": 0.2774,
      "step": 3999
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.20715390145778656,
      "learning_rate": 8.141614508065209e-05,
      "loss": 0.382,
      "step": 4000
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.13767492771148682,
      "learning_rate": 8.13723118415096e-05,
      "loss": 0.2911,
      "step": 4001
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.19688397645950317,
      "learning_rate": 8.132848230974324e-05,
      "loss": 0.3132,
      "step": 4002
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.16183501482009888,
      "learning_rate": 8.12846564940763e-05,
      "loss": 0.3232,
      "step": 4003
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.153907909989357,
      "learning_rate": 8.124083440323111e-05,
      "loss": 0.2923,
      "step": 4004
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.167322039604187,
      "learning_rate": 8.119701604592944e-05,
      "loss": 0.4107,
      "step": 4005
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.1541239470243454,
      "learning_rate": 8.115320143089216e-05,
      "loss": 0.2465,
      "step": 4006
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.14493663609027863,
      "learning_rate": 8.110939056683956e-05,
      "loss": 0.285,
      "step": 4007
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.13516178727149963,
      "learning_rate": 8.106558346249103e-05,
      "loss": 0.2618,
      "step": 4008
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.15317560732364655,
      "learning_rate": 8.102178012656534e-05,
      "loss": 0.2935,
      "step": 4009
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.16768769919872284,
      "learning_rate": 8.097798056778041e-05,
      "loss": 0.283,
      "step": 4010
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.1433350145816803,
      "learning_rate": 8.093418479485345e-05,
      "loss": 0.2672,
      "step": 4011
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.21871082484722137,
      "learning_rate": 8.089039281650093e-05,
      "loss": 0.3968,
      "step": 4012
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.16380396485328674,
      "learning_rate": 8.084660464143848e-05,
      "loss": 0.3713,
      "step": 4013
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.1344839483499527,
      "learning_rate": 8.080282027838118e-05,
      "loss": 0.2909,
      "step": 4014
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.14229583740234375,
      "learning_rate": 8.07590397360431e-05,
      "loss": 0.2881,
      "step": 4015
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.15139858424663544,
      "learning_rate": 8.071526302313772e-05,
      "loss": 0.325,
      "step": 4016
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.12086792290210724,
      "learning_rate": 8.067149014837764e-05,
      "loss": 0.252,
      "step": 4017
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.13581722974777222,
      "learning_rate": 8.062772112047486e-05,
      "loss": 0.2714,
      "step": 4018
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.15714037418365479,
      "learning_rate": 8.058395594814043e-05,
      "loss": 0.2842,
      "step": 4019
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.14386270940303802,
      "learning_rate": 8.054019464008474e-05,
      "loss": 0.2924,
      "step": 4020
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.15558014810085297,
      "learning_rate": 8.049643720501736e-05,
      "loss": 0.3104,
      "step": 4021
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.15776436030864716,
      "learning_rate": 8.045268365164717e-05,
      "loss": 0.329,
      "step": 4022
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.1960344761610031,
      "learning_rate": 8.040893398868216e-05,
      "loss": 0.395,
      "step": 4023
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.13200756907463074,
      "learning_rate": 8.036518822482968e-05,
      "loss": 0.2386,
      "step": 4024
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.17373137176036835,
      "learning_rate": 8.032144636879615e-05,
      "loss": 0.2453,
      "step": 4025
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.1262345165014267,
      "learning_rate": 8.027770842928736e-05,
      "loss": 0.2625,
      "step": 4026
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.14770597219467163,
      "learning_rate": 8.023397441500821e-05,
      "loss": 0.3623,
      "step": 4027
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.14924833178520203,
      "learning_rate": 8.019024433466292e-05,
      "loss": 0.2989,
      "step": 4028
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.18202553689479828,
      "learning_rate": 8.014651819695478e-05,
      "loss": 0.3391,
      "step": 4029
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.13350091874599457,
      "learning_rate": 8.010279601058649e-05,
      "loss": 0.2833,
      "step": 4030
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.17133426666259766,
      "learning_rate": 8.005907778425979e-05,
      "loss": 0.2968,
      "step": 4031
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.10102900117635727,
      "learning_rate": 8.001536352667572e-05,
      "loss": 0.2756,
      "step": 4032
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.15472525358200073,
      "learning_rate": 7.997165324653449e-05,
      "loss": 0.3026,
      "step": 4033
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.16008499264717102,
      "learning_rate": 7.992794695253559e-05,
      "loss": 0.3525,
      "step": 4034
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.18316908180713654,
      "learning_rate": 7.988424465337762e-05,
      "loss": 0.3153,
      "step": 4035
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.1471581608057022,
      "learning_rate": 7.984054635775847e-05,
      "loss": 0.2829,
      "step": 4036
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.11316068470478058,
      "learning_rate": 7.979685207437513e-05,
      "loss": 0.2877,
      "step": 4037
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.15714699029922485,
      "learning_rate": 7.975316181192395e-05,
      "loss": 0.3025,
      "step": 4038
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.13037894666194916,
      "learning_rate": 7.97094755791003e-05,
      "loss": 0.2562,
      "step": 4039
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.17585718631744385,
      "learning_rate": 7.966579338459891e-05,
      "loss": 0.3837,
      "step": 4040
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.16349001228809357,
      "learning_rate": 7.962211523711357e-05,
      "loss": 0.3041,
      "step": 4041
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.16141343116760254,
      "learning_rate": 7.957844114533732e-05,
      "loss": 0.3061,
      "step": 4042
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.16803564131259918,
      "learning_rate": 7.953477111796245e-05,
      "loss": 0.3395,
      "step": 4043
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.13876165449619293,
      "learning_rate": 7.949110516368034e-05,
      "loss": 0.3023,
      "step": 4044
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.1637594997882843,
      "learning_rate": 7.944744329118165e-05,
      "loss": 0.374,
      "step": 4045
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.13651162385940552,
      "learning_rate": 7.940378550915612e-05,
      "loss": 0.3097,
      "step": 4046
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.12692299485206604,
      "learning_rate": 7.936013182629283e-05,
      "loss": 0.2301,
      "step": 4047
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.13550451397895813,
      "learning_rate": 7.931648225127988e-05,
      "loss": 0.2777,
      "step": 4048
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.1267554759979248,
      "learning_rate": 7.927283679280468e-05,
      "loss": 0.2525,
      "step": 4049
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.14837197959423065,
      "learning_rate": 7.922919545955372e-05,
      "loss": 0.263,
      "step": 4050
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.13741575181484222,
      "learning_rate": 7.918555826021276e-05,
      "loss": 0.2491,
      "step": 4051
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.15876178443431854,
      "learning_rate": 7.914192520346669e-05,
      "loss": 0.2937,
      "step": 4052
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.14858752489089966,
      "learning_rate": 7.909829629799956e-05,
      "loss": 0.2422,
      "step": 4053
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.18878987431526184,
      "learning_rate": 7.905467155249461e-05,
      "loss": 0.3827,
      "step": 4054
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.15936115384101868,
      "learning_rate": 7.90110509756343e-05,
      "loss": 0.29,
      "step": 4055
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.13186268508434296,
      "learning_rate": 7.896743457610015e-05,
      "loss": 0.3006,
      "step": 4056
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.16926680505275726,
      "learning_rate": 7.892382236257298e-05,
      "loss": 0.3387,
      "step": 4057
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.1288817673921585,
      "learning_rate": 7.888021434373265e-05,
      "loss": 0.294,
      "step": 4058
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.15417245030403137,
      "learning_rate": 7.883661052825832e-05,
      "loss": 0.2646,
      "step": 4059
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.15896821022033691,
      "learning_rate": 7.879301092482818e-05,
      "loss": 0.2958,
      "step": 4060
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.17267198860645294,
      "learning_rate": 7.87494155421197e-05,
      "loss": 0.3227,
      "step": 4061
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.23443010449409485,
      "learning_rate": 7.870582438880935e-05,
      "loss": 0.3186,
      "step": 4062
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.12220601737499237,
      "learning_rate": 7.866223747357298e-05,
      "loss": 0.2308,
      "step": 4063
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.14947004616260529,
      "learning_rate": 7.86186548050854e-05,
      "loss": 0.3115,
      "step": 4064
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.17307934165000916,
      "learning_rate": 7.857507639202069e-05,
      "loss": 0.2956,
      "step": 4065
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.13002189993858337,
      "learning_rate": 7.853150224305201e-05,
      "loss": 0.2478,
      "step": 4066
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14373624324798584,
      "learning_rate": 7.848793236685174e-05,
      "loss": 0.2661,
      "step": 4067
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1208266019821167,
      "learning_rate": 7.844436677209137e-05,
      "loss": 0.2196,
      "step": 4068
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.15844379365444183,
      "learning_rate": 7.840080546744155e-05,
      "loss": 0.3185,
      "step": 4069
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14688648283481598,
      "learning_rate": 7.835724846157199e-05,
      "loss": 0.2798,
      "step": 4070
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.16407598555088043,
      "learning_rate": 7.831369576315176e-05,
      "loss": 0.3169,
      "step": 4071
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.132633775472641,
      "learning_rate": 7.827014738084885e-05,
      "loss": 0.2463,
      "step": 4072
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1367608904838562,
      "learning_rate": 7.82266033233305e-05,
      "loss": 0.2535,
      "step": 4073
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.12158942967653275,
      "learning_rate": 7.818306359926307e-05,
      "loss": 0.2301,
      "step": 4074
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14495502412319183,
      "learning_rate": 7.8139528217312e-05,
      "loss": 0.2363,
      "step": 4075
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1307189166545868,
      "learning_rate": 7.809599718614203e-05,
      "loss": 0.2284,
      "step": 4076
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.12142480164766312,
      "learning_rate": 7.805247051441682e-05,
      "loss": 0.1689,
      "step": 4077
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1435975879430771,
      "learning_rate": 7.800894821079935e-05,
      "loss": 0.282,
      "step": 4078
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14403794705867767,
      "learning_rate": 7.796543028395155e-05,
      "loss": 0.2629,
      "step": 4079
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.15334364771842957,
      "learning_rate": 7.792191674253468e-05,
      "loss": 0.2417,
      "step": 4080
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.16585880517959595,
      "learning_rate": 7.787840759520897e-05,
      "loss": 0.238,
      "step": 4081
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.16879530251026154,
      "learning_rate": 7.783490285063387e-05,
      "loss": 0.3128,
      "step": 4082
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.13945838809013367,
      "learning_rate": 7.779140251746782e-05,
      "loss": 0.2701,
      "step": 4083
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1370973140001297,
      "learning_rate": 7.774790660436858e-05,
      "loss": 0.2679,
      "step": 4084
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.09842707961797714,
      "learning_rate": 7.770441511999285e-05,
      "loss": 0.2074,
      "step": 4085
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.16549870371818542,
      "learning_rate": 7.766092807299658e-05,
      "loss": 0.2787,
      "step": 4086
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.16834215819835663,
      "learning_rate": 7.761744547203473e-05,
      "loss": 0.2675,
      "step": 4087
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.15445314347743988,
      "learning_rate": 7.75739673257615e-05,
      "loss": 0.2257,
      "step": 4088
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1693095862865448,
      "learning_rate": 7.753049364283005e-05,
      "loss": 0.35,
      "step": 4089
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14927054941654205,
      "learning_rate": 7.748702443189277e-05,
      "loss": 0.269,
      "step": 4090
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.13299311697483063,
      "learning_rate": 7.744355970160109e-05,
      "loss": 0.2644,
      "step": 4091
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.11817921698093414,
      "learning_rate": 7.740009946060564e-05,
      "loss": 0.2188,
      "step": 4092
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.13758769631385803,
      "learning_rate": 7.735664371755605e-05,
      "loss": 0.2503,
      "step": 4093
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14538075029850006,
      "learning_rate": 7.731319248110111e-05,
      "loss": 0.2838,
      "step": 4094
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14547157287597656,
      "learning_rate": 7.726974575988868e-05,
      "loss": 0.2768,
      "step": 4095
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.17325744032859802,
      "learning_rate": 7.722630356256581e-05,
      "loss": 0.2734,
      "step": 4096
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.2056874930858612,
      "learning_rate": 7.71828658977785e-05,
      "loss": 0.414,
      "step": 4097
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.17534711956977844,
      "learning_rate": 7.7139432774172e-05,
      "loss": 0.3012,
      "step": 4098
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.200116366147995,
      "learning_rate": 7.709600420039053e-05,
      "loss": 0.3271,
      "step": 4099
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.14115296304225922,
      "learning_rate": 7.705258018507757e-05,
      "loss": 0.3084,
      "step": 4100
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1654243767261505,
      "learning_rate": 7.700916073687544e-05,
      "loss": 0.2828,
      "step": 4101
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.16916461288928986,
      "learning_rate": 7.696574586442581e-05,
      "loss": 0.3485,
      "step": 4102
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.12249670922756195,
      "learning_rate": 7.69223355763693e-05,
      "loss": 0.2058,
      "step": 4103
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.23092120885849,
      "learning_rate": 7.68789298813456e-05,
      "loss": 0.3001,
      "step": 4104
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1689637452363968,
      "learning_rate": 7.683552878799357e-05,
      "loss": 0.2667,
      "step": 4105
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.11872020363807678,
      "learning_rate": 7.679213230495107e-05,
      "loss": 0.2239,
      "step": 4106
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.11424458771944046,
      "learning_rate": 7.674874044085516e-05,
      "loss": 0.2107,
      "step": 4107
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.14795921742916107,
      "learning_rate": 7.670535320434185e-05,
      "loss": 0.2796,
      "step": 4108
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.14758257567882538,
      "learning_rate": 7.666197060404632e-05,
      "loss": 0.2894,
      "step": 4109
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.11242177337408066,
      "learning_rate": 7.661859264860274e-05,
      "loss": 0.2401,
      "step": 4110
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1503223031759262,
      "learning_rate": 7.657521934664449e-05,
      "loss": 0.2032,
      "step": 4111
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1255597174167633,
      "learning_rate": 7.653185070680386e-05,
      "loss": 0.2495,
      "step": 4112
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.108152374625206,
      "learning_rate": 7.648848673771237e-05,
      "loss": 0.2891,
      "step": 4113
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.11318574845790863,
      "learning_rate": 7.644512744800045e-05,
      "loss": 0.2806,
      "step": 4114
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.14785048365592957,
      "learning_rate": 7.640177284629778e-05,
      "loss": 0.2903,
      "step": 4115
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.17499345541000366,
      "learning_rate": 7.635842294123293e-05,
      "loss": 0.3047,
      "step": 4116
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.15967004001140594,
      "learning_rate": 7.631507774143368e-05,
      "loss": 0.2744,
      "step": 4117
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.13933764398097992,
      "learning_rate": 7.627173725552673e-05,
      "loss": 0.2273,
      "step": 4118
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1546328365802765,
      "learning_rate": 7.622840149213803e-05,
      "loss": 0.2248,
      "step": 4119
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.13984067738056183,
      "learning_rate": 7.618507045989239e-05,
      "loss": 0.2663,
      "step": 4120
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.17148831486701965,
      "learning_rate": 7.614174416741381e-05,
      "loss": 0.332,
      "step": 4121
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1366771161556244,
      "learning_rate": 7.609842262332525e-05,
      "loss": 0.2296,
      "step": 4122
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1441086381673813,
      "learning_rate": 7.605510583624889e-05,
      "loss": 0.2403,
      "step": 4123
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.12313520163297653,
      "learning_rate": 7.601179381480577e-05,
      "loss": 0.2184,
      "step": 4124
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.16442155838012695,
      "learning_rate": 7.596848656761612e-05,
      "loss": 0.2563,
      "step": 4125
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.16280598938465118,
      "learning_rate": 7.592518410329908e-05,
      "loss": 0.252,
      "step": 4126
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.15158282220363617,
      "learning_rate": 7.588188643047304e-05,
      "loss": 0.2941,
      "step": 4127
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.140925332903862,
      "learning_rate": 7.583859355775522e-05,
      "loss": 0.3007,
      "step": 4128
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.12908655405044556,
      "learning_rate": 7.579530549376206e-05,
      "loss": 0.2206,
      "step": 4129
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.08949121832847595,
      "learning_rate": 7.57520222471089e-05,
      "loss": 0.1533,
      "step": 4130
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.16098634898662567,
      "learning_rate": 7.570874382641026e-05,
      "loss": 0.2654,
      "step": 4131
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1723407655954361,
      "learning_rate": 7.566547024027956e-05,
      "loss": 0.379,
      "step": 4132
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.18478679656982422,
      "learning_rate": 7.56222014973294e-05,
      "loss": 0.309,
      "step": 4133
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1397874653339386,
      "learning_rate": 7.557893760617129e-05,
      "loss": 0.2147,
      "step": 4134
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.18246901035308838,
      "learning_rate": 7.553567857541582e-05,
      "loss": 0.4054,
      "step": 4135
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.14068099856376648,
      "learning_rate": 7.549242441367266e-05,
      "loss": 0.313,
      "step": 4136
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1843249350786209,
      "learning_rate": 7.544917512955044e-05,
      "loss": 0.3432,
      "step": 4137
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.18436568975448608,
      "learning_rate": 7.54059307316569e-05,
      "loss": 0.3129,
      "step": 4138
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.3235307037830353,
      "learning_rate": 7.536269122859865e-05,
      "loss": 0.2251,
      "step": 4139
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.14532312750816345,
      "learning_rate": 7.531945662898155e-05,
      "loss": 0.2448,
      "step": 4140
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1252395212650299,
      "learning_rate": 7.52762269414103e-05,
      "loss": 0.2274,
      "step": 4141
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.15720956027507782,
      "learning_rate": 7.523300217448873e-05,
      "loss": 0.2668,
      "step": 4142
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1426539272069931,
      "learning_rate": 7.51897823368196e-05,
      "loss": 0.2541,
      "step": 4143
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1282825618982315,
      "learning_rate": 7.514656743700479e-05,
      "loss": 0.2441,
      "step": 4144
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.14934365451335907,
      "learning_rate": 7.510335748364512e-05,
      "loss": 0.2511,
      "step": 4145
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13914617896080017,
      "learning_rate": 7.506015248534048e-05,
      "loss": 0.3328,
      "step": 4146
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.17937342822551727,
      "learning_rate": 7.501695245068968e-05,
      "loss": 0.2472,
      "step": 4147
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.16137129068374634,
      "learning_rate": 7.497375738829069e-05,
      "loss": 0.3518,
      "step": 4148
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1507863849401474,
      "learning_rate": 7.493056730674035e-05,
      "loss": 0.3216,
      "step": 4149
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.12572145462036133,
      "learning_rate": 7.48873822146346e-05,
      "loss": 0.2325,
      "step": 4150
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.14234422147274017,
      "learning_rate": 7.484420212056832e-05,
      "loss": 0.3318,
      "step": 4151
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.15387004613876343,
      "learning_rate": 7.48010270331355e-05,
      "loss": 0.2323,
      "step": 4152
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.16161060333251953,
      "learning_rate": 7.475785696092897e-05,
      "loss": 0.2609,
      "step": 4153
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.15862378478050232,
      "learning_rate": 7.471469191254073e-05,
      "loss": 0.3339,
      "step": 4154
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.21959826350212097,
      "learning_rate": 7.467153189656164e-05,
      "loss": 0.4602,
      "step": 4155
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.15521691739559174,
      "learning_rate": 7.462837692158169e-05,
      "loss": 0.2812,
      "step": 4156
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.15623469650745392,
      "learning_rate": 7.458522699618977e-05,
      "loss": 0.3177,
      "step": 4157
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13715718686580658,
      "learning_rate": 7.45420821289738e-05,
      "loss": 0.2596,
      "step": 4158
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1448991596698761,
      "learning_rate": 7.449894232852064e-05,
      "loss": 0.3442,
      "step": 4159
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.09082207828760147,
      "learning_rate": 7.445580760341626e-05,
      "loss": 0.1776,
      "step": 4160
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.09341327846050262,
      "learning_rate": 7.441267796224551e-05,
      "loss": 0.2365,
      "step": 4161
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13493937253952026,
      "learning_rate": 7.436955341359232e-05,
      "loss": 0.2607,
      "step": 4162
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.10569830238819122,
      "learning_rate": 7.43264339660395e-05,
      "loss": 0.1824,
      "step": 4163
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13074631989002228,
      "learning_rate": 7.428331962816888e-05,
      "loss": 0.2444,
      "step": 4164
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.15392005443572998,
      "learning_rate": 7.424021040856135e-05,
      "loss": 0.2658,
      "step": 4165
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1878470927476883,
      "learning_rate": 7.419710631579671e-05,
      "loss": 0.3862,
      "step": 4166
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13632185757160187,
      "learning_rate": 7.415400735845374e-05,
      "loss": 0.2824,
      "step": 4167
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13796155154705048,
      "learning_rate": 7.411091354511017e-05,
      "loss": 0.2931,
      "step": 4168
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13494151830673218,
      "learning_rate": 7.406782488434285e-05,
      "loss": 0.2355,
      "step": 4169
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.1790134608745575,
      "learning_rate": 7.402474138472742e-05,
      "loss": 0.2598,
      "step": 4170
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.17280831933021545,
      "learning_rate": 7.398166305483862e-05,
      "loss": 0.3099,
      "step": 4171
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.13932591676712036,
      "learning_rate": 7.393858990325005e-05,
      "loss": 0.2914,
      "step": 4172
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.10544037073850632,
      "learning_rate": 7.389552193853444e-05,
      "loss": 0.2148,
      "step": 4173
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.14159181714057922,
      "learning_rate": 7.38524591692633e-05,
      "loss": 0.2689,
      "step": 4174
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.18192297220230103,
      "learning_rate": 7.380940160400729e-05,
      "loss": 0.3274,
      "step": 4175
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.128031387925148,
      "learning_rate": 7.376634925133586e-05,
      "loss": 0.2454,
      "step": 4176
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.16273747384548187,
      "learning_rate": 7.372330211981755e-05,
      "loss": 0.2632,
      "step": 4177
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.1524604856967926,
      "learning_rate": 7.368026021801982e-05,
      "loss": 0.289,
      "step": 4178
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.1056726723909378,
      "learning_rate": 7.363722355450907e-05,
      "loss": 0.2057,
      "step": 4179
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15862925350666046,
      "learning_rate": 7.359419213785063e-05,
      "loss": 0.3169,
      "step": 4180
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15511123836040497,
      "learning_rate": 7.355116597660896e-05,
      "loss": 0.3049,
      "step": 4181
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.1628769487142563,
      "learning_rate": 7.350814507934718e-05,
      "loss": 0.2947,
      "step": 4182
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.14800161123275757,
      "learning_rate": 7.346512945462767e-05,
      "loss": 0.2764,
      "step": 4183
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.11803498864173889,
      "learning_rate": 7.342211911101149e-05,
      "loss": 0.2052,
      "step": 4184
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.14036524295806885,
      "learning_rate": 7.337911405705889e-05,
      "loss": 0.2884,
      "step": 4185
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.12031558901071548,
      "learning_rate": 7.333611430132885e-05,
      "loss": 0.2523,
      "step": 4186
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.09062840044498444,
      "learning_rate": 7.329311985237948e-05,
      "loss": 0.1635,
      "step": 4187
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15673646330833435,
      "learning_rate": 7.32501307187677e-05,
      "loss": 0.3139,
      "step": 4188
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.13969644904136658,
      "learning_rate": 7.320714690904944e-05,
      "loss": 0.2396,
      "step": 4189
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.17863881587982178,
      "learning_rate": 7.316416843177953e-05,
      "loss": 0.4078,
      "step": 4190
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15516792237758636,
      "learning_rate": 7.312119529551182e-05,
      "loss": 0.2939,
      "step": 4191
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.16791054606437683,
      "learning_rate": 7.3078227508799e-05,
      "loss": 0.3276,
      "step": 4192
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15927638113498688,
      "learning_rate": 7.303526508019276e-05,
      "loss": 0.3147,
      "step": 4193
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15494905412197113,
      "learning_rate": 7.299230801824368e-05,
      "loss": 0.2772,
      "step": 4194
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.13226231932640076,
      "learning_rate": 7.294935633150123e-05,
      "loss": 0.223,
      "step": 4195
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.14489546418190002,
      "learning_rate": 7.2906410028514e-05,
      "loss": 0.2791,
      "step": 4196
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15814056992530823,
      "learning_rate": 7.286346911782927e-05,
      "loss": 0.3119,
      "step": 4197
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.10925871878862381,
      "learning_rate": 7.282053360799341e-05,
      "loss": 0.1907,
      "step": 4198
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.12875764071941376,
      "learning_rate": 7.277760350755163e-05,
      "loss": 0.2694,
      "step": 4199
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.16456542909145355,
      "learning_rate": 7.273467882504813e-05,
      "loss": 0.2777,
      "step": 4200
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.125311478972435,
      "learning_rate": 7.269175956902596e-05,
      "loss": 0.2377,
      "step": 4201
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.17996565997600555,
      "learning_rate": 7.264884574802718e-05,
      "loss": 0.3408,
      "step": 4202
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.1412418931722641,
      "learning_rate": 7.260593737059263e-05,
      "loss": 0.2635,
      "step": 4203
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.16264641284942627,
      "learning_rate": 7.256303444526225e-05,
      "loss": 0.3377,
      "step": 4204
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.12242384999990463,
      "learning_rate": 7.252013698057471e-05,
      "loss": 0.2445,
      "step": 4205
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.15753065049648285,
      "learning_rate": 7.247724498506773e-05,
      "loss": 0.2696,
      "step": 4206
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.17703703045845032,
      "learning_rate": 7.243435846727787e-05,
      "loss": 0.3417,
      "step": 4207
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1402127891778946,
      "learning_rate": 7.239147743574065e-05,
      "loss": 0.3022,
      "step": 4208
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.12979218363761902,
      "learning_rate": 7.23486018989904e-05,
      "loss": 0.2169,
      "step": 4209
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.13175632059574127,
      "learning_rate": 7.230573186556051e-05,
      "loss": 0.273,
      "step": 4210
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1610470563173294,
      "learning_rate": 7.226286734398311e-05,
      "loss": 0.3066,
      "step": 4211
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.13059112429618835,
      "learning_rate": 7.222000834278939e-05,
      "loss": 0.2411,
      "step": 4212
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.14468857645988464,
      "learning_rate": 7.217715487050932e-05,
      "loss": 0.2782,
      "step": 4213
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.15344250202178955,
      "learning_rate": 7.213430693567181e-05,
      "loss": 0.2973,
      "step": 4214
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.17546674609184265,
      "learning_rate": 7.209146454680465e-05,
      "loss": 0.2992,
      "step": 4215
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1556113362312317,
      "learning_rate": 7.204862771243464e-05,
      "loss": 0.2492,
      "step": 4216
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.12653741240501404,
      "learning_rate": 7.200579644108727e-05,
      "loss": 0.2302,
      "step": 4217
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.14098913967609406,
      "learning_rate": 7.196297074128713e-05,
      "loss": 0.2989,
      "step": 4218
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.16935628652572632,
      "learning_rate": 7.19201506215575e-05,
      "loss": 0.3772,
      "step": 4219
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1498890221118927,
      "learning_rate": 7.187733609042078e-05,
      "loss": 0.2639,
      "step": 4220
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.17833416163921356,
      "learning_rate": 7.183452715639805e-05,
      "loss": 0.3211,
      "step": 4221
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1954263299703598,
      "learning_rate": 7.179172382800939e-05,
      "loss": 0.3627,
      "step": 4222
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.15099921822547913,
      "learning_rate": 7.174892611377369e-05,
      "loss": 0.3087,
      "step": 4223
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.16558191180229187,
      "learning_rate": 7.170613402220883e-05,
      "loss": 0.2523,
      "step": 4224
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.14567384123802185,
      "learning_rate": 7.166334756183148e-05,
      "loss": 0.2873,
      "step": 4225
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.15050671994686127,
      "learning_rate": 7.16205667411572e-05,
      "loss": 0.2691,
      "step": 4226
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1523110270500183,
      "learning_rate": 7.157779156870048e-05,
      "loss": 0.2421,
      "step": 4227
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.14870744943618774,
      "learning_rate": 7.15350220529746e-05,
      "loss": 0.2549,
      "step": 4228
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.15582513809204102,
      "learning_rate": 7.149225820249182e-05,
      "loss": 0.3035,
      "step": 4229
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.13096021115779877,
      "learning_rate": 7.144950002576316e-05,
      "loss": 0.2517,
      "step": 4230
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1378224939107895,
      "learning_rate": 7.140674753129862e-05,
      "loss": 0.2188,
      "step": 4231
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1322021484375,
      "learning_rate": 7.136400072760696e-05,
      "loss": 0.2708,
      "step": 4232
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.18126001954078674,
      "learning_rate": 7.132125962319594e-05,
      "loss": 0.3021,
      "step": 4233
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.4008914530277252,
      "learning_rate": 7.127852422657203e-05,
      "loss": 0.3446,
      "step": 4234
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.16576607525348663,
      "learning_rate": 7.123579454624072e-05,
      "loss": 0.2973,
      "step": 4235
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.12494324147701263,
      "learning_rate": 7.11930705907062e-05,
      "loss": 0.2436,
      "step": 4236
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.2227199673652649,
      "learning_rate": 7.115035236847168e-05,
      "loss": 0.3288,
      "step": 4237
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.12751030921936035,
      "learning_rate": 7.11076398880391e-05,
      "loss": 0.2462,
      "step": 4238
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1332090198993683,
      "learning_rate": 7.106493315790938e-05,
      "loss": 0.2881,
      "step": 4239
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1246018260717392,
      "learning_rate": 7.102223218658215e-05,
      "loss": 0.2543,
      "step": 4240
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.1609916090965271,
      "learning_rate": 7.097953698255604e-05,
      "loss": 0.3193,
      "step": 4241
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.16055209934711456,
      "learning_rate": 7.093684755432842e-05,
      "loss": 0.2934,
      "step": 4242
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.14582286775112152,
      "learning_rate": 7.08941639103956e-05,
      "loss": 0.3462,
      "step": 4243
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.14814572036266327,
      "learning_rate": 7.08514860592526e-05,
      "loss": 0.233,
      "step": 4244
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.17086684703826904,
      "learning_rate": 7.08088140093935e-05,
      "loss": 0.2296,
      "step": 4245
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16564211249351501,
      "learning_rate": 7.076614776931104e-05,
      "loss": 0.3154,
      "step": 4246
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.11817870289087296,
      "learning_rate": 7.072348734749688e-05,
      "loss": 0.2166,
      "step": 4247
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16537372767925262,
      "learning_rate": 7.068083275244146e-05,
      "loss": 0.3101,
      "step": 4248
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.13504943251609802,
      "learning_rate": 7.063818399263422e-05,
      "loss": 0.2573,
      "step": 4249
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.17262868583202362,
      "learning_rate": 7.059554107656326e-05,
      "loss": 0.3803,
      "step": 4250
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16704916954040527,
      "learning_rate": 7.055290401271561e-05,
      "loss": 0.2486,
      "step": 4251
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16021357476711273,
      "learning_rate": 7.051027280957707e-05,
      "loss": 0.2796,
      "step": 4252
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.1608348786830902,
      "learning_rate": 7.04676474756324e-05,
      "loss": 0.2951,
      "step": 4253
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.12713520228862762,
      "learning_rate": 7.042502801936502e-05,
      "loss": 0.3034,
      "step": 4254
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.17538610100746155,
      "learning_rate": 7.038241444925733e-05,
      "loss": 0.3012,
      "step": 4255
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.19207759201526642,
      "learning_rate": 7.033980677379048e-05,
      "loss": 0.2877,
      "step": 4256
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0956462025642395,
      "learning_rate": 7.029720500144442e-05,
      "loss": 0.1769,
      "step": 4257
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.12127815186977386,
      "learning_rate": 7.025460914069804e-05,
      "loss": 0.2247,
      "step": 4258
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.13484317064285278,
      "learning_rate": 7.021201920002895e-05,
      "loss": 0.2759,
      "step": 4259
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.12289436161518097,
      "learning_rate": 7.016943518791362e-05,
      "loss": 0.2905,
      "step": 4260
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.18825925886631012,
      "learning_rate": 7.012685711282729e-05,
      "loss": 0.2884,
      "step": 4261
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.1636820137500763,
      "learning_rate": 7.008428498324413e-05,
      "loss": 0.2515,
      "step": 4262
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.1394530087709427,
      "learning_rate": 7.004171880763702e-05,
      "loss": 0.288,
      "step": 4263
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.18259091675281525,
      "learning_rate": 6.999915859447772e-05,
      "loss": 0.2607,
      "step": 4264
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.15208908915519714,
      "learning_rate": 6.995660435223673e-05,
      "loss": 0.2624,
      "step": 4265
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.23146894574165344,
      "learning_rate": 6.991405608938351e-05,
      "loss": 0.2975,
      "step": 4266
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16720083355903625,
      "learning_rate": 6.987151381438608e-05,
      "loss": 0.2835,
      "step": 4267
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16629864275455475,
      "learning_rate": 6.982897753571155e-05,
      "loss": 0.2631,
      "step": 4268
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16012147068977356,
      "learning_rate": 6.978644726182561e-05,
      "loss": 0.2692,
      "step": 4269
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.11336049437522888,
      "learning_rate": 6.974392300119295e-05,
      "loss": 0.2475,
      "step": 4270
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.1442052274942398,
      "learning_rate": 6.970140476227684e-05,
      "loss": 0.3099,
      "step": 4271
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.16049402952194214,
      "learning_rate": 6.965889255353958e-05,
      "loss": 0.313,
      "step": 4272
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.11845849454402924,
      "learning_rate": 6.96163863834421e-05,
      "loss": 0.2338,
      "step": 4273
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.14247789978981018,
      "learning_rate": 6.957388626044426e-05,
      "loss": 0.3045,
      "step": 4274
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.13475054502487183,
      "learning_rate": 6.953139219300454e-05,
      "loss": 0.2402,
      "step": 4275
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.14954353868961334,
      "learning_rate": 6.948890418958041e-05,
      "loss": 0.2363,
      "step": 4276
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.1447264850139618,
      "learning_rate": 6.9446422258628e-05,
      "loss": 0.2436,
      "step": 4277
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.1571080982685089,
      "learning_rate": 6.940394640860235e-05,
      "loss": 0.321,
      "step": 4278
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.12743709981441498,
      "learning_rate": 6.936147664795711e-05,
      "loss": 0.239,
      "step": 4279
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.15445946156978607,
      "learning_rate": 6.931901298514492e-05,
      "loss": 0.3064,
      "step": 4280
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.18088552355766296,
      "learning_rate": 6.927655542861705e-05,
      "loss": 0.2903,
      "step": 4281
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.13596248626708984,
      "learning_rate": 6.923410398682364e-05,
      "loss": 0.2679,
      "step": 4282
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.16619442403316498,
      "learning_rate": 6.919165866821358e-05,
      "loss": 0.3147,
      "step": 4283
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.17958460748195648,
      "learning_rate": 6.914921948123459e-05,
      "loss": 0.3543,
      "step": 4284
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.12701690196990967,
      "learning_rate": 6.910678643433306e-05,
      "loss": 0.2187,
      "step": 4285
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.12466517090797424,
      "learning_rate": 6.90643595359543e-05,
      "loss": 0.2666,
      "step": 4286
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.18634812533855438,
      "learning_rate": 6.90219387945423e-05,
      "loss": 0.2863,
      "step": 4287
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.14247089624404907,
      "learning_rate": 6.89795242185398e-05,
      "loss": 0.2517,
      "step": 4288
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.13955475389957428,
      "learning_rate": 6.893711581638843e-05,
      "loss": 0.2154,
      "step": 4289
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.13678574562072754,
      "learning_rate": 6.889471359652849e-05,
      "loss": 0.3079,
      "step": 4290
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.12313789129257202,
      "learning_rate": 6.885231756739912e-05,
      "loss": 0.2796,
      "step": 4291
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.1489781141281128,
      "learning_rate": 6.88099277374381e-05,
      "loss": 0.2919,
      "step": 4292
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.14637155830860138,
      "learning_rate": 6.876754411508217e-05,
      "loss": 0.2674,
      "step": 4293
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.15691350400447845,
      "learning_rate": 6.872516670876668e-05,
      "loss": 0.2923,
      "step": 4294
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.1322014182806015,
      "learning_rate": 6.868279552692582e-05,
      "loss": 0.2307,
      "step": 4295
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.12504945695400238,
      "learning_rate": 6.864043057799247e-05,
      "loss": 0.2227,
      "step": 4296
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.186867818236351,
      "learning_rate": 6.859807187039838e-05,
      "loss": 0.3833,
      "step": 4297
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.15860624611377716,
      "learning_rate": 6.855571941257394e-05,
      "loss": 0.3358,
      "step": 4298
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.14332325756549835,
      "learning_rate": 6.851337321294839e-05,
      "loss": 0.3131,
      "step": 4299
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.12972913682460785,
      "learning_rate": 6.847103327994961e-05,
      "loss": 0.2529,
      "step": 4300
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.15575042366981506,
      "learning_rate": 6.842869962200442e-05,
      "loss": 0.2724,
      "step": 4301
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.14111143350601196,
      "learning_rate": 6.838637224753817e-05,
      "loss": 0.2455,
      "step": 4302
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.1375219225883484,
      "learning_rate": 6.834405116497515e-05,
      "loss": 0.2578,
      "step": 4303
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.13796041905879974,
      "learning_rate": 6.830173638273823e-05,
      "loss": 0.2641,
      "step": 4304
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.14768549799919128,
      "learning_rate": 6.82594279092492e-05,
      "loss": 0.2507,
      "step": 4305
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.17200161516666412,
      "learning_rate": 6.821712575292844e-05,
      "loss": 0.3935,
      "step": 4306
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.15398402512073517,
      "learning_rate": 6.817482992219518e-05,
      "loss": 0.3641,
      "step": 4307
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.14808326959609985,
      "learning_rate": 6.81325404254673e-05,
      "loss": 0.271,
      "step": 4308
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.1380385160446167,
      "learning_rate": 6.809025727116153e-05,
      "loss": 0.2654,
      "step": 4309
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.1224575862288475,
      "learning_rate": 6.804798046769323e-05,
      "loss": 0.2199,
      "step": 4310
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.15315020084381104,
      "learning_rate": 6.800571002347657e-05,
      "loss": 0.2457,
      "step": 4311
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.15114301443099976,
      "learning_rate": 6.796344594692437e-05,
      "loss": 0.3146,
      "step": 4312
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.17736709117889404,
      "learning_rate": 6.792118824644833e-05,
      "loss": 0.2616,
      "step": 4313
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.1927073448896408,
      "learning_rate": 6.787893693045873e-05,
      "loss": 0.3729,
      "step": 4314
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.16217945516109467,
      "learning_rate": 6.783669200736464e-05,
      "loss": 0.354,
      "step": 4315
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.14593762159347534,
      "learning_rate": 6.779445348557389e-05,
      "loss": 0.2566,
      "step": 4316
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.150557741522789,
      "learning_rate": 6.775222137349295e-05,
      "loss": 0.3205,
      "step": 4317
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1604607254266739,
      "learning_rate": 6.770999567952713e-05,
      "loss": 0.2902,
      "step": 4318
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.15906879305839539,
      "learning_rate": 6.766777641208035e-05,
      "loss": 0.2631,
      "step": 4319
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.21081353724002838,
      "learning_rate": 6.762556357955534e-05,
      "loss": 0.4249,
      "step": 4320
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.21671295166015625,
      "learning_rate": 6.758335719035345e-05,
      "loss": 0.33,
      "step": 4321
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.19237662851810455,
      "learning_rate": 6.754115725287488e-05,
      "loss": 0.2774,
      "step": 4322
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1798907071352005,
      "learning_rate": 6.749896377551843e-05,
      "loss": 0.3772,
      "step": 4323
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.15442195534706116,
      "learning_rate": 6.745677676668168e-05,
      "loss": 0.2635,
      "step": 4324
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.13887737691402435,
      "learning_rate": 6.741459623476085e-05,
      "loss": 0.2919,
      "step": 4325
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.18748900294303894,
      "learning_rate": 6.737242218815102e-05,
      "loss": 0.3675,
      "step": 4326
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1213478371500969,
      "learning_rate": 6.733025463524578e-05,
      "loss": 0.2214,
      "step": 4327
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.13114573061466217,
      "learning_rate": 6.728809358443761e-05,
      "loss": 0.2547,
      "step": 4328
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.18787330389022827,
      "learning_rate": 6.724593904411753e-05,
      "loss": 0.3447,
      "step": 4329
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.11833122372627258,
      "learning_rate": 6.720379102267544e-05,
      "loss": 0.2661,
      "step": 4330
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.149226576089859,
      "learning_rate": 6.716164952849977e-05,
      "loss": 0.2697,
      "step": 4331
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1634136289358139,
      "learning_rate": 6.71195145699778e-05,
      "loss": 0.2912,
      "step": 4332
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.18539318442344666,
      "learning_rate": 6.707738615549537e-05,
      "loss": 0.3353,
      "step": 4333
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.15104758739471436,
      "learning_rate": 6.703526429343716e-05,
      "loss": 0.2362,
      "step": 4334
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1660139262676239,
      "learning_rate": 6.699314899218643e-05,
      "loss": 0.3077,
      "step": 4335
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1377354860305786,
      "learning_rate": 6.695104026012519e-05,
      "loss": 0.2981,
      "step": 4336
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.16242443025112152,
      "learning_rate": 6.690893810563413e-05,
      "loss": 0.2832,
      "step": 4337
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1608339250087738,
      "learning_rate": 6.686684253709266e-05,
      "loss": 0.2924,
      "step": 4338
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.16437052190303802,
      "learning_rate": 6.68247535628788e-05,
      "loss": 0.2661,
      "step": 4339
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.17269276082515717,
      "learning_rate": 6.678267119136935e-05,
      "loss": 0.3807,
      "step": 4340
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.16556216776371002,
      "learning_rate": 6.674059543093972e-05,
      "loss": 0.2913,
      "step": 4341
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.19256417453289032,
      "learning_rate": 6.669852628996409e-05,
      "loss": 0.3257,
      "step": 4342
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1393216848373413,
      "learning_rate": 6.665646377681523e-05,
      "loss": 0.2296,
      "step": 4343
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1980155110359192,
      "learning_rate": 6.661440789986468e-05,
      "loss": 0.3124,
      "step": 4344
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1406874805688858,
      "learning_rate": 6.657235866748251e-05,
      "loss": 0.2805,
      "step": 4345
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1515820026397705,
      "learning_rate": 6.65303160880377e-05,
      "loss": 0.2818,
      "step": 4346
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.12768761813640594,
      "learning_rate": 6.648828016989772e-05,
      "loss": 0.2791,
      "step": 4347
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.195980504155159,
      "learning_rate": 6.644625092142872e-05,
      "loss": 0.3222,
      "step": 4348
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.1786508560180664,
      "learning_rate": 6.640422835099565e-05,
      "loss": 0.2863,
      "step": 4349
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.20076695084571838,
      "learning_rate": 6.636221246696196e-05,
      "loss": 0.3054,
      "step": 4350
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.19351717829704285,
      "learning_rate": 6.632020327769003e-05,
      "loss": 0.2806,
      "step": 4351
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.17016851902008057,
      "learning_rate": 6.627820079154052e-05,
      "loss": 0.3559,
      "step": 4352
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.21185798943042755,
      "learning_rate": 6.623620501687317e-05,
      "loss": 0.3012,
      "step": 4353
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.14674817025661469,
      "learning_rate": 6.619421596204604e-05,
      "loss": 0.2412,
      "step": 4354
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.13533896207809448,
      "learning_rate": 6.615223363541613e-05,
      "loss": 0.2579,
      "step": 4355
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.1106814593076706,
      "learning_rate": 6.611025804533888e-05,
      "loss": 0.2321,
      "step": 4356
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.17647813260555267,
      "learning_rate": 6.606828920016854e-05,
      "loss": 0.3441,
      "step": 4357
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.18003803491592407,
      "learning_rate": 6.602632710825794e-05,
      "loss": 0.3502,
      "step": 4358
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.12687215209007263,
      "learning_rate": 6.598437177795858e-05,
      "loss": 0.21,
      "step": 4359
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15165147185325623,
      "learning_rate": 6.59424232176206e-05,
      "loss": 0.3099,
      "step": 4360
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.13549192249774933,
      "learning_rate": 6.590048143559288e-05,
      "loss": 0.3713,
      "step": 4361
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15842150151729584,
      "learning_rate": 6.585854644022282e-05,
      "loss": 0.2712,
      "step": 4362
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.14081664383411407,
      "learning_rate": 6.581661823985657e-05,
      "loss": 0.2709,
      "step": 4363
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.20421934127807617,
      "learning_rate": 6.577469684283885e-05,
      "loss": 0.3782,
      "step": 4364
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.14108479022979736,
      "learning_rate": 6.573278225751313e-05,
      "loss": 0.2771,
      "step": 4365
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.12164505571126938,
      "learning_rate": 6.569087449222142e-05,
      "loss": 0.2321,
      "step": 4366
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.14369207620620728,
      "learning_rate": 6.564897355530444e-05,
      "loss": 0.2665,
      "step": 4367
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.13184122741222382,
      "learning_rate": 6.560707945510146e-05,
      "loss": 0.3356,
      "step": 4368
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15289519727230072,
      "learning_rate": 6.556519219995055e-05,
      "loss": 0.3352,
      "step": 4369
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.1420127898454666,
      "learning_rate": 6.552331179818825e-05,
      "loss": 0.309,
      "step": 4370
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.14458444714546204,
      "learning_rate": 6.548143825814986e-05,
      "loss": 0.2476,
      "step": 4371
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.13214027881622314,
      "learning_rate": 6.543957158816918e-05,
      "loss": 0.2674,
      "step": 4372
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.16127832233905792,
      "learning_rate": 6.539771179657883e-05,
      "loss": 0.3383,
      "step": 4373
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.16265113651752472,
      "learning_rate": 6.535585889170987e-05,
      "loss": 0.3335,
      "step": 4374
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.17272306978702545,
      "learning_rate": 6.531401288189216e-05,
      "loss": 0.2927,
      "step": 4375
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.12691918015480042,
      "learning_rate": 6.5272173775454e-05,
      "loss": 0.2658,
      "step": 4376
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15827719867229462,
      "learning_rate": 6.523034158072253e-05,
      "loss": 0.3286,
      "step": 4377
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15332159399986267,
      "learning_rate": 6.518851630602331e-05,
      "loss": 0.3202,
      "step": 4378
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.10923060029745102,
      "learning_rate": 6.514669795968067e-05,
      "loss": 0.2206,
      "step": 4379
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.17141753435134888,
      "learning_rate": 6.51048865500175e-05,
      "loss": 0.3489,
      "step": 4380
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15803316235542297,
      "learning_rate": 6.506308208535527e-05,
      "loss": 0.3037,
      "step": 4381
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.1674094796180725,
      "learning_rate": 6.50212845740142e-05,
      "loss": 0.2816,
      "step": 4382
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15715652704238892,
      "learning_rate": 6.497949402431298e-05,
      "loss": 0.3511,
      "step": 4383
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.17634667456150055,
      "learning_rate": 6.4937710444569e-05,
      "loss": 0.2946,
      "step": 4384
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.1539815217256546,
      "learning_rate": 6.48959338430982e-05,
      "loss": 0.2796,
      "step": 4385
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.15512396395206451,
      "learning_rate": 6.485416422821521e-05,
      "loss": 0.3021,
      "step": 4386
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.14723902940750122,
      "learning_rate": 6.481240160823323e-05,
      "loss": 0.3542,
      "step": 4387
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.15450111031532288,
      "learning_rate": 6.477064599146407e-05,
      "loss": 0.3171,
      "step": 4388
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.16320809721946716,
      "learning_rate": 6.472889738621808e-05,
      "loss": 0.2876,
      "step": 4389
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.1303100436925888,
      "learning_rate": 6.468715580080437e-05,
      "loss": 0.249,
      "step": 4390
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.13031527400016785,
      "learning_rate": 6.464542124353048e-05,
      "loss": 0.2246,
      "step": 4391
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.15746986865997314,
      "learning_rate": 6.46036937227027e-05,
      "loss": 0.3067,
      "step": 4392
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.128363698720932,
      "learning_rate": 6.456197324662577e-05,
      "loss": 0.211,
      "step": 4393
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.14546994864940643,
      "learning_rate": 6.45202598236032e-05,
      "loss": 0.3735,
      "step": 4394
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.16985704004764557,
      "learning_rate": 6.447855346193694e-05,
      "loss": 0.2988,
      "step": 4395
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.1532365083694458,
      "learning_rate": 6.443685416992764e-05,
      "loss": 0.2636,
      "step": 4396
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.16502922773361206,
      "learning_rate": 6.439516195587445e-05,
      "loss": 0.2948,
      "step": 4397
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.13338129222393036,
      "learning_rate": 6.435347682807522e-05,
      "loss": 0.2595,
      "step": 4398
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.13557910919189453,
      "learning_rate": 6.431179879482632e-05,
      "loss": 0.25,
      "step": 4399
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.11578599363565445,
      "learning_rate": 6.42701278644227e-05,
      "loss": 0.2344,
      "step": 4400
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.14468947052955627,
      "learning_rate": 6.422846404515793e-05,
      "loss": 0.1994,
      "step": 4401
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.1539686918258667,
      "learning_rate": 6.418680734532416e-05,
      "loss": 0.2806,
      "step": 4402
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.13505840301513672,
      "learning_rate": 6.41451577732121e-05,
      "loss": 0.2615,
      "step": 4403
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.1606103777885437,
      "learning_rate": 6.41035153371111e-05,
      "loss": 0.2853,
      "step": 4404
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.13739220798015594,
      "learning_rate": 6.406188004530896e-05,
      "loss": 0.2824,
      "step": 4405
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.14443939924240112,
      "learning_rate": 6.402025190609226e-05,
      "loss": 0.3131,
      "step": 4406
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.14923591911792755,
      "learning_rate": 6.397863092774594e-05,
      "loss": 0.2682,
      "step": 4407
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.17411868274211884,
      "learning_rate": 6.39370171185537e-05,
      "loss": 0.3287,
      "step": 4408
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.14526169002056122,
      "learning_rate": 6.389541048679767e-05,
      "loss": 0.2903,
      "step": 4409
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.16619257628917694,
      "learning_rate": 6.385381104075859e-05,
      "loss": 0.2791,
      "step": 4410
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.11337759345769882,
      "learning_rate": 6.381221878871588e-05,
      "loss": 0.1726,
      "step": 4411
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.1426847130060196,
      "learning_rate": 6.377063373894735e-05,
      "loss": 0.2459,
      "step": 4412
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.17571666836738586,
      "learning_rate": 6.372905589972955e-05,
      "loss": 0.3215,
      "step": 4413
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.13922172784805298,
      "learning_rate": 6.368748527933741e-05,
      "loss": 0.2876,
      "step": 4414
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.13967330753803253,
      "learning_rate": 6.364592188604463e-05,
      "loss": 0.302,
      "step": 4415
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.16330565512180328,
      "learning_rate": 6.360436572812328e-05,
      "loss": 0.3145,
      "step": 4416
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.17123273015022278,
      "learning_rate": 6.356281681384414e-05,
      "loss": 0.297,
      "step": 4417
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.18316084146499634,
      "learning_rate": 6.352127515147641e-05,
      "loss": 0.3638,
      "step": 4418
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.17977198958396912,
      "learning_rate": 6.3479740749288e-05,
      "loss": 0.2978,
      "step": 4419
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.166530042886734,
      "learning_rate": 6.343821361554525e-05,
      "loss": 0.2732,
      "step": 4420
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.18452394008636475,
      "learning_rate": 6.339669375851314e-05,
      "loss": 0.2905,
      "step": 4421
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.166828915476799,
      "learning_rate": 6.335518118645507e-05,
      "loss": 0.267,
      "step": 4422
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1665612906217575,
      "learning_rate": 6.33136759076332e-05,
      "loss": 0.3156,
      "step": 4423
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.14145953953266144,
      "learning_rate": 6.327217793030802e-05,
      "loss": 0.2828,
      "step": 4424
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.17500251531600952,
      "learning_rate": 6.323068726273875e-05,
      "loss": 0.2625,
      "step": 4425
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.17958009243011475,
      "learning_rate": 6.318920391318296e-05,
      "loss": 0.3241,
      "step": 4426
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.15221638977527618,
      "learning_rate": 6.314772788989701e-05,
      "loss": 0.2845,
      "step": 4427
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.16465917229652405,
      "learning_rate": 6.310625920113556e-05,
      "loss": 0.2982,
      "step": 4428
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.14357693493366241,
      "learning_rate": 6.306479785515199e-05,
      "loss": 0.2578,
      "step": 4429
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.13758377730846405,
      "learning_rate": 6.302334386019806e-05,
      "loss": 0.2865,
      "step": 4430
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.2147952765226364,
      "learning_rate": 6.298189722452425e-05,
      "loss": 0.3627,
      "step": 4431
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.13658760488033295,
      "learning_rate": 6.294045795637942e-05,
      "loss": 0.2721,
      "step": 4432
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.16527198255062103,
      "learning_rate": 6.289902606401105e-05,
      "loss": 0.2626,
      "step": 4433
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.15497539937496185,
      "learning_rate": 6.285760155566506e-05,
      "loss": 0.2751,
      "step": 4434
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1510801613330841,
      "learning_rate": 6.281618443958606e-05,
      "loss": 0.2885,
      "step": 4435
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1840425580739975,
      "learning_rate": 6.277477472401703e-05,
      "loss": 0.3159,
      "step": 4436
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.15955621004104614,
      "learning_rate": 6.273337241719956e-05,
      "loss": 0.2939,
      "step": 4437
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.16726383566856384,
      "learning_rate": 6.26919775273737e-05,
      "loss": 0.2641,
      "step": 4438
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.16122236847877502,
      "learning_rate": 6.265059006277816e-05,
      "loss": 0.3117,
      "step": 4439
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.12792882323265076,
      "learning_rate": 6.260921003165005e-05,
      "loss": 0.2088,
      "step": 4440
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.19622842967510223,
      "learning_rate": 6.256783744222494e-05,
      "loss": 0.3543,
      "step": 4441
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.14795899391174316,
      "learning_rate": 6.252647230273714e-05,
      "loss": 0.2771,
      "step": 4442
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.13444258272647858,
      "learning_rate": 6.248511462141926e-05,
      "loss": 0.2296,
      "step": 4443
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1612212359905243,
      "learning_rate": 6.244376440650257e-05,
      "loss": 0.3259,
      "step": 4444
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.17541147768497467,
      "learning_rate": 6.240242166621673e-05,
      "loss": 0.3524,
      "step": 4445
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.15439270436763763,
      "learning_rate": 6.236108640879006e-05,
      "loss": 0.2729,
      "step": 4446
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.16032211482524872,
      "learning_rate": 6.231975864244926e-05,
      "loss": 0.2867,
      "step": 4447
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.19377374649047852,
      "learning_rate": 6.227843837541963e-05,
      "loss": 0.3632,
      "step": 4448
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.13275638222694397,
      "learning_rate": 6.223712561592486e-05,
      "loss": 0.2362,
      "step": 4449
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.11571761965751648,
      "learning_rate": 6.21958203721873e-05,
      "loss": 0.2434,
      "step": 4450
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.16886776685714722,
      "learning_rate": 6.21545226524277e-05,
      "loss": 0.3333,
      "step": 4451
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1806327998638153,
      "learning_rate": 6.211323246486536e-05,
      "loss": 0.343,
      "step": 4452
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1612834930419922,
      "learning_rate": 6.2071949817718e-05,
      "loss": 0.2917,
      "step": 4453
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.14152541756629944,
      "learning_rate": 6.203067471920199e-05,
      "loss": 0.282,
      "step": 4454
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.18213701248168945,
      "learning_rate": 6.198940717753203e-05,
      "loss": 0.2769,
      "step": 4455
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.20921964943408966,
      "learning_rate": 6.194814720092144e-05,
      "loss": 0.3644,
      "step": 4456
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.16125279664993286,
      "learning_rate": 6.190689479758194e-05,
      "loss": 0.3327,
      "step": 4457
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1467079371213913,
      "learning_rate": 6.186564997572386e-05,
      "loss": 0.274,
      "step": 4458
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.11625004559755325,
      "learning_rate": 6.18244127435559e-05,
      "loss": 0.2223,
      "step": 4459
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.13379834592342377,
      "learning_rate": 6.178318310928533e-05,
      "loss": 0.2434,
      "step": 4460
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.17479945719242096,
      "learning_rate": 6.174196108111781e-05,
      "loss": 0.3215,
      "step": 4461
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.14876537024974823,
      "learning_rate": 6.170074666725767e-05,
      "loss": 0.2898,
      "step": 4462
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.16582880914211273,
      "learning_rate": 6.165953987590753e-05,
      "loss": 0.314,
      "step": 4463
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1596505045890808,
      "learning_rate": 6.16183407152686e-05,
      "loss": 0.2605,
      "step": 4464
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1631554514169693,
      "learning_rate": 6.15771491935405e-05,
      "loss": 0.349,
      "step": 4465
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1472858488559723,
      "learning_rate": 6.153596531892145e-05,
      "loss": 0.2944,
      "step": 4466
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1803467720746994,
      "learning_rate": 6.149478909960802e-05,
      "loss": 0.3643,
      "step": 4467
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.15029048919677734,
      "learning_rate": 6.145362054379535e-05,
      "loss": 0.2873,
      "step": 4468
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.17058609426021576,
      "learning_rate": 6.141245965967697e-05,
      "loss": 0.2267,
      "step": 4469
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.14020374417304993,
      "learning_rate": 6.13713064554449e-05,
      "loss": 0.2741,
      "step": 4470
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.15106123685836792,
      "learning_rate": 6.133016093928974e-05,
      "loss": 0.2393,
      "step": 4471
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.12892970442771912,
      "learning_rate": 6.128902311940041e-05,
      "loss": 0.2343,
      "step": 4472
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.12347020953893661,
      "learning_rate": 6.124789300396443e-05,
      "loss": 0.2408,
      "step": 4473
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.13191881775856018,
      "learning_rate": 6.120677060116763e-05,
      "loss": 0.2212,
      "step": 4474
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.15978455543518066,
      "learning_rate": 6.11656559191945e-05,
      "loss": 0.295,
      "step": 4475
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.19470232725143433,
      "learning_rate": 6.11245489662278e-05,
      "loss": 0.347,
      "step": 4476
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.17270459234714508,
      "learning_rate": 6.108344975044893e-05,
      "loss": 0.2931,
      "step": 4477
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.18023957312107086,
      "learning_rate": 6.104235828003756e-05,
      "loss": 0.3378,
      "step": 4478
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1858557015657425,
      "learning_rate": 6.100127456317202e-05,
      "loss": 0.3109,
      "step": 4479
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.16586080193519592,
      "learning_rate": 6.096019860802895e-05,
      "loss": 0.2741,
      "step": 4480
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.12705320119857788,
      "learning_rate": 6.09191304227835e-05,
      "loss": 0.2453,
      "step": 4481
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.14718811213970184,
      "learning_rate": 6.087807001560923e-05,
      "loss": 0.261,
      "step": 4482
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1479690968990326,
      "learning_rate": 6.083701739467829e-05,
      "loss": 0.344,
      "step": 4483
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.17330750823020935,
      "learning_rate": 6.079597256816107e-05,
      "loss": 0.2978,
      "step": 4484
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.15644711256027222,
      "learning_rate": 6.0754935544226576e-05,
      "loss": 0.3317,
      "step": 4485
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.194166362285614,
      "learning_rate": 6.071390633104216e-05,
      "loss": 0.227,
      "step": 4486
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.15643160045146942,
      "learning_rate": 6.067288493677373e-05,
      "loss": 0.2956,
      "step": 4487
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.16698762774467468,
      "learning_rate": 6.063187136958551e-05,
      "loss": 0.3152,
      "step": 4488
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.16107100248336792,
      "learning_rate": 6.059086563764027e-05,
      "loss": 0.2899,
      "step": 4489
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.15949532389640808,
      "learning_rate": 6.054986774909911e-05,
      "loss": 0.2568,
      "step": 4490
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.09035889804363251,
      "learning_rate": 6.0508877712121723e-05,
      "loss": 0.1645,
      "step": 4491
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.1685899794101715,
      "learning_rate": 6.0467895534866094e-05,
      "loss": 0.3049,
      "step": 4492
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.16684192419052124,
      "learning_rate": 6.042692122548873e-05,
      "loss": 0.3297,
      "step": 4493
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.21499989926815033,
      "learning_rate": 6.03859547921445e-05,
      "loss": 0.3651,
      "step": 4494
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1373288780450821,
      "learning_rate": 6.034499624298682e-05,
      "loss": 0.3077,
      "step": 4495
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.15383456647396088,
      "learning_rate": 6.03040455861674e-05,
      "loss": 0.3222,
      "step": 4496
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.13763917982578278,
      "learning_rate": 6.0263102829836506e-05,
      "loss": 0.2512,
      "step": 4497
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.133260577917099,
      "learning_rate": 6.022216798214269e-05,
      "loss": 0.2621,
      "step": 4498
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.17320410907268524,
      "learning_rate": 6.0181241051233104e-05,
      "loss": 0.2684,
      "step": 4499
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1571587175130844,
      "learning_rate": 6.014032204525319e-05,
      "loss": 0.3201,
      "step": 4500
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1887950748205185,
      "learning_rate": 6.009941097234683e-05,
      "loss": 0.2931,
      "step": 4501
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1492529958486557,
      "learning_rate": 6.005850784065639e-05,
      "loss": 0.2773,
      "step": 4502
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.15414653718471527,
      "learning_rate": 6.0017612658322564e-05,
      "loss": 0.3299,
      "step": 4503
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.13892528414726257,
      "learning_rate": 5.9976725433484594e-05,
      "loss": 0.2336,
      "step": 4504
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.16354383528232574,
      "learning_rate": 5.993584617428e-05,
      "loss": 0.3063,
      "step": 4505
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.174382746219635,
      "learning_rate": 5.9894974888844815e-05,
      "loss": 0.3044,
      "step": 4506
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1442834734916687,
      "learning_rate": 5.98541115853134e-05,
      "loss": 0.2524,
      "step": 4507
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.11745288223028183,
      "learning_rate": 5.981325627181864e-05,
      "loss": 0.2492,
      "step": 4508
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.15458136796951294,
      "learning_rate": 5.977240895649171e-05,
      "loss": 0.2925,
      "step": 4509
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1470915675163269,
      "learning_rate": 5.973156964746229e-05,
      "loss": 0.245,
      "step": 4510
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.15745815634727478,
      "learning_rate": 5.9690738352858366e-05,
      "loss": 0.2291,
      "step": 4511
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.11178316920995712,
      "learning_rate": 5.9649915080806476e-05,
      "loss": 0.2111,
      "step": 4512
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1801094263792038,
      "learning_rate": 5.960909983943139e-05,
      "loss": 0.3385,
      "step": 4513
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.15948110818862915,
      "learning_rate": 5.9568292636856414e-05,
      "loss": 0.2469,
      "step": 4514
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1459042727947235,
      "learning_rate": 5.9527493481203154e-05,
      "loss": 0.2644,
      "step": 4515
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.15758700668811798,
      "learning_rate": 5.948670238059173e-05,
      "loss": 0.2891,
      "step": 4516
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.15981325507164001,
      "learning_rate": 5.944591934314053e-05,
      "loss": 0.3558,
      "step": 4517
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1408974826335907,
      "learning_rate": 5.940514437696645e-05,
      "loss": 0.2543,
      "step": 4518
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1329917460680008,
      "learning_rate": 5.936437749018466e-05,
      "loss": 0.2569,
      "step": 4519
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.11970777809619904,
      "learning_rate": 5.9323618690908876e-05,
      "loss": 0.1817,
      "step": 4520
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.12506146728992462,
      "learning_rate": 5.928286798725106e-05,
      "loss": 0.2408,
      "step": 4521
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.14185865223407745,
      "learning_rate": 5.924212538732166e-05,
      "loss": 0.2438,
      "step": 4522
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.16375315189361572,
      "learning_rate": 5.9201390899229406e-05,
      "loss": 0.3034,
      "step": 4523
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.20063355565071106,
      "learning_rate": 5.9160664531081566e-05,
      "loss": 0.367,
      "step": 4524
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.13179899752140045,
      "learning_rate": 5.911994629098365e-05,
      "loss": 0.2199,
      "step": 4525
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.13926205039024353,
      "learning_rate": 5.9079236187039654e-05,
      "loss": 0.2541,
      "step": 4526
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.14536191523075104,
      "learning_rate": 5.903853422735183e-05,
      "loss": 0.2702,
      "step": 4527
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.15047499537467957,
      "learning_rate": 5.899784042002099e-05,
      "loss": 0.2452,
      "step": 4528
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1730250120162964,
      "learning_rate": 5.895715477314612e-05,
      "loss": 0.3681,
      "step": 4529
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.18682615458965302,
      "learning_rate": 5.8916477294824753e-05,
      "loss": 0.3169,
      "step": 4530
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16455301642417908,
      "learning_rate": 5.887580799315271e-05,
      "loss": 0.3148,
      "step": 4531
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.18583868443965912,
      "learning_rate": 5.883514687622417e-05,
      "loss": 0.3295,
      "step": 4532
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.13422970473766327,
      "learning_rate": 5.879449395213175e-05,
      "loss": 0.2701,
      "step": 4533
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.13266104459762573,
      "learning_rate": 5.875384922896634e-05,
      "loss": 0.2263,
      "step": 4534
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.14783400297164917,
      "learning_rate": 5.871321271481734e-05,
      "loss": 0.2513,
      "step": 4535
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1995120346546173,
      "learning_rate": 5.867258441777237e-05,
      "loss": 0.3055,
      "step": 4536
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16407549381256104,
      "learning_rate": 5.863196434591752e-05,
      "loss": 0.291,
      "step": 4537
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.14236222207546234,
      "learning_rate": 5.859135250733714e-05,
      "loss": 0.2186,
      "step": 4538
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16999571025371552,
      "learning_rate": 5.855074891011409e-05,
      "loss": 0.3096,
      "step": 4539
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.15565010905265808,
      "learning_rate": 5.851015356232944e-05,
      "loss": 0.2974,
      "step": 4540
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16782012581825256,
      "learning_rate": 5.846956647206272e-05,
      "loss": 0.3593,
      "step": 4541
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.19858446717262268,
      "learning_rate": 5.8428987647391697e-05,
      "loss": 0.3683,
      "step": 4542
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.14057143032550812,
      "learning_rate": 5.838841709639268e-05,
      "loss": 0.2442,
      "step": 4543
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.17085865139961243,
      "learning_rate": 5.834785482714013e-05,
      "loss": 0.3499,
      "step": 4544
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1963375061750412,
      "learning_rate": 5.830730084770703e-05,
      "loss": 0.2647,
      "step": 4545
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16026891767978668,
      "learning_rate": 5.826675516616462e-05,
      "loss": 0.2319,
      "step": 4546
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.14422187209129333,
      "learning_rate": 5.8226217790582485e-05,
      "loss": 0.241,
      "step": 4547
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.19347572326660156,
      "learning_rate": 5.818568872902853e-05,
      "loss": 0.2822,
      "step": 4548
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.14856168627738953,
      "learning_rate": 5.814516798956915e-05,
      "loss": 0.253,
      "step": 4549
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.18244343996047974,
      "learning_rate": 5.810465558026891e-05,
      "loss": 0.2141,
      "step": 4550
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1567554473876953,
      "learning_rate": 5.806415150919086e-05,
      "loss": 0.2727,
      "step": 4551
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16308103501796722,
      "learning_rate": 5.802365578439624e-05,
      "loss": 0.3079,
      "step": 4552
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1531815081834793,
      "learning_rate": 5.79831684139448e-05,
      "loss": 0.2863,
      "step": 4553
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.17976154386997223,
      "learning_rate": 5.7942689405894516e-05,
      "loss": 0.2929,
      "step": 4554
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.15273918211460114,
      "learning_rate": 5.790221876830171e-05,
      "loss": 0.32,
      "step": 4555
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.2314218282699585,
      "learning_rate": 5.786175650922099e-05,
      "loss": 0.3511,
      "step": 4556
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.14307913184165955,
      "learning_rate": 5.7821302636705465e-05,
      "loss": 0.2764,
      "step": 4557
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1556551456451416,
      "learning_rate": 5.778085715880639e-05,
      "loss": 0.2584,
      "step": 4558
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.27458515763282776,
      "learning_rate": 5.77404200835735e-05,
      "loss": 0.3738,
      "step": 4559
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.17614305019378662,
      "learning_rate": 5.769999141905471e-05,
      "loss": 0.281,
      "step": 4560
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.12826527655124664,
      "learning_rate": 5.76595711732964e-05,
      "loss": 0.2629,
      "step": 4561
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.19433841109275818,
      "learning_rate": 5.761915935434319e-05,
      "loss": 0.3125,
      "step": 4562
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1326959729194641,
      "learning_rate": 5.757875597023803e-05,
      "loss": 0.2543,
      "step": 4563
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.16734260320663452,
      "learning_rate": 5.7538361029022206e-05,
      "loss": 0.3361,
      "step": 4564
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.14948487281799316,
      "learning_rate": 5.749797453873529e-05,
      "loss": 0.2973,
      "step": 4565
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.1416664570569992,
      "learning_rate": 5.7457596507415276e-05,
      "loss": 0.2446,
      "step": 4566
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.12886936962604523,
      "learning_rate": 5.7417226943098336e-05,
      "loss": 0.2241,
      "step": 4567
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.17349299788475037,
      "learning_rate": 5.73768658538191e-05,
      "loss": 0.3484,
      "step": 4568
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.21132665872573853,
      "learning_rate": 5.7336513247610334e-05,
      "loss": 0.3697,
      "step": 4569
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.1497400999069214,
      "learning_rate": 5.7296169132503306e-05,
      "loss": 0.3323,
      "step": 4570
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.161498561501503,
      "learning_rate": 5.725583351652749e-05,
      "loss": 0.2792,
      "step": 4571
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.17588269710540771,
      "learning_rate": 5.721550640771066e-05,
      "loss": 0.3163,
      "step": 4572
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.12112846225500107,
      "learning_rate": 5.717518781407889e-05,
      "loss": 0.1804,
      "step": 4573
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.12996290624141693,
      "learning_rate": 5.7134877743656646e-05,
      "loss": 0.2328,
      "step": 4574
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.1120748296380043,
      "learning_rate": 5.7094576204466586e-05,
      "loss": 0.1728,
      "step": 4575
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.15931552648544312,
      "learning_rate": 5.7054283204529814e-05,
      "loss": 0.2834,
      "step": 4576
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.170438751578331,
      "learning_rate": 5.7013998751865524e-05,
      "loss": 0.2762,
      "step": 4577
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.12910640239715576,
      "learning_rate": 5.697372285449145e-05,
      "loss": 0.244,
      "step": 4578
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.12186441570520401,
      "learning_rate": 5.693345552042346e-05,
      "loss": 0.2321,
      "step": 4579
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.15135015547275543,
      "learning_rate": 5.689319675767574e-05,
      "loss": 0.2487,
      "step": 4580
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.1409933716058731,
      "learning_rate": 5.685294657426076e-05,
      "loss": 0.2278,
      "step": 4581
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.16312351822853088,
      "learning_rate": 5.681270497818939e-05,
      "loss": 0.3073,
      "step": 4582
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.27208560705184937,
      "learning_rate": 5.677247197747064e-05,
      "loss": 0.2686,
      "step": 4583
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.15655550360679626,
      "learning_rate": 5.6732247580111975e-05,
      "loss": 0.2822,
      "step": 4584
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.1789020150899887,
      "learning_rate": 5.669203179411897e-05,
      "loss": 0.3364,
      "step": 4585
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.17624349892139435,
      "learning_rate": 5.665182462749565e-05,
      "loss": 0.3309,
      "step": 4586
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.17597293853759766,
      "learning_rate": 5.6611626088244194e-05,
      "loss": 0.2389,
      "step": 4587
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.18035109341144562,
      "learning_rate": 5.6571436184365134e-05,
      "loss": 0.3151,
      "step": 4588
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.16794459521770477,
      "learning_rate": 5.6531254923857236e-05,
      "loss": 0.315,
      "step": 4589
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.12430354207754135,
      "learning_rate": 5.6491082314717635e-05,
      "loss": 0.2076,
      "step": 4590
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.17222195863723755,
      "learning_rate": 5.645091836494162e-05,
      "loss": 0.3063,
      "step": 4591
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.13835036754608154,
      "learning_rate": 5.641076308252289e-05,
      "loss": 0.2577,
      "step": 4592
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.17564664781093597,
      "learning_rate": 5.637061647545332e-05,
      "loss": 0.3546,
      "step": 4593
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.14812181890010834,
      "learning_rate": 5.6330478551723054e-05,
      "loss": 0.267,
      "step": 4594
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.18196547031402588,
      "learning_rate": 5.629034931932061e-05,
      "loss": 0.2945,
      "step": 4595
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.1648121476173401,
      "learning_rate": 5.625022878623268e-05,
      "loss": 0.2787,
      "step": 4596
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.2256452441215515,
      "learning_rate": 5.621011696044426e-05,
      "loss": 0.3361,
      "step": 4597
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.14894551038742065,
      "learning_rate": 5.617001384993854e-05,
      "loss": 0.2664,
      "step": 4598
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1817561537027359,
      "learning_rate": 5.6129919462697166e-05,
      "loss": 0.2798,
      "step": 4599
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.11654547601938248,
      "learning_rate": 5.6089833806699796e-05,
      "loss": 0.2083,
      "step": 4600
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.19058430194854736,
      "learning_rate": 5.60497568899246e-05,
      "loss": 0.3773,
      "step": 4601
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.17600367963314056,
      "learning_rate": 5.6009688720347786e-05,
      "loss": 0.3135,
      "step": 4602
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.182351216673851,
      "learning_rate": 5.5969629305944004e-05,
      "loss": 0.3475,
      "step": 4603
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.16242900490760803,
      "learning_rate": 5.592957865468604e-05,
      "loss": 0.2534,
      "step": 4604
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1668669730424881,
      "learning_rate": 5.5889536774544985e-05,
      "loss": 0.3281,
      "step": 4605
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.15508566796779633,
      "learning_rate": 5.5849503673490136e-05,
      "loss": 0.2948,
      "step": 4606
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1586674302816391,
      "learning_rate": 5.580947935948915e-05,
      "loss": 0.3163,
      "step": 4607
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.12846627831459045,
      "learning_rate": 5.5769463840507786e-05,
      "loss": 0.244,
      "step": 4608
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.13717427849769592,
      "learning_rate": 5.572945712451023e-05,
      "loss": 0.2885,
      "step": 4609
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.18244518339633942,
      "learning_rate": 5.568945921945872e-05,
      "loss": 0.2836,
      "step": 4610
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.13275764882564545,
      "learning_rate": 5.564947013331399e-05,
      "loss": 0.2433,
      "step": 4611
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1422896832227707,
      "learning_rate": 5.560948987403467e-05,
      "loss": 0.2658,
      "step": 4612
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.15774743258953094,
      "learning_rate": 5.556951844957798e-05,
      "loss": 0.3245,
      "step": 4613
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.14160606265068054,
      "learning_rate": 5.552955586789915e-05,
      "loss": 0.2424,
      "step": 4614
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.12957553565502167,
      "learning_rate": 5.54896021369518e-05,
      "loss": 0.2248,
      "step": 4615
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.16142891347408295,
      "learning_rate": 5.544965726468767e-05,
      "loss": 0.3443,
      "step": 4616
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1222967728972435,
      "learning_rate": 5.540972125905684e-05,
      "loss": 0.2325,
      "step": 4617
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1856568306684494,
      "learning_rate": 5.536979412800756e-05,
      "loss": 0.3536,
      "step": 4618
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1494312882423401,
      "learning_rate": 5.5329875879486295e-05,
      "loss": 0.2488,
      "step": 4619
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.16669759154319763,
      "learning_rate": 5.5289966521437766e-05,
      "loss": 0.2552,
      "step": 4620
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1369309276342392,
      "learning_rate": 5.525006606180501e-05,
      "loss": 0.2884,
      "step": 4621
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.16948500275611877,
      "learning_rate": 5.5210174508529157e-05,
      "loss": 0.2684,
      "step": 4622
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.13199640810489655,
      "learning_rate": 5.517029186954961e-05,
      "loss": 0.2679,
      "step": 4623
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.17694871127605438,
      "learning_rate": 5.5130418152804065e-05,
      "loss": 0.292,
      "step": 4624
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.14131662249565125,
      "learning_rate": 5.509055336622835e-05,
      "loss": 0.245,
      "step": 4625
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1670905351638794,
      "learning_rate": 5.50506975177566e-05,
      "loss": 0.299,
      "step": 4626
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.20200000703334808,
      "learning_rate": 5.5010850615321096e-05,
      "loss": 0.362,
      "step": 4627
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.14216315746307373,
      "learning_rate": 5.497101266685236e-05,
      "loss": 0.2922,
      "step": 4628
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.11602496355772018,
      "learning_rate": 5.4931183680279116e-05,
      "loss": 0.1591,
      "step": 4629
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1605081856250763,
      "learning_rate": 5.489136366352843e-05,
      "loss": 0.2616,
      "step": 4630
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.124811552464962,
      "learning_rate": 5.485155262452535e-05,
      "loss": 0.2275,
      "step": 4631
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.171999990940094,
      "learning_rate": 5.481175057119339e-05,
      "loss": 0.3613,
      "step": 4632
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.137136310338974,
      "learning_rate": 5.4771957511454044e-05,
      "loss": 0.329,
      "step": 4633
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.17648455500602722,
      "learning_rate": 5.473217345322723e-05,
      "loss": 0.217,
      "step": 4634
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1556718647480011,
      "learning_rate": 5.4692398404430924e-05,
      "loss": 0.3039,
      "step": 4635
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.17329640686511993,
      "learning_rate": 5.465263237298137e-05,
      "loss": 0.2391,
      "step": 4636
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.15258947014808655,
      "learning_rate": 5.461287536679294e-05,
      "loss": 0.3417,
      "step": 4637
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.154946967959404,
      "learning_rate": 5.4573127393778355e-05,
      "loss": 0.2412,
      "step": 4638
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.14684666693210602,
      "learning_rate": 5.45333884618484e-05,
      "loss": 0.2722,
      "step": 4639
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.14992885291576385,
      "learning_rate": 5.449365857891218e-05,
      "loss": 0.316,
      "step": 4640
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1565581113100052,
      "learning_rate": 5.445393775287686e-05,
      "loss": 0.2731,
      "step": 4641
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.22625644505023956,
      "learning_rate": 5.4414225991647946e-05,
      "loss": 0.3476,
      "step": 4642
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.14332926273345947,
      "learning_rate": 5.437452330312905e-05,
      "loss": 0.2639,
      "step": 4643
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.17615948617458344,
      "learning_rate": 5.4334829695222e-05,
      "loss": 0.3421,
      "step": 4644
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1707642674446106,
      "learning_rate": 5.4295145175826765e-05,
      "loss": 0.2955,
      "step": 4645
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.12917502224445343,
      "learning_rate": 5.425546975284165e-05,
      "loss": 0.2105,
      "step": 4646
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.16342484951019287,
      "learning_rate": 5.421580343416297e-05,
      "loss": 0.3356,
      "step": 4647
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.25142163038253784,
      "learning_rate": 5.417614622768539e-05,
      "loss": 0.3212,
      "step": 4648
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.14598536491394043,
      "learning_rate": 5.4136498141301616e-05,
      "loss": 0.2865,
      "step": 4649
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.16286617517471313,
      "learning_rate": 5.4096859182902706e-05,
      "loss": 0.2941,
      "step": 4650
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.15778574347496033,
      "learning_rate": 5.405722936037772e-05,
      "loss": 0.3087,
      "step": 4651
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.14389635622501373,
      "learning_rate": 5.401760868161403e-05,
      "loss": 0.2505,
      "step": 4652
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.18607448041439056,
      "learning_rate": 5.3977997154497104e-05,
      "loss": 0.2434,
      "step": 4653
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.21551771461963654,
      "learning_rate": 5.393839478691062e-05,
      "loss": 0.3108,
      "step": 4654
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1474980264902115,
      "learning_rate": 5.38988015867365e-05,
      "loss": 0.2696,
      "step": 4655
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1466393619775772,
      "learning_rate": 5.385921756185472e-05,
      "loss": 0.2644,
      "step": 4656
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.17438381910324097,
      "learning_rate": 5.3819642720143546e-05,
      "loss": 0.2893,
      "step": 4657
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1630895733833313,
      "learning_rate": 5.3780077069479315e-05,
      "loss": 0.2961,
      "step": 4658
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.12107589840888977,
      "learning_rate": 5.374052061773662e-05,
      "loss": 0.2238,
      "step": 4659
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.16645178198814392,
      "learning_rate": 5.370097337278819e-05,
      "loss": 0.287,
      "step": 4660
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.13956545293331146,
      "learning_rate": 5.36614353425049e-05,
      "loss": 0.2337,
      "step": 4661
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.18952131271362305,
      "learning_rate": 5.362190653475574e-05,
      "loss": 0.3371,
      "step": 4662
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.16022972762584686,
      "learning_rate": 5.358238695740805e-05,
      "loss": 0.2867,
      "step": 4663
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.18491311371326447,
      "learning_rate": 5.354287661832711e-05,
      "loss": 0.3198,
      "step": 4664
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.19167910516262054,
      "learning_rate": 5.350337552537656e-05,
      "loss": 0.3179,
      "step": 4665
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.188920795917511,
      "learning_rate": 5.346388368641801e-05,
      "loss": 0.3892,
      "step": 4666
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1483944058418274,
      "learning_rate": 5.342440110931144e-05,
      "loss": 0.2779,
      "step": 4667
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.15974657237529755,
      "learning_rate": 5.3384927801914794e-05,
      "loss": 0.3059,
      "step": 4668
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.18396781384944916,
      "learning_rate": 5.334546377208427e-05,
      "loss": 0.3093,
      "step": 4669
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.15558382868766785,
      "learning_rate": 5.330600902767415e-05,
      "loss": 0.2792,
      "step": 4670
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.15011005103588104,
      "learning_rate": 5.326656357653699e-05,
      "loss": 0.2886,
      "step": 4671
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.18432261049747467,
      "learning_rate": 5.322712742652335e-05,
      "loss": 0.3194,
      "step": 4672
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.12625862658023834,
      "learning_rate": 5.318770058548208e-05,
      "loss": 0.248,
      "step": 4673
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.14531467854976654,
      "learning_rate": 5.314828306126005e-05,
      "loss": 0.263,
      "step": 4674
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.18651938438415527,
      "learning_rate": 5.31088748617024e-05,
      "loss": 0.2869,
      "step": 4675
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.19978845119476318,
      "learning_rate": 5.306947599465229e-05,
      "loss": 0.2738,
      "step": 4676
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.12236233800649643,
      "learning_rate": 5.3030086467951125e-05,
      "loss": 0.2378,
      "step": 4677
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.13598525524139404,
      "learning_rate": 5.299070628943832e-05,
      "loss": 0.247,
      "step": 4678
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.13814890384674072,
      "learning_rate": 5.295133546695164e-05,
      "loss": 0.2622,
      "step": 4679
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.1523931622505188,
      "learning_rate": 5.2911974008326733e-05,
      "loss": 0.2886,
      "step": 4680
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.18314804136753082,
      "learning_rate": 5.287262192139764e-05,
      "loss": 0.3204,
      "step": 4681
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.3333892524242401,
      "learning_rate": 5.283327921399631e-05,
      "loss": 0.3308,
      "step": 4682
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.15654531121253967,
      "learning_rate": 5.279394589395301e-05,
      "loss": 0.3023,
      "step": 4683
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.22799396514892578,
      "learning_rate": 5.275462196909602e-05,
      "loss": 0.3692,
      "step": 4684
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.1612306833267212,
      "learning_rate": 5.271530744725177e-05,
      "loss": 0.2854,
      "step": 4685
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.15276600420475006,
      "learning_rate": 5.2676002336244854e-05,
      "loss": 0.2291,
      "step": 4686
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.1503552943468094,
      "learning_rate": 5.2636706643897926e-05,
      "loss": 0.2755,
      "step": 4687
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.15159361064434052,
      "learning_rate": 5.259742037803189e-05,
      "loss": 0.4066,
      "step": 4688
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.14802752435207367,
      "learning_rate": 5.255814354646562e-05,
      "loss": 0.2654,
      "step": 4689
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.23064884543418884,
      "learning_rate": 5.251887615701625e-05,
      "loss": 0.4054,
      "step": 4690
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.156578928232193,
      "learning_rate": 5.247961821749892e-05,
      "loss": 0.3059,
      "step": 4691
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.16144968569278717,
      "learning_rate": 5.244036973572701e-05,
      "loss": 0.2906,
      "step": 4692
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.12818525731563568,
      "learning_rate": 5.2401130719511904e-05,
      "loss": 0.1931,
      "step": 4693
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.22041575610637665,
      "learning_rate": 5.2361901176663155e-05,
      "loss": 0.3964,
      "step": 4694
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.14079077541828156,
      "learning_rate": 5.232268111498839e-05,
      "loss": 0.2484,
      "step": 4695
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.11936142295598984,
      "learning_rate": 5.228347054229346e-05,
      "loss": 0.2247,
      "step": 4696
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20791687071323395,
      "learning_rate": 5.224426946638217e-05,
      "loss": 0.3982,
      "step": 4697
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.1335519701242447,
      "learning_rate": 5.2205077895056574e-05,
      "loss": 0.2632,
      "step": 4698
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.14909198880195618,
      "learning_rate": 5.2165895836116727e-05,
      "loss": 0.2655,
      "step": 4699
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.19057688117027283,
      "learning_rate": 5.2126723297360945e-05,
      "loss": 0.368,
      "step": 4700
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.1321669965982437,
      "learning_rate": 5.208756028658539e-05,
      "loss": 0.2322,
      "step": 4701
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.22182218730449677,
      "learning_rate": 5.2048406811584596e-05,
      "loss": 0.2969,
      "step": 4702
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20775936543941498,
      "learning_rate": 5.2009262880151e-05,
      "loss": 0.3098,
      "step": 4703
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.15319226682186127,
      "learning_rate": 5.197012850007532e-05,
      "loss": 0.2582,
      "step": 4704
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.13882207870483398,
      "learning_rate": 5.193100367914618e-05,
      "loss": 0.2214,
      "step": 4705
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.17585594952106476,
      "learning_rate": 5.189188842515048e-05,
      "loss": 0.252,
      "step": 4706
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1430778056383133,
      "learning_rate": 5.185278274587311e-05,
      "loss": 0.2612,
      "step": 4707
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.16892236471176147,
      "learning_rate": 5.181368664909706e-05,
      "loss": 0.2777,
      "step": 4708
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.18900427222251892,
      "learning_rate": 5.17746001426034e-05,
      "loss": 0.2912,
      "step": 4709
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.18456871807575226,
      "learning_rate": 5.1735523234171416e-05,
      "loss": 0.2505,
      "step": 4710
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.17239470779895782,
      "learning_rate": 5.169645593157829e-05,
      "loss": 0.3709,
      "step": 4711
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.15171363949775696,
      "learning_rate": 5.165739824259948e-05,
      "loss": 0.2901,
      "step": 4712
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.16812117397785187,
      "learning_rate": 5.161835017500838e-05,
      "loss": 0.2025,
      "step": 4713
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1867331713438034,
      "learning_rate": 5.157931173657658e-05,
      "loss": 0.336,
      "step": 4714
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1698775738477707,
      "learning_rate": 5.154028293507369e-05,
      "loss": 0.3304,
      "step": 4715
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.14770938456058502,
      "learning_rate": 5.1501263778267404e-05,
      "loss": 0.3168,
      "step": 4716
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.16161984205245972,
      "learning_rate": 5.146225427392354e-05,
      "loss": 0.3136,
      "step": 4717
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1412675380706787,
      "learning_rate": 5.142325442980589e-05,
      "loss": 0.285,
      "step": 4718
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1548534631729126,
      "learning_rate": 5.1384264253676505e-05,
      "loss": 0.3098,
      "step": 4719
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.194606214761734,
      "learning_rate": 5.1345283753295305e-05,
      "loss": 0.3586,
      "step": 4720
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1781149059534073,
      "learning_rate": 5.130631293642048e-05,
      "loss": 0.2943,
      "step": 4721
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1609889715909958,
      "learning_rate": 5.126735181080813e-05,
      "loss": 0.2476,
      "step": 4722
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.18242910504341125,
      "learning_rate": 5.122840038421254e-05,
      "loss": 0.2757,
      "step": 4723
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1584809422492981,
      "learning_rate": 5.1189458664386e-05,
      "loss": 0.2304,
      "step": 4724
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1668863445520401,
      "learning_rate": 5.115052665907888e-05,
      "loss": 0.256,
      "step": 4725
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.14121481776237488,
      "learning_rate": 5.111160437603959e-05,
      "loss": 0.268,
      "step": 4726
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.14505627751350403,
      "learning_rate": 5.107269182301472e-05,
      "loss": 0.2798,
      "step": 4727
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.16899646818637848,
      "learning_rate": 5.1033789007748755e-05,
      "loss": 0.3245,
      "step": 4728
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.15022961795330048,
      "learning_rate": 5.099489593798441e-05,
      "loss": 0.2507,
      "step": 4729
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1443237066268921,
      "learning_rate": 5.0956012621462304e-05,
      "loss": 0.234,
      "step": 4730
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.14841563999652863,
      "learning_rate": 5.091713906592126e-05,
      "loss": 0.2481,
      "step": 4731
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.15715743601322174,
      "learning_rate": 5.087827527909806e-05,
      "loss": 0.3297,
      "step": 4732
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.183602437376976,
      "learning_rate": 5.083942126872757e-05,
      "loss": 0.3139,
      "step": 4733
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.19789722561836243,
      "learning_rate": 5.080057704254266e-05,
      "loss": 0.3624,
      "step": 4734
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.16932813823223114,
      "learning_rate": 5.07617426082744e-05,
      "loss": 0.2403,
      "step": 4735
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1283886432647705,
      "learning_rate": 5.0722917973651717e-05,
      "loss": 0.2503,
      "step": 4736
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.15448182821273804,
      "learning_rate": 5.068410314640177e-05,
      "loss": 0.2559,
      "step": 4737
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.17186613380908966,
      "learning_rate": 5.064529813424961e-05,
      "loss": 0.2545,
      "step": 4738
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1888466328382492,
      "learning_rate": 5.0606502944918476e-05,
      "loss": 0.3043,
      "step": 4739
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.20893529057502747,
      "learning_rate": 5.056771758612955e-05,
      "loss": 0.3693,
      "step": 4740
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1504000872373581,
      "learning_rate": 5.052894206560208e-05,
      "loss": 0.3245,
      "step": 4741
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.13588307797908783,
      "learning_rate": 5.049017639105332e-05,
      "loss": 0.2147,
      "step": 4742
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.16521601378917694,
      "learning_rate": 5.045142057019872e-05,
      "loss": 0.2606,
      "step": 4743
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1690300852060318,
      "learning_rate": 5.041267461075154e-05,
      "loss": 0.3298,
      "step": 4744
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.142868772149086,
      "learning_rate": 5.037393852042329e-05,
      "loss": 0.2642,
      "step": 4745
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.16043469309806824,
      "learning_rate": 5.0335212306923396e-05,
      "loss": 0.2739,
      "step": 4746
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1542799174785614,
      "learning_rate": 5.029649597795929e-05,
      "loss": 0.2363,
      "step": 4747
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.20496094226837158,
      "learning_rate": 5.0257789541236566e-05,
      "loss": 0.3276,
      "step": 4748
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.14105242490768433,
      "learning_rate": 5.021909300445875e-05,
      "loss": 0.3044,
      "step": 4749
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.18881821632385254,
      "learning_rate": 5.01804063753274e-05,
      "loss": 0.3071,
      "step": 4750
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.13185593485832214,
      "learning_rate": 5.014172966154211e-05,
      "loss": 0.18,
      "step": 4751
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.15264371037483215,
      "learning_rate": 5.0103062870800564e-05,
      "loss": 0.2945,
      "step": 4752
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.18696360290050507,
      "learning_rate": 5.006440601079836e-05,
      "loss": 0.3371,
      "step": 4753
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1505526304244995,
      "learning_rate": 5.002575908922926e-05,
      "loss": 0.2304,
      "step": 4754
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.14552469551563263,
      "learning_rate": 4.998712211378489e-05,
      "loss": 0.2556,
      "step": 4755
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.20301124453544617,
      "learning_rate": 4.9948495092155054e-05,
      "loss": 0.2934,
      "step": 4756
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.2223386913537979,
      "learning_rate": 4.990987803202745e-05,
      "loss": 0.3581,
      "step": 4757
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.15686410665512085,
      "learning_rate": 4.9871270941087834e-05,
      "loss": 0.2445,
      "step": 4758
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.16450689733028412,
      "learning_rate": 4.983267382701996e-05,
      "loss": 0.3255,
      "step": 4759
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.15918490290641785,
      "learning_rate": 4.979408669750568e-05,
      "loss": 0.2385,
      "step": 4760
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.21438974142074585,
      "learning_rate": 4.9755509560224745e-05,
      "loss": 0.3566,
      "step": 4761
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.14110663533210754,
      "learning_rate": 4.971694242285503e-05,
      "loss": 0.2506,
      "step": 4762
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.14927423000335693,
      "learning_rate": 4.9678385293072296e-05,
      "loss": 0.2505,
      "step": 4763
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.17640824615955353,
      "learning_rate": 4.9639838178550435e-05,
      "loss": 0.3544,
      "step": 4764
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.16980576515197754,
      "learning_rate": 4.960130108696126e-05,
      "loss": 0.3157,
      "step": 4765
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.14830639958381653,
      "learning_rate": 4.9562774025974626e-05,
      "loss": 0.2844,
      "step": 4766
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1564718633890152,
      "learning_rate": 4.952425700325833e-05,
      "loss": 0.294,
      "step": 4767
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.18434804677963257,
      "learning_rate": 4.948575002647831e-05,
      "loss": 0.3684,
      "step": 4768
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.12082348763942719,
      "learning_rate": 4.944725310329833e-05,
      "loss": 0.2662,
      "step": 4769
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1647600531578064,
      "learning_rate": 4.9408766241380335e-05,
      "loss": 0.2736,
      "step": 4770
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.15380693972110748,
      "learning_rate": 4.9370289448384074e-05,
      "loss": 0.259,
      "step": 4771
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.19654448330402374,
      "learning_rate": 4.933182273196749e-05,
      "loss": 0.3362,
      "step": 4772
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1268290877342224,
      "learning_rate": 4.9293366099786375e-05,
      "loss": 0.251,
      "step": 4773
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.14726866781711578,
      "learning_rate": 4.925491955949456e-05,
      "loss": 0.3001,
      "step": 4774
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1768796145915985,
      "learning_rate": 4.921648311874384e-05,
      "loss": 0.1628,
      "step": 4775
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.16199305653572083,
      "learning_rate": 4.917805678518409e-05,
      "loss": 0.3249,
      "step": 4776
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1609150916337967,
      "learning_rate": 4.9139640566463084e-05,
      "loss": 0.3858,
      "step": 4777
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.12736527621746063,
      "learning_rate": 4.9101234470226576e-05,
      "loss": 0.2414,
      "step": 4778
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.11932217329740524,
      "learning_rate": 4.9062838504118406e-05,
      "loss": 0.2365,
      "step": 4779
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.21126705408096313,
      "learning_rate": 4.9024452675780266e-05,
      "loss": 0.269,
      "step": 4780
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.10224048048257828,
      "learning_rate": 4.898607699285199e-05,
      "loss": 0.3545,
      "step": 4781
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1821947693824768,
      "learning_rate": 4.894771146297118e-05,
      "loss": 0.3425,
      "step": 4782
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.15957459807395935,
      "learning_rate": 4.890935609377363e-05,
      "loss": 0.2483,
      "step": 4783
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1504759043455124,
      "learning_rate": 4.887101089289295e-05,
      "loss": 0.2502,
      "step": 4784
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.15830598771572113,
      "learning_rate": 4.8832675867960864e-05,
      "loss": 0.2852,
      "step": 4785
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.16558025777339935,
      "learning_rate": 4.879435102660693e-05,
      "loss": 0.2877,
      "step": 4786
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.13185705244541168,
      "learning_rate": 4.8756036376458824e-05,
      "loss": 0.2511,
      "step": 4787
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.19582444429397583,
      "learning_rate": 4.8717731925142085e-05,
      "loss": 0.3979,
      "step": 4788
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.15326490998268127,
      "learning_rate": 4.867943768028026e-05,
      "loss": 0.2836,
      "step": 4789
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.16766083240509033,
      "learning_rate": 4.864115364949482e-05,
      "loss": 0.2972,
      "step": 4790
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.12594719231128693,
      "learning_rate": 4.860287984040531e-05,
      "loss": 0.2248,
      "step": 4791
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.16890233755111694,
      "learning_rate": 4.856461626062913e-05,
      "loss": 0.2565,
      "step": 4792
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.13513316214084625,
      "learning_rate": 4.852636291778174e-05,
      "loss": 0.2514,
      "step": 4793
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.15622420608997345,
      "learning_rate": 4.8488119819476444e-05,
      "loss": 0.253,
      "step": 4794
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.13081838190555573,
      "learning_rate": 4.844988697332465e-05,
      "loss": 0.2928,
      "step": 4795
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.14931945502758026,
      "learning_rate": 4.841166438693563e-05,
      "loss": 0.2755,
      "step": 4796
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1710655242204666,
      "learning_rate": 4.83734520679166e-05,
      "loss": 0.3288,
      "step": 4797
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.13388566672801971,
      "learning_rate": 4.833525002387277e-05,
      "loss": 0.2593,
      "step": 4798
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1461360901594162,
      "learning_rate": 4.829705826240736e-05,
      "loss": 0.2362,
      "step": 4799
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1546294391155243,
      "learning_rate": 4.82588767911214e-05,
      "loss": 0.4288,
      "step": 4800
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.17323024570941925,
      "learning_rate": 4.822070561761405e-05,
      "loss": 0.2729,
      "step": 4801
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.13545991480350494,
      "learning_rate": 4.818254474948224e-05,
      "loss": 0.2264,
      "step": 4802
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1374415010213852,
      "learning_rate": 4.814439419432103e-05,
      "loss": 0.2413,
      "step": 4803
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.16795313358306885,
      "learning_rate": 4.810625395972329e-05,
      "loss": 0.2563,
      "step": 4804
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.14996977150440216,
      "learning_rate": 4.8068124053279884e-05,
      "loss": 0.2568,
      "step": 4805
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.16126024723052979,
      "learning_rate": 4.8030004482579604e-05,
      "loss": 0.226,
      "step": 4806
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.16848121583461761,
      "learning_rate": 4.799189525520919e-05,
      "loss": 0.331,
      "step": 4807
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.20984555780887604,
      "learning_rate": 4.795379637875337e-05,
      "loss": 0.3278,
      "step": 4808
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.24785730242729187,
      "learning_rate": 4.7915707860794724e-05,
      "loss": 0.3476,
      "step": 4809
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.20267949998378754,
      "learning_rate": 4.787762970891389e-05,
      "loss": 0.3189,
      "step": 4810
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.13709880411624908,
      "learning_rate": 4.783956193068929e-05,
      "loss": 0.2315,
      "step": 4811
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.16813577711582184,
      "learning_rate": 4.780150453369745e-05,
      "loss": 0.2786,
      "step": 4812
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.15320312976837158,
      "learning_rate": 4.776345752551271e-05,
      "loss": 0.3871,
      "step": 4813
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.1794334203004837,
      "learning_rate": 4.772542091370737e-05,
      "loss": 0.3603,
      "step": 4814
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18919870257377625,
      "learning_rate": 4.768739470585163e-05,
      "loss": 0.325,
      "step": 4815
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.179154634475708,
      "learning_rate": 4.7649378909513734e-05,
      "loss": 0.3391,
      "step": 4816
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.12306929379701614,
      "learning_rate": 4.76113735322597e-05,
      "loss": 0.1367,
      "step": 4817
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.11532285064458847,
      "learning_rate": 4.757337858165363e-05,
      "loss": 0.1838,
      "step": 4818
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.13252270221710205,
      "learning_rate": 4.7535394065257386e-05,
      "loss": 0.2107,
      "step": 4819
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.12817737460136414,
      "learning_rate": 4.749741999063092e-05,
      "loss": 0.2278,
      "step": 4820
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.15460969507694244,
      "learning_rate": 4.745945636533198e-05,
      "loss": 0.3269,
      "step": 4821
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.1433103233575821,
      "learning_rate": 4.742150319691628e-05,
      "loss": 0.2487,
      "step": 4822
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.12503786385059357,
      "learning_rate": 4.738356049293742e-05,
      "loss": 0.2238,
      "step": 4823
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.1723024547100067,
      "learning_rate": 4.734562826094702e-05,
      "loss": 0.2932,
      "step": 4824
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18069389462471008,
      "learning_rate": 4.7307706508494455e-05,
      "loss": 0.2829,
      "step": 4825
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.17989394068717957,
      "learning_rate": 4.726979524312719e-05,
      "loss": 0.3489,
      "step": 4826
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.17851285636425018,
      "learning_rate": 4.723189447239044e-05,
      "loss": 0.3669,
      "step": 4827
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.13738402724266052,
      "learning_rate": 4.719400420382748e-05,
      "loss": 0.247,
      "step": 4828
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18809303641319275,
      "learning_rate": 4.715612444497939e-05,
      "loss": 0.3513,
      "step": 4829
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.14805296063423157,
      "learning_rate": 4.7118255203385177e-05,
      "loss": 0.242,
      "step": 4830
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.150576651096344,
      "learning_rate": 4.708039648658175e-05,
      "loss": 0.2495,
      "step": 4831
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.1534959226846695,
      "learning_rate": 4.7042548302104e-05,
      "loss": 0.2677,
      "step": 4832
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.14082565903663635,
      "learning_rate": 4.700471065748459e-05,
      "loss": 0.2029,
      "step": 4833
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.1411561518907547,
      "learning_rate": 4.6966883560254235e-05,
      "loss": 0.2857,
      "step": 4834
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.19660043716430664,
      "learning_rate": 4.69290670179414e-05,
      "loss": 0.2545,
      "step": 4835
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.13534170389175415,
      "learning_rate": 4.6891261038072596e-05,
      "loss": 0.2557,
      "step": 4836
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.14749504625797272,
      "learning_rate": 4.6853465628172135e-05,
      "loss": 0.2534,
      "step": 4837
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.19735126197338104,
      "learning_rate": 4.681568079576224e-05,
      "loss": 0.3161,
      "step": 4838
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.14576838910579681,
      "learning_rate": 4.6777906548363026e-05,
      "loss": 0.291,
      "step": 4839
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.16348375380039215,
      "learning_rate": 4.67401428934925e-05,
      "loss": 0.2714,
      "step": 4840
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.10746356844902039,
      "learning_rate": 4.6702389838666625e-05,
      "loss": 0.182,
      "step": 4841
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.17043519020080566,
      "learning_rate": 4.6664647391399155e-05,
      "loss": 0.2297,
      "step": 4842
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18477636575698853,
      "learning_rate": 4.6626915559201835e-05,
      "loss": 0.2966,
      "step": 4843
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.2305145114660263,
      "learning_rate": 4.658919434958417e-05,
      "loss": 0.3279,
      "step": 4844
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18363919854164124,
      "learning_rate": 4.6551483770053715e-05,
      "loss": 0.2666,
      "step": 4845
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.16497991979122162,
      "learning_rate": 4.6513783828115776e-05,
      "loss": 0.301,
      "step": 4846
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.25128623843193054,
      "learning_rate": 4.647609453127357e-05,
      "loss": 0.3619,
      "step": 4847
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.15346558392047882,
      "learning_rate": 4.6438415887028197e-05,
      "loss": 0.2382,
      "step": 4848
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.15686552226543427,
      "learning_rate": 4.640074790287872e-05,
      "loss": 0.2791,
      "step": 4849
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.18434135615825653,
      "learning_rate": 4.6363090586321914e-05,
      "loss": 0.3341,
      "step": 4850
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1754455417394638,
      "learning_rate": 4.632544394485262e-05,
      "loss": 0.2899,
      "step": 4851
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.15958558022975922,
      "learning_rate": 4.628780798596339e-05,
      "loss": 0.3159,
      "step": 4852
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1666330248117447,
      "learning_rate": 4.62501827171448e-05,
      "loss": 0.2763,
      "step": 4853
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1592869609594345,
      "learning_rate": 4.621256814588516e-05,
      "loss": 0.3815,
      "step": 4854
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1655745655298233,
      "learning_rate": 4.617496427967073e-05,
      "loss": 0.3058,
      "step": 4855
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.17823082208633423,
      "learning_rate": 4.613737112598557e-05,
      "loss": 0.3079,
      "step": 4856
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.12886901199817657,
      "learning_rate": 4.609978869231175e-05,
      "loss": 0.2103,
      "step": 4857
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.17932619154453278,
      "learning_rate": 4.606221698612904e-05,
      "loss": 0.291,
      "step": 4858
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.17916394770145416,
      "learning_rate": 4.60246560149152e-05,
      "loss": 0.2903,
      "step": 4859
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16579651832580566,
      "learning_rate": 4.598710578614576e-05,
      "loss": 0.2877,
      "step": 4860
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.11802862584590912,
      "learning_rate": 4.5949566307294214e-05,
      "loss": 0.2057,
      "step": 4861
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16055449843406677,
      "learning_rate": 4.591203758583181e-05,
      "loss": 0.3039,
      "step": 4862
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16317860782146454,
      "learning_rate": 4.587451962922773e-05,
      "loss": 0.3363,
      "step": 4863
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.19816702604293823,
      "learning_rate": 4.583701244494892e-05,
      "loss": 0.3614,
      "step": 4864
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.21260397136211395,
      "learning_rate": 4.579951604046034e-05,
      "loss": 0.2537,
      "step": 4865
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.2386249154806137,
      "learning_rate": 4.576203042322464e-05,
      "loss": 0.4058,
      "step": 4866
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1589832901954651,
      "learning_rate": 4.572455560070247e-05,
      "loss": 0.2424,
      "step": 4867
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16585639119148254,
      "learning_rate": 4.5687091580352214e-05,
      "loss": 0.3278,
      "step": 4868
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.15354163944721222,
      "learning_rate": 4.564963836963011e-05,
      "loss": 0.2532,
      "step": 4869
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.13326333463191986,
      "learning_rate": 4.561219597599041e-05,
      "loss": 0.2129,
      "step": 4870
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.15469467639923096,
      "learning_rate": 4.557476440688492e-05,
      "loss": 0.2779,
      "step": 4871
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16272616386413574,
      "learning_rate": 4.553734366976359e-05,
      "loss": 0.3005,
      "step": 4872
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16937974095344543,
      "learning_rate": 4.5499933772073985e-05,
      "loss": 0.2923,
      "step": 4873
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1942720264196396,
      "learning_rate": 4.546253472126172e-05,
      "loss": 0.2639,
      "step": 4874
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.2009246051311493,
      "learning_rate": 4.542514652477003e-05,
      "loss": 0.346,
      "step": 4875
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16582171618938446,
      "learning_rate": 4.5387769190040205e-05,
      "loss": 0.2589,
      "step": 4876
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.17227281630039215,
      "learning_rate": 4.535040272451122e-05,
      "loss": 0.2996,
      "step": 4877
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16540862619876862,
      "learning_rate": 4.5313047135619936e-05,
      "loss": 0.2796,
      "step": 4878
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1433800458908081,
      "learning_rate": 4.5275702430801014e-05,
      "loss": 0.2297,
      "step": 4879
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1579250991344452,
      "learning_rate": 4.523836861748706e-05,
      "loss": 0.2652,
      "step": 4880
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.1434888392686844,
      "learning_rate": 4.520104570310837e-05,
      "loss": 0.2595,
      "step": 4881
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.16413289308547974,
      "learning_rate": 4.51637336950932e-05,
      "loss": 0.3287,
      "step": 4882
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1738908290863037,
      "learning_rate": 4.512643260086751e-05,
      "loss": 0.3426,
      "step": 4883
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1309657096862793,
      "learning_rate": 4.5089142427855224e-05,
      "loss": 0.2101,
      "step": 4884
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.18274739384651184,
      "learning_rate": 4.505186318347797e-05,
      "loss": 0.2801,
      "step": 4885
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.14513251185417175,
      "learning_rate": 4.501459487515527e-05,
      "loss": 0.1943,
      "step": 4886
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.19418476521968842,
      "learning_rate": 4.497733751030439e-05,
      "loss": 0.316,
      "step": 4887
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1443171352148056,
      "learning_rate": 4.494009109634059e-05,
      "loss": 0.2511,
      "step": 4888
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1587558537721634,
      "learning_rate": 4.4902855640676724e-05,
      "loss": 0.2374,
      "step": 4889
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.166544109582901,
      "learning_rate": 4.4865631150723676e-05,
      "loss": 0.2705,
      "step": 4890
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.15219835937023163,
      "learning_rate": 4.482841763388996e-05,
      "loss": 0.2461,
      "step": 4891
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1681736707687378,
      "learning_rate": 4.47912150975821e-05,
      "loss": 0.3235,
      "step": 4892
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.5041557550430298,
      "learning_rate": 4.475402354920427e-05,
      "loss": 0.1945,
      "step": 4893
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.17847269773483276,
      "learning_rate": 4.4716842996158525e-05,
      "loss": 0.3323,
      "step": 4894
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1895896941423416,
      "learning_rate": 4.4679673445844694e-05,
      "loss": 0.277,
      "step": 4895
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.18345853686332703,
      "learning_rate": 4.464251490566051e-05,
      "loss": 0.3201,
      "step": 4896
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.14012199640274048,
      "learning_rate": 4.46053673830014e-05,
      "loss": 0.2801,
      "step": 4897
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1428329199552536,
      "learning_rate": 4.4568230885260696e-05,
      "loss": 0.2821,
      "step": 4898
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.15315265953540802,
      "learning_rate": 4.453110541982948e-05,
      "loss": 0.3121,
      "step": 4899
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.18562807142734528,
      "learning_rate": 4.44939909940966e-05,
      "loss": 0.3532,
      "step": 4900
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.14725901186466217,
      "learning_rate": 4.445688761544883e-05,
      "loss": 0.245,
      "step": 4901
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1523972749710083,
      "learning_rate": 4.4419795291270626e-05,
      "loss": 0.2664,
      "step": 4902
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1571485996246338,
      "learning_rate": 4.4382714028944304e-05,
      "loss": 0.3349,
      "step": 4903
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.11785395443439484,
      "learning_rate": 4.4345643835849926e-05,
      "loss": 0.1841,
      "step": 4904
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.16907477378845215,
      "learning_rate": 4.430858471936545e-05,
      "loss": 0.2669,
      "step": 4905
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.18758629262447357,
      "learning_rate": 4.42715366868665e-05,
      "loss": 0.2849,
      "step": 4906
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.13429367542266846,
      "learning_rate": 4.423449974572663e-05,
      "loss": 0.2531,
      "step": 4907
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.09775236994028091,
      "learning_rate": 4.419747390331706e-05,
      "loss": 0.2035,
      "step": 4908
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1531999558210373,
      "learning_rate": 4.416045916700692e-05,
      "loss": 0.2574,
      "step": 4909
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1218976303935051,
      "learning_rate": 4.412345554416303e-05,
      "loss": 0.2568,
      "step": 4910
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.11294187605381012,
      "learning_rate": 4.408646304215005e-05,
      "loss": 0.2195,
      "step": 4911
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.12681569159030914,
      "learning_rate": 4.404948166833036e-05,
      "loss": 0.2063,
      "step": 4912
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.4480881690979004,
      "learning_rate": 4.401251143006427e-05,
      "loss": 0.3461,
      "step": 4913
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.1609475016593933,
      "learning_rate": 4.39755523347097e-05,
      "loss": 0.2383,
      "step": 4914
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.13542672991752625,
      "learning_rate": 4.393860438962251e-05,
      "loss": 0.2498,
      "step": 4915
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.16612979769706726,
      "learning_rate": 4.390166760215619e-05,
      "loss": 0.2679,
      "step": 4916
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.18262077867984772,
      "learning_rate": 4.386474197966216e-05,
      "loss": 0.3276,
      "step": 4917
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.14393024146556854,
      "learning_rate": 4.3827827529489506e-05,
      "loss": 0.2317,
      "step": 4918
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.13801613450050354,
      "learning_rate": 4.3790924258985135e-05,
      "loss": 0.2764,
      "step": 4919
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.19068311154842377,
      "learning_rate": 4.3754032175493676e-05,
      "loss": 0.3036,
      "step": 4920
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.0907493606209755,
      "learning_rate": 4.371715128635765e-05,
      "loss": 0.1562,
      "step": 4921
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.16965095698833466,
      "learning_rate": 4.368028159891721e-05,
      "loss": 0.2874,
      "step": 4922
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.14887316524982452,
      "learning_rate": 4.364342312051042e-05,
      "loss": 0.2591,
      "step": 4923
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.20984084904193878,
      "learning_rate": 4.3606575858472956e-05,
      "loss": 0.3179,
      "step": 4924
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.16171355545520782,
      "learning_rate": 4.356973982013842e-05,
      "loss": 0.2906,
      "step": 4925
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.13360758125782013,
      "learning_rate": 4.3532915012838084e-05,
      "loss": 0.2422,
      "step": 4926
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.17771261930465698,
      "learning_rate": 4.3496101443900994e-05,
      "loss": 0.2953,
      "step": 4927
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.16619731485843658,
      "learning_rate": 4.345929912065394e-05,
      "loss": 0.3378,
      "step": 4928
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.15798036754131317,
      "learning_rate": 4.3422508050421576e-05,
      "loss": 0.2846,
      "step": 4929
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.1884661167860031,
      "learning_rate": 4.338572824052621e-05,
      "loss": 0.3078,
      "step": 4930
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.12518548965454102,
      "learning_rate": 4.3348959698287906e-05,
      "loss": 0.2268,
      "step": 4931
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.1500222086906433,
      "learning_rate": 4.331220243102461e-05,
      "loss": 0.2404,
      "step": 4932
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.16246581077575684,
      "learning_rate": 4.327545644605184e-05,
      "loss": 0.2992,
      "step": 4933
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.15140852332115173,
      "learning_rate": 4.3238721750683065e-05,
      "loss": 0.2463,
      "step": 4934
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.12847237288951874,
      "learning_rate": 4.320199835222935e-05,
      "loss": 0.2273,
      "step": 4935
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.16959145665168762,
      "learning_rate": 4.3165286257999595e-05,
      "loss": 0.3277,
      "step": 4936
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.1455288827419281,
      "learning_rate": 4.3128585475300366e-05,
      "loss": 0.2493,
      "step": 4937
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.10836588591337204,
      "learning_rate": 4.309189601143612e-05,
      "loss": 0.1903,
      "step": 4938
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.14381560683250427,
      "learning_rate": 4.305521787370891e-05,
      "loss": 0.1444,
      "step": 4939
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.1656414121389389,
      "learning_rate": 4.301855106941868e-05,
      "loss": 0.2633,
      "step": 4940
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.13762716948986053,
      "learning_rate": 4.298189560586296e-05,
      "loss": 0.2516,
      "step": 4941
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.14166195690631866,
      "learning_rate": 4.294525149033717e-05,
      "loss": 0.2836,
      "step": 4942
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.13100673258304596,
      "learning_rate": 4.290861873013438e-05,
      "loss": 0.2014,
      "step": 4943
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.21603883802890778,
      "learning_rate": 4.2871997332545424e-05,
      "loss": 0.353,
      "step": 4944
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.12326662987470627,
      "learning_rate": 4.2835387304858844e-05,
      "loss": 0.2143,
      "step": 4945
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.15117289125919342,
      "learning_rate": 4.279878865436102e-05,
      "loss": 0.3014,
      "step": 4946
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.12823152542114258,
      "learning_rate": 4.2762201388335934e-05,
      "loss": 0.2457,
      "step": 4947
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.17235541343688965,
      "learning_rate": 4.272562551406544e-05,
      "loss": 0.3016,
      "step": 4948
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.1782030463218689,
      "learning_rate": 4.268906103882896e-05,
      "loss": 0.3442,
      "step": 4949
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.13646037876605988,
      "learning_rate": 4.265250796990383e-05,
      "loss": 0.274,
      "step": 4950
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.17762024700641632,
      "learning_rate": 4.261596631456499e-05,
      "loss": 0.3297,
      "step": 4951
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.15658731758594513,
      "learning_rate": 4.257943608008514e-05,
      "loss": 0.2752,
      "step": 4952
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.15383580327033997,
      "learning_rate": 4.2542917273734684e-05,
      "loss": 0.281,
      "step": 4953
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.15214970707893372,
      "learning_rate": 4.250640990278184e-05,
      "loss": 0.3191,
      "step": 4954
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.20660588145256042,
      "learning_rate": 4.246991397449241e-05,
      "loss": 0.2863,
      "step": 4955
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1441587656736374,
      "learning_rate": 4.2433429496130086e-05,
      "loss": 0.2565,
      "step": 4956
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.19827823340892792,
      "learning_rate": 4.239695647495611e-05,
      "loss": 0.3357,
      "step": 4957
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.15180973708629608,
      "learning_rate": 4.236049491822963e-05,
      "loss": 0.2813,
      "step": 4958
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1632784605026245,
      "learning_rate": 4.232404483320731e-05,
      "loss": 0.2476,
      "step": 4959
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.18077950179576874,
      "learning_rate": 4.228760622714363e-05,
      "loss": 0.341,
      "step": 4960
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1599024385213852,
      "learning_rate": 4.2251179107290853e-05,
      "loss": 0.3215,
      "step": 4961
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.20381714403629303,
      "learning_rate": 4.221476348089881e-05,
      "loss": 0.3139,
      "step": 4962
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1667608916759491,
      "learning_rate": 4.21783593552152e-05,
      "loss": 0.2623,
      "step": 4963
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1546933948993683,
      "learning_rate": 4.2141966737485286e-05,
      "loss": 0.3023,
      "step": 4964
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1063363254070282,
      "learning_rate": 4.210558563495217e-05,
      "loss": 0.2033,
      "step": 4965
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.18789145350456238,
      "learning_rate": 4.206921605485659e-05,
      "loss": 0.3495,
      "step": 4966
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1519414335489273,
      "learning_rate": 4.203285800443697e-05,
      "loss": 0.3252,
      "step": 4967
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1828729659318924,
      "learning_rate": 4.1996511490929454e-05,
      "loss": 0.3283,
      "step": 4968
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.17611844837665558,
      "learning_rate": 4.1960176521568e-05,
      "loss": 0.3406,
      "step": 4969
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.12390928715467453,
      "learning_rate": 4.1923853103584064e-05,
      "loss": 0.2473,
      "step": 4970
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.20671845972537994,
      "learning_rate": 4.1887541244207006e-05,
      "loss": 0.3166,
      "step": 4971
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.13637050986289978,
      "learning_rate": 4.185124095066374e-05,
      "loss": 0.2566,
      "step": 4972
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.16059374809265137,
      "learning_rate": 4.1814952230178975e-05,
      "loss": 0.3038,
      "step": 4973
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1363392323255539,
      "learning_rate": 4.177867508997505e-05,
      "loss": 0.2547,
      "step": 4974
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1411910504102707,
      "learning_rate": 4.174240953727203e-05,
      "loss": 0.2603,
      "step": 4975
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1731652319431305,
      "learning_rate": 4.170615557928763e-05,
      "loss": 0.311,
      "step": 4976
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.15589480102062225,
      "learning_rate": 4.1669913223237364e-05,
      "loss": 0.2724,
      "step": 4977
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.19796884059906006,
      "learning_rate": 4.16336824763343e-05,
      "loss": 0.339,
      "step": 4978
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.21442049741744995,
      "learning_rate": 4.159746334578934e-05,
      "loss": 0.3689,
      "step": 4979
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.19583846628665924,
      "learning_rate": 4.1561255838810895e-05,
      "loss": 0.2948,
      "step": 4980
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.15798704326152802,
      "learning_rate": 4.152505996260528e-05,
      "loss": 0.2259,
      "step": 4981
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.175058975815773,
      "learning_rate": 4.148887572437632e-05,
      "loss": 0.2881,
      "step": 4982
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.12862028181552887,
      "learning_rate": 4.145270313132558e-05,
      "loss": 0.2011,
      "step": 4983
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.17237940430641174,
      "learning_rate": 4.1416542190652284e-05,
      "loss": 0.2375,
      "step": 4984
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.18051883578300476,
      "learning_rate": 4.1380392909553444e-05,
      "loss": 0.3623,
      "step": 4985
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.15709014236927032,
      "learning_rate": 4.134425529522359e-05,
      "loss": 0.2386,
      "step": 4986
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.12709026038646698,
      "learning_rate": 4.1308129354855086e-05,
      "loss": 0.2212,
      "step": 4987
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.141377255320549,
      "learning_rate": 4.127201509563783e-05,
      "loss": 0.2777,
      "step": 4988
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1728404462337494,
      "learning_rate": 4.1235912524759525e-05,
      "loss": 0.3465,
      "step": 4989
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.1653372347354889,
      "learning_rate": 4.119982164940546e-05,
      "loss": 0.2833,
      "step": 4990
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.16690512001514435,
      "learning_rate": 4.1163742476758615e-05,
      "loss": 0.3675,
      "step": 4991
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.1467750519514084,
      "learning_rate": 4.112767501399965e-05,
      "loss": 0.2356,
      "step": 4992
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15677577257156372,
      "learning_rate": 4.109161926830687e-05,
      "loss": 0.2473,
      "step": 4993
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.1830405741930008,
      "learning_rate": 4.1055575246856326e-05,
      "loss": 0.3567,
      "step": 4994
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.19665689766407013,
      "learning_rate": 4.101954295682161e-05,
      "loss": 0.3399,
      "step": 4995
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.12144993245601654,
      "learning_rate": 4.098352240537413e-05,
      "loss": 0.2122,
      "step": 4996
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.17535972595214844,
      "learning_rate": 4.094751359968281e-05,
      "loss": 0.2673,
      "step": 4997
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.1354995220899582,
      "learning_rate": 4.0911516546914354e-05,
      "loss": 0.245,
      "step": 4998
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.1427864283323288,
      "learning_rate": 4.0875531254233067e-05,
      "loss": 0.2487,
      "step": 4999
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15515859425067902,
      "learning_rate": 4.08395577288009e-05,
      "loss": 0.3011,
      "step": 5000
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.145294651389122,
      "learning_rate": 4.0803595977777466e-05,
      "loss": 0.2358,
      "step": 5001
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15712812542915344,
      "learning_rate": 4.0767646008320105e-05,
      "loss": 0.2976,
      "step": 5002
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15316203236579895,
      "learning_rate": 4.073170782758371e-05,
      "loss": 0.2896,
      "step": 5003
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.20754177868366241,
      "learning_rate": 4.0695781442720946e-05,
      "loss": 0.3553,
      "step": 5004
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.13313007354736328,
      "learning_rate": 4.065986686088198e-05,
      "loss": 0.2162,
      "step": 5005
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.10017000138759613,
      "learning_rate": 4.062396408921479e-05,
      "loss": 0.1792,
      "step": 5006
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.16934500634670258,
      "learning_rate": 4.05880731348649e-05,
      "loss": 0.2988,
      "step": 5007
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.16497653722763062,
      "learning_rate": 4.055219400497551e-05,
      "loss": 0.3093,
      "step": 5008
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.17234696447849274,
      "learning_rate": 4.05163267066874e-05,
      "loss": 0.2827,
      "step": 5009
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.13008654117584229,
      "learning_rate": 4.048047124713916e-05,
      "loss": 0.2476,
      "step": 5010
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.14904694259166718,
      "learning_rate": 4.044462763346683e-05,
      "loss": 0.2974,
      "step": 5011
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.18917886912822723,
      "learning_rate": 4.0408795872804295e-05,
      "loss": 0.2986,
      "step": 5012
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.1423002928495407,
      "learning_rate": 4.0372975972282855e-05,
      "loss": 0.2686,
      "step": 5013
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15783992409706116,
      "learning_rate": 4.033716793903167e-05,
      "loss": 0.2556,
      "step": 5014
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.2506060004234314,
      "learning_rate": 4.0301371780177396e-05,
      "loss": 0.3458,
      "step": 5015
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15896812081336975,
      "learning_rate": 4.026558750284435e-05,
      "loss": 0.2288,
      "step": 5016
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15801243484020233,
      "learning_rate": 4.022981511415447e-05,
      "loss": 0.2789,
      "step": 5017
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15676651895046234,
      "learning_rate": 4.019405462122743e-05,
      "loss": 0.2512,
      "step": 5018
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.15027789771556854,
      "learning_rate": 4.0158306031180395e-05,
      "loss": 0.2499,
      "step": 5019
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.17744891345500946,
      "learning_rate": 4.012256935112829e-05,
      "loss": 0.2974,
      "step": 5020
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.1672959327697754,
      "learning_rate": 4.008684458818358e-05,
      "loss": 0.2216,
      "step": 5021
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.16638271510601044,
      "learning_rate": 4.005113174945636e-05,
      "loss": 0.2467,
      "step": 5022
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.11948738992214203,
      "learning_rate": 4.001543084205444e-05,
      "loss": 0.2047,
      "step": 5023
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.20239847898483276,
      "learning_rate": 3.9979741873083146e-05,
      "loss": 0.416,
      "step": 5024
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.17450393736362457,
      "learning_rate": 3.994406484964549e-05,
      "loss": 0.2775,
      "step": 5025
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.1401061713695526,
      "learning_rate": 3.990839977884207e-05,
      "loss": 0.2553,
      "step": 5026
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.13914266228675842,
      "learning_rate": 3.987274666777118e-05,
      "loss": 0.2353,
      "step": 5027
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.14938023686408997,
      "learning_rate": 3.983710552352862e-05,
      "loss": 0.2696,
      "step": 5028
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.1678989678621292,
      "learning_rate": 3.9801476353207924e-05,
      "loss": 0.2609,
      "step": 5029
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.19662262499332428,
      "learning_rate": 3.976585916390014e-05,
      "loss": 0.302,
      "step": 5030
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.14729604125022888,
      "learning_rate": 3.973025396269404e-05,
      "loss": 0.2623,
      "step": 5031
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.14546839892864227,
      "learning_rate": 3.969466075667592e-05,
      "loss": 0.2766,
      "step": 5032
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.17360197007656097,
      "learning_rate": 3.96590795529297e-05,
      "loss": 0.251,
      "step": 5033
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.17260324954986572,
      "learning_rate": 3.962351035853693e-05,
      "loss": 0.2737,
      "step": 5034
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.19822368025779724,
      "learning_rate": 3.958795318057681e-05,
      "loss": 0.2465,
      "step": 5035
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.15667304396629333,
      "learning_rate": 3.955240802612604e-05,
      "loss": 0.2784,
      "step": 5036
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.18168912827968597,
      "learning_rate": 3.951687490225909e-05,
      "loss": 0.3314,
      "step": 5037
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.12393247336149216,
      "learning_rate": 3.948135381604785e-05,
      "loss": 0.2305,
      "step": 5038
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.20542505383491516,
      "learning_rate": 3.9445844774562016e-05,
      "loss": 0.3457,
      "step": 5039
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.20824499428272247,
      "learning_rate": 3.941034778486863e-05,
      "loss": 0.3479,
      "step": 5040
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.14829964935779572,
      "learning_rate": 3.93748628540326e-05,
      "loss": 0.2326,
      "step": 5041
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.1626531034708023,
      "learning_rate": 3.933938998911623e-05,
      "loss": 0.3454,
      "step": 5042
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.17079894244670868,
      "learning_rate": 3.930392919717959e-05,
      "loss": 0.3109,
      "step": 5043
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.16758961975574493,
      "learning_rate": 3.926848048528018e-05,
      "loss": 0.2586,
      "step": 5044
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.12726669013500214,
      "learning_rate": 3.923304386047327e-05,
      "loss": 0.2348,
      "step": 5045
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.2045813649892807,
      "learning_rate": 3.9197619329811554e-05,
      "loss": 0.282,
      "step": 5046
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.14238397777080536,
      "learning_rate": 3.916220690034551e-05,
      "loss": 0.2349,
      "step": 5047
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.13601961731910706,
      "learning_rate": 3.9126806579122954e-05,
      "loss": 0.2652,
      "step": 5048
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.17844384908676147,
      "learning_rate": 3.909141837318955e-05,
      "loss": 0.2476,
      "step": 5049
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.17072288691997528,
      "learning_rate": 3.905604228958835e-05,
      "loss": 0.2803,
      "step": 5050
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.19289684295654297,
      "learning_rate": 3.902067833536015e-05,
      "loss": 0.3214,
      "step": 5051
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.19562289118766785,
      "learning_rate": 3.8985326517543255e-05,
      "loss": 0.3594,
      "step": 5052
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.21156719326972961,
      "learning_rate": 3.8949986843173506e-05,
      "loss": 0.2499,
      "step": 5053
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.16751956939697266,
      "learning_rate": 3.8914659319284444e-05,
      "loss": 0.3035,
      "step": 5054
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.2363716959953308,
      "learning_rate": 3.887934395290711e-05,
      "loss": 0.3665,
      "step": 5055
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.12379909306764603,
      "learning_rate": 3.8844040751070144e-05,
      "loss": 0.2328,
      "step": 5056
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.14398345351219177,
      "learning_rate": 3.880874972079972e-05,
      "loss": 0.2483,
      "step": 5057
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.13881978392601013,
      "learning_rate": 3.877347086911973e-05,
      "loss": 0.2583,
      "step": 5058
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.169009730219841,
      "learning_rate": 3.8738204203051455e-05,
      "loss": 0.2691,
      "step": 5059
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.12690170109272003,
      "learning_rate": 3.870294972961393e-05,
      "loss": 0.2431,
      "step": 5060
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.16248534619808197,
      "learning_rate": 3.86677074558236e-05,
      "loss": 0.2308,
      "step": 5061
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14623533189296722,
      "learning_rate": 3.8632477388694634e-05,
      "loss": 0.2401,
      "step": 5062
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.17694155871868134,
      "learning_rate": 3.859725953523865e-05,
      "loss": 0.3589,
      "step": 5063
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.13513202965259552,
      "learning_rate": 3.8562053902464904e-05,
      "loss": 0.2101,
      "step": 5064
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.16269473731517792,
      "learning_rate": 3.8526860497380135e-05,
      "loss": 0.2708,
      "step": 5065
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.17003805935382843,
      "learning_rate": 3.849167932698881e-05,
      "loss": 0.3281,
      "step": 5066
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.1410619020462036,
      "learning_rate": 3.8456510398292775e-05,
      "loss": 0.2131,
      "step": 5067
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.1668117642402649,
      "learning_rate": 3.84213537182916e-05,
      "loss": 0.3192,
      "step": 5068
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.15540754795074463,
      "learning_rate": 3.838620929398228e-05,
      "loss": 0.3164,
      "step": 5069
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.13677771389484406,
      "learning_rate": 3.835107713235949e-05,
      "loss": 0.2936,
      "step": 5070
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14720457792282104,
      "learning_rate": 3.83159572404154e-05,
      "loss": 0.291,
      "step": 5071
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14099930226802826,
      "learning_rate": 3.8280849625139726e-05,
      "loss": 0.2625,
      "step": 5072
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.13775354623794556,
      "learning_rate": 3.824575429351973e-05,
      "loss": 0.2565,
      "step": 5073
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.12494207918643951,
      "learning_rate": 3.821067125254034e-05,
      "loss": 0.2099,
      "step": 5074
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.12499606609344482,
      "learning_rate": 3.8175600509183896e-05,
      "loss": 0.2271,
      "step": 5075
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14336630702018738,
      "learning_rate": 3.8140542070430397e-05,
      "loss": 0.2974,
      "step": 5076
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.16923436522483826,
      "learning_rate": 3.8105495943257295e-05,
      "loss": 0.2988,
      "step": 5077
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.15875720977783203,
      "learning_rate": 3.8070462134639726e-05,
      "loss": 0.3225,
      "step": 5078
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14156197011470795,
      "learning_rate": 3.8035440651550246e-05,
      "loss": 0.2663,
      "step": 5079
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.16154612600803375,
      "learning_rate": 3.800043150095901e-05,
      "loss": 0.3296,
      "step": 5080
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.1303533911705017,
      "learning_rate": 3.796543468983368e-05,
      "loss": 0.2372,
      "step": 5081
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.15238168835639954,
      "learning_rate": 3.793045022513958e-05,
      "loss": 0.214,
      "step": 5082
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.15881744027137756,
      "learning_rate": 3.7895478113839436e-05,
      "loss": 0.2514,
      "step": 5083
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.178181454539299,
      "learning_rate": 3.786051836289355e-05,
      "loss": 0.3586,
      "step": 5084
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.18224382400512695,
      "learning_rate": 3.782557097925986e-05,
      "loss": 0.3549,
      "step": 5085
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14312514662742615,
      "learning_rate": 3.779063596989371e-05,
      "loss": 0.2168,
      "step": 5086
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14309892058372498,
      "learning_rate": 3.775571334174809e-05,
      "loss": 0.264,
      "step": 5087
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.17629709839820862,
      "learning_rate": 3.772080310177345e-05,
      "loss": 0.3372,
      "step": 5088
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.17251046001911163,
      "learning_rate": 3.7685905256917797e-05,
      "loss": 0.3213,
      "step": 5089
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14875836670398712,
      "learning_rate": 3.7651019814126654e-05,
      "loss": 0.2518,
      "step": 5090
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.15299159288406372,
      "learning_rate": 3.761614678034316e-05,
      "loss": 0.2345,
      "step": 5091
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.13204413652420044,
      "learning_rate": 3.758128616250786e-05,
      "loss": 0.1882,
      "step": 5092
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.14179402589797974,
      "learning_rate": 3.754643796755894e-05,
      "loss": 0.2434,
      "step": 5093
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.1732233613729477,
      "learning_rate": 3.751160220243199e-05,
      "loss": 0.3072,
      "step": 5094
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.223664328455925,
      "learning_rate": 3.7476778874060305e-05,
      "loss": 0.2939,
      "step": 5095
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2010924220085144,
      "learning_rate": 3.744196798937454e-05,
      "loss": 0.406,
      "step": 5096
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.16986745595932007,
      "learning_rate": 3.740716955530293e-05,
      "loss": 0.3532,
      "step": 5097
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.16423554718494415,
      "learning_rate": 3.73723835787712e-05,
      "loss": 0.3073,
      "step": 5098
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1271766573190689,
      "learning_rate": 3.73376100667027e-05,
      "loss": 0.2226,
      "step": 5099
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.16574090719223022,
      "learning_rate": 3.7302849026018174e-05,
      "loss": 0.2691,
      "step": 5100
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1444842368364334,
      "learning_rate": 3.726810046363599e-05,
      "loss": 0.2878,
      "step": 5101
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.17283369600772858,
      "learning_rate": 3.7233364386471925e-05,
      "loss": 0.2443,
      "step": 5102
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1865324079990387,
      "learning_rate": 3.719864080143939e-05,
      "loss": 0.2748,
      "step": 5103
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.17075896263122559,
      "learning_rate": 3.716392971544922e-05,
      "loss": 0.2601,
      "step": 5104
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.13666817545890808,
      "learning_rate": 3.712923113540978e-05,
      "loss": 0.226,
      "step": 5105
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.13068856298923492,
      "learning_rate": 3.709454506822693e-05,
      "loss": 0.2411,
      "step": 5106
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.15324197709560394,
      "learning_rate": 3.7059871520804125e-05,
      "loss": 0.2555,
      "step": 5107
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.22155135869979858,
      "learning_rate": 3.702521050004221e-05,
      "loss": 0.3267,
      "step": 5108
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.144523024559021,
      "learning_rate": 3.699056201283966e-05,
      "loss": 0.2332,
      "step": 5109
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.16187632083892822,
      "learning_rate": 3.6955926066092315e-05,
      "loss": 0.27,
      "step": 5110
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.14023658633232117,
      "learning_rate": 3.692130266669368e-05,
      "loss": 0.2599,
      "step": 5111
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1606612205505371,
      "learning_rate": 3.6886691821534636e-05,
      "loss": 0.2463,
      "step": 5112
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1554192453622818,
      "learning_rate": 3.6852093537503595e-05,
      "loss": 0.3289,
      "step": 5113
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.15571962296962738,
      "learning_rate": 3.6817507821486505e-05,
      "loss": 0.263,
      "step": 5114
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.154205784201622,
      "learning_rate": 3.678293468036674e-05,
      "loss": 0.2707,
      "step": 5115
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.18968668580055237,
      "learning_rate": 3.67483741210253e-05,
      "loss": 0.3213,
      "step": 5116
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.14664039015769958,
      "learning_rate": 3.671382615034051e-05,
      "loss": 0.1805,
      "step": 5117
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.21045255661010742,
      "learning_rate": 3.667929077518838e-05,
      "loss": 0.3622,
      "step": 5118
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.13611933588981628,
      "learning_rate": 3.664476800244222e-05,
      "loss": 0.1977,
      "step": 5119
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.14355093240737915,
      "learning_rate": 3.661025783897301e-05,
      "loss": 0.2488,
      "step": 5120
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1507565677165985,
      "learning_rate": 3.65757602916491e-05,
      "loss": 0.2496,
      "step": 5121
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.14637522399425507,
      "learning_rate": 3.654127536733635e-05,
      "loss": 0.2533,
      "step": 5122
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2129470705986023,
      "learning_rate": 3.650680307289811e-05,
      "loss": 0.2857,
      "step": 5123
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.15428617596626282,
      "learning_rate": 3.647234341519529e-05,
      "loss": 0.2144,
      "step": 5124
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.17066378891468048,
      "learning_rate": 3.6437896401086134e-05,
      "loss": 0.2706,
      "step": 5125
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.19627143442630768,
      "learning_rate": 3.640346203742657e-05,
      "loss": 0.2545,
      "step": 5126
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.14971724152565002,
      "learning_rate": 3.636904033106981e-05,
      "loss": 0.2677,
      "step": 5127
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.18337981402873993,
      "learning_rate": 3.633463128886673e-05,
      "loss": 0.3465,
      "step": 5128
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.15400142967700958,
      "learning_rate": 3.6300234917665454e-05,
      "loss": 0.2985,
      "step": 5129
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.18201950192451477,
      "learning_rate": 3.626585122431183e-05,
      "loss": 0.2697,
      "step": 5130
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.159280925989151,
      "learning_rate": 3.623148021564902e-05,
      "loss": 0.2974,
      "step": 5131
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.21501252055168152,
      "learning_rate": 3.619712189851775e-05,
      "loss": 0.3526,
      "step": 5132
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.16172656416893005,
      "learning_rate": 3.616277627975615e-05,
      "loss": 0.2671,
      "step": 5133
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1493978500366211,
      "learning_rate": 3.6128443366199904e-05,
      "loss": 0.2422,
      "step": 5134
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.14875668287277222,
      "learning_rate": 3.609412316468209e-05,
      "loss": 0.2874,
      "step": 5135
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1537596434354782,
      "learning_rate": 3.605981568203329e-05,
      "loss": 0.2697,
      "step": 5136
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1287265568971634,
      "learning_rate": 3.6025520925081535e-05,
      "loss": 0.2461,
      "step": 5137
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.17023861408233643,
      "learning_rate": 3.599123890065238e-05,
      "loss": 0.2483,
      "step": 5138
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.11987126618623734,
      "learning_rate": 3.595696961556875e-05,
      "loss": 0.215,
      "step": 5139
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.16265524923801422,
      "learning_rate": 3.592271307665116e-05,
      "loss": 0.2787,
      "step": 5140
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1455807089805603,
      "learning_rate": 3.588846929071745e-05,
      "loss": 0.2898,
      "step": 5141
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.19894270598888397,
      "learning_rate": 3.585423826458305e-05,
      "loss": 0.3491,
      "step": 5142
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1446765810251236,
      "learning_rate": 3.582002000506077e-05,
      "loss": 0.2258,
      "step": 5143
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.14701825380325317,
      "learning_rate": 3.57858145189609e-05,
      "loss": 0.229,
      "step": 5144
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.17333480715751648,
      "learning_rate": 3.5751621813091174e-05,
      "loss": 0.2508,
      "step": 5145
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.18929243087768555,
      "learning_rate": 3.571744189425678e-05,
      "loss": 0.34,
      "step": 5146
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1544838547706604,
      "learning_rate": 3.5683274769260435e-05,
      "loss": 0.2334,
      "step": 5147
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.17825551331043243,
      "learning_rate": 3.564912044490217e-05,
      "loss": 0.2993,
      "step": 5148
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1487571746110916,
      "learning_rate": 3.561497892797965e-05,
      "loss": 0.2517,
      "step": 5149
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.15219254791736603,
      "learning_rate": 3.55808502252878e-05,
      "loss": 0.2263,
      "step": 5150
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.18622250854969025,
      "learning_rate": 3.554673434361916e-05,
      "loss": 0.2698,
      "step": 5151
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.14522118866443634,
      "learning_rate": 3.551263128976361e-05,
      "loss": 0.2791,
      "step": 5152
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.22931478917598724,
      "learning_rate": 3.547854107050852e-05,
      "loss": 0.4196,
      "step": 5153
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.13337022066116333,
      "learning_rate": 3.544446369263865e-05,
      "loss": 0.2372,
      "step": 5154
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.20759685337543488,
      "learning_rate": 3.541039916293633e-05,
      "loss": 0.3165,
      "step": 5155
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.20524127781391144,
      "learning_rate": 3.5376347488181175e-05,
      "loss": 0.2977,
      "step": 5156
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.13387924432754517,
      "learning_rate": 3.534230867515039e-05,
      "loss": 0.2419,
      "step": 5157
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.15053251385688782,
      "learning_rate": 3.53082827306185e-05,
      "loss": 0.2647,
      "step": 5158
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.12425070255994797,
      "learning_rate": 3.527426966135756e-05,
      "loss": 0.2105,
      "step": 5159
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1845378577709198,
      "learning_rate": 3.524026947413701e-05,
      "loss": 0.3245,
      "step": 5160
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.14600199460983276,
      "learning_rate": 3.520628217572374e-05,
      "loss": 0.2292,
      "step": 5161
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1471051275730133,
      "learning_rate": 3.517230777288202e-05,
      "loss": 0.2447,
      "step": 5162
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.13139133155345917,
      "learning_rate": 3.513834627237369e-05,
      "loss": 0.1898,
      "step": 5163
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.2115171104669571,
      "learning_rate": 3.5104397680957854e-05,
      "loss": 0.3481,
      "step": 5164
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.17606408894062042,
      "learning_rate": 3.507046200539123e-05,
      "loss": 0.2975,
      "step": 5165
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.16573625802993774,
      "learning_rate": 3.503653925242776e-05,
      "loss": 0.2251,
      "step": 5166
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.18501846492290497,
      "learning_rate": 3.500262942881901e-05,
      "loss": 0.2767,
      "step": 5167
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.17825685441493988,
      "learning_rate": 3.496873254131385e-05,
      "loss": 0.2374,
      "step": 5168
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.17069776356220245,
      "learning_rate": 3.493484859665862e-05,
      "loss": 0.3288,
      "step": 5169
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.11299881339073181,
      "learning_rate": 3.490097760159702e-05,
      "loss": 0.2083,
      "step": 5170
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.154473215341568,
      "learning_rate": 3.486711956287029e-05,
      "loss": 0.2469,
      "step": 5171
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.19317041337490082,
      "learning_rate": 3.483327448721698e-05,
      "loss": 0.2984,
      "step": 5172
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.19133546948432922,
      "learning_rate": 3.479944238137316e-05,
      "loss": 0.3089,
      "step": 5173
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.17424918711185455,
      "learning_rate": 3.4765623252072236e-05,
      "loss": 0.2803,
      "step": 5174
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.18606217205524445,
      "learning_rate": 3.473181710604503e-05,
      "loss": 0.3123,
      "step": 5175
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.1324869841337204,
      "learning_rate": 3.469802395001988e-05,
      "loss": 0.2216,
      "step": 5176
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.15850427746772766,
      "learning_rate": 3.466424379072242e-05,
      "loss": 0.3124,
      "step": 5177
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.1810329407453537,
      "learning_rate": 3.4630476634875766e-05,
      "loss": 0.3337,
      "step": 5178
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.1686287224292755,
      "learning_rate": 3.459672248920038e-05,
      "loss": 0.2623,
      "step": 5179
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.165002703666687,
      "learning_rate": 3.456298136041427e-05,
      "loss": 0.2639,
      "step": 5180
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.13962699472904205,
      "learning_rate": 3.452925325523268e-05,
      "loss": 0.2915,
      "step": 5181
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.11780650913715363,
      "learning_rate": 3.4495538180368415e-05,
      "loss": 0.2415,
      "step": 5182
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.15982885658740997,
      "learning_rate": 3.4461836142531557e-05,
      "loss": 0.2698,
      "step": 5183
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.15913143754005432,
      "learning_rate": 3.4428147148429715e-05,
      "loss": 0.2817,
      "step": 5184
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.14505548775196075,
      "learning_rate": 3.439447120476782e-05,
      "loss": 0.2329,
      "step": 5185
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.19876715540885925,
      "learning_rate": 3.4360808318248215e-05,
      "loss": 0.3244,
      "step": 5186
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.19746997952461243,
      "learning_rate": 3.432715849557063e-05,
      "loss": 0.3265,
      "step": 5187
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.17389896512031555,
      "learning_rate": 3.42935217434323e-05,
      "loss": 0.2718,
      "step": 5188
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.15687844157218933,
      "learning_rate": 3.42598980685277e-05,
      "loss": 0.2439,
      "step": 5189
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.14588096737861633,
      "learning_rate": 3.422628747754885e-05,
      "loss": 0.277,
      "step": 5190
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.16590403020381927,
      "learning_rate": 3.419268997718502e-05,
      "loss": 0.384,
      "step": 5191
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.13006779551506042,
      "learning_rate": 3.415910557412305e-05,
      "loss": 0.2581,
      "step": 5192
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.16605359315872192,
      "learning_rate": 3.4125534275047024e-05,
      "loss": 0.2639,
      "step": 5193
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.11423223465681076,
      "learning_rate": 3.409197608663848e-05,
      "loss": 0.2088,
      "step": 5194
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.1547412872314453,
      "learning_rate": 3.405843101557629e-05,
      "loss": 0.2874,
      "step": 5195
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.1481127142906189,
      "learning_rate": 3.402489906853684e-05,
      "loss": 0.2511,
      "step": 5196
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.19615048170089722,
      "learning_rate": 3.399138025219376e-05,
      "loss": 0.3668,
      "step": 5197
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.15644285082817078,
      "learning_rate": 3.395787457321821e-05,
      "loss": 0.2619,
      "step": 5198
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.13852256536483765,
      "learning_rate": 3.3924382038278565e-05,
      "loss": 0.211,
      "step": 5199
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.1545366495847702,
      "learning_rate": 3.389090265404077e-05,
      "loss": 0.2728,
      "step": 5200
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.2057032585144043,
      "learning_rate": 3.385743642716801e-05,
      "loss": 0.2138,
      "step": 5201
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.15857666730880737,
      "learning_rate": 3.382398336432091e-05,
      "loss": 0.252,
      "step": 5202
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.24517413973808289,
      "learning_rate": 3.3790543472157434e-05,
      "loss": 0.3677,
      "step": 5203
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.13663868606090546,
      "learning_rate": 3.375711675733302e-05,
      "loss": 0.2224,
      "step": 5204
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.14972586929798126,
      "learning_rate": 3.372370322650039e-05,
      "loss": 0.2539,
      "step": 5205
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.16986386477947235,
      "learning_rate": 3.3690302886309645e-05,
      "loss": 0.3176,
      "step": 5206
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.24372263252735138,
      "learning_rate": 3.3656915743408347e-05,
      "loss": 0.1624,
      "step": 5207
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.19941769540309906,
      "learning_rate": 3.3623541804441305e-05,
      "loss": 0.3467,
      "step": 5208
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1551693081855774,
      "learning_rate": 3.359018107605088e-05,
      "loss": 0.2719,
      "step": 5209
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1479458063840866,
      "learning_rate": 3.355683356487654e-05,
      "loss": 0.2339,
      "step": 5210
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1329934298992157,
      "learning_rate": 3.352349927755539e-05,
      "loss": 0.2375,
      "step": 5211
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1423896700143814,
      "learning_rate": 3.349017822072172e-05,
      "loss": 0.2757,
      "step": 5212
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.14662832021713257,
      "learning_rate": 3.3456870401007325e-05,
      "loss": 0.2605,
      "step": 5213
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.2206965684890747,
      "learning_rate": 3.342357582504121e-05,
      "loss": 0.4402,
      "step": 5214
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.14881476759910583,
      "learning_rate": 3.3390294499449916e-05,
      "loss": 0.2342,
      "step": 5215
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.15365277230739594,
      "learning_rate": 3.335702643085721e-05,
      "loss": 0.2653,
      "step": 5216
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.15668027102947235,
      "learning_rate": 3.332377162588427e-05,
      "loss": 0.3673,
      "step": 5217
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.16926118731498718,
      "learning_rate": 3.329053009114962e-05,
      "loss": 0.3005,
      "step": 5218
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1884821355342865,
      "learning_rate": 3.3257301833269204e-05,
      "loss": 0.3256,
      "step": 5219
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.15583102405071259,
      "learning_rate": 3.322408685885622e-05,
      "loss": 0.2635,
      "step": 5220
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.20409637689590454,
      "learning_rate": 3.319088517452135e-05,
      "loss": 0.3095,
      "step": 5221
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.14665931463241577,
      "learning_rate": 3.3157696786872485e-05,
      "loss": 0.2754,
      "step": 5222
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.15098965167999268,
      "learning_rate": 3.312452170251501e-05,
      "loss": 0.2393,
      "step": 5223
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.16260457038879395,
      "learning_rate": 3.309135992805158e-05,
      "loss": 0.2785,
      "step": 5224
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.16556261479854584,
      "learning_rate": 3.30582114700822e-05,
      "loss": 0.2233,
      "step": 5225
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1664324700832367,
      "learning_rate": 3.3025076335204206e-05,
      "loss": 0.3497,
      "step": 5226
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.17974621057510376,
      "learning_rate": 3.2991954530012414e-05,
      "loss": 0.3086,
      "step": 5227
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1964578926563263,
      "learning_rate": 3.295884606109879e-05,
      "loss": 0.3283,
      "step": 5228
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.18636073172092438,
      "learning_rate": 3.292575093505285e-05,
      "loss": 0.3086,
      "step": 5229
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.19266505539417267,
      "learning_rate": 3.2892669158461256e-05,
      "loss": 0.324,
      "step": 5230
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1734338104724884,
      "learning_rate": 3.2859600737908195e-05,
      "loss": 0.2767,
      "step": 5231
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.13590139150619507,
      "learning_rate": 3.282654567997506e-05,
      "loss": 0.2394,
      "step": 5232
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.23116078972816467,
      "learning_rate": 3.279350399124066e-05,
      "loss": 0.2894,
      "step": 5233
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1676325649023056,
      "learning_rate": 3.276047567828106e-05,
      "loss": 0.263,
      "step": 5234
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.18189921975135803,
      "learning_rate": 3.2727460747669794e-05,
      "loss": 0.2585,
      "step": 5235
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1714959442615509,
      "learning_rate": 3.2694459205977635e-05,
      "loss": 0.263,
      "step": 5236
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.17711754143238068,
      "learning_rate": 3.2661471059772675e-05,
      "loss": 0.3106,
      "step": 5237
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.16370728611946106,
      "learning_rate": 3.262849631562045e-05,
      "loss": 0.3695,
      "step": 5238
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.16174446046352386,
      "learning_rate": 3.25955349800837e-05,
      "loss": 0.2573,
      "step": 5239
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.120816171169281,
      "learning_rate": 3.25625870597226e-05,
      "loss": 0.2384,
      "step": 5240
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14801771938800812,
      "learning_rate": 3.2529652561094604e-05,
      "loss": 0.2252,
      "step": 5241
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14663362503051758,
      "learning_rate": 3.2496731490754486e-05,
      "loss": 0.2584,
      "step": 5242
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14949415624141693,
      "learning_rate": 3.246382385525434e-05,
      "loss": 0.322,
      "step": 5243
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14245115220546722,
      "learning_rate": 3.243092966114366e-05,
      "loss": 0.2619,
      "step": 5244
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.15852682292461395,
      "learning_rate": 3.239804891496916e-05,
      "loss": 0.2583,
      "step": 5245
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.17584864795207977,
      "learning_rate": 3.2365181623274986e-05,
      "loss": 0.2876,
      "step": 5246
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.19530056416988373,
      "learning_rate": 3.2332327792602504e-05,
      "loss": 0.2792,
      "step": 5247
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.13240090012550354,
      "learning_rate": 3.2299487429490505e-05,
      "loss": 0.2934,
      "step": 5248
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.15821295976638794,
      "learning_rate": 3.2266660540475004e-05,
      "loss": 0.2544,
      "step": 5249
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1707688421010971,
      "learning_rate": 3.223384713208939e-05,
      "loss": 0.2428,
      "step": 5250
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.16962337493896484,
      "learning_rate": 3.22010472108643e-05,
      "loss": 0.3401,
      "step": 5251
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1835109293460846,
      "learning_rate": 3.216826078332781e-05,
      "loss": 0.2817,
      "step": 5252
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.17667441070079803,
      "learning_rate": 3.213548785600518e-05,
      "loss": 0.303,
      "step": 5253
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14722105860710144,
      "learning_rate": 3.210272843541911e-05,
      "loss": 0.2371,
      "step": 5254
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.16282017529010773,
      "learning_rate": 3.206998252808948e-05,
      "loss": 0.2872,
      "step": 5255
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14722539484500885,
      "learning_rate": 3.2037250140533603e-05,
      "loss": 0.2621,
      "step": 5256
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.15790843963623047,
      "learning_rate": 3.200453127926602e-05,
      "loss": 0.3011,
      "step": 5257
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.169013112783432,
      "learning_rate": 3.197182595079858e-05,
      "loss": 0.249,
      "step": 5258
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1649458259344101,
      "learning_rate": 3.193913416164047e-05,
      "loss": 0.235,
      "step": 5259
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.13155147433280945,
      "learning_rate": 3.190645591829821e-05,
      "loss": 0.2461,
      "step": 5260
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.18578146398067474,
      "learning_rate": 3.1873791227275516e-05,
      "loss": 0.2664,
      "step": 5261
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.15167336165905,
      "learning_rate": 3.1841140095073565e-05,
      "loss": 0.2974,
      "step": 5262
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14706474542617798,
      "learning_rate": 3.1808502528190675e-05,
      "loss": 0.2546,
      "step": 5263
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1760987937450409,
      "learning_rate": 3.1775878533122606e-05,
      "loss": 0.2669,
      "step": 5264
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.20130200684070587,
      "learning_rate": 3.174326811636232e-05,
      "loss": 0.2667,
      "step": 5265
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.19627001881599426,
      "learning_rate": 3.171067128440011e-05,
      "loss": 0.3749,
      "step": 5266
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.15893130004405975,
      "learning_rate": 3.167808804372354e-05,
      "loss": 0.2839,
      "step": 5267
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14289744198322296,
      "learning_rate": 3.164551840081748e-05,
      "loss": 0.2281,
      "step": 5268
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1670151650905609,
      "learning_rate": 3.1612962362164156e-05,
      "loss": 0.2825,
      "step": 5269
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.18905232846736908,
      "learning_rate": 3.158041993424298e-05,
      "loss": 0.3368,
      "step": 5270
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.17674016952514648,
      "learning_rate": 3.154789112353077e-05,
      "loss": 0.3871,
      "step": 5271
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.14858394861221313,
      "learning_rate": 3.15153759365015e-05,
      "loss": 0.2947,
      "step": 5272
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.15107566118240356,
      "learning_rate": 3.148287437962659e-05,
      "loss": 0.2731,
      "step": 5273
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.19622476398944855,
      "learning_rate": 3.145038645937461e-05,
      "loss": 0.298,
      "step": 5274
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.15529751777648926,
      "learning_rate": 3.1417912182211494e-05,
      "loss": 0.291,
      "step": 5275
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.13471703231334686,
      "learning_rate": 3.138545155460038e-05,
      "loss": 0.2223,
      "step": 5276
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.17115142941474915,
      "learning_rate": 3.135300458300182e-05,
      "loss": 0.2706,
      "step": 5277
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16203325986862183,
      "learning_rate": 3.1320571273873514e-05,
      "loss": 0.3089,
      "step": 5278
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.18082162737846375,
      "learning_rate": 3.128815163367055e-05,
      "loss": 0.298,
      "step": 5279
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16064484417438507,
      "learning_rate": 3.125574566884519e-05,
      "loss": 0.2535,
      "step": 5280
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.1641870141029358,
      "learning_rate": 3.122335338584712e-05,
      "loss": 0.2559,
      "step": 5281
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16948644816875458,
      "learning_rate": 3.119097479112315e-05,
      "loss": 0.3401,
      "step": 5282
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16410066187381744,
      "learning_rate": 3.115860989111744e-05,
      "loss": 0.3391,
      "step": 5283
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.14836165308952332,
      "learning_rate": 3.112625869227141e-05,
      "loss": 0.3116,
      "step": 5284
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.15251798927783966,
      "learning_rate": 3.1093921201023776e-05,
      "loss": 0.2947,
      "step": 5285
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.13427655398845673,
      "learning_rate": 3.1061597423810475e-05,
      "loss": 0.2511,
      "step": 5286
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.19820259511470795,
      "learning_rate": 3.1029287367064806e-05,
      "loss": 0.3109,
      "step": 5287
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.14228792488574982,
      "learning_rate": 3.0996991037217215e-05,
      "loss": 0.2531,
      "step": 5288
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16787774860858917,
      "learning_rate": 3.0964708440695535e-05,
      "loss": 0.3371,
      "step": 5289
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16507308185100555,
      "learning_rate": 3.09324395839248e-05,
      "loss": 0.2663,
      "step": 5290
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.14720942080020905,
      "learning_rate": 3.09001844733273e-05,
      "loss": 0.2899,
      "step": 5291
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.15106076002120972,
      "learning_rate": 3.0867943115322574e-05,
      "loss": 0.2563,
      "step": 5292
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16554942727088928,
      "learning_rate": 3.083571551632755e-05,
      "loss": 0.3526,
      "step": 5293
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.1501411348581314,
      "learning_rate": 3.0803501682756233e-05,
      "loss": 0.235,
      "step": 5294
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.1813962310552597,
      "learning_rate": 3.0771301621020065e-05,
      "loss": 0.3308,
      "step": 5295
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.21347518265247345,
      "learning_rate": 3.0739115337527626e-05,
      "loss": 0.3794,
      "step": 5296
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16926245391368866,
      "learning_rate": 3.070694283868476e-05,
      "loss": 0.265,
      "step": 5297
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.18415021896362305,
      "learning_rate": 3.0674784130894694e-05,
      "loss": 0.2691,
      "step": 5298
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.14546512067317963,
      "learning_rate": 3.0642639220557686e-05,
      "loss": 0.239,
      "step": 5299
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.17060990631580353,
      "learning_rate": 3.061050811407148e-05,
      "loss": 0.3345,
      "step": 5300
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.13870389759540558,
      "learning_rate": 3.05783908178309e-05,
      "loss": 0.252,
      "step": 5301
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.1911049634218216,
      "learning_rate": 3.054628733822818e-05,
      "loss": 0.1976,
      "step": 5302
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.15402111411094666,
      "learning_rate": 3.0514197681652612e-05,
      "loss": 0.2602,
      "step": 5303
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16787515580654144,
      "learning_rate": 3.048212185449093e-05,
      "loss": 0.2959,
      "step": 5304
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16915859282016754,
      "learning_rate": 3.045005986312699e-05,
      "loss": 0.2841,
      "step": 5305
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.1452462375164032,
      "learning_rate": 3.041801171394193e-05,
      "loss": 0.239,
      "step": 5306
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.20793522894382477,
      "learning_rate": 3.0385977413314094e-05,
      "loss": 0.3571,
      "step": 5307
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.20458842813968658,
      "learning_rate": 3.035395696761919e-05,
      "loss": 0.3277,
      "step": 5308
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.16433638334274292,
      "learning_rate": 3.0321950383230013e-05,
      "loss": 0.2696,
      "step": 5309
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.17423348128795624,
      "learning_rate": 3.0289957666516733e-05,
      "loss": 0.2771,
      "step": 5310
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1270640641450882,
      "learning_rate": 3.0257978823846654e-05,
      "loss": 0.2822,
      "step": 5311
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.13011400401592255,
      "learning_rate": 3.022601386158441e-05,
      "loss": 0.2219,
      "step": 5312
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.12933263182640076,
      "learning_rate": 3.0194062786091826e-05,
      "loss": 0.2298,
      "step": 5313
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1328740417957306,
      "learning_rate": 3.016212560372793e-05,
      "loss": 0.2269,
      "step": 5314
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.13659168779850006,
      "learning_rate": 3.013020232084902e-05,
      "loss": 0.2327,
      "step": 5315
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.13207823038101196,
      "learning_rate": 3.009829294380867e-05,
      "loss": 0.2382,
      "step": 5316
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.14480239152908325,
      "learning_rate": 3.0066397478957588e-05,
      "loss": 0.2427,
      "step": 5317
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1804356724023819,
      "learning_rate": 3.0034515932643837e-05,
      "loss": 0.3208,
      "step": 5318
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.16857081651687622,
      "learning_rate": 3.0002648311212577e-05,
      "loss": 0.2889,
      "step": 5319
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.15298737585544586,
      "learning_rate": 2.9970794621006327e-05,
      "loss": 0.2515,
      "step": 5320
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.14210352301597595,
      "learning_rate": 2.9938954868364733e-05,
      "loss": 0.2399,
      "step": 5321
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1612263023853302,
      "learning_rate": 2.9907129059624705e-05,
      "loss": 0.2839,
      "step": 5322
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.15932929515838623,
      "learning_rate": 2.9875317201120355e-05,
      "loss": 0.2775,
      "step": 5323
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.15438829362392426,
      "learning_rate": 2.9843519299183077e-05,
      "loss": 0.2331,
      "step": 5324
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.16390658915042877,
      "learning_rate": 2.981173536014141e-05,
      "loss": 0.2839,
      "step": 5325
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.30489709973335266,
      "learning_rate": 2.9779965390321195e-05,
      "loss": 0.3419,
      "step": 5326
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.18301081657409668,
      "learning_rate": 2.9748209396045446e-05,
      "loss": 0.2902,
      "step": 5327
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19695232808589935,
      "learning_rate": 2.971646738363435e-05,
      "loss": 0.2701,
      "step": 5328
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19729472696781158,
      "learning_rate": 2.968473935940542e-05,
      "loss": 0.2662,
      "step": 5329
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.16419078409671783,
      "learning_rate": 2.965302532967332e-05,
      "loss": 0.2997,
      "step": 5330
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.18089084327220917,
      "learning_rate": 2.9621325300749912e-05,
      "loss": 0.3518,
      "step": 5331
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.14662474393844604,
      "learning_rate": 2.9589639278944282e-05,
      "loss": 0.2152,
      "step": 5332
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.16685955226421356,
      "learning_rate": 2.955796727056278e-05,
      "loss": 0.2706,
      "step": 5333
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.17299893498420715,
      "learning_rate": 2.9526309281908892e-05,
      "loss": 0.2598,
      "step": 5334
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1586117148399353,
      "learning_rate": 2.94946653192834e-05,
      "loss": 0.2231,
      "step": 5335
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1692376285791397,
      "learning_rate": 2.9463035388984185e-05,
      "loss": 0.2944,
      "step": 5336
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19328907132148743,
      "learning_rate": 2.9431419497306456e-05,
      "loss": 0.3185,
      "step": 5337
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.18097250163555145,
      "learning_rate": 2.9399817650542526e-05,
      "loss": 0.2805,
      "step": 5338
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.14990022778511047,
      "learning_rate": 2.9368229854981976e-05,
      "loss": 0.2787,
      "step": 5339
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.17162573337554932,
      "learning_rate": 2.933665611691151e-05,
      "loss": 0.2831,
      "step": 5340
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19334574043750763,
      "learning_rate": 2.9305096442615177e-05,
      "loss": 0.3251,
      "step": 5341
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.15515251457691193,
      "learning_rate": 2.9273550838374075e-05,
      "loss": 0.2868,
      "step": 5342
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.20567327737808228,
      "learning_rate": 2.9242019310466616e-05,
      "loss": 0.3279,
      "step": 5343
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1483021229505539,
      "learning_rate": 2.9210501865168316e-05,
      "loss": 0.2391,
      "step": 5344
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.16882354021072388,
      "learning_rate": 2.9178998508751997e-05,
      "loss": 0.307,
      "step": 5345
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.12042614072561264,
      "learning_rate": 2.914750924748758e-05,
      "loss": 0.2328,
      "step": 5346
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.18059854209423065,
      "learning_rate": 2.9116034087642218e-05,
      "loss": 0.3194,
      "step": 5347
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.23176443576812744,
      "learning_rate": 2.9084573035480224e-05,
      "loss": 0.301,
      "step": 5348
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.18214187026023865,
      "learning_rate": 2.9053126097263193e-05,
      "loss": 0.2704,
      "step": 5349
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.15252718329429626,
      "learning_rate": 2.9021693279249796e-05,
      "loss": 0.2363,
      "step": 5350
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.14875538647174835,
      "learning_rate": 2.899027458769601e-05,
      "loss": 0.2497,
      "step": 5351
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.14680561423301697,
      "learning_rate": 2.8958870028854878e-05,
      "loss": 0.2655,
      "step": 5352
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.13343337178230286,
      "learning_rate": 2.892747960897676e-05,
      "loss": 0.2404,
      "step": 5353
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.14701445400714874,
      "learning_rate": 2.88961033343091e-05,
      "loss": 0.2594,
      "step": 5354
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.14369848370552063,
      "learning_rate": 2.886474121109657e-05,
      "loss": 0.2649,
      "step": 5355
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.12420087307691574,
      "learning_rate": 2.8833393245580976e-05,
      "loss": 0.2125,
      "step": 5356
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.14199788868427277,
      "learning_rate": 2.8802059444001404e-05,
      "loss": 0.2196,
      "step": 5357
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.19767819344997406,
      "learning_rate": 2.877073981259405e-05,
      "loss": 0.286,
      "step": 5358
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.11436358094215393,
      "learning_rate": 2.8739434357592276e-05,
      "loss": 0.2193,
      "step": 5359
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.13837213814258575,
      "learning_rate": 2.870814308522669e-05,
      "loss": 0.2416,
      "step": 5360
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.1658327281475067,
      "learning_rate": 2.8676866001725e-05,
      "loss": 0.3059,
      "step": 5361
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.1605639010667801,
      "learning_rate": 2.8645603113312182e-05,
      "loss": 0.3194,
      "step": 5362
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.15703622996807098,
      "learning_rate": 2.86143544262103e-05,
      "loss": 0.2811,
      "step": 5363
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.17709723114967346,
      "learning_rate": 2.8583119946638614e-05,
      "loss": 0.2888,
      "step": 5364
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.18334966897964478,
      "learning_rate": 2.8551899680813564e-05,
      "loss": 0.3217,
      "step": 5365
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.13609230518341064,
      "learning_rate": 2.8520693634948803e-05,
      "loss": 0.2081,
      "step": 5366
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.15558141469955444,
      "learning_rate": 2.848950181525506e-05,
      "loss": 0.2496,
      "step": 5367
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.1535770446062088,
      "learning_rate": 2.8458324227940358e-05,
      "loss": 0.2156,
      "step": 5368
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.17031019926071167,
      "learning_rate": 2.8427160879209745e-05,
      "loss": 0.313,
      "step": 5369
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.13602499663829803,
      "learning_rate": 2.8396011775265564e-05,
      "loss": 0.2803,
      "step": 5370
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.1517122983932495,
      "learning_rate": 2.836487692230725e-05,
      "loss": 0.2966,
      "step": 5371
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.15834014117717743,
      "learning_rate": 2.8333756326531414e-05,
      "loss": 0.2819,
      "step": 5372
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.14322634041309357,
      "learning_rate": 2.8302649994131802e-05,
      "loss": 0.2445,
      "step": 5373
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.16581590473651886,
      "learning_rate": 2.8271557931299408e-05,
      "loss": 0.3113,
      "step": 5374
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.20156502723693848,
      "learning_rate": 2.824048014422227e-05,
      "loss": 0.27,
      "step": 5375
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.154539093375206,
      "learning_rate": 2.8209416639085717e-05,
      "loss": 0.2686,
      "step": 5376
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.13167332112789154,
      "learning_rate": 2.8178367422072094e-05,
      "loss": 0.2862,
      "step": 5377
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.16766220331192017,
      "learning_rate": 2.8147332499361045e-05,
      "loss": 0.2706,
      "step": 5378
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.185450941324234,
      "learning_rate": 2.811631187712924e-05,
      "loss": 0.3179,
      "step": 5379
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.18125911056995392,
      "learning_rate": 2.808530556155059e-05,
      "loss": 0.3637,
      "step": 5380
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1399930715560913,
      "learning_rate": 2.8054313558796074e-05,
      "loss": 0.2987,
      "step": 5381
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.20679041743278503,
      "learning_rate": 2.802333587503395e-05,
      "loss": 0.3383,
      "step": 5382
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.16407255828380585,
      "learning_rate": 2.79923725164295e-05,
      "loss": 0.2891,
      "step": 5383
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.15624822676181793,
      "learning_rate": 2.7961423489145243e-05,
      "loss": 0.2507,
      "step": 5384
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.22516906261444092,
      "learning_rate": 2.793048879934076e-05,
      "loss": 0.4324,
      "step": 5385
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.15623526275157928,
      "learning_rate": 2.7899568453172932e-05,
      "loss": 0.2466,
      "step": 5386
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.11173149943351746,
      "learning_rate": 2.7868662456795547e-05,
      "loss": 0.1874,
      "step": 5387
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1369260549545288,
      "learning_rate": 2.7837770816359764e-05,
      "loss": 0.2657,
      "step": 5388
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.15032555162906647,
      "learning_rate": 2.7806893538013767e-05,
      "loss": 0.2184,
      "step": 5389
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.11896254867315292,
      "learning_rate": 2.7776030627902873e-05,
      "loss": 0.4451,
      "step": 5390
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.13557104766368866,
      "learning_rate": 2.774518209216964e-05,
      "loss": 0.1948,
      "step": 5391
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1707778126001358,
      "learning_rate": 2.771434793695363e-05,
      "loss": 0.28,
      "step": 5392
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.18575802445411682,
      "learning_rate": 2.768352816839168e-05,
      "loss": 0.292,
      "step": 5393
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.17491723597049713,
      "learning_rate": 2.7652722792617657e-05,
      "loss": 0.2499,
      "step": 5394
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.14741294085979462,
      "learning_rate": 2.7621931815762614e-05,
      "loss": 0.2924,
      "step": 5395
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1637730747461319,
      "learning_rate": 2.7591155243954682e-05,
      "loss": 0.2424,
      "step": 5396
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.4782281219959259,
      "learning_rate": 2.7560393083319235e-05,
      "loss": 0.3,
      "step": 5397
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.16651159524917603,
      "learning_rate": 2.752964533997866e-05,
      "loss": 0.3028,
      "step": 5398
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.13110166788101196,
      "learning_rate": 2.749891202005258e-05,
      "loss": 0.2174,
      "step": 5399
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1357114017009735,
      "learning_rate": 2.7468193129657627e-05,
      "loss": 0.2424,
      "step": 5400
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.14599142968654633,
      "learning_rate": 2.7437488674907707e-05,
      "loss": 0.2666,
      "step": 5401
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1513800024986267,
      "learning_rate": 2.7406798661913725e-05,
      "loss": 0.2365,
      "step": 5402
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.18236170709133148,
      "learning_rate": 2.737612309678378e-05,
      "loss": 0.3021,
      "step": 5403
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.16131827235221863,
      "learning_rate": 2.7345461985623046e-05,
      "loss": 0.2479,
      "step": 5404
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.16416753828525543,
      "learning_rate": 2.7314815334533893e-05,
      "loss": 0.3152,
      "step": 5405
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.14052902162075043,
      "learning_rate": 2.7284183149615728e-05,
      "loss": 0.2214,
      "step": 5406
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1456676721572876,
      "learning_rate": 2.725356543696519e-05,
      "loss": 0.2441,
      "step": 5407
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.16118548810482025,
      "learning_rate": 2.7222962202675885e-05,
      "loss": 0.2774,
      "step": 5408
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1695701777935028,
      "learning_rate": 2.7192373452838705e-05,
      "loss": 0.238,
      "step": 5409
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.16714230179786682,
      "learning_rate": 2.7161799193541525e-05,
      "loss": 0.2437,
      "step": 5410
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.20659518241882324,
      "learning_rate": 2.7131239430869416e-05,
      "loss": 0.3269,
      "step": 5411
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.17952224612236023,
      "learning_rate": 2.7100694170904482e-05,
      "loss": 0.373,
      "step": 5412
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.12441334873437881,
      "learning_rate": 2.7070163419726068e-05,
      "loss": 0.2148,
      "step": 5413
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1637352705001831,
      "learning_rate": 2.7039647183410487e-05,
      "loss": 0.2759,
      "step": 5414
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.19892367720603943,
      "learning_rate": 2.7009145468031306e-05,
      "loss": 0.4347,
      "step": 5415
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.17142876982688904,
      "learning_rate": 2.6978658279659052e-05,
      "loss": 0.2604,
      "step": 5416
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1568078249692917,
      "learning_rate": 2.694818562436152e-05,
      "loss": 0.2517,
      "step": 5417
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1748574823141098,
      "learning_rate": 2.6917727508203484e-05,
      "loss": 0.2694,
      "step": 5418
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.16966348886489868,
      "learning_rate": 2.688728393724689e-05,
      "loss": 0.226,
      "step": 5419
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.14599938690662384,
      "learning_rate": 2.6856854917550745e-05,
      "loss": 0.3311,
      "step": 5420
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.14380842447280884,
      "learning_rate": 2.6826440455171176e-05,
      "loss": 0.2087,
      "step": 5421
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1284792721271515,
      "learning_rate": 2.6796040556161483e-05,
      "loss": 0.1885,
      "step": 5422
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1569969207048416,
      "learning_rate": 2.676565522657193e-05,
      "loss": 0.2787,
      "step": 5423
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.21697232127189636,
      "learning_rate": 2.673528447245003e-05,
      "loss": 0.2945,
      "step": 5424
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.17591255903244019,
      "learning_rate": 2.670492829984026e-05,
      "loss": 0.2762,
      "step": 5425
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.15609034895896912,
      "learning_rate": 2.6674586714784323e-05,
      "loss": 0.2986,
      "step": 5426
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.17663636803627014,
      "learning_rate": 2.6644259723320908e-05,
      "loss": 0.2486,
      "step": 5427
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.18549855053424835,
      "learning_rate": 2.6613947331485868e-05,
      "loss": 0.274,
      "step": 5428
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.17665721476078033,
      "learning_rate": 2.6583649545312085e-05,
      "loss": 0.2716,
      "step": 5429
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1430746167898178,
      "learning_rate": 2.6553366370829634e-05,
      "loss": 0.2252,
      "step": 5430
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.18118129670619965,
      "learning_rate": 2.652309781406558e-05,
      "loss": 0.2625,
      "step": 5431
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1435779631137848,
      "learning_rate": 2.6492843881044172e-05,
      "loss": 0.2624,
      "step": 5432
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1598609834909439,
      "learning_rate": 2.6462604577786632e-05,
      "loss": 0.2606,
      "step": 5433
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.14589042961597443,
      "learning_rate": 2.643237991031141e-05,
      "loss": 0.2469,
      "step": 5434
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.19621199369430542,
      "learning_rate": 2.6402169884633944e-05,
      "loss": 0.3209,
      "step": 5435
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1852237433195114,
      "learning_rate": 2.637197450676677e-05,
      "loss": 0.2857,
      "step": 5436
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.13911867141723633,
      "learning_rate": 2.6341793782719504e-05,
      "loss": 0.2126,
      "step": 5437
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.155852273106575,
      "learning_rate": 2.631162771849893e-05,
      "loss": 0.2446,
      "step": 5438
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.16604314744472504,
      "learning_rate": 2.6281476320108787e-05,
      "loss": 0.3014,
      "step": 5439
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.17496486008167267,
      "learning_rate": 2.6251339593550007e-05,
      "loss": 0.2907,
      "step": 5440
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.17964179813861847,
      "learning_rate": 2.6221217544820508e-05,
      "loss": 0.3545,
      "step": 5441
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.15169395506381989,
      "learning_rate": 2.619111017991539e-05,
      "loss": 0.2442,
      "step": 5442
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.16315199434757233,
      "learning_rate": 2.6161017504826736e-05,
      "loss": 0.3093,
      "step": 5443
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.20088541507720947,
      "learning_rate": 2.613093952554373e-05,
      "loss": 0.3887,
      "step": 5444
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.16890069842338562,
      "learning_rate": 2.610087624805264e-05,
      "loss": 0.2544,
      "step": 5445
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.18512152135372162,
      "learning_rate": 2.607082767833685e-05,
      "loss": 0.2717,
      "step": 5446
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1851019263267517,
      "learning_rate": 2.604079382237672e-05,
      "loss": 0.2392,
      "step": 5447
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.12363296747207642,
      "learning_rate": 2.6010774686149807e-05,
      "loss": 0.2026,
      "step": 5448
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.1744290441274643,
      "learning_rate": 2.5980770275630638e-05,
      "loss": 0.3047,
      "step": 5449
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.13684681057929993,
      "learning_rate": 2.5950780596790813e-05,
      "loss": 0.2019,
      "step": 5450
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1453327238559723,
      "learning_rate": 2.5920805655599078e-05,
      "loss": 0.2347,
      "step": 5451
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1876239776611328,
      "learning_rate": 2.5890845458021183e-05,
      "loss": 0.3528,
      "step": 5452
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.15684694051742554,
      "learning_rate": 2.586090001001994e-05,
      "loss": 0.2973,
      "step": 5453
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.17149564623832703,
      "learning_rate": 2.5830969317555233e-05,
      "loss": 0.3033,
      "step": 5454
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.15936990082263947,
      "learning_rate": 2.5801053386584052e-05,
      "loss": 0.2984,
      "step": 5455
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.17888925969600677,
      "learning_rate": 2.577115222306038e-05,
      "loss": 0.3293,
      "step": 5456
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.15577545762062073,
      "learning_rate": 2.5741265832935346e-05,
      "loss": 0.2774,
      "step": 5457
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.20167188346385956,
      "learning_rate": 2.5711394222157036e-05,
      "loss": 0.3234,
      "step": 5458
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.17572852969169617,
      "learning_rate": 2.5681537396670695e-05,
      "loss": 0.2562,
      "step": 5459
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1744759976863861,
      "learning_rate": 2.565169536241857e-05,
      "loss": 0.2899,
      "step": 5460
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.21787559986114502,
      "learning_rate": 2.5621868125339953e-05,
      "loss": 0.2942,
      "step": 5461
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.16434337198734283,
      "learning_rate": 2.5592055691371187e-05,
      "loss": 0.2714,
      "step": 5462
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1465805023908615,
      "learning_rate": 2.5562258066445753e-05,
      "loss": 0.2847,
      "step": 5463
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.13739730417728424,
      "learning_rate": 2.553247525649407e-05,
      "loss": 0.2764,
      "step": 5464
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.17134281992912292,
      "learning_rate": 2.5502707267443716e-05,
      "loss": 0.2626,
      "step": 5465
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.144966259598732,
      "learning_rate": 2.5472954105219204e-05,
      "loss": 0.2628,
      "step": 5466
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.26818257570266724,
      "learning_rate": 2.5443215775742224e-05,
      "loss": 0.3661,
      "step": 5467
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.19026392698287964,
      "learning_rate": 2.541349228493142e-05,
      "loss": 0.2695,
      "step": 5468
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.19745175540447235,
      "learning_rate": 2.5383783638702496e-05,
      "loss": 0.3294,
      "step": 5469
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.12850531935691833,
      "learning_rate": 2.535408984296821e-05,
      "loss": 0.2153,
      "step": 5470
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.18101778626441956,
      "learning_rate": 2.5324410903638406e-05,
      "loss": 0.3286,
      "step": 5471
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1543479710817337,
      "learning_rate": 2.5294746826619886e-05,
      "loss": 0.2928,
      "step": 5472
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.18181489408016205,
      "learning_rate": 2.52650976178166e-05,
      "loss": 0.2442,
      "step": 5473
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1695728600025177,
      "learning_rate": 2.5235463283129434e-05,
      "loss": 0.3019,
      "step": 5474
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.16827890276908875,
      "learning_rate": 2.5205843828456443e-05,
      "loss": 0.3261,
      "step": 5475
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.17161999642848969,
      "learning_rate": 2.5176239259692524e-05,
      "loss": 0.2412,
      "step": 5476
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.14600443840026855,
      "learning_rate": 2.514664958272982e-05,
      "loss": 0.2588,
      "step": 5477
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.16768789291381836,
      "learning_rate": 2.511707480345734e-05,
      "loss": 0.285,
      "step": 5478
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1527300328016281,
      "learning_rate": 2.508751492776129e-05,
      "loss": 0.2471,
      "step": 5479
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.19164279103279114,
      "learning_rate": 2.5057969961524773e-05,
      "loss": 0.345,
      "step": 5480
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1655353456735611,
      "learning_rate": 2.5028439910627967e-05,
      "loss": 0.3275,
      "step": 5481
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.17682208120822906,
      "learning_rate": 2.499892478094813e-05,
      "loss": 0.4252,
      "step": 5482
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.150242879986763,
      "learning_rate": 2.49694245783595e-05,
      "loss": 0.2616,
      "step": 5483
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.16285981237888336,
      "learning_rate": 2.493993930873335e-05,
      "loss": 0.3844,
      "step": 5484
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.14433686435222626,
      "learning_rate": 2.491046897793795e-05,
      "loss": 0.2616,
      "step": 5485
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.1420111209154129,
      "learning_rate": 2.4881013591838698e-05,
      "loss": 0.2326,
      "step": 5486
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1484519988298416,
      "learning_rate": 2.485157315629789e-05,
      "loss": 0.2357,
      "step": 5487
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.18465553224086761,
      "learning_rate": 2.482214767717498e-05,
      "loss": 0.3285,
      "step": 5488
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1657891869544983,
      "learning_rate": 2.4792737160326307e-05,
      "loss": 0.3046,
      "step": 5489
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1271953284740448,
      "learning_rate": 2.4763341611605363e-05,
      "loss": 0.2083,
      "step": 5490
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14022614061832428,
      "learning_rate": 2.4733961036862563e-05,
      "loss": 0.252,
      "step": 5491
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.13692913949489594,
      "learning_rate": 2.4704595441945376e-05,
      "loss": 0.2183,
      "step": 5492
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14650870859622955,
      "learning_rate": 2.4675244832698264e-05,
      "loss": 0.2509,
      "step": 5493
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.16422908008098602,
      "learning_rate": 2.464590921496279e-05,
      "loss": 0.333,
      "step": 5494
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.16968564689159393,
      "learning_rate": 2.4616588594577428e-05,
      "loss": 0.2246,
      "step": 5495
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14098778367042542,
      "learning_rate": 2.4587282977377767e-05,
      "loss": 0.2165,
      "step": 5496
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.15919870138168335,
      "learning_rate": 2.455799236919629e-05,
      "loss": 0.3343,
      "step": 5497
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.17159098386764526,
      "learning_rate": 2.4528716775862625e-05,
      "loss": 0.3159,
      "step": 5498
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1551104635000229,
      "learning_rate": 2.449945620320333e-05,
      "loss": 0.254,
      "step": 5499
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.18916140496730804,
      "learning_rate": 2.4470210657041982e-05,
      "loss": 0.3152,
      "step": 5500
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14263643324375153,
      "learning_rate": 2.4440980143199153e-05,
      "loss": 0.2317,
      "step": 5501
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14438332617282867,
      "learning_rate": 2.4411764667492487e-05,
      "loss": 0.2921,
      "step": 5502
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.17000305652618408,
      "learning_rate": 2.438256423573656e-05,
      "loss": 0.2828,
      "step": 5503
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.17835769057273865,
      "learning_rate": 2.4353378853743037e-05,
      "loss": 0.3241,
      "step": 5504
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.16891250014305115,
      "learning_rate": 2.432420852732048e-05,
      "loss": 0.2581,
      "step": 5505
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14099326729774475,
      "learning_rate": 2.429505326227457e-05,
      "loss": 0.2299,
      "step": 5506
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.16251111030578613,
      "learning_rate": 2.4265913064407918e-05,
      "loss": 0.2791,
      "step": 5507
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14191727340221405,
      "learning_rate": 2.4236787939520135e-05,
      "loss": 0.24,
      "step": 5508
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1798502802848816,
      "learning_rate": 2.420767789340783e-05,
      "loss": 0.2884,
      "step": 5509
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.16274575889110565,
      "learning_rate": 2.4178582931864703e-05,
      "loss": 0.2833,
      "step": 5510
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.16689661145210266,
      "learning_rate": 2.4149503060681323e-05,
      "loss": 0.2712,
      "step": 5511
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.20596452057361603,
      "learning_rate": 2.4120438285645298e-05,
      "loss": 0.3647,
      "step": 5512
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1706531047821045,
      "learning_rate": 2.40913886125413e-05,
      "loss": 0.3355,
      "step": 5513
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1244746670126915,
      "learning_rate": 2.406235404715089e-05,
      "loss": 0.2008,
      "step": 5514
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.1671217828989029,
      "learning_rate": 2.403333459525272e-05,
      "loss": 0.3127,
      "step": 5515
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.15920385718345642,
      "learning_rate": 2.4004330262622378e-05,
      "loss": 0.2666,
      "step": 5516
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.2001011073589325,
      "learning_rate": 2.397534105503243e-05,
      "loss": 0.2385,
      "step": 5517
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.15688960254192352,
      "learning_rate": 2.3946366978252434e-05,
      "loss": 0.3148,
      "step": 5518
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.18351568281650543,
      "learning_rate": 2.3917408038049006e-05,
      "loss": 0.2892,
      "step": 5519
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.16406409442424774,
      "learning_rate": 2.388846424018566e-05,
      "loss": 0.2499,
      "step": 5520
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.14567141234874725,
      "learning_rate": 2.3859535590422977e-05,
      "loss": 0.228,
      "step": 5521
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.19012506306171417,
      "learning_rate": 2.383062209451844e-05,
      "loss": 0.2682,
      "step": 5522
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1685197502374649,
      "learning_rate": 2.38017237582266e-05,
      "loss": 0.2843,
      "step": 5523
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1885470449924469,
      "learning_rate": 2.377284058729894e-05,
      "loss": 0.3589,
      "step": 5524
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.13515383005142212,
      "learning_rate": 2.374397258748391e-05,
      "loss": 0.2303,
      "step": 5525
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.20282065868377686,
      "learning_rate": 2.3715119764526962e-05,
      "loss": 0.2961,
      "step": 5526
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.19267123937606812,
      "learning_rate": 2.3686282124170556e-05,
      "loss": 0.3278,
      "step": 5527
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.16077366471290588,
      "learning_rate": 2.365745967215407e-05,
      "loss": 0.24,
      "step": 5528
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1545446366071701,
      "learning_rate": 2.3628652414213946e-05,
      "loss": 0.2927,
      "step": 5529
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.19468112289905548,
      "learning_rate": 2.3599860356083504e-05,
      "loss": 0.358,
      "step": 5530
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.14390058815479279,
      "learning_rate": 2.3571083503493106e-05,
      "loss": 0.2497,
      "step": 5531
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.167350172996521,
      "learning_rate": 2.354232186217008e-05,
      "loss": 0.3165,
      "step": 5532
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.19562019407749176,
      "learning_rate": 2.3513575437838675e-05,
      "loss": 0.2992,
      "step": 5533
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.12517961859703064,
      "learning_rate": 2.3484844236220148e-05,
      "loss": 0.2397,
      "step": 5534
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.2525912821292877,
      "learning_rate": 2.3456128263032774e-05,
      "loss": 0.3784,
      "step": 5535
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.17250336706638336,
      "learning_rate": 2.3427427523991684e-05,
      "loss": 0.3052,
      "step": 5536
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.16532303392887115,
      "learning_rate": 2.3398742024809116e-05,
      "loss": 0.3145,
      "step": 5537
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.14462034404277802,
      "learning_rate": 2.3370071771194146e-05,
      "loss": 0.2759,
      "step": 5538
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.18903328478336334,
      "learning_rate": 2.334141676885292e-05,
      "loss": 0.3226,
      "step": 5539
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.18029280006885529,
      "learning_rate": 2.3312777023488463e-05,
      "loss": 0.2577,
      "step": 5540
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.14831823110580444,
      "learning_rate": 2.3284152540800818e-05,
      "loss": 0.2426,
      "step": 5541
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.15305456519126892,
      "learning_rate": 2.325554332648697e-05,
      "loss": 0.2665,
      "step": 5542
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.23496001958847046,
      "learning_rate": 2.3226949386240837e-05,
      "loss": 0.3917,
      "step": 5543
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.13877075910568237,
      "learning_rate": 2.3198370725753394e-05,
      "loss": 0.2414,
      "step": 5544
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.14578256011009216,
      "learning_rate": 2.3169807350712435e-05,
      "loss": 0.2434,
      "step": 5545
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1717572957277298,
      "learning_rate": 2.3141259266802862e-05,
      "loss": 0.2684,
      "step": 5546
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1777443140745163,
      "learning_rate": 2.3112726479706394e-05,
      "loss": 0.3698,
      "step": 5547
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1532997488975525,
      "learning_rate": 2.3084208995101818e-05,
      "loss": 0.2753,
      "step": 5548
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.23474697768688202,
      "learning_rate": 2.3055706818664814e-05,
      "loss": 0.3176,
      "step": 5549
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.21156691014766693,
      "learning_rate": 2.3027219956068023e-05,
      "loss": 0.3213,
      "step": 5550
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.19393488764762878,
      "learning_rate": 2.299874841298101e-05,
      "loss": 0.2908,
      "step": 5551
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1421230584383011,
      "learning_rate": 2.2970292195070387e-05,
      "loss": 0.2172,
      "step": 5552
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.17421676218509674,
      "learning_rate": 2.2941851307999585e-05,
      "loss": 0.2992,
      "step": 5553
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.16021710634231567,
      "learning_rate": 2.291342575742913e-05,
      "loss": 0.2872,
      "step": 5554
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.14353053271770477,
      "learning_rate": 2.2885015549016354e-05,
      "loss": 0.2834,
      "step": 5555
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.13471606373786926,
      "learning_rate": 2.2856620688415676e-05,
      "loss": 0.3073,
      "step": 5556
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.16983479261398315,
      "learning_rate": 2.2828241181278276e-05,
      "loss": 0.2776,
      "step": 5557
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.20449978113174438,
      "learning_rate": 2.279987703325247e-05,
      "loss": 0.3354,
      "step": 5558
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1633235365152359,
      "learning_rate": 2.2771528249983377e-05,
      "loss": 0.2587,
      "step": 5559
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.12662792205810547,
      "learning_rate": 2.274319483711318e-05,
      "loss": 0.2216,
      "step": 5560
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1949274241924286,
      "learning_rate": 2.271487680028086e-05,
      "loss": 0.3054,
      "step": 5561
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.12173739075660706,
      "learning_rate": 2.2686574145122497e-05,
      "loss": 0.2721,
      "step": 5562
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.2354026883840561,
      "learning_rate": 2.2658286877270974e-05,
      "loss": 0.3476,
      "step": 5563
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.14190681278705597,
      "learning_rate": 2.2630015002356188e-05,
      "loss": 0.2758,
      "step": 5564
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.14330661296844482,
      "learning_rate": 2.26017585260049e-05,
      "loss": 0.2205,
      "step": 5565
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.16000619530677795,
      "learning_rate": 2.257351745384094e-05,
      "loss": 0.2715,
      "step": 5566
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1820695847272873,
      "learning_rate": 2.25452917914849e-05,
      "loss": 0.3395,
      "step": 5567
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.14278873801231384,
      "learning_rate": 2.2517081544554476e-05,
      "loss": 0.27,
      "step": 5568
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.16958297789096832,
      "learning_rate": 2.2488886718664148e-05,
      "loss": 0.3394,
      "step": 5569
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1965220421552658,
      "learning_rate": 2.2460707319425444e-05,
      "loss": 0.2866,
      "step": 5570
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.16376899182796478,
      "learning_rate": 2.2432543352446743e-05,
      "loss": 0.3145,
      "step": 5571
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.16436108946800232,
      "learning_rate": 2.2404394823333374e-05,
      "loss": 0.2673,
      "step": 5572
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1896980106830597,
      "learning_rate": 2.237626173768762e-05,
      "loss": 0.2958,
      "step": 5573
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.17592567205429077,
      "learning_rate": 2.2348144101108616e-05,
      "loss": 0.3022,
      "step": 5574
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1854444295167923,
      "learning_rate": 2.2320041919192547e-05,
      "loss": 0.3354,
      "step": 5575
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.17997054755687714,
      "learning_rate": 2.229195519753239e-05,
      "loss": 0.2705,
      "step": 5576
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.23260922729969025,
      "learning_rate": 2.2263883941718155e-05,
      "loss": 0.3329,
      "step": 5577
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.15275125205516815,
      "learning_rate": 2.223582815733668e-05,
      "loss": 0.2584,
      "step": 5578
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.14763101935386658,
      "learning_rate": 2.220778784997182e-05,
      "loss": 0.2448,
      "step": 5579
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.17586098611354828,
      "learning_rate": 2.217976302520427e-05,
      "loss": 0.3198,
      "step": 5580
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.14720949530601501,
      "learning_rate": 2.2151753688611665e-05,
      "loss": 0.2784,
      "step": 5581
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.17435850203037262,
      "learning_rate": 2.2123759845768555e-05,
      "loss": 0.3182,
      "step": 5582
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1830746829509735,
      "learning_rate": 2.209578150224645e-05,
      "loss": 0.319,
      "step": 5583
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.14395183324813843,
      "learning_rate": 2.2067818663613683e-05,
      "loss": 0.2223,
      "step": 5584
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1510954648256302,
      "learning_rate": 2.2039871335435635e-05,
      "loss": 0.2487,
      "step": 5585
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.14893458783626556,
      "learning_rate": 2.201193952327446e-05,
      "loss": 0.2574,
      "step": 5586
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.15665507316589355,
      "learning_rate": 2.1984023232689334e-05,
      "loss": 0.2847,
      "step": 5587
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.1695677489042282,
      "learning_rate": 2.1956122469236285e-05,
      "loss": 0.3103,
      "step": 5588
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.17159634828567505,
      "learning_rate": 2.192823723846825e-05,
      "loss": 0.2806,
      "step": 5589
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.13594168424606323,
      "learning_rate": 2.1900367545935063e-05,
      "loss": 0.2334,
      "step": 5590
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.2549445629119873,
      "learning_rate": 2.1872513397183547e-05,
      "loss": 0.3145,
      "step": 5591
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.11800217628479004,
      "learning_rate": 2.1844674797757324e-05,
      "loss": 0.2159,
      "step": 5592
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.23393851518630981,
      "learning_rate": 2.181685175319702e-05,
      "loss": 0.4634,
      "step": 5593
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.16171430051326752,
      "learning_rate": 2.178904426904007e-05,
      "loss": 0.2346,
      "step": 5594
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.19427555799484253,
      "learning_rate": 2.1761252350820914e-05,
      "loss": 0.2926,
      "step": 5595
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1629563868045807,
      "learning_rate": 2.173347600407081e-05,
      "loss": 0.2967,
      "step": 5596
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.15419745445251465,
      "learning_rate": 2.1705715234317935e-05,
      "loss": 0.2891,
      "step": 5597
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.14454969763755798,
      "learning_rate": 2.167797004708736e-05,
      "loss": 0.2358,
      "step": 5598
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1468920111656189,
      "learning_rate": 2.1650240447901127e-05,
      "loss": 0.2371,
      "step": 5599
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.13011202216148376,
      "learning_rate": 2.1622526442278067e-05,
      "loss": 0.2561,
      "step": 5600
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.21200056374073029,
      "learning_rate": 2.1594828035734005e-05,
      "loss": 0.3382,
      "step": 5601
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1689589023590088,
      "learning_rate": 2.1567145233781604e-05,
      "loss": 0.2567,
      "step": 5602
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.15683689713478088,
      "learning_rate": 2.1539478041930393e-05,
      "loss": 0.2765,
      "step": 5603
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.153503879904747,
      "learning_rate": 2.1511826465686914e-05,
      "loss": 0.3027,
      "step": 5604
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.16702693700790405,
      "learning_rate": 2.1484190510554458e-05,
      "loss": 0.2672,
      "step": 5605
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.18685278296470642,
      "learning_rate": 2.1456570182033308e-05,
      "loss": 0.3497,
      "step": 5606
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1520567536354065,
      "learning_rate": 2.1428965485620555e-05,
      "loss": 0.2401,
      "step": 5607
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1405232846736908,
      "learning_rate": 2.1401376426810282e-05,
      "loss": 0.227,
      "step": 5608
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.16608959436416626,
      "learning_rate": 2.1373803011093353e-05,
      "loss": 0.3039,
      "step": 5609
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.14023457467556,
      "learning_rate": 2.1346245243957607e-05,
      "loss": 0.269,
      "step": 5610
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1804310828447342,
      "learning_rate": 2.1318703130887686e-05,
      "loss": 0.3178,
      "step": 5611
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1421067863702774,
      "learning_rate": 2.1291176677365222e-05,
      "loss": 0.2378,
      "step": 5612
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.16507911682128906,
      "learning_rate": 2.1263665888868635e-05,
      "loss": 0.2284,
      "step": 5613
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.15346914529800415,
      "learning_rate": 2.1236170770873243e-05,
      "loss": 0.2609,
      "step": 5614
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.19659192860126495,
      "learning_rate": 2.120869132885126e-05,
      "loss": 0.3267,
      "step": 5615
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.15515322983264923,
      "learning_rate": 2.1181227568271833e-05,
      "loss": 0.3046,
      "step": 5616
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.18362189829349518,
      "learning_rate": 2.1153779494600868e-05,
      "loss": 0.2872,
      "step": 5617
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.13781869411468506,
      "learning_rate": 2.1126347113301292e-05,
      "loss": 0.239,
      "step": 5618
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.14405792951583862,
      "learning_rate": 2.1098930429832765e-05,
      "loss": 0.2247,
      "step": 5619
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.16283906996250153,
      "learning_rate": 2.1071529449651962e-05,
      "loss": 0.3201,
      "step": 5620
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.12286626547574997,
      "learning_rate": 2.104414417821233e-05,
      "loss": 0.2106,
      "step": 5621
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.170738086104393,
      "learning_rate": 2.1016774620964218e-05,
      "loss": 0.2692,
      "step": 5622
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.15800000727176666,
      "learning_rate": 2.098942078335483e-05,
      "loss": 0.2688,
      "step": 5623
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.11484528332948685,
      "learning_rate": 2.096208267082833e-05,
      "loss": 0.1725,
      "step": 5624
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.15115498006343842,
      "learning_rate": 2.0934760288825616e-05,
      "loss": 0.2799,
      "step": 5625
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.14554950594902039,
      "learning_rate": 2.090745364278458e-05,
      "loss": 0.2703,
      "step": 5626
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1316293478012085,
      "learning_rate": 2.0880162738139886e-05,
      "loss": 0.2224,
      "step": 5627
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.14621905982494354,
      "learning_rate": 2.0852887580323156e-05,
      "loss": 0.2654,
      "step": 5628
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1654478758573532,
      "learning_rate": 2.08256281747628e-05,
      "loss": 0.3147,
      "step": 5629
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.18574883043766022,
      "learning_rate": 2.079838452688412e-05,
      "loss": 0.2937,
      "step": 5630
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16796323657035828,
      "learning_rate": 2.0771156642109258e-05,
      "loss": 0.318,
      "step": 5631
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1691562682390213,
      "learning_rate": 2.0743944525857305e-05,
      "loss": 0.3001,
      "step": 5632
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16128197312355042,
      "learning_rate": 2.071674818354412e-05,
      "loss": 0.2694,
      "step": 5633
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.17307455837726593,
      "learning_rate": 2.068956762058244e-05,
      "loss": 0.2626,
      "step": 5634
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.15193936228752136,
      "learning_rate": 2.0662402842381912e-05,
      "loss": 0.2501,
      "step": 5635
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1730511486530304,
      "learning_rate": 2.0635253854348968e-05,
      "loss": 0.2506,
      "step": 5636
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1591256856918335,
      "learning_rate": 2.060812066188701e-05,
      "loss": 0.2758,
      "step": 5637
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.20348691940307617,
      "learning_rate": 2.0581003270396115e-05,
      "loss": 0.2255,
      "step": 5638
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.22290772199630737,
      "learning_rate": 2.05539016852734e-05,
      "loss": 0.2487,
      "step": 5639
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1450284719467163,
      "learning_rate": 2.0526815911912722e-05,
      "loss": 0.2531,
      "step": 5640
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1748490333557129,
      "learning_rate": 2.0499745955704865e-05,
      "loss": 0.275,
      "step": 5641
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16910399496555328,
      "learning_rate": 2.047269182203737e-05,
      "loss": 0.246,
      "step": 5642
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.10687598586082458,
      "learning_rate": 2.044565351629476e-05,
      "loss": 0.1802,
      "step": 5643
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1990787237882614,
      "learning_rate": 2.041863104385826e-05,
      "loss": 0.2841,
      "step": 5644
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1632084995508194,
      "learning_rate": 2.0391624410106125e-05,
      "loss": 0.3249,
      "step": 5645
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.148289754986763,
      "learning_rate": 2.036463362041321e-05,
      "loss": 0.2192,
      "step": 5646
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.2295958250761032,
      "learning_rate": 2.033765868015146e-05,
      "loss": 0.3171,
      "step": 5647
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16750922799110413,
      "learning_rate": 2.031069959468951e-05,
      "loss": 0.24,
      "step": 5648
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.18547189235687256,
      "learning_rate": 2.028375636939295e-05,
      "loss": 0.2755,
      "step": 5649
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16606265306472778,
      "learning_rate": 2.0256829009624078e-05,
      "loss": 0.2764,
      "step": 5650
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16358043253421783,
      "learning_rate": 2.0229917520742192e-05,
      "loss": 0.3117,
      "step": 5651
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.13256597518920898,
      "learning_rate": 2.0203021908103315e-05,
      "loss": 0.2138,
      "step": 5652
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.20527124404907227,
      "learning_rate": 2.017614217706034e-05,
      "loss": 0.3376,
      "step": 5653
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.14984294772148132,
      "learning_rate": 2.0149278332962997e-05,
      "loss": 0.2603,
      "step": 5654
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16879871487617493,
      "learning_rate": 2.01224303811579e-05,
      "loss": 0.334,
      "step": 5655
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.16617774963378906,
      "learning_rate": 2.009559832698842e-05,
      "loss": 0.2796,
      "step": 5656
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.18368571996688843,
      "learning_rate": 2.0068782175794855e-05,
      "loss": 0.3103,
      "step": 5657
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1505439430475235,
      "learning_rate": 2.0041981932914245e-05,
      "loss": 0.2767,
      "step": 5658
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.19305765628814697,
      "learning_rate": 2.0015197603680557e-05,
      "loss": 0.2954,
      "step": 5659
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.21481376886367798,
      "learning_rate": 1.9988429193424506e-05,
      "loss": 0.326,
      "step": 5660
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.14743714034557343,
      "learning_rate": 1.9961676707473698e-05,
      "loss": 0.2565,
      "step": 5661
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.15458247065544128,
      "learning_rate": 1.9934940151152505e-05,
      "loss": 0.2878,
      "step": 5662
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.1462622433900833,
      "learning_rate": 1.9908219529782224e-05,
      "loss": 0.2711,
      "step": 5663
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.14728480577468872,
      "learning_rate": 1.9881514848680915e-05,
      "loss": 0.2331,
      "step": 5664
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.15018169581890106,
      "learning_rate": 1.985482611316344e-05,
      "loss": 0.2898,
      "step": 5665
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1500205248594284,
      "learning_rate": 1.9828153328541565e-05,
      "loss": 0.294,
      "step": 5666
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.14052249491214752,
      "learning_rate": 1.9801496500123816e-05,
      "loss": 0.2181,
      "step": 5667
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.17413483560085297,
      "learning_rate": 1.9774855633215607e-05,
      "loss": 0.2961,
      "step": 5668
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.16371046006679535,
      "learning_rate": 1.9748230733119112e-05,
      "loss": 0.251,
      "step": 5669
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.13565045595169067,
      "learning_rate": 1.972162180513335e-05,
      "loss": 0.2301,
      "step": 5670
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1737726777791977,
      "learning_rate": 1.9695028854554143e-05,
      "loss": 0.2972,
      "step": 5671
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.17185726761817932,
      "learning_rate": 1.966845188667421e-05,
      "loss": 0.3506,
      "step": 5672
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1348239630460739,
      "learning_rate": 1.9641890906782968e-05,
      "loss": 0.2421,
      "step": 5673
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1573084443807602,
      "learning_rate": 1.9615345920166783e-05,
      "loss": 0.3119,
      "step": 5674
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.15042121708393097,
      "learning_rate": 1.958881693210871e-05,
      "loss": 0.2355,
      "step": 5675
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.18005134165287018,
      "learning_rate": 1.9562303947888726e-05,
      "loss": 0.2868,
      "step": 5676
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.10645134001970291,
      "learning_rate": 1.9535806972783577e-05,
      "loss": 0.2273,
      "step": 5677
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.169367253780365,
      "learning_rate": 1.950932601206681e-05,
      "loss": 0.2907,
      "step": 5678
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.14431026577949524,
      "learning_rate": 1.9482861071008764e-05,
      "loss": 0.2059,
      "step": 5679
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1401616632938385,
      "learning_rate": 1.945641215487669e-05,
      "loss": 0.2339,
      "step": 5680
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.277900367975235,
      "learning_rate": 1.9429979268934517e-05,
      "loss": 0.3591,
      "step": 5681
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.149418905377388,
      "learning_rate": 1.9403562418443134e-05,
      "loss": 0.1905,
      "step": 5682
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.14834915101528168,
      "learning_rate": 1.9377161608660066e-05,
      "loss": 0.2725,
      "step": 5683
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.14097227156162262,
      "learning_rate": 1.9350776844839812e-05,
      "loss": 0.1804,
      "step": 5684
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.15491056442260742,
      "learning_rate": 1.9324408132233562e-05,
      "loss": 0.2931,
      "step": 5685
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.18087239563465118,
      "learning_rate": 1.929805547608936e-05,
      "loss": 0.259,
      "step": 5686
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2011123150587082,
      "learning_rate": 1.9271718881652014e-05,
      "loss": 0.351,
      "step": 5687
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.19269034266471863,
      "learning_rate": 1.9245398354163203e-05,
      "loss": 0.3161,
      "step": 5688
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.18758586049079895,
      "learning_rate": 1.921909389886134e-05,
      "loss": 0.3825,
      "step": 5689
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1523495763540268,
      "learning_rate": 1.9192805520981716e-05,
      "loss": 0.2892,
      "step": 5690
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.16357535123825073,
      "learning_rate": 1.916653322575632e-05,
      "loss": 0.2994,
      "step": 5691
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.13488887250423431,
      "learning_rate": 1.9140277018414043e-05,
      "loss": 0.2123,
      "step": 5692
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1619752049446106,
      "learning_rate": 1.911403690418052e-05,
      "loss": 0.2575,
      "step": 5693
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.19255037605762482,
      "learning_rate": 1.908781288827818e-05,
      "loss": 0.263,
      "step": 5694
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1519818902015686,
      "learning_rate": 1.906160497592625e-05,
      "loss": 0.2961,
      "step": 5695
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.16198675334453583,
      "learning_rate": 1.9035413172340745e-05,
      "loss": 0.2666,
      "step": 5696
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2125035524368286,
      "learning_rate": 1.900923748273453e-05,
      "loss": 0.2797,
      "step": 5697
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1744663417339325,
      "learning_rate": 1.8983077912317193e-05,
      "loss": 0.3698,
      "step": 5698
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.18451163172721863,
      "learning_rate": 1.8956934466295172e-05,
      "loss": 0.3789,
      "step": 5699
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1524769812822342,
      "learning_rate": 1.8930807149871632e-05,
      "loss": 0.241,
      "step": 5700
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1574368178844452,
      "learning_rate": 1.89046959682466e-05,
      "loss": 0.2801,
      "step": 5701
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.2444712519645691,
      "learning_rate": 1.8878600926616842e-05,
      "loss": 0.3595,
      "step": 5702
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.2047332525253296,
      "learning_rate": 1.885252203017591e-05,
      "loss": 0.4226,
      "step": 5703
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.15072114765644073,
      "learning_rate": 1.882645928411415e-05,
      "loss": 0.2371,
      "step": 5704
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.16230005025863647,
      "learning_rate": 1.880041269361874e-05,
      "loss": 0.2959,
      "step": 5705
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.20368778705596924,
      "learning_rate": 1.8774382263873557e-05,
      "loss": 0.3213,
      "step": 5706
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.18157577514648438,
      "learning_rate": 1.8748368000059347e-05,
      "loss": 0.2525,
      "step": 5707
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.17664265632629395,
      "learning_rate": 1.8722369907353566e-05,
      "loss": 0.3057,
      "step": 5708
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.13872823119163513,
      "learning_rate": 1.869638799093052e-05,
      "loss": 0.1969,
      "step": 5709
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1960989385843277,
      "learning_rate": 1.867042225596125e-05,
      "loss": 0.4446,
      "step": 5710
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.16594772040843964,
      "learning_rate": 1.864447270761358e-05,
      "loss": 0.3254,
      "step": 5711
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.18627801537513733,
      "learning_rate": 1.8618539351052088e-05,
      "loss": 0.2914,
      "step": 5712
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1773284375667572,
      "learning_rate": 1.8592622191438224e-05,
      "loss": 0.3169,
      "step": 5713
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.16775217652320862,
      "learning_rate": 1.8566721233930107e-05,
      "loss": 0.2469,
      "step": 5714
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.10922444611787796,
      "learning_rate": 1.85408364836827e-05,
      "loss": 0.1889,
      "step": 5715
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.15501391887664795,
      "learning_rate": 1.8514967945847683e-05,
      "loss": 0.3288,
      "step": 5716
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.20653194189071655,
      "learning_rate": 1.8489115625573595e-05,
      "loss": 0.2869,
      "step": 5717
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1964302361011505,
      "learning_rate": 1.846327952800566e-05,
      "loss": 0.3017,
      "step": 5718
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.2416910082101822,
      "learning_rate": 1.8437459658285904e-05,
      "loss": 0.3107,
      "step": 5719
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1632777899503708,
      "learning_rate": 1.8411656021553124e-05,
      "loss": 0.3007,
      "step": 5720
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.17097660899162292,
      "learning_rate": 1.8385868622942926e-05,
      "loss": 0.2885,
      "step": 5721
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.13037806749343872,
      "learning_rate": 1.83600974675876e-05,
      "loss": 0.2609,
      "step": 5722
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1564532220363617,
      "learning_rate": 1.833434256061629e-05,
      "loss": 0.3393,
      "step": 5723
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.13938076794147491,
      "learning_rate": 1.8308603907154842e-05,
      "loss": 0.2933,
      "step": 5724
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1281983107328415,
      "learning_rate": 1.8282881512325912e-05,
      "loss": 0.1896,
      "step": 5725
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.17176738381385803,
      "learning_rate": 1.8257175381248927e-05,
      "loss": 0.3322,
      "step": 5726
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.16308727860450745,
      "learning_rate": 1.823148551903996e-05,
      "loss": 0.2699,
      "step": 5727
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1707669198513031,
      "learning_rate": 1.820581193081201e-05,
      "loss": 0.3139,
      "step": 5728
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.17694588005542755,
      "learning_rate": 1.818015462167473e-05,
      "loss": 0.2771,
      "step": 5729
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.15168963372707367,
      "learning_rate": 1.8154513596734602e-05,
      "loss": 0.3432,
      "step": 5730
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1590060144662857,
      "learning_rate": 1.8128888861094784e-05,
      "loss": 0.2415,
      "step": 5731
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.18027867376804352,
      "learning_rate": 1.8103280419855284e-05,
      "loss": 0.2687,
      "step": 5732
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.18351267278194427,
      "learning_rate": 1.8077688278112814e-05,
      "loss": 0.3177,
      "step": 5733
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.14022842049598694,
      "learning_rate": 1.8052112440960845e-05,
      "loss": 0.2937,
      "step": 5734
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.17521637678146362,
      "learning_rate": 1.802655291348957e-05,
      "loss": 0.3084,
      "step": 5735
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.19361673295497894,
      "learning_rate": 1.800100970078604e-05,
      "loss": 0.3236,
      "step": 5736
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.18165142834186554,
      "learning_rate": 1.7975482807933942e-05,
      "loss": 0.3641,
      "step": 5737
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.13776223361492157,
      "learning_rate": 1.7949972240013812e-05,
      "loss": 0.2196,
      "step": 5738
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.14526769518852234,
      "learning_rate": 1.792447800210284e-05,
      "loss": 0.2536,
      "step": 5739
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.19235454499721527,
      "learning_rate": 1.7899000099275076e-05,
      "loss": 0.2977,
      "step": 5740
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.12521794438362122,
      "learning_rate": 1.7873538536601218e-05,
      "loss": 0.2329,
      "step": 5741
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.1089698076248169,
      "learning_rate": 1.7848093319148784e-05,
      "loss": 0.1907,
      "step": 5742
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.16316846013069153,
      "learning_rate": 1.782266445198195e-05,
      "loss": 0.3006,
      "step": 5743
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.1338195949792862,
      "learning_rate": 1.7797251940161773e-05,
      "loss": 0.2248,
      "step": 5744
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21265076100826263,
      "learning_rate": 1.777185578874592e-05,
      "loss": 0.3634,
      "step": 5745
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.15879954397678375,
      "learning_rate": 1.7746476002788905e-05,
      "loss": 0.2888,
      "step": 5746
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.18980737030506134,
      "learning_rate": 1.7721112587341904e-05,
      "loss": 0.3868,
      "step": 5747
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.15780356526374817,
      "learning_rate": 1.7695765547452903e-05,
      "loss": 0.3259,
      "step": 5748
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.20106983184814453,
      "learning_rate": 1.7670434888166587e-05,
      "loss": 0.3065,
      "step": 5749
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.18155303597450256,
      "learning_rate": 1.764512061452439e-05,
      "loss": 0.3285,
      "step": 5750
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.15316922962665558,
      "learning_rate": 1.761982273156445e-05,
      "loss": 0.2625,
      "step": 5751
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.16153444349765778,
      "learning_rate": 1.759454124432174e-05,
      "loss": 0.2657,
      "step": 5752
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.17316153645515442,
      "learning_rate": 1.756927615782786e-05,
      "loss": 0.2886,
      "step": 5753
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.14367206394672394,
      "learning_rate": 1.7544027477111237e-05,
      "loss": 0.2474,
      "step": 5754
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.19003619253635406,
      "learning_rate": 1.751879520719697e-05,
      "loss": 0.338,
      "step": 5755
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.16484704613685608,
      "learning_rate": 1.749357935310688e-05,
      "loss": 0.2834,
      "step": 5756
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.225568026304245,
      "learning_rate": 1.7468379919859613e-05,
      "loss": 0.3169,
      "step": 5757
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.14385312795639038,
      "learning_rate": 1.7443196912470462e-05,
      "loss": 0.2553,
      "step": 5758
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.14878828823566437,
      "learning_rate": 1.741803033595146e-05,
      "loss": 0.2527,
      "step": 5759
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.14574062824249268,
      "learning_rate": 1.739288019531139e-05,
      "loss": 0.2653,
      "step": 5760
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.15675826370716095,
      "learning_rate": 1.736774649555578e-05,
      "loss": 0.298,
      "step": 5761
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.09782113879919052,
      "learning_rate": 1.7342629241686826e-05,
      "loss": 0.1863,
      "step": 5762
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.13900285959243774,
      "learning_rate": 1.7317528438703545e-05,
      "loss": 0.2512,
      "step": 5763
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.15999719500541687,
      "learning_rate": 1.7292444091601566e-05,
      "loss": 0.2479,
      "step": 5764
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.1424470990896225,
      "learning_rate": 1.7267376205373365e-05,
      "loss": 0.2137,
      "step": 5765
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.1674310714006424,
      "learning_rate": 1.7242324785008046e-05,
      "loss": 0.3036,
      "step": 5766
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.1360873281955719,
      "learning_rate": 1.7217289835491458e-05,
      "loss": 0.2354,
      "step": 5767
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.15203523635864258,
      "learning_rate": 1.719227136180618e-05,
      "loss": 0.2367,
      "step": 5768
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.2005993276834488,
      "learning_rate": 1.716726936893155e-05,
      "loss": 0.3147,
      "step": 5769
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.1507319211959839,
      "learning_rate": 1.7142283861843532e-05,
      "loss": 0.3591,
      "step": 5770
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1961357742547989,
      "learning_rate": 1.7117314845514943e-05,
      "loss": 0.3076,
      "step": 5771
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.18158750236034393,
      "learning_rate": 1.709236232491517e-05,
      "loss": 0.2819,
      "step": 5772
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.20276741683483124,
      "learning_rate": 1.706742630501045e-05,
      "loss": 0.3528,
      "step": 5773
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.16413617134094238,
      "learning_rate": 1.7042506790763645e-05,
      "loss": 0.3224,
      "step": 5774
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.16199450194835663,
      "learning_rate": 1.701760378713436e-05,
      "loss": 0.2987,
      "step": 5775
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.16721364855766296,
      "learning_rate": 1.6992717299078898e-05,
      "loss": 0.2777,
      "step": 5776
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.11706220358610153,
      "learning_rate": 1.6967847331550345e-05,
      "loss": 0.1971,
      "step": 5777
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.12023631483316422,
      "learning_rate": 1.6942993889498383e-05,
      "loss": 0.2406,
      "step": 5778
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.15149618685245514,
      "learning_rate": 1.6918156977869535e-05,
      "loss": 0.3338,
      "step": 5779
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.14793340861797333,
      "learning_rate": 1.6893336601606914e-05,
      "loss": 0.279,
      "step": 5780
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1601419746875763,
      "learning_rate": 1.6868532765650435e-05,
      "loss": 0.2519,
      "step": 5781
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1808079481124878,
      "learning_rate": 1.6843745474936668e-05,
      "loss": 0.2908,
      "step": 5782
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.15623925626277924,
      "learning_rate": 1.6818974734398895e-05,
      "loss": 0.2637,
      "step": 5783
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1710151582956314,
      "learning_rate": 1.679422054896711e-05,
      "loss": 0.2104,
      "step": 5784
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.18239860236644745,
      "learning_rate": 1.6769482923568036e-05,
      "loss": 0.2717,
      "step": 5785
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.12587366998195648,
      "learning_rate": 1.6744761863125082e-05,
      "loss": 0.1994,
      "step": 5786
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.19791975617408752,
      "learning_rate": 1.6720057372558306e-05,
      "loss": 0.2901,
      "step": 5787
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.17348062992095947,
      "learning_rate": 1.6695369456784592e-05,
      "loss": 0.3261,
      "step": 5788
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.17820751667022705,
      "learning_rate": 1.6670698120717398e-05,
      "loss": 0.3913,
      "step": 5789
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1534879207611084,
      "learning_rate": 1.6646043369266972e-05,
      "loss": 0.2418,
      "step": 5790
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.23450210690498352,
      "learning_rate": 1.6621405207340225e-05,
      "loss": 0.3034,
      "step": 5791
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.18088489770889282,
      "learning_rate": 1.659678363984075e-05,
      "loss": 0.2716,
      "step": 5792
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1450349986553192,
      "learning_rate": 1.6572178671668847e-05,
      "loss": 0.2374,
      "step": 5793
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.20427735149860382,
      "learning_rate": 1.654759030772155e-05,
      "loss": 0.2987,
      "step": 5794
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.17199741303920746,
      "learning_rate": 1.6523018552892533e-05,
      "loss": 0.3239,
      "step": 5795
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.181333988904953,
      "learning_rate": 1.649846341207222e-05,
      "loss": 0.2458,
      "step": 5796
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.19613231718540192,
      "learning_rate": 1.6473924890147653e-05,
      "loss": 0.252,
      "step": 5797
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.16195477545261383,
      "learning_rate": 1.644940299200266e-05,
      "loss": 0.2864,
      "step": 5798
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.19689254462718964,
      "learning_rate": 1.6424897722517696e-05,
      "loss": 0.3064,
      "step": 5799
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1533033698797226,
      "learning_rate": 1.6400409086569912e-05,
      "loss": 0.2777,
      "step": 5800
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.16274836659431458,
      "learning_rate": 1.6375937089033156e-05,
      "loss": 0.2852,
      "step": 5801
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.14942410588264465,
      "learning_rate": 1.6351481734777997e-05,
      "loss": 0.2338,
      "step": 5802
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1604493409395218,
      "learning_rate": 1.6327043028671607e-05,
      "loss": 0.2686,
      "step": 5803
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.15211953222751617,
      "learning_rate": 1.6302620975577976e-05,
      "loss": 0.2684,
      "step": 5804
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.16134029626846313,
      "learning_rate": 1.6278215580357635e-05,
      "loss": 0.3605,
      "step": 5805
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.12035055458545685,
      "learning_rate": 1.6253826847867927e-05,
      "loss": 0.1867,
      "step": 5806
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.18655210733413696,
      "learning_rate": 1.6229454782962794e-05,
      "loss": 0.353,
      "step": 5807
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.18197377026081085,
      "learning_rate": 1.6205099390492874e-05,
      "loss": 0.2715,
      "step": 5808
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1532095968723297,
      "learning_rate": 1.6180760675305494e-05,
      "loss": 0.2846,
      "step": 5809
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.14849242568016052,
      "learning_rate": 1.6156438642244708e-05,
      "loss": 0.2523,
      "step": 5810
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.13968335092067719,
      "learning_rate": 1.6132133296151153e-05,
      "loss": 0.2542,
      "step": 5811
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.13135135173797607,
      "learning_rate": 1.6107844641862267e-05,
      "loss": 0.2004,
      "step": 5812
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.15963037312030792,
      "learning_rate": 1.6083572684212035e-05,
      "loss": 0.2944,
      "step": 5813
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.14138539135456085,
      "learning_rate": 1.605931742803127e-05,
      "loss": 0.248,
      "step": 5814
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1826644241809845,
      "learning_rate": 1.603507887814727e-05,
      "loss": 0.3259,
      "step": 5815
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.16479936242103577,
      "learning_rate": 1.6010857039384185e-05,
      "loss": 0.3069,
      "step": 5816
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.16296400129795074,
      "learning_rate": 1.5986651916562755e-05,
      "loss": 0.3044,
      "step": 5817
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.13620571792125702,
      "learning_rate": 1.596246351450036e-05,
      "loss": 0.3062,
      "step": 5818
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1412692815065384,
      "learning_rate": 1.5938291838011167e-05,
      "loss": 0.2533,
      "step": 5819
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.16014036536216736,
      "learning_rate": 1.5914136891905886e-05,
      "loss": 0.3073,
      "step": 5820
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.12915204465389252,
      "learning_rate": 1.5889998680992002e-05,
      "loss": 0.2591,
      "step": 5821
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.13561460375785828,
      "learning_rate": 1.5865877210073597e-05,
      "loss": 0.2153,
      "step": 5822
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1396850198507309,
      "learning_rate": 1.5841772483951466e-05,
      "loss": 0.23,
      "step": 5823
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.14885978400707245,
      "learning_rate": 1.5817684507423004e-05,
      "loss": 0.2711,
      "step": 5824
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.13856789469718933,
      "learning_rate": 1.5793613285282384e-05,
      "loss": 0.2188,
      "step": 5825
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.19081848859786987,
      "learning_rate": 1.5769558822320328e-05,
      "loss": 0.3207,
      "step": 5826
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.18591490387916565,
      "learning_rate": 1.5745521123324336e-05,
      "loss": 0.2102,
      "step": 5827
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1357942670583725,
      "learning_rate": 1.572150019307845e-05,
      "loss": 0.2051,
      "step": 5828
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.19043564796447754,
      "learning_rate": 1.569749603636349e-05,
      "loss": 0.3342,
      "step": 5829
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1710910201072693,
      "learning_rate": 1.567350865795686e-05,
      "loss": 0.2972,
      "step": 5830
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.15596550703048706,
      "learning_rate": 1.564953806263264e-05,
      "loss": 0.2447,
      "step": 5831
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.16390855610370636,
      "learning_rate": 1.562558425516156e-05,
      "loss": 0.3104,
      "step": 5832
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.20869150757789612,
      "learning_rate": 1.560164724031109e-05,
      "loss": 0.4366,
      "step": 5833
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.15146471560001373,
      "learning_rate": 1.5577727022845223e-05,
      "loss": 0.2485,
      "step": 5834
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.19485414028167725,
      "learning_rate": 1.5553823607524742e-05,
      "loss": 0.3805,
      "step": 5835
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.09842771291732788,
      "learning_rate": 1.5529936999106976e-05,
      "loss": 0.1623,
      "step": 5836
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.18933700025081635,
      "learning_rate": 1.5506067202346007e-05,
      "loss": 0.3603,
      "step": 5837
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.18436786532402039,
      "learning_rate": 1.5482214221992496e-05,
      "loss": 0.3103,
      "step": 5838
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1437373161315918,
      "learning_rate": 1.545837806279379e-05,
      "loss": 0.2397,
      "step": 5839
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.1717805415391922,
      "learning_rate": 1.5434558729493842e-05,
      "loss": 0.2404,
      "step": 5840
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.17414626479148865,
      "learning_rate": 1.5410756226833358e-05,
      "loss": 0.2784,
      "step": 5841
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.15164116024971008,
      "learning_rate": 1.5386970559549563e-05,
      "loss": 0.255,
      "step": 5842
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16425056755542755,
      "learning_rate": 1.5363201732376475e-05,
      "loss": 0.2557,
      "step": 5843
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.18195204436779022,
      "learning_rate": 1.533944975004462e-05,
      "loss": 0.2892,
      "step": 5844
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.21900346875190735,
      "learning_rate": 1.5315714617281296e-05,
      "loss": 0.2872,
      "step": 5845
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.15850071609020233,
      "learning_rate": 1.5291996338810354e-05,
      "loss": 0.2664,
      "step": 5846
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.22777912020683289,
      "learning_rate": 1.5268294919352333e-05,
      "loss": 0.3793,
      "step": 5847
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.12569676339626312,
      "learning_rate": 1.5244610363624412e-05,
      "loss": 0.218,
      "step": 5848
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.18054352700710297,
      "learning_rate": 1.5220942676340365e-05,
      "loss": 0.3058,
      "step": 5849
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.18304669857025146,
      "learning_rate": 1.5197291862210727e-05,
      "loss": 0.3178,
      "step": 5850
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.14240480959415436,
      "learning_rate": 1.5173657925942553e-05,
      "loss": 0.2405,
      "step": 5851
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.15232911705970764,
      "learning_rate": 1.5150040872239613e-05,
      "loss": 0.2834,
      "step": 5852
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.1703275889158249,
      "learning_rate": 1.5126440705802259e-05,
      "loss": 0.2386,
      "step": 5853
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.14041468501091003,
      "learning_rate": 1.5102857431327566e-05,
      "loss": 0.2306,
      "step": 5854
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.14470623433589935,
      "learning_rate": 1.507929105350917e-05,
      "loss": 0.2748,
      "step": 5855
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16296575963497162,
      "learning_rate": 1.5055741577037363e-05,
      "loss": 0.2616,
      "step": 5856
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.15962901711463928,
      "learning_rate": 1.5032209006599062e-05,
      "loss": 0.2675,
      "step": 5857
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.09405208379030228,
      "learning_rate": 1.5008693346877878e-05,
      "loss": 0.1593,
      "step": 5858
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.1664394736289978,
      "learning_rate": 1.4985194602553987e-05,
      "loss": 0.3211,
      "step": 5859
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16326722502708435,
      "learning_rate": 1.4961712778304249e-05,
      "loss": 0.2658,
      "step": 5860
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.14173831045627594,
      "learning_rate": 1.4938247878802115e-05,
      "loss": 0.2898,
      "step": 5861
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.18413349986076355,
      "learning_rate": 1.4914799908717714e-05,
      "loss": 0.2614,
      "step": 5862
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16582095623016357,
      "learning_rate": 1.489136887271776e-05,
      "loss": 0.3477,
      "step": 5863
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.18491636216640472,
      "learning_rate": 1.486795477546562e-05,
      "loss": 0.2325,
      "step": 5864
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.13805308938026428,
      "learning_rate": 1.4844557621621247e-05,
      "loss": 0.228,
      "step": 5865
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.173675999045372,
      "learning_rate": 1.4821177415841337e-05,
      "loss": 0.3078,
      "step": 5866
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16200795769691467,
      "learning_rate": 1.4797814162779056e-05,
      "loss": 0.2837,
      "step": 5867
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16095983982086182,
      "learning_rate": 1.4774467867084352e-05,
      "loss": 0.2599,
      "step": 5868
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.22770923376083374,
      "learning_rate": 1.4751138533403653e-05,
      "loss": 0.3213,
      "step": 5869
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.11390607804059982,
      "learning_rate": 1.4727826166380143e-05,
      "loss": 0.2001,
      "step": 5870
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.15590912103652954,
      "learning_rate": 1.4704530770653535e-05,
      "loss": 0.2305,
      "step": 5871
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.1294282078742981,
      "learning_rate": 1.4681252350860186e-05,
      "loss": 0.2147,
      "step": 5872
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.15506798028945923,
      "learning_rate": 1.4657990911633079e-05,
      "loss": 0.2361,
      "step": 5873
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16738411784172058,
      "learning_rate": 1.4634746457601867e-05,
      "loss": 0.3277,
      "step": 5874
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16055963933467865,
      "learning_rate": 1.4611518993392726e-05,
      "loss": 0.2811,
      "step": 5875
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.16029727458953857,
      "learning_rate": 1.4588308523628547e-05,
      "loss": 0.2847,
      "step": 5876
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.12132754921913147,
      "learning_rate": 1.4565115052928746e-05,
      "loss": 0.209,
      "step": 5877
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.18790175020694733,
      "learning_rate": 1.4541938585909465e-05,
      "loss": 0.2777,
      "step": 5878
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.32833513617515564,
      "learning_rate": 1.4518779127183357e-05,
      "loss": 0.3452,
      "step": 5879
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1524253487586975,
      "learning_rate": 1.4495636681359748e-05,
      "loss": 0.2514,
      "step": 5880
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.17407356202602386,
      "learning_rate": 1.4472511253044573e-05,
      "loss": 0.3031,
      "step": 5881
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.19497081637382507,
      "learning_rate": 1.4449402846840322e-05,
      "loss": 0.2891,
      "step": 5882
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.17778781056404114,
      "learning_rate": 1.442631146734621e-05,
      "loss": 0.3074,
      "step": 5883
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1541050523519516,
      "learning_rate": 1.4403237119157953e-05,
      "loss": 0.2473,
      "step": 5884
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1421268880367279,
      "learning_rate": 1.4380179806867965e-05,
      "loss": 0.2201,
      "step": 5885
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1693756878376007,
      "learning_rate": 1.4357139535065189e-05,
      "loss": 0.2585,
      "step": 5886
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.12542462348937988,
      "learning_rate": 1.4334116308335254e-05,
      "loss": 0.2149,
      "step": 5887
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.18342041969299316,
      "learning_rate": 1.4311110131260342e-05,
      "loss": 0.3301,
      "step": 5888
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1734197586774826,
      "learning_rate": 1.4288121008419242e-05,
      "loss": 0.2733,
      "step": 5889
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1600121706724167,
      "learning_rate": 1.4265148944387363e-05,
      "loss": 0.3152,
      "step": 5890
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.15006616711616516,
      "learning_rate": 1.4242193943736759e-05,
      "loss": 0.2261,
      "step": 5891
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1307845413684845,
      "learning_rate": 1.4219256011035997e-05,
      "loss": 0.2205,
      "step": 5892
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.12536463141441345,
      "learning_rate": 1.419633515085036e-05,
      "loss": 0.2428,
      "step": 5893
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1440790444612503,
      "learning_rate": 1.4173431367741607e-05,
      "loss": 0.2315,
      "step": 5894
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1330672949552536,
      "learning_rate": 1.4150544666268229e-05,
      "loss": 0.2026,
      "step": 5895
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.20358002185821533,
      "learning_rate": 1.4127675050985212e-05,
      "loss": 0.3544,
      "step": 5896
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.13909222185611725,
      "learning_rate": 1.4104822526444205e-05,
      "loss": 0.2583,
      "step": 5897
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.17314030230045319,
      "learning_rate": 1.4081987097193383e-05,
      "loss": 0.3352,
      "step": 5898
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.13725249469280243,
      "learning_rate": 1.4059168767777641e-05,
      "loss": 0.2533,
      "step": 5899
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.11365337669849396,
      "learning_rate": 1.4036367542738327e-05,
      "loss": 0.1812,
      "step": 5900
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.13747340440750122,
      "learning_rate": 1.4013583426613518e-05,
      "loss": 0.225,
      "step": 5901
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1725737750530243,
      "learning_rate": 1.399081642393777e-05,
      "loss": 0.2432,
      "step": 5902
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.16938598453998566,
      "learning_rate": 1.3968066539242353e-05,
      "loss": 0.299,
      "step": 5903
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.17109256982803345,
      "learning_rate": 1.394533377705497e-05,
      "loss": 0.2808,
      "step": 5904
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.21132732927799225,
      "learning_rate": 1.3922618141900101e-05,
      "loss": 0.298,
      "step": 5905
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.1482100784778595,
      "learning_rate": 1.3899919638298653e-05,
      "loss": 0.3098,
      "step": 5906
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.16350939869880676,
      "learning_rate": 1.3877238270768244e-05,
      "loss": 0.2656,
      "step": 5907
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.15147164463996887,
      "learning_rate": 1.3854574043823032e-05,
      "loss": 0.2568,
      "step": 5908
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.15049518644809723,
      "learning_rate": 1.3831926961973729e-05,
      "loss": 0.2628,
      "step": 5909
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.15295550227165222,
      "learning_rate": 1.3809297029727707e-05,
      "loss": 0.286,
      "step": 5910
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.14532573521137238,
      "learning_rate": 1.3786684251588888e-05,
      "loss": 0.3337,
      "step": 5911
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.18020975589752197,
      "learning_rate": 1.3764088632057759e-05,
      "loss": 0.3121,
      "step": 5912
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.17262662947177887,
      "learning_rate": 1.3741510175631412e-05,
      "loss": 0.3098,
      "step": 5913
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.15735334157943726,
      "learning_rate": 1.3718948886803551e-05,
      "loss": 0.2306,
      "step": 5914
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.17703945934772491,
      "learning_rate": 1.3696404770064408e-05,
      "loss": 0.284,
      "step": 5915
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.17440445721149445,
      "learning_rate": 1.367387782990086e-05,
      "loss": 0.2655,
      "step": 5916
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.15478625893592834,
      "learning_rate": 1.365136807079629e-05,
      "loss": 0.242,
      "step": 5917
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.15315645933151245,
      "learning_rate": 1.3628875497230753e-05,
      "loss": 0.2506,
      "step": 5918
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.16651463508605957,
      "learning_rate": 1.3606400113680806e-05,
      "loss": 0.2897,
      "step": 5919
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.3406803607940674,
      "learning_rate": 1.3583941924619614e-05,
      "loss": 0.3182,
      "step": 5920
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.18386322259902954,
      "learning_rate": 1.3561500934516903e-05,
      "loss": 0.3117,
      "step": 5921
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.16158364713191986,
      "learning_rate": 1.353907714783903e-05,
      "loss": 0.2545,
      "step": 5922
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.13027486205101013,
      "learning_rate": 1.351667056904884e-05,
      "loss": 0.2966,
      "step": 5923
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.14820070564746857,
      "learning_rate": 1.3494281202605863e-05,
      "loss": 0.2232,
      "step": 5924
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.16854356229305267,
      "learning_rate": 1.347190905296608e-05,
      "loss": 0.2955,
      "step": 5925
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.13352356851100922,
      "learning_rate": 1.3449554124582175e-05,
      "loss": 0.204,
      "step": 5926
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.1367141455411911,
      "learning_rate": 1.3427216421903289e-05,
      "loss": 0.211,
      "step": 5927
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.13221098482608795,
      "learning_rate": 1.3404895949375207e-05,
      "loss": 0.1655,
      "step": 5928
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.1806333363056183,
      "learning_rate": 1.3382592711440234e-05,
      "loss": 0.2889,
      "step": 5929
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.11819574981927872,
      "learning_rate": 1.3360306712537306e-05,
      "loss": 0.1196,
      "step": 5930
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.1393255740404129,
      "learning_rate": 1.3338037957101868e-05,
      "loss": 0.2912,
      "step": 5931
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.18421213328838348,
      "learning_rate": 1.3315786449565981e-05,
      "loss": 0.3458,
      "step": 5932
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.16117995977401733,
      "learning_rate": 1.3293552194358238e-05,
      "loss": 0.3356,
      "step": 5933
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23960557579994202,
      "learning_rate": 1.3271335195903833e-05,
      "loss": 0.3182,
      "step": 5934
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.1780014932155609,
      "learning_rate": 1.3249135458624484e-05,
      "loss": 0.3439,
      "step": 5935
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.18277738988399506,
      "learning_rate": 1.3226952986938502e-05,
      "loss": 0.3117,
      "step": 5936
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.189543217420578,
      "learning_rate": 1.320478778526073e-05,
      "loss": 0.2633,
      "step": 5937
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.16342419385910034,
      "learning_rate": 1.3182639858002644e-05,
      "loss": 0.3353,
      "step": 5938
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.15170802175998688,
      "learning_rate": 1.3160509209572214e-05,
      "loss": 0.2634,
      "step": 5939
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.13820892572402954,
      "learning_rate": 1.3138395844373963e-05,
      "loss": 0.2178,
      "step": 5940
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.12791121006011963,
      "learning_rate": 1.3116299766809048e-05,
      "loss": 0.2088,
      "step": 5941
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.2220628410577774,
      "learning_rate": 1.3094220981275119e-05,
      "loss": 0.247,
      "step": 5942
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.25256112217903137,
      "learning_rate": 1.3072159492166425e-05,
      "loss": 0.2709,
      "step": 5943
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.15589569509029388,
      "learning_rate": 1.3050115303873744e-05,
      "loss": 0.286,
      "step": 5944
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.3425603210926056,
      "learning_rate": 1.3028088420784423e-05,
      "loss": 0.3923,
      "step": 5945
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.1429942399263382,
      "learning_rate": 1.3006078847282333e-05,
      "loss": 0.2415,
      "step": 5946
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.15171299874782562,
      "learning_rate": 1.298408658774798e-05,
      "loss": 0.1841,
      "step": 5947
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1669292151927948,
      "learning_rate": 1.2962111646558329e-05,
      "loss": 0.2813,
      "step": 5948
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1533670872449875,
      "learning_rate": 1.2940154028086992e-05,
      "loss": 0.206,
      "step": 5949
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.16633394360542297,
      "learning_rate": 1.2918213736704033e-05,
      "loss": 0.268,
      "step": 5950
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.12911590933799744,
      "learning_rate": 1.2896290776776165e-05,
      "loss": 0.2347,
      "step": 5951
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1452421247959137,
      "learning_rate": 1.287438515266658e-05,
      "loss": 0.2588,
      "step": 5952
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.10691319406032562,
      "learning_rate": 1.2852496868735053e-05,
      "loss": 0.1447,
      "step": 5953
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1582997441291809,
      "learning_rate": 1.283062592933788e-05,
      "loss": 0.2645,
      "step": 5954
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.15755319595336914,
      "learning_rate": 1.2808772338827968e-05,
      "loss": 0.271,
      "step": 5955
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.17055192589759827,
      "learning_rate": 1.2786936101554681e-05,
      "loss": 0.339,
      "step": 5956
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.18096113204956055,
      "learning_rate": 1.276511722186401e-05,
      "loss": 0.324,
      "step": 5957
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.13557671010494232,
      "learning_rate": 1.2743315704098436e-05,
      "loss": 0.2519,
      "step": 5958
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1842537224292755,
      "learning_rate": 1.2721531552597032e-05,
      "loss": 0.278,
      "step": 5959
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1258639246225357,
      "learning_rate": 1.2699764771695389e-05,
      "loss": 0.2179,
      "step": 5960
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.15323050320148468,
      "learning_rate": 1.2678015365725615e-05,
      "loss": 0.2443,
      "step": 5961
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.3065865933895111,
      "learning_rate": 1.2656283339016383e-05,
      "loss": 0.3115,
      "step": 5962
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.14797693490982056,
      "learning_rate": 1.2634568695892945e-05,
      "loss": 0.3125,
      "step": 5963
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.14023758471012115,
      "learning_rate": 1.261287144067702e-05,
      "loss": 0.233,
      "step": 5964
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1423114538192749,
      "learning_rate": 1.2591191577686945e-05,
      "loss": 0.2439,
      "step": 5965
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1741502434015274,
      "learning_rate": 1.256952911123751e-05,
      "loss": 0.2553,
      "step": 5966
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.13748951256275177,
      "learning_rate": 1.2547884045640146e-05,
      "loss": 0.2403,
      "step": 5967
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.2053319662809372,
      "learning_rate": 1.2526256385202717e-05,
      "loss": 0.3246,
      "step": 5968
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1304558515548706,
      "learning_rate": 1.2504646134229692e-05,
      "loss": 0.2232,
      "step": 5969
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1741839498281479,
      "learning_rate": 1.2483053297022041e-05,
      "loss": 0.2561,
      "step": 5970
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.14752669632434845,
      "learning_rate": 1.2461477877877248e-05,
      "loss": 0.5221,
      "step": 5971
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.15249301493167877,
      "learning_rate": 1.2439919881089424e-05,
      "loss": 0.2491,
      "step": 5972
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.16002589464187622,
      "learning_rate": 1.241837931094909e-05,
      "loss": 0.2308,
      "step": 5973
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.13503500819206238,
      "learning_rate": 1.2396856171743409e-05,
      "loss": 0.1693,
      "step": 5974
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1619839370250702,
      "learning_rate": 1.2375350467755986e-05,
      "loss": 0.2289,
      "step": 5975
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1877562254667282,
      "learning_rate": 1.2353862203267031e-05,
      "loss": 0.3181,
      "step": 5976
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.15337146818637848,
      "learning_rate": 1.2332391382553221e-05,
      "loss": 0.2329,
      "step": 5977
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.14007702469825745,
      "learning_rate": 1.2310938009887807e-05,
      "loss": 0.2049,
      "step": 5978
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.14685192704200745,
      "learning_rate": 1.2289502089540495e-05,
      "loss": 0.2516,
      "step": 5979
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.21295785903930664,
      "learning_rate": 1.2268083625777637e-05,
      "loss": 0.3397,
      "step": 5980
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.16265708208084106,
      "learning_rate": 1.2246682622861993e-05,
      "loss": 0.328,
      "step": 5981
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.13980986177921295,
      "learning_rate": 1.2225299085052933e-05,
      "loss": 0.1971,
      "step": 5982
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.16210943460464478,
      "learning_rate": 1.2203933016606283e-05,
      "loss": 0.2521,
      "step": 5983
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.15382155776023865,
      "learning_rate": 1.2182584421774502e-05,
      "loss": 0.25,
      "step": 5984
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.19791336357593536,
      "learning_rate": 1.2161253304806374e-05,
      "loss": 0.4034,
      "step": 5985
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.2208898365497589,
      "learning_rate": 1.213993966994742e-05,
      "loss": 0.2674,
      "step": 5986
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.18741053342819214,
      "learning_rate": 1.2118643521439532e-05,
      "loss": 0.3176,
      "step": 5987
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.21943828463554382,
      "learning_rate": 1.2097364863521221e-05,
      "loss": 0.3888,
      "step": 5988
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.13944824039936066,
      "learning_rate": 1.2076103700427432e-05,
      "loss": 0.2281,
      "step": 5989
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.15647892653942108,
      "learning_rate": 1.2054860036389704e-05,
      "loss": 0.274,
      "step": 5990
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.15566983819007874,
      "learning_rate": 1.2033633875636042e-05,
      "loss": 0.2835,
      "step": 5991
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.16848674416542053,
      "learning_rate": 1.2012425222390988e-05,
      "loss": 0.2901,
      "step": 5992
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.13414432108402252,
      "learning_rate": 1.1991234080875569e-05,
      "loss": 0.2407,
      "step": 5993
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.15392588078975677,
      "learning_rate": 1.1970060455307385e-05,
      "loss": 0.2573,
      "step": 5994
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1935926079750061,
      "learning_rate": 1.1948904349900492e-05,
      "loss": 0.3583,
      "step": 5995
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.18362052738666534,
      "learning_rate": 1.1927765768865517e-05,
      "loss": 0.3243,
      "step": 5996
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.14303946495056152,
      "learning_rate": 1.1906644716409532e-05,
      "loss": 0.2127,
      "step": 5997
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1713518500328064,
      "learning_rate": 1.1885541196736194e-05,
      "loss": 0.2923,
      "step": 5998
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1453476995229721,
      "learning_rate": 1.18644552140456e-05,
      "loss": 0.2034,
      "step": 5999
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.16183896362781525,
      "learning_rate": 1.1843386772534403e-05,
      "loss": 0.3052,
      "step": 6000
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.11660173535346985,
      "learning_rate": 1.182233587639574e-05,
      "loss": 0.1845,
      "step": 6001
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1564585268497467,
      "learning_rate": 1.1801302529819246e-05,
      "loss": 0.2624,
      "step": 6002
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.22737720608711243,
      "learning_rate": 1.1780286736991141e-05,
      "loss": 0.3583,
      "step": 6003
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.157206729054451,
      "learning_rate": 1.1759288502094034e-05,
      "loss": 0.2491,
      "step": 6004
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.22560694813728333,
      "learning_rate": 1.173830782930715e-05,
      "loss": 0.2488,
      "step": 6005
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.15411408245563507,
      "learning_rate": 1.1717344722806112e-05,
      "loss": 0.2678,
      "step": 6006
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1490553319454193,
      "learning_rate": 1.1696399186763163e-05,
      "loss": 0.242,
      "step": 6007
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.18881025910377502,
      "learning_rate": 1.1675471225346957e-05,
      "loss": 0.3186,
      "step": 6008
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.16422045230865479,
      "learning_rate": 1.1654560842722696e-05,
      "loss": 0.3288,
      "step": 6009
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.16813971102237701,
      "learning_rate": 1.1633668043052026e-05,
      "loss": 0.2615,
      "step": 6010
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.21497292816638947,
      "learning_rate": 1.1612792830493202e-05,
      "loss": 0.3558,
      "step": 6011
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.15059269964694977,
      "learning_rate": 1.1591935209200855e-05,
      "loss": 0.2335,
      "step": 6012
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.16645808517932892,
      "learning_rate": 1.157109518332623e-05,
      "loss": 0.3229,
      "step": 6013
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.21605397760868073,
      "learning_rate": 1.1550272757016955e-05,
      "loss": 0.3013,
      "step": 6014
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.191618874669075,
      "learning_rate": 1.152946793441727e-05,
      "loss": 0.3454,
      "step": 6015
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1441444307565689,
      "learning_rate": 1.1508680719667831e-05,
      "loss": 0.1957,
      "step": 6016
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.16916991770267487,
      "learning_rate": 1.1487911116905802e-05,
      "loss": 0.2341,
      "step": 6017
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1754491925239563,
      "learning_rate": 1.1467159130264848e-05,
      "loss": 0.3009,
      "step": 6018
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.18206004798412323,
      "learning_rate": 1.1446424763875174e-05,
      "loss": 0.3453,
      "step": 6019
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15505538880825043,
      "learning_rate": 1.142570802186339e-05,
      "loss": 0.2786,
      "step": 6020
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15590615570545197,
      "learning_rate": 1.1405008908352688e-05,
      "loss": 0.2566,
      "step": 6021
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15461698174476624,
      "learning_rate": 1.1384327427462682e-05,
      "loss": 0.2795,
      "step": 6022
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.2407625913619995,
      "learning_rate": 1.1363663583309525e-05,
      "loss": 0.3259,
      "step": 6023
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.19466841220855713,
      "learning_rate": 1.1343017380005827e-05,
      "loss": 0.3325,
      "step": 6024
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1842820942401886,
      "learning_rate": 1.1322388821660701e-05,
      "loss": 0.2765,
      "step": 6025
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.12334786355495453,
      "learning_rate": 1.130177791237973e-05,
      "loss": 0.2298,
      "step": 6026
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1950785517692566,
      "learning_rate": 1.1281184656265043e-05,
      "loss": 0.2645,
      "step": 6027
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1734296828508377,
      "learning_rate": 1.126060905741515e-05,
      "loss": 0.2832,
      "step": 6028
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.22357164323329926,
      "learning_rate": 1.1240051119925176e-05,
      "loss": 0.3121,
      "step": 6029
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.13244321942329407,
      "learning_rate": 1.1219510847886616e-05,
      "loss": 0.2978,
      "step": 6030
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1461271196603775,
      "learning_rate": 1.1198988245387543e-05,
      "loss": 0.2422,
      "step": 6031
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.16193093359470367,
      "learning_rate": 1.1178483316512434e-05,
      "loss": 0.3035,
      "step": 6032
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1297035962343216,
      "learning_rate": 1.1157996065342301e-05,
      "loss": 0.2495,
      "step": 6033
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.16260984539985657,
      "learning_rate": 1.1137526495954608e-05,
      "loss": 0.2718,
      "step": 6034
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.17212820053100586,
      "learning_rate": 1.1117074612423306e-05,
      "loss": 0.3467,
      "step": 6035
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.13131390511989594,
      "learning_rate": 1.1096640418818848e-05,
      "loss": 0.2544,
      "step": 6036
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.179496169090271,
      "learning_rate": 1.1076223919208129e-05,
      "loss": 0.3238,
      "step": 6037
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1457401067018509,
      "learning_rate": 1.1055825117654572e-05,
      "loss": 0.2747,
      "step": 6038
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1573660969734192,
      "learning_rate": 1.1035444018218022e-05,
      "loss": 0.3646,
      "step": 6039
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1701745241880417,
      "learning_rate": 1.1015080624954855e-05,
      "loss": 0.2438,
      "step": 6040
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1744665652513504,
      "learning_rate": 1.0994734941917884e-05,
      "loss": 0.2374,
      "step": 6041
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.17213526368141174,
      "learning_rate": 1.0974406973156415e-05,
      "loss": 0.3204,
      "step": 6042
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.13670679926872253,
      "learning_rate": 1.0954096722716178e-05,
      "loss": 0.2272,
      "step": 6043
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1915612518787384,
      "learning_rate": 1.0933804194639485e-05,
      "loss": 0.3044,
      "step": 6044
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.17041683197021484,
      "learning_rate": 1.0913529392965016e-05,
      "loss": 0.3294,
      "step": 6045
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15587200224399567,
      "learning_rate": 1.0893272321727987e-05,
      "loss": 0.2473,
      "step": 6046
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.16644778847694397,
      "learning_rate": 1.0873032984960042e-05,
      "loss": 0.2503,
      "step": 6047
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.18534649908542633,
      "learning_rate": 1.0852811386689343e-05,
      "loss": 0.2492,
      "step": 6048
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.1449323147535324,
      "learning_rate": 1.0832607530940474e-05,
      "loss": 0.2221,
      "step": 6049
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.13726738095283508,
      "learning_rate": 1.081242142173452e-05,
      "loss": 0.2205,
      "step": 6050
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.17926743626594543,
      "learning_rate": 1.0792253063088986e-05,
      "loss": 0.3553,
      "step": 6051
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.19337430596351624,
      "learning_rate": 1.077210245901793e-05,
      "loss": 0.3478,
      "step": 6052
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.13778848946094513,
      "learning_rate": 1.0751969613531788e-05,
      "loss": 0.2687,
      "step": 6053
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.11726447939872742,
      "learning_rate": 1.0731854530637531e-05,
      "loss": 0.2151,
      "step": 6054
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.16494691371917725,
      "learning_rate": 1.0711757214338525e-05,
      "loss": 0.2972,
      "step": 6055
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.14552058279514313,
      "learning_rate": 1.0691677668634691e-05,
      "loss": 0.2226,
      "step": 6056
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.1925324946641922,
      "learning_rate": 1.0671615897522336e-05,
      "loss": 0.3156,
      "step": 6057
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.11747346073389053,
      "learning_rate": 1.065157190499424e-05,
      "loss": 0.193,
      "step": 6058
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.14150746166706085,
      "learning_rate": 1.0631545695039657e-05,
      "loss": 0.2696,
      "step": 6059
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.13981108367443085,
      "learning_rate": 1.0611537271644345e-05,
      "loss": 0.2474,
      "step": 6060
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.13720524311065674,
      "learning_rate": 1.0591546638790428e-05,
      "loss": 0.1881,
      "step": 6061
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.14558109641075134,
      "learning_rate": 1.0571573800456591e-05,
      "loss": 0.2854,
      "step": 6062
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.18774929642677307,
      "learning_rate": 1.0551618760617909e-05,
      "loss": 0.3248,
      "step": 6063
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.17643271386623383,
      "learning_rate": 1.0531681523245907e-05,
      "loss": 0.2777,
      "step": 6064
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.12638874351978302,
      "learning_rate": 1.0511762092308642e-05,
      "loss": 0.2269,
      "step": 6065
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.16949783265590668,
      "learning_rate": 1.0491860471770554e-05,
      "loss": 0.2545,
      "step": 6066
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.11231797933578491,
      "learning_rate": 1.0471976665592564e-05,
      "loss": 0.1604,
      "step": 6067
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.13671375811100006,
      "learning_rate": 1.045211067773203e-05,
      "loss": 0.2136,
      "step": 6068
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.1718767285346985,
      "learning_rate": 1.0432262512142821e-05,
      "loss": 0.3649,
      "step": 6069
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.2159322053194046,
      "learning_rate": 1.0412432172775188e-05,
      "loss": 0.3393,
      "step": 6070
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.15161411464214325,
      "learning_rate": 1.0392619663575875e-05,
      "loss": 0.2555,
      "step": 6071
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.14903782308101654,
      "learning_rate": 1.0372824988488062e-05,
      "loss": 0.2648,
      "step": 6072
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.13428017497062683,
      "learning_rate": 1.0353048151451428e-05,
      "loss": 0.2403,
      "step": 6073
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.16874490678310394,
      "learning_rate": 1.033328915640197e-05,
      "loss": 0.2689,
      "step": 6074
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.10469426214694977,
      "learning_rate": 1.03135480072723e-05,
      "loss": 0.1882,
      "step": 6075
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.13550327718257904,
      "learning_rate": 1.029382470799135e-05,
      "loss": 0.2265,
      "step": 6076
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.13731488585472107,
      "learning_rate": 1.0274119262484605e-05,
      "loss": 0.2254,
      "step": 6077
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.1647460013628006,
      "learning_rate": 1.0254431674673882e-05,
      "loss": 0.2532,
      "step": 6078
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.18237930536270142,
      "learning_rate": 1.0234761948477546e-05,
      "loss": 0.3126,
      "step": 6079
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.18778519332408905,
      "learning_rate": 1.0215110087810365e-05,
      "loss": 0.293,
      "step": 6080
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.15756140649318695,
      "learning_rate": 1.0195476096583523e-05,
      "loss": 0.2488,
      "step": 6081
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.14221985638141632,
      "learning_rate": 1.0175859978704683e-05,
      "loss": 0.2086,
      "step": 6082
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.1573459357023239,
      "learning_rate": 1.0156261738077955e-05,
      "loss": 0.2439,
      "step": 6083
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.16543875634670258,
      "learning_rate": 1.0136681378603863e-05,
      "loss": 0.2441,
      "step": 6084
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.17906327545642853,
      "learning_rate": 1.0117118904179424e-05,
      "loss": 0.2805,
      "step": 6085
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.15768980979919434,
      "learning_rate": 1.0097574318698012e-05,
      "loss": 0.2086,
      "step": 6086
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.15621334314346313,
      "learning_rate": 1.0078047626049537e-05,
      "loss": 0.2567,
      "step": 6087
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.14697925746440887,
      "learning_rate": 1.0058538830120279e-05,
      "loss": 0.2303,
      "step": 6088
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.171922504901886,
      "learning_rate": 1.0039047934792967e-05,
      "loss": 0.2222,
      "step": 6089
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1561119705438614,
      "learning_rate": 1.0019574943946763e-05,
      "loss": 0.3011,
      "step": 6090
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1495576649904251,
      "learning_rate": 1.0000119861457325e-05,
      "loss": 0.2537,
      "step": 6091
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.16931796073913574,
      "learning_rate": 9.980682691196664e-06,
      "loss": 0.2976,
      "step": 6092
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.19661486148834229,
      "learning_rate": 9.961263437033274e-06,
      "loss": 0.2885,
      "step": 6093
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.19467326998710632,
      "learning_rate": 9.941862102832078e-06,
      "loss": 0.233,
      "step": 6094
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.14894115924835205,
      "learning_rate": 9.922478692454418e-06,
      "loss": 0.2687,
      "step": 6095
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.129232257604599,
      "learning_rate": 9.903113209758096e-06,
      "loss": 0.2193,
      "step": 6096
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1106250062584877,
      "learning_rate": 9.88376565859731e-06,
      "loss": 0.1667,
      "step": 6097
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.2542809844017029,
      "learning_rate": 9.864436042822721e-06,
      "loss": 0.2594,
      "step": 6098
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.12963148951530457,
      "learning_rate": 9.845124366281367e-06,
      "loss": 0.1965,
      "step": 6099
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.16923829913139343,
      "learning_rate": 9.825830632816813e-06,
      "loss": 0.2459,
      "step": 6100
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.17388753592967987,
      "learning_rate": 9.806554846268945e-06,
      "loss": 0.2854,
      "step": 6101
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.17407652735710144,
      "learning_rate": 9.787297010474173e-06,
      "loss": 0.3093,
      "step": 6102
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1865890771150589,
      "learning_rate": 9.76805712926524e-06,
      "loss": 0.2676,
      "step": 6103
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1999080330133438,
      "learning_rate": 9.748835206471418e-06,
      "loss": 0.3511,
      "step": 6104
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1669287383556366,
      "learning_rate": 9.729631245918314e-06,
      "loss": 0.3356,
      "step": 6105
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.22880791127681732,
      "learning_rate": 9.710445251428003e-06,
      "loss": 0.2572,
      "step": 6106
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.18830439448356628,
      "learning_rate": 9.691277226818962e-06,
      "loss": 0.2907,
      "step": 6107
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.21014463901519775,
      "learning_rate": 9.672127175906143e-06,
      "loss": 0.3442,
      "step": 6108
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.17443472146987915,
      "learning_rate": 9.65299510250084e-06,
      "loss": 0.281,
      "step": 6109
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1659056693315506,
      "learning_rate": 9.633881010410873e-06,
      "loss": 0.2784,
      "step": 6110
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.15512853860855103,
      "learning_rate": 9.614784903440365e-06,
      "loss": 0.2446,
      "step": 6111
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1309489607810974,
      "learning_rate": 9.595706785389979e-06,
      "loss": 0.2233,
      "step": 6112
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.12480737268924713,
      "learning_rate": 9.576646660056699e-06,
      "loss": 0.2226,
      "step": 6113
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.19822899997234344,
      "learning_rate": 9.557604531233976e-06,
      "loss": 0.3863,
      "step": 6114
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.19029009342193604,
      "learning_rate": 9.53858040271165e-06,
      "loss": 0.3149,
      "step": 6115
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.5793996453285217,
      "learning_rate": 9.519574278276034e-06,
      "loss": 0.1548,
      "step": 6116
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.21495650708675385,
      "learning_rate": 9.500586161709791e-06,
      "loss": 0.3297,
      "step": 6117
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.18668049573898315,
      "learning_rate": 9.481616056792065e-06,
      "loss": 0.324,
      "step": 6118
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.15419405698776245,
      "learning_rate": 9.462663967298346e-06,
      "loss": 0.2579,
      "step": 6119
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.14045009016990662,
      "learning_rate": 9.443729897000608e-06,
      "loss": 0.2004,
      "step": 6120
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.14120306074619293,
      "learning_rate": 9.42481384966718e-06,
      "loss": 0.313,
      "step": 6121
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.16524256765842438,
      "learning_rate": 9.40591582906285e-06,
      "loss": 0.2811,
      "step": 6122
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.15919731557369232,
      "learning_rate": 9.387035838948776e-06,
      "loss": 0.2707,
      "step": 6123
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.21712398529052734,
      "learning_rate": 9.368173883082543e-06,
      "loss": 0.4079,
      "step": 6124
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.1700991839170456,
      "learning_rate": 9.34932996521819e-06,
      "loss": 0.3069,
      "step": 6125
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1616693139076233,
      "learning_rate": 9.330504089106073e-06,
      "loss": 0.2285,
      "step": 6126
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.15365199744701385,
      "learning_rate": 9.311696258493075e-06,
      "loss": 0.2715,
      "step": 6127
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.14523309469223022,
      "learning_rate": 9.292906477122377e-06,
      "loss": 0.3005,
      "step": 6128
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.16270706057548523,
      "learning_rate": 9.274134748733643e-06,
      "loss": 0.2698,
      "step": 6129
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.18445894122123718,
      "learning_rate": 9.255381077062908e-06,
      "loss": 0.2955,
      "step": 6130
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.14925971627235413,
      "learning_rate": 9.236645465842619e-06,
      "loss": 0.2926,
      "step": 6131
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.14959655702114105,
      "learning_rate": 9.217927918801616e-06,
      "loss": 0.3185,
      "step": 6132
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1446799635887146,
      "learning_rate": 9.199228439665197e-06,
      "loss": 0.2629,
      "step": 6133
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1317935287952423,
      "learning_rate": 9.180547032154995e-06,
      "loss": 0.2582,
      "step": 6134
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1937861144542694,
      "learning_rate": 9.161883699989093e-06,
      "loss": 0.2927,
      "step": 6135
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.13252875208854675,
      "learning_rate": 9.143238446881952e-06,
      "loss": 0.2367,
      "step": 6136
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1892106533050537,
      "learning_rate": 9.124611276544459e-06,
      "loss": 0.2684,
      "step": 6137
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.20029038190841675,
      "learning_rate": 9.106002192683883e-06,
      "loss": 0.3321,
      "step": 6138
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.21399326622486115,
      "learning_rate": 9.087411199003881e-06,
      "loss": 0.3713,
      "step": 6139
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.12998011708259583,
      "learning_rate": 9.06883829920453e-06,
      "loss": 0.216,
      "step": 6140
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.19225192070007324,
      "learning_rate": 9.050283496982325e-06,
      "loss": 0.2634,
      "step": 6141
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1834508180618286,
      "learning_rate": 9.031746796030094e-06,
      "loss": 0.2835,
      "step": 6142
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.21258267760276794,
      "learning_rate": 9.013228200037161e-06,
      "loss": 0.3108,
      "step": 6143
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.17724336683750153,
      "learning_rate": 8.994727712689133e-06,
      "loss": 0.3099,
      "step": 6144
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.17134879529476166,
      "learning_rate": 8.97624533766811e-06,
      "loss": 0.2569,
      "step": 6145
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.14117899537086487,
      "learning_rate": 8.957781078652539e-06,
      "loss": 0.2807,
      "step": 6146
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.17972102761268616,
      "learning_rate": 8.939334939317267e-06,
      "loss": 0.2606,
      "step": 6147
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1755094826221466,
      "learning_rate": 8.920906923333517e-06,
      "loss": 0.3068,
      "step": 6148
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.14701932668685913,
      "learning_rate": 8.902497034368951e-06,
      "loss": 0.2077,
      "step": 6149
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.16984255611896515,
      "learning_rate": 8.884105276087584e-06,
      "loss": 0.2816,
      "step": 6150
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1169215515255928,
      "learning_rate": 8.865731652149855e-06,
      "loss": 0.1993,
      "step": 6151
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.17447811365127563,
      "learning_rate": 8.84737616621254e-06,
      "loss": 0.3218,
      "step": 6152
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1476898044347763,
      "learning_rate": 8.829038821928882e-06,
      "loss": 0.2508,
      "step": 6153
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.16651256382465363,
      "learning_rate": 8.81071962294847e-06,
      "loss": 0.2763,
      "step": 6154
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.12218715250492096,
      "learning_rate": 8.792418572917237e-06,
      "loss": 0.2377,
      "step": 6155
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1441831737756729,
      "learning_rate": 8.77413567547759e-06,
      "loss": 0.2394,
      "step": 6156
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.1854463666677475,
      "learning_rate": 8.75587093426825e-06,
      "loss": 0.2865,
      "step": 6157
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.18845266103744507,
      "learning_rate": 8.7376243529244e-06,
      "loss": 0.3175,
      "step": 6158
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.14015398919582367,
      "learning_rate": 8.719395935077524e-06,
      "loss": 0.1932,
      "step": 6159
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.15321125090122223,
      "learning_rate": 8.701185684355584e-06,
      "loss": 0.255,
      "step": 6160
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1994723081588745,
      "learning_rate": 8.682993604382828e-06,
      "loss": 0.2963,
      "step": 6161
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.16653583943843842,
      "learning_rate": 8.66481969877997e-06,
      "loss": 0.2965,
      "step": 6162
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.17607565224170685,
      "learning_rate": 8.646663971164027e-06,
      "loss": 0.2589,
      "step": 6163
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.17620345950126648,
      "learning_rate": 8.628526425148498e-06,
      "loss": 0.2871,
      "step": 6164
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1553492397069931,
      "learning_rate": 8.61040706434315e-06,
      "loss": 0.3067,
      "step": 6165
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.14431963860988617,
      "learning_rate": 8.592305892354258e-06,
      "loss": 0.2519,
      "step": 6166
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.14733701944351196,
      "learning_rate": 8.574222912784336e-06,
      "loss": 0.2627,
      "step": 6167
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.16792334616184235,
      "learning_rate": 8.556158129232416e-06,
      "loss": 0.2763,
      "step": 6168
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.16712777316570282,
      "learning_rate": 8.538111545293803e-06,
      "loss": 0.2972,
      "step": 6169
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.15916785597801208,
      "learning_rate": 8.520083164560233e-06,
      "loss": 0.2675,
      "step": 6170
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.16782082617282867,
      "learning_rate": 8.50207299061978e-06,
      "loss": 0.2713,
      "step": 6171
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.15897749364376068,
      "learning_rate": 8.484081027056967e-06,
      "loss": 0.3069,
      "step": 6172
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.14629361033439636,
      "learning_rate": 8.466107277452583e-06,
      "loss": 0.3053,
      "step": 6173
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1545356661081314,
      "learning_rate": 8.448151745383914e-06,
      "loss": 0.2184,
      "step": 6174
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1681022346019745,
      "learning_rate": 8.430214434424521e-06,
      "loss": 0.3179,
      "step": 6175
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.17389287054538727,
      "learning_rate": 8.412295348144394e-06,
      "loss": 0.2648,
      "step": 6176
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.17396661639213562,
      "learning_rate": 8.394394490109891e-06,
      "loss": 0.2835,
      "step": 6177
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.15216094255447388,
      "learning_rate": 8.376511863883718e-06,
      "loss": 0.2923,
      "step": 6178
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.15513882040977478,
      "learning_rate": 8.358647473024938e-06,
      "loss": 0.284,
      "step": 6179
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.15140675008296967,
      "learning_rate": 8.340801321089053e-06,
      "loss": 0.2684,
      "step": 6180
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.10421110689640045,
      "learning_rate": 8.322973411627866e-06,
      "loss": 0.1669,
      "step": 6181
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1870799958705902,
      "learning_rate": 8.305163748189603e-06,
      "loss": 0.2961,
      "step": 6182
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.17470338940620422,
      "learning_rate": 8.28737233431881e-06,
      "loss": 0.2522,
      "step": 6183
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.16412732005119324,
      "learning_rate": 8.269599173556441e-06,
      "loss": 0.3478,
      "step": 6184
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.11502160131931305,
      "learning_rate": 8.251844269439801e-06,
      "loss": 0.1825,
      "step": 6185
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.18416550755500793,
      "learning_rate": 8.234107625502551e-06,
      "loss": 0.2816,
      "step": 6186
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.18343289196491241,
      "learning_rate": 8.216389245274725e-06,
      "loss": 0.2622,
      "step": 6187
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1630547195672989,
      "learning_rate": 8.19868913228271e-06,
      "loss": 0.2591,
      "step": 6188
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1447511613368988,
      "learning_rate": 8.181007290049303e-06,
      "loss": 0.2444,
      "step": 6189
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.14541199803352356,
      "learning_rate": 8.163343722093608e-06,
      "loss": 0.2532,
      "step": 6190
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.2246779203414917,
      "learning_rate": 8.145698431931136e-06,
      "loss": 0.3102,
      "step": 6191
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.14917834103107452,
      "learning_rate": 8.128071423073724e-06,
      "loss": 0.3075,
      "step": 6192
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.16403399407863617,
      "learning_rate": 8.110462699029609e-06,
      "loss": 0.3253,
      "step": 6193
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.17021392285823822,
      "learning_rate": 8.092872263303353e-06,
      "loss": 0.3123,
      "step": 6194
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.14585956931114197,
      "learning_rate": 8.075300119395901e-06,
      "loss": 0.1972,
      "step": 6195
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.15026158094406128,
      "learning_rate": 8.057746270804522e-06,
      "loss": 0.2919,
      "step": 6196
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.17663218080997467,
      "learning_rate": 8.040210721022912e-06,
      "loss": 0.3059,
      "step": 6197
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.14806656539440155,
      "learning_rate": 8.022693473541055e-06,
      "loss": 0.2486,
      "step": 6198
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.18750376999378204,
      "learning_rate": 8.00519453184534e-06,
      "loss": 0.2957,
      "step": 6199
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.14397595822811127,
      "learning_rate": 7.98771389941847e-06,
      "loss": 0.2362,
      "step": 6200
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1397297978401184,
      "learning_rate": 7.970251579739574e-06,
      "loss": 0.2179,
      "step": 6201
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1456225961446762,
      "learning_rate": 7.95280757628405e-06,
      "loss": 0.2844,
      "step": 6202
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.20058006048202515,
      "learning_rate": 7.935381892523707e-06,
      "loss": 0.271,
      "step": 6203
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.14351791143417358,
      "learning_rate": 7.917974531926676e-06,
      "loss": 0.23,
      "step": 6204
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.16333673894405365,
      "learning_rate": 7.90058549795748e-06,
      "loss": 0.2852,
      "step": 6205
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.19500647485256195,
      "learning_rate": 7.883214794076943e-06,
      "loss": 0.2972,
      "step": 6206
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1645132452249527,
      "learning_rate": 7.86586242374231e-06,
      "loss": 0.2247,
      "step": 6207
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.20745104551315308,
      "learning_rate": 7.848528390407105e-06,
      "loss": 0.3103,
      "step": 6208
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1296449899673462,
      "learning_rate": 7.83121269752125e-06,
      "loss": 0.2267,
      "step": 6209
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.15310776233673096,
      "learning_rate": 7.81391534853101e-06,
      "loss": 0.3347,
      "step": 6210
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.175560861825943,
      "learning_rate": 7.79663634687896e-06,
      "loss": 0.2512,
      "step": 6211
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.14275173842906952,
      "learning_rate": 7.779375696004066e-06,
      "loss": 0.2637,
      "step": 6212
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.17253077030181885,
      "learning_rate": 7.762133399341642e-06,
      "loss": 0.2927,
      "step": 6213
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.16794921457767487,
      "learning_rate": 7.744909460323324e-06,
      "loss": 0.2609,
      "step": 6214
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.19174417853355408,
      "learning_rate": 7.727703882377124e-06,
      "loss": 0.28,
      "step": 6215
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.13081811368465424,
      "learning_rate": 7.71051666892737e-06,
      "loss": 0.2109,
      "step": 6216
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1542489379644394,
      "learning_rate": 7.693347823394726e-06,
      "loss": 0.2502,
      "step": 6217
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1332533061504364,
      "learning_rate": 7.676197349196268e-06,
      "loss": 0.21,
      "step": 6218
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1594277024269104,
      "learning_rate": 7.659065249745334e-06,
      "loss": 0.2741,
      "step": 6219
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.13544371724128723,
      "learning_rate": 7.641951528451664e-06,
      "loss": 0.2523,
      "step": 6220
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.12858590483665466,
      "learning_rate": 7.624856188721285e-06,
      "loss": 0.2241,
      "step": 6221
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.14701104164123535,
      "learning_rate": 7.607779233956635e-06,
      "loss": 0.2285,
      "step": 6222
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.19345997273921967,
      "learning_rate": 7.590720667556428e-06,
      "loss": 0.3256,
      "step": 6223
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.16855396330356598,
      "learning_rate": 7.573680492915758e-06,
      "loss": 0.2765,
      "step": 6224
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1785161793231964,
      "learning_rate": 7.556658713426034e-06,
      "loss": 0.2919,
      "step": 6225
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.14265301823616028,
      "learning_rate": 7.5396553324750484e-06,
      "loss": 0.251,
      "step": 6226
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.18223366141319275,
      "learning_rate": 7.52267035344687e-06,
      "loss": 0.2875,
      "step": 6227
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.19464997947216034,
      "learning_rate": 7.505703779721951e-06,
      "loss": 0.2571,
      "step": 6228
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.17072731256484985,
      "learning_rate": 7.488755614677024e-06,
      "loss": 0.3689,
      "step": 6229
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1594325602054596,
      "learning_rate": 7.4718258616852555e-06,
      "loss": 0.2611,
      "step": 6230
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.16823934018611908,
      "learning_rate": 7.454914524116052e-06,
      "loss": 0.2656,
      "step": 6231
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.17555785179138184,
      "learning_rate": 7.43802160533521e-06,
      "loss": 0.2675,
      "step": 6232
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.18027007579803467,
      "learning_rate": 7.421147108704829e-06,
      "loss": 0.3198,
      "step": 6233
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.11542586237192154,
      "learning_rate": 7.404291037583389e-06,
      "loss": 0.2025,
      "step": 6234
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1988973468542099,
      "learning_rate": 7.387453395325628e-06,
      "loss": 0.4392,
      "step": 6235
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.17454995214939117,
      "learning_rate": 7.370634185282688e-06,
      "loss": 0.2449,
      "step": 6236
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1893974095582962,
      "learning_rate": 7.353833410801992e-06,
      "loss": 0.3062,
      "step": 6237
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15771335363388062,
      "learning_rate": 7.33705107522733e-06,
      "loss": 0.2552,
      "step": 6238
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1451442837715149,
      "learning_rate": 7.320287181898777e-06,
      "loss": 0.2312,
      "step": 6239
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15055438876152039,
      "learning_rate": 7.303541734152819e-06,
      "loss": 0.248,
      "step": 6240
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.10561373829841614,
      "learning_rate": 7.286814735322178e-06,
      "loss": 0.1699,
      "step": 6241
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15990300476551056,
      "learning_rate": 7.27010618873597e-06,
      "loss": 0.2657,
      "step": 6242
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.17800694704055786,
      "learning_rate": 7.253416097719601e-06,
      "loss": 0.2761,
      "step": 6243
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1823468953371048,
      "learning_rate": 7.236744465594825e-06,
      "loss": 0.2766,
      "step": 6244
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.17784403264522552,
      "learning_rate": 7.220091295679698e-06,
      "loss": 0.232,
      "step": 6245
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1169421598315239,
      "learning_rate": 7.203456591288616e-06,
      "loss": 0.2257,
      "step": 6246
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.20467160642147064,
      "learning_rate": 7.186840355732327e-06,
      "loss": 0.3187,
      "step": 6247
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.13615773618221283,
      "learning_rate": 7.170242592317855e-06,
      "loss": 0.1997,
      "step": 6248
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15175725519657135,
      "learning_rate": 7.15366330434859e-06,
      "loss": 0.2339,
      "step": 6249
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.19899871945381165,
      "learning_rate": 7.137102495124215e-06,
      "loss": 0.2169,
      "step": 6250
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.14762312173843384,
      "learning_rate": 7.120560167940749e-06,
      "loss": 0.2592,
      "step": 6251
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1536455601453781,
      "learning_rate": 7.104036326090502e-06,
      "loss": 0.2791,
      "step": 6252
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1939568817615509,
      "learning_rate": 7.0875309728621775e-06,
      "loss": 0.2866,
      "step": 6253
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.16243986785411835,
      "learning_rate": 7.071044111540704e-06,
      "loss": 0.3413,
      "step": 6254
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.18112008273601532,
      "learning_rate": 7.054575745407433e-06,
      "loss": 0.2766,
      "step": 6255
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.16708306968212128,
      "learning_rate": 7.038125877739943e-06,
      "loss": 0.2796,
      "step": 6256
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15824179351329803,
      "learning_rate": 7.021694511812194e-06,
      "loss": 0.2685,
      "step": 6257
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15215745568275452,
      "learning_rate": 7.005281650894424e-06,
      "loss": 0.2615,
      "step": 6258
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.17772191762924194,
      "learning_rate": 6.988887298253211e-06,
      "loss": 0.2972,
      "step": 6259
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.2867843210697174,
      "learning_rate": 6.97251145715141e-06,
      "loss": 0.322,
      "step": 6260
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15724804997444153,
      "learning_rate": 6.9561541308482805e-06,
      "loss": 0.2371,
      "step": 6261
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.15080374479293823,
      "learning_rate": 6.9398153225992855e-06,
      "loss": 0.2483,
      "step": 6262
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.18822522461414337,
      "learning_rate": 6.923495035656291e-06,
      "loss": 0.2569,
      "step": 6263
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.18834641575813293,
      "learning_rate": 6.907193273267431e-06,
      "loss": 0.294,
      "step": 6264
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.18379686772823334,
      "learning_rate": 6.890910038677168e-06,
      "loss": 0.3093,
      "step": 6265
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.16097339987754822,
      "learning_rate": 6.874645335126284e-06,
      "loss": 0.2369,
      "step": 6266
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.16245922446250916,
      "learning_rate": 6.858399165851836e-06,
      "loss": 0.2256,
      "step": 6267
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.13222429156303406,
      "learning_rate": 6.842171534087227e-06,
      "loss": 0.1994,
      "step": 6268
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.14997486770153046,
      "learning_rate": 6.825962443062173e-06,
      "loss": 0.238,
      "step": 6269
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.16395770013332367,
      "learning_rate": 6.80977189600267e-06,
      "loss": 0.265,
      "step": 6270
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.17785681784152985,
      "learning_rate": 6.793599896131064e-06,
      "loss": 0.2668,
      "step": 6271
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.17799945175647736,
      "learning_rate": 6.777446446665969e-06,
      "loss": 0.2734,
      "step": 6272
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.20084603130817413,
      "learning_rate": 6.761311550822347e-06,
      "loss": 0.3086,
      "step": 6273
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.1556583195924759,
      "learning_rate": 6.745195211811428e-06,
      "loss": 0.2641,
      "step": 6274
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.11848267912864685,
      "learning_rate": 6.729097432840781e-06,
      "loss": 0.2222,
      "step": 6275
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.16042205691337585,
      "learning_rate": 6.713018217114264e-06,
      "loss": 0.3,
      "step": 6276
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.1668020486831665,
      "learning_rate": 6.696957567832007e-06,
      "loss": 0.2834,
      "step": 6277
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.1640458106994629,
      "learning_rate": 6.680915488190542e-06,
      "loss": 0.2698,
      "step": 6278
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.23560599982738495,
      "learning_rate": 6.664891981382593e-06,
      "loss": 0.386,
      "step": 6279
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.17074376344680786,
      "learning_rate": 6.6488870505972745e-06,
      "loss": 0.2611,
      "step": 6280
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.1871640384197235,
      "learning_rate": 6.632900699019928e-06,
      "loss": 0.336,
      "step": 6281
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.16367265582084656,
      "learning_rate": 6.6169329298322976e-06,
      "loss": 0.2681,
      "step": 6282
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.14551402628421783,
      "learning_rate": 6.600983746212319e-06,
      "loss": 0.2433,
      "step": 6283
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.5092684626579285,
      "learning_rate": 6.5850531513343085e-06,
      "loss": 0.2516,
      "step": 6284
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.20161864161491394,
      "learning_rate": 6.569141148368818e-06,
      "loss": 0.3391,
      "step": 6285
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.16840574145317078,
      "learning_rate": 6.553247740482771e-06,
      "loss": 0.2867,
      "step": 6286
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.1820167452096939,
      "learning_rate": 6.537372930839325e-06,
      "loss": 0.257,
      "step": 6287
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.17872919142246246,
      "learning_rate": 6.521516722597998e-06,
      "loss": 0.2864,
      "step": 6288
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.17023693025112152,
      "learning_rate": 6.505679118914531e-06,
      "loss": 0.2131,
      "step": 6289
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.20038950443267822,
      "learning_rate": 6.489860122941039e-06,
      "loss": 0.3115,
      "step": 6290
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.12823423743247986,
      "learning_rate": 6.474059737825888e-06,
      "loss": 0.2307,
      "step": 6291
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.16912756860256195,
      "learning_rate": 6.458277966713744e-06,
      "loss": 0.3124,
      "step": 6292
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.13277435302734375,
      "learning_rate": 6.442514812745559e-06,
      "loss": 0.2462,
      "step": 6293
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.21788688004016876,
      "learning_rate": 6.426770279058636e-06,
      "loss": 0.3429,
      "step": 6294
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.21455992758274078,
      "learning_rate": 6.41104436878649e-06,
      "loss": 0.3398,
      "step": 6295
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.17905600368976593,
      "learning_rate": 6.395337085058994e-06,
      "loss": 0.2756,
      "step": 6296
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.15465997159481049,
      "learning_rate": 6.379648431002283e-06,
      "loss": 0.2403,
      "step": 6297
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.13777507841587067,
      "learning_rate": 6.363978409738802e-06,
      "loss": 0.2797,
      "step": 6298
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.15997599065303802,
      "learning_rate": 6.348327024387268e-06,
      "loss": 0.3347,
      "step": 6299
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.17103040218353271,
      "learning_rate": 6.332694278062712e-06,
      "loss": 0.2991,
      "step": 6300
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.1424751728773117,
      "learning_rate": 6.3170801738764e-06,
      "loss": 0.2181,
      "step": 6301
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.15911360085010529,
      "learning_rate": 6.301484714935979e-06,
      "loss": 0.2539,
      "step": 6302
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.21512717008590698,
      "learning_rate": 6.285907904345312e-06,
      "loss": 0.2736,
      "step": 6303
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.14698278903961182,
      "learning_rate": 6.270349745204584e-06,
      "loss": 0.2289,
      "step": 6304
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.15640822052955627,
      "learning_rate": 6.254810240610232e-06,
      "loss": 0.2629,
      "step": 6305
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1752476990222931,
      "learning_rate": 6.239289393655057e-06,
      "loss": 0.3149,
      "step": 6306
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.16282574832439423,
      "learning_rate": 6.223787207428056e-06,
      "loss": 0.2714,
      "step": 6307
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.20537418127059937,
      "learning_rate": 6.2083036850145605e-06,
      "loss": 0.386,
      "step": 6308
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.17577828466892242,
      "learning_rate": 6.192838829496184e-06,
      "loss": 0.2701,
      "step": 6309
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1890176385641098,
      "learning_rate": 6.177392643950797e-06,
      "loss": 0.4007,
      "step": 6310
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.16490714251995087,
      "learning_rate": 6.161965131452618e-06,
      "loss": 0.2617,
      "step": 6311
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.16168707609176636,
      "learning_rate": 6.146556295072059e-06,
      "loss": 0.2787,
      "step": 6312
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1489313244819641,
      "learning_rate": 6.131166137875921e-06,
      "loss": 0.25,
      "step": 6313
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.19230423867702484,
      "learning_rate": 6.115794662927177e-06,
      "loss": 0.3332,
      "step": 6314
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1518939882516861,
      "learning_rate": 6.100441873285179e-06,
      "loss": 0.2818,
      "step": 6315
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.17723894119262695,
      "learning_rate": 6.085107772005494e-06,
      "loss": 0.2567,
      "step": 6316
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.15427711606025696,
      "learning_rate": 6.0697923621399924e-06,
      "loss": 0.2643,
      "step": 6317
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.15294699370861053,
      "learning_rate": 6.054495646736813e-06,
      "loss": 0.2441,
      "step": 6318
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.061487078666687,
      "learning_rate": 6.03921762884041e-06,
      "loss": 0.3186,
      "step": 6319
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1605231761932373,
      "learning_rate": 6.023958311491473e-06,
      "loss": 0.2701,
      "step": 6320
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.18505382537841797,
      "learning_rate": 6.0087176977270066e-06,
      "loss": 0.3283,
      "step": 6321
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.193095400929451,
      "learning_rate": 5.99349579058025e-06,
      "loss": 0.4408,
      "step": 6322
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.47644782066345215,
      "learning_rate": 5.97829259308077e-06,
      "loss": 0.42,
      "step": 6323
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1211531013250351,
      "learning_rate": 5.963108108254367e-06,
      "loss": 0.1548,
      "step": 6324
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.14388282597064972,
      "learning_rate": 5.9479423391231355e-06,
      "loss": 0.2083,
      "step": 6325
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1444411277770996,
      "learning_rate": 5.9327952887054286e-06,
      "loss": 0.2674,
      "step": 6326
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.17181357741355896,
      "learning_rate": 5.917666960015922e-06,
      "loss": 0.2743,
      "step": 6327
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.20051558315753937,
      "learning_rate": 5.902557356065497e-06,
      "loss": 0.2765,
      "step": 6328
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1315556764602661,
      "learning_rate": 5.88746647986137e-06,
      "loss": 0.2475,
      "step": 6329
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.21327392756938934,
      "learning_rate": 5.872394334406983e-06,
      "loss": 0.4466,
      "step": 6330
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.13808031380176544,
      "learning_rate": 5.857340922702104e-06,
      "loss": 0.2195,
      "step": 6331
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.15477731823921204,
      "learning_rate": 5.842306247742691e-06,
      "loss": 0.2993,
      "step": 6332
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.15641683340072632,
      "learning_rate": 5.827290312521061e-06,
      "loss": 0.3488,
      "step": 6333
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.27782416343688965,
      "learning_rate": 5.812293120025725e-06,
      "loss": 0.3653,
      "step": 6334
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.18501593172550201,
      "learning_rate": 5.797314673241527e-06,
      "loss": 0.2721,
      "step": 6335
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.15762236714363098,
      "learning_rate": 5.78235497514954e-06,
      "loss": 0.2655,
      "step": 6336
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.21786096692085266,
      "learning_rate": 5.767414028727136e-06,
      "loss": 0.3115,
      "step": 6337
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.17399908602237701,
      "learning_rate": 5.7524918369479154e-06,
      "loss": 0.258,
      "step": 6338
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.14535823464393616,
      "learning_rate": 5.73758840278179e-06,
      "loss": 0.3019,
      "step": 6339
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.16070380806922913,
      "learning_rate": 5.722703729194889e-06,
      "loss": 0.2345,
      "step": 6340
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.14533887803554535,
      "learning_rate": 5.707837819149642e-06,
      "loss": 0.2689,
      "step": 6341
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.16180209815502167,
      "learning_rate": 5.692990675604759e-06,
      "loss": 0.2835,
      "step": 6342
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1803731620311737,
      "learning_rate": 5.678162301515167e-06,
      "loss": 0.267,
      "step": 6343
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.14500975608825684,
      "learning_rate": 5.663352699832103e-06,
      "loss": 0.2437,
      "step": 6344
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.16416238248348236,
      "learning_rate": 5.648561873503022e-06,
      "loss": 0.2906,
      "step": 6345
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.18806587159633636,
      "learning_rate": 5.6337898254717135e-06,
      "loss": 0.3248,
      "step": 6346
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1454233080148697,
      "learning_rate": 5.619036558678148e-06,
      "loss": 0.238,
      "step": 6347
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1973034143447876,
      "learning_rate": 5.60430207605861e-06,
      "loss": 0.3234,
      "step": 6348
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.17978771030902863,
      "learning_rate": 5.589586380545609e-06,
      "loss": 0.2768,
      "step": 6349
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1880788952112198,
      "learning_rate": 5.574889475067968e-06,
      "loss": 0.3484,
      "step": 6350
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.17612867057323456,
      "learning_rate": 5.5602113625507045e-06,
      "loss": 0.3032,
      "step": 6351
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.16765925288200378,
      "learning_rate": 5.54555204591517e-06,
      "loss": 0.2785,
      "step": 6352
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1870851069688797,
      "learning_rate": 5.530911528078908e-06,
      "loss": 0.293,
      "step": 6353
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.15655075013637543,
      "learning_rate": 5.516289811955755e-06,
      "loss": 0.2813,
      "step": 6354
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.19475094974040985,
      "learning_rate": 5.501686900455805e-06,
      "loss": 0.3221,
      "step": 6355
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.17426522076129913,
      "learning_rate": 5.4871027964854e-06,
      "loss": 0.2679,
      "step": 6356
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.14955617487430573,
      "learning_rate": 5.472537502947117e-06,
      "loss": 0.2683,
      "step": 6357
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1385527402162552,
      "learning_rate": 5.457991022739861e-06,
      "loss": 0.2316,
      "step": 6358
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.17539910972118378,
      "learning_rate": 5.443463358758693e-06,
      "loss": 0.2963,
      "step": 6359
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.16382083296775818,
      "learning_rate": 5.428954513895035e-06,
      "loss": 0.2989,
      "step": 6360
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.15293818712234497,
      "learning_rate": 5.4144644910364635e-06,
      "loss": 0.2453,
      "step": 6361
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.12748682498931885,
      "learning_rate": 5.399993293066885e-06,
      "loss": 0.2318,
      "step": 6362
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.16059057414531708,
      "learning_rate": 5.385540922866428e-06,
      "loss": 0.2841,
      "step": 6363
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1681465059518814,
      "learning_rate": 5.371107383311469e-06,
      "loss": 0.3117,
      "step": 6364
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.17929643392562866,
      "learning_rate": 5.356692677274633e-06,
      "loss": 0.2695,
      "step": 6365
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1828789860010147,
      "learning_rate": 5.3422968076248245e-06,
      "loss": 0.2892,
      "step": 6366
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.12655453383922577,
      "learning_rate": 5.3279197772271636e-06,
      "loss": 0.2217,
      "step": 6367
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.18653595447540283,
      "learning_rate": 5.313561588943072e-06,
      "loss": 0.2679,
      "step": 6368
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.22131842374801636,
      "learning_rate": 5.299222245630153e-06,
      "loss": 0.3365,
      "step": 6369
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.18718382716178894,
      "learning_rate": 5.284901750142312e-06,
      "loss": 0.377,
      "step": 6370
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.19818559288978577,
      "learning_rate": 5.270600105329693e-06,
      "loss": 0.2949,
      "step": 6371
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.22178208827972412,
      "learning_rate": 5.256317314038661e-06,
      "loss": 0.3079,
      "step": 6372
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.15510500967502594,
      "learning_rate": 5.2420533791118775e-06,
      "loss": 0.2409,
      "step": 6373
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.14754076302051544,
      "learning_rate": 5.227808303388182e-06,
      "loss": 0.2168,
      "step": 6374
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.15730327367782593,
      "learning_rate": 5.213582089702729e-06,
      "loss": 0.2526,
      "step": 6375
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1732667237520218,
      "learning_rate": 5.199374740886887e-06,
      "loss": 0.3453,
      "step": 6376
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.18554092943668365,
      "learning_rate": 5.185186259768282e-06,
      "loss": 0.3527,
      "step": 6377
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.14242452383041382,
      "learning_rate": 5.171016649170746e-06,
      "loss": 0.2471,
      "step": 6378
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1544932872056961,
      "learning_rate": 5.1568659119144324e-06,
      "loss": 0.2226,
      "step": 6379
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.13121397793293,
      "learning_rate": 5.142734050815668e-06,
      "loss": 0.2102,
      "step": 6380
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.150778129696846,
      "learning_rate": 5.128621068687034e-06,
      "loss": 0.247,
      "step": 6381
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.13683968782424927,
      "learning_rate": 5.114526968337385e-06,
      "loss": 0.2075,
      "step": 6382
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.15413299202919006,
      "learning_rate": 5.100451752571789e-06,
      "loss": 0.2303,
      "step": 6383
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.14476066827774048,
      "learning_rate": 5.0863954241915705e-06,
      "loss": 0.2264,
      "step": 6384
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.15091629326343536,
      "learning_rate": 5.072357985994303e-06,
      "loss": 0.3012,
      "step": 6385
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.19118937849998474,
      "learning_rate": 5.058339440773763e-06,
      "loss": 0.2853,
      "step": 6386
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.14899715781211853,
      "learning_rate": 5.0443397913200185e-06,
      "loss": 0.2411,
      "step": 6387
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1264827847480774,
      "learning_rate": 5.030359040419341e-06,
      "loss": 0.2047,
      "step": 6388
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.14603149890899658,
      "learning_rate": 5.016397190854239e-06,
      "loss": 0.2217,
      "step": 6389
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.11705189198255539,
      "learning_rate": 5.002454245403476e-06,
      "loss": 0.2171,
      "step": 6390
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1960371434688568,
      "learning_rate": 4.988530206842046e-06,
      "loss": 0.2939,
      "step": 6391
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.18940183520317078,
      "learning_rate": 4.974625077941187e-06,
      "loss": 0.3008,
      "step": 6392
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.14086908102035522,
      "learning_rate": 4.960738861468362e-06,
      "loss": 0.2334,
      "step": 6393
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1581934690475464,
      "learning_rate": 4.9468715601872716e-06,
      "loss": 0.2787,
      "step": 6394
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.15416133403778076,
      "learning_rate": 4.933023176857876e-06,
      "loss": 0.2645,
      "step": 6395
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.16713683307170868,
      "learning_rate": 4.919193714236348e-06,
      "loss": 0.3181,
      "step": 6396
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1436467468738556,
      "learning_rate": 4.9053831750750735e-06,
      "loss": 0.2574,
      "step": 6397
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.14898142218589783,
      "learning_rate": 4.891591562122699e-06,
      "loss": 0.2539,
      "step": 6398
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1713373363018036,
      "learning_rate": 4.8778188781241075e-06,
      "loss": 0.2968,
      "step": 6399
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.13757087290287018,
      "learning_rate": 4.864065125820416e-06,
      "loss": 0.2561,
      "step": 6400
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.23213501274585724,
      "learning_rate": 4.850330307948947e-06,
      "loss": 0.4159,
      "step": 6401
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1647282838821411,
      "learning_rate": 4.836614427243302e-06,
      "loss": 0.2675,
      "step": 6402
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.19119076430797577,
      "learning_rate": 4.822917486433254e-06,
      "loss": 0.304,
      "step": 6403
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.14891527593135834,
      "learning_rate": 4.809239488244854e-06,
      "loss": 0.2897,
      "step": 6404
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1476309895515442,
      "learning_rate": 4.795580435400371e-06,
      "loss": 0.2541,
      "step": 6405
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.12962189316749573,
      "learning_rate": 4.781940330618295e-06,
      "loss": 0.2146,
      "step": 6406
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.18080297112464905,
      "learning_rate": 4.768319176613312e-06,
      "loss": 0.2682,
      "step": 6407
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.47732409834861755,
      "learning_rate": 4.75471697609643e-06,
      "loss": 0.2194,
      "step": 6408
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1574772149324417,
      "learning_rate": 4.741133731774783e-06,
      "loss": 0.242,
      "step": 6409
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.19792790710926056,
      "learning_rate": 4.72756944635181e-06,
      "loss": 0.3071,
      "step": 6410
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.13780134916305542,
      "learning_rate": 4.714024122527116e-06,
      "loss": 0.2323,
      "step": 6411
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.17654640972614288,
      "learning_rate": 4.700497762996592e-06,
      "loss": 0.2795,
      "step": 6412
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.14468254148960114,
      "learning_rate": 4.686990370452282e-06,
      "loss": 0.2169,
      "step": 6413
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.16448797285556793,
      "learning_rate": 4.6735019475825255e-06,
      "loss": 0.2842,
      "step": 6414
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.15235121548175812,
      "learning_rate": 4.660032497071831e-06,
      "loss": 0.2413,
      "step": 6415
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.12757235765457153,
      "learning_rate": 4.646582021600976e-06,
      "loss": 0.2007,
      "step": 6416
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.13145025074481964,
      "learning_rate": 4.63315052384693e-06,
      "loss": 0.2469,
      "step": 6417
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.17890186607837677,
      "learning_rate": 4.619738006482921e-06,
      "loss": 0.2373,
      "step": 6418
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.18334229290485382,
      "learning_rate": 4.606344472178337e-06,
      "loss": 0.3292,
      "step": 6419
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.15766267478466034,
      "learning_rate": 4.592969923598878e-06,
      "loss": 0.2818,
      "step": 6420
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.23985999822616577,
      "learning_rate": 4.57961436340636e-06,
      "loss": 0.318,
      "step": 6421
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.14308440685272217,
      "learning_rate": 4.56627779425891e-06,
      "loss": 0.2391,
      "step": 6422
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.2055489867925644,
      "learning_rate": 4.552960218810809e-06,
      "loss": 0.3258,
      "step": 6423
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.14810329675674438,
      "learning_rate": 4.539661639712623e-06,
      "loss": 0.2491,
      "step": 6424
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.11673770099878311,
      "learning_rate": 4.526382059611067e-06,
      "loss": 0.1989,
      "step": 6425
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.1627652496099472,
      "learning_rate": 4.513121481149141e-06,
      "loss": 0.2976,
      "step": 6426
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.18098559975624084,
      "learning_rate": 4.49987990696602e-06,
      "loss": 0.2827,
      "step": 6427
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.1888156533241272,
      "learning_rate": 4.486657339697109e-06,
      "loss": 0.2548,
      "step": 6428
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.15842540562152863,
      "learning_rate": 4.473453781974024e-06,
      "loss": 0.2767,
      "step": 6429
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.15989170968532562,
      "learning_rate": 4.4602692364245965e-06,
      "loss": 0.3594,
      "step": 6430
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.16904772818088531,
      "learning_rate": 4.447103705672906e-06,
      "loss": 0.2548,
      "step": 6431
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.18490883708000183,
      "learning_rate": 4.433957192339188e-06,
      "loss": 0.294,
      "step": 6432
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.16799534857273102,
      "learning_rate": 4.420829699039974e-06,
      "loss": 0.2265,
      "step": 6433
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.18498636782169342,
      "learning_rate": 4.407721228387918e-06,
      "loss": 0.2781,
      "step": 6434
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.16146372258663177,
      "learning_rate": 4.394631782991965e-06,
      "loss": 0.2392,
      "step": 6435
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.14135803282260895,
      "learning_rate": 4.381561365457232e-06,
      "loss": 0.2401,
      "step": 6436
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.17736932635307312,
      "learning_rate": 4.3685099783850605e-06,
      "loss": 0.2912,
      "step": 6437
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.14530453085899353,
      "learning_rate": 4.3554776243729835e-06,
      "loss": 0.2602,
      "step": 6438
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.16700205206871033,
      "learning_rate": 4.342464306014793e-06,
      "loss": 0.2564,
      "step": 6439
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.14842137694358826,
      "learning_rate": 4.329470025900451e-06,
      "loss": 0.283,
      "step": 6440
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.18685320019721985,
      "learning_rate": 4.316494786616154e-06,
      "loss": 0.2364,
      "step": 6441
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.11918070167303085,
      "learning_rate": 4.303538590744294e-06,
      "loss": 0.1681,
      "step": 6442
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.22243401408195496,
      "learning_rate": 4.290601440863473e-06,
      "loss": 0.3522,
      "step": 6443
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.15129800140857697,
      "learning_rate": 4.277683339548522e-06,
      "loss": 0.3131,
      "step": 6444
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.19214382767677307,
      "learning_rate": 4.26478428937046e-06,
      "loss": 0.3035,
      "step": 6445
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.17466974258422852,
      "learning_rate": 4.251904292896503e-06,
      "loss": 0.3397,
      "step": 6446
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1375364363193512,
      "learning_rate": 4.239043352690119e-06,
      "loss": 0.2402,
      "step": 6447
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1595124900341034,
      "learning_rate": 4.226201471310942e-06,
      "loss": 0.2836,
      "step": 6448
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.15295900404453278,
      "learning_rate": 4.213378651314836e-06,
      "loss": 0.2842,
      "step": 6449
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.17149478197097778,
      "learning_rate": 4.200574895253839e-06,
      "loss": 0.362,
      "step": 6450
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1413610875606537,
      "learning_rate": 4.187790205676268e-06,
      "loss": 0.2083,
      "step": 6451
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.17041854560375214,
      "learning_rate": 4.175024585126552e-06,
      "loss": 0.3427,
      "step": 6452
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.191515251994133,
      "learning_rate": 4.162278036145395e-06,
      "loss": 0.3533,
      "step": 6453
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1708880215883255,
      "learning_rate": 4.149550561269655e-06,
      "loss": 0.2765,
      "step": 6454
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.13073712587356567,
      "learning_rate": 4.136842163032439e-06,
      "loss": 0.1948,
      "step": 6455
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.15170718729496002,
      "learning_rate": 4.124152843963014e-06,
      "loss": 0.1941,
      "step": 6456
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.15366993844509125,
      "learning_rate": 4.1114826065869025e-06,
      "loss": 0.273,
      "step": 6457
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.2073686420917511,
      "learning_rate": 4.098831453425766e-06,
      "loss": 0.2531,
      "step": 6458
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.15488843619823456,
      "learning_rate": 4.0861993869975355e-06,
      "loss": 0.3242,
      "step": 6459
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.18934974074363708,
      "learning_rate": 4.073586409816288e-06,
      "loss": 0.2957,
      "step": 6460
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1643899828195572,
      "learning_rate": 4.060992524392326e-06,
      "loss": 0.212,
      "step": 6461
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.12901310622692108,
      "learning_rate": 4.048417733232146e-06,
      "loss": 0.237,
      "step": 6462
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1858687400817871,
      "learning_rate": 4.035862038838434e-06,
      "loss": 0.311,
      "step": 6463
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1811075657606125,
      "learning_rate": 4.023325443710113e-06,
      "loss": 0.3534,
      "step": 6464
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.19469715654850006,
      "learning_rate": 4.010807950342255e-06,
      "loss": 0.2549,
      "step": 6465
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.18488408625125885,
      "learning_rate": 3.998309561226177e-06,
      "loss": 0.3402,
      "step": 6466
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.18895502388477325,
      "learning_rate": 3.985830278849345e-06,
      "loss": 0.3532,
      "step": 6467
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.147941455245018,
      "learning_rate": 3.973370105695485e-06,
      "loss": 0.2961,
      "step": 6468
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1409202665090561,
      "learning_rate": 3.960929044244444e-06,
      "loss": 0.2808,
      "step": 6469
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.16958506405353546,
      "learning_rate": 3.948507096972343e-06,
      "loss": 0.2784,
      "step": 6470
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.17084559798240662,
      "learning_rate": 3.936104266351415e-06,
      "loss": 0.2526,
      "step": 6471
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1663779616355896,
      "learning_rate": 3.923720554850164e-06,
      "loss": 0.2769,
      "step": 6472
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.17952017486095428,
      "learning_rate": 3.91135596493325e-06,
      "loss": 0.296,
      "step": 6473
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.14218682050704956,
      "learning_rate": 3.899010499061551e-06,
      "loss": 0.2739,
      "step": 6474
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.17802898585796356,
      "learning_rate": 3.8866841596921e-06,
      "loss": 0.2924,
      "step": 6475
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.17582967877388,
      "learning_rate": 3.874376949278169e-06,
      "loss": 0.3327,
      "step": 6476
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1569453924894333,
      "learning_rate": 3.862088870269187e-06,
      "loss": 0.2591,
      "step": 6477
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.14793626964092255,
      "learning_rate": 3.849819925110798e-06,
      "loss": 0.249,
      "step": 6478
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.18527992069721222,
      "learning_rate": 3.837570116244815e-06,
      "loss": 0.3504,
      "step": 6479
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.14354294538497925,
      "learning_rate": 3.825339446109266e-06,
      "loss": 0.2967,
      "step": 6480
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.18017710745334625,
      "learning_rate": 3.8131279171383594e-06,
      "loss": 0.3258,
      "step": 6481
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.14829039573669434,
      "learning_rate": 3.800935531762506e-06,
      "loss": 0.2245,
      "step": 6482
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.18811769783496857,
      "learning_rate": 3.7887622924082657e-06,
      "loss": 0.2884,
      "step": 6483
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.14184290170669556,
      "learning_rate": 3.776608201498455e-06,
      "loss": 0.2777,
      "step": 6484
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.14847475290298462,
      "learning_rate": 3.7644732614520285e-06,
      "loss": 0.2931,
      "step": 6485
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1903364062309265,
      "learning_rate": 3.7523574746841315e-06,
      "loss": 0.2818,
      "step": 6486
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.15377779304981232,
      "learning_rate": 3.740260843606114e-06,
      "loss": 0.2445,
      "step": 6487
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.16865174472332,
      "learning_rate": 3.7281833706255154e-06,
      "loss": 0.282,
      "step": 6488
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.12844347953796387,
      "learning_rate": 3.716125058146036e-06,
      "loss": 0.2186,
      "step": 6489
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.15544986724853516,
      "learning_rate": 3.7040859085676116e-06,
      "loss": 0.2594,
      "step": 6490
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.20759819447994232,
      "learning_rate": 3.6920659242863253e-06,
      "loss": 0.2522,
      "step": 6491
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.17317895591259003,
      "learning_rate": 3.6800651076944305e-06,
      "loss": 0.2917,
      "step": 6492
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.14320193231105804,
      "learning_rate": 3.668083461180416e-06,
      "loss": 0.2191,
      "step": 6493
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.16470567882061005,
      "learning_rate": 3.6561209871289303e-06,
      "loss": 0.3244,
      "step": 6494
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1901153326034546,
      "learning_rate": 3.644177687920791e-06,
      "loss": 0.2777,
      "step": 6495
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.17789477109909058,
      "learning_rate": 3.632253565933008e-06,
      "loss": 0.3109,
      "step": 6496
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.17235635221004486,
      "learning_rate": 3.620348623538805e-06,
      "loss": 0.2519,
      "step": 6497
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.16754673421382904,
      "learning_rate": 3.608462863107531e-06,
      "loss": 0.2572,
      "step": 6498
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.15803977847099304,
      "learning_rate": 3.5965962870047944e-06,
      "loss": 0.269,
      "step": 6499
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.18463680148124695,
      "learning_rate": 3.5847488975922937e-06,
      "loss": 0.3147,
      "step": 6500
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.15413668751716614,
      "learning_rate": 3.5729206972279994e-06,
      "loss": 0.2242,
      "step": 6501
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.16821859776973724,
      "learning_rate": 3.5611116882659723e-06,
      "loss": 0.3014,
      "step": 6502
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1743982881307602,
      "learning_rate": 3.5493218730565438e-06,
      "loss": 0.3105,
      "step": 6503
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.16563287377357483,
      "learning_rate": 3.5375512539461476e-06,
      "loss": 0.2831,
      "step": 6504
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.18778960406780243,
      "learning_rate": 3.5257998332774544e-06,
      "loss": 0.2777,
      "step": 6505
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.19272619485855103,
      "learning_rate": 3.5140676133892825e-06,
      "loss": 0.31,
      "step": 6506
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.14870710670948029,
      "learning_rate": 3.5023545966166414e-06,
      "loss": 0.2398,
      "step": 6507
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1530308574438095,
      "learning_rate": 3.4906607852907223e-06,
      "loss": 0.3254,
      "step": 6508
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.18460121750831604,
      "learning_rate": 3.4789861817388747e-06,
      "loss": 0.2659,
      "step": 6509
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.12079501897096634,
      "learning_rate": 3.467330788284617e-06,
      "loss": 0.2216,
      "step": 6510
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.18750646710395813,
      "learning_rate": 3.4556946072477057e-06,
      "loss": 0.3262,
      "step": 6511
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.17920804023742676,
      "learning_rate": 3.44407764094401e-06,
      "loss": 0.3019,
      "step": 6512
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.20049332082271576,
      "learning_rate": 3.4324798916855916e-06,
      "loss": 0.2696,
      "step": 6513
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1623551845550537,
      "learning_rate": 3.420901361780704e-06,
      "loss": 0.2605,
      "step": 6514
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.14463448524475098,
      "learning_rate": 3.4093420535337706e-06,
      "loss": 0.2561,
      "step": 6515
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1809009611606598,
      "learning_rate": 3.3978019692453623e-06,
      "loss": 0.2691,
      "step": 6516
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1594880372285843,
      "learning_rate": 3.3862811112122638e-06,
      "loss": 0.2678,
      "step": 6517
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.14986376464366913,
      "learning_rate": 3.374779481727397e-06,
      "loss": 0.2415,
      "step": 6518
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.16565394401550293,
      "learning_rate": 3.363297083079897e-06,
      "loss": 0.282,
      "step": 6519
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.15063567459583282,
      "learning_rate": 3.351833917555014e-06,
      "loss": 0.2486,
      "step": 6520
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.16708238422870636,
      "learning_rate": 3.340389987434245e-06,
      "loss": 0.2464,
      "step": 6521
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.19368255138397217,
      "learning_rate": 3.328965294995201e-06,
      "loss": 0.313,
      "step": 6522
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.20120787620544434,
      "learning_rate": 3.317559842511664e-06,
      "loss": 0.3413,
      "step": 6523
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.16552568972110748,
      "learning_rate": 3.3061736322536286e-06,
      "loss": 0.2446,
      "step": 6524
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.20358307659626007,
      "learning_rate": 3.294806666487238e-06,
      "loss": 0.3028,
      "step": 6525
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1398933231830597,
      "learning_rate": 3.283458947474782e-06,
      "loss": 0.2302,
      "step": 6526
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.13290895521640778,
      "learning_rate": 3.272130477474744e-06,
      "loss": 0.2333,
      "step": 6527
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.11184276640415192,
      "learning_rate": 3.260821258741786e-06,
      "loss": 0.1803,
      "step": 6528
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.19405190646648407,
      "learning_rate": 3.2495312935267197e-06,
      "loss": 0.3271,
      "step": 6529
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1679762899875641,
      "learning_rate": 3.2382605840765355e-06,
      "loss": 0.2157,
      "step": 6530
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.13513857126235962,
      "learning_rate": 3.2270091326343733e-06,
      "loss": 0.2539,
      "step": 6531
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1705009639263153,
      "learning_rate": 3.2157769414395744e-06,
      "loss": 0.2667,
      "step": 6532
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.16163212060928345,
      "learning_rate": 3.2045640127276065e-06,
      "loss": 0.2431,
      "step": 6533
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.14092615246772766,
      "learning_rate": 3.1933703487301405e-06,
      "loss": 0.2396,
      "step": 6534
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2502100169658661,
      "learning_rate": 3.18219595167496e-06,
      "loss": 0.3667,
      "step": 6535
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.20659594237804413,
      "learning_rate": 3.171040823786098e-06,
      "loss": 0.3142,
      "step": 6536
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.15538112819194794,
      "learning_rate": 3.1599049672836666e-06,
      "loss": 0.286,
      "step": 6537
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1356275975704193,
      "learning_rate": 3.148788384384016e-06,
      "loss": 0.2306,
      "step": 6538
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.14482559263706207,
      "learning_rate": 3.137691077299576e-06,
      "loss": 0.2441,
      "step": 6539
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.18232591450214386,
      "learning_rate": 3.1266130482390354e-06,
      "loss": 0.3454,
      "step": 6540
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.16387739777565002,
      "learning_rate": 3.1155542994071863e-06,
      "loss": 0.2744,
      "step": 6541
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.14649024605751038,
      "learning_rate": 3.104514833004979e-06,
      "loss": 0.3064,
      "step": 6542
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.21711291372776031,
      "learning_rate": 3.093494651229545e-06,
      "loss": 0.3561,
      "step": 6543
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.15892326831817627,
      "learning_rate": 3.0824937562742074e-06,
      "loss": 0.2248,
      "step": 6544
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1848789006471634,
      "learning_rate": 3.0715121503283705e-06,
      "loss": 0.2776,
      "step": 6545
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1786855310201645,
      "learning_rate": 3.0605498355776974e-06,
      "loss": 0.3217,
      "step": 6546
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2569738030433655,
      "learning_rate": 3.049606814203931e-06,
      "loss": 0.3822,
      "step": 6547
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.21074369549751282,
      "learning_rate": 3.0386830883850306e-06,
      "loss": 0.3241,
      "step": 6548
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.16439209878444672,
      "learning_rate": 3.0277786602950776e-06,
      "loss": 0.307,
      "step": 6549
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.15087710320949554,
      "learning_rate": 3.0168935321043148e-06,
      "loss": 0.2442,
      "step": 6550
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.1560659259557724,
      "learning_rate": 3.0060277059791753e-06,
      "loss": 0.2296,
      "step": 6551
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.16046801209449768,
      "learning_rate": 2.9951811840822186e-06,
      "loss": 0.2974,
      "step": 6552
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.15640927851200104,
      "learning_rate": 2.9843539685721734e-06,
      "loss": 0.3185,
      "step": 6553
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1809173822402954,
      "learning_rate": 2.973546061603927e-06,
      "loss": 0.2854,
      "step": 6554
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.14187714457511902,
      "learning_rate": 2.962757465328547e-06,
      "loss": 0.2587,
      "step": 6555
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1432766318321228,
      "learning_rate": 2.9519881818931836e-06,
      "loss": 0.2422,
      "step": 6556
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.14974850416183472,
      "learning_rate": 2.9412382134412554e-06,
      "loss": 0.2345,
      "step": 6557
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1381266564130783,
      "learning_rate": 2.930507562112228e-06,
      "loss": 0.2268,
      "step": 6558
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.15868742763996124,
      "learning_rate": 2.9197962300417935e-06,
      "loss": 0.3145,
      "step": 6559
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.17276766896247864,
      "learning_rate": 2.909104219361758e-06,
      "loss": 0.2951,
      "step": 6560
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.17127618193626404,
      "learning_rate": 2.898431532200119e-06,
      "loss": 0.2971,
      "step": 6561
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.14553581178188324,
      "learning_rate": 2.887778170680977e-06,
      "loss": 0.244,
      "step": 6562
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.16196052730083466,
      "learning_rate": 2.877144136924659e-06,
      "loss": 0.2617,
      "step": 6563
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.17152172327041626,
      "learning_rate": 2.866529433047571e-06,
      "loss": 0.2512,
      "step": 6564
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.17752738296985626,
      "learning_rate": 2.8559340611623244e-06,
      "loss": 0.3002,
      "step": 6565
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1898394078016281,
      "learning_rate": 2.8453580233776642e-06,
      "loss": 0.405,
      "step": 6566
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.16564388573169708,
      "learning_rate": 2.8348013217984636e-06,
      "loss": 0.2815,
      "step": 6567
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1812855750322342,
      "learning_rate": 2.8242639585257857e-06,
      "loss": 0.3413,
      "step": 6568
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1444179266691208,
      "learning_rate": 2.813745935656842e-06,
      "loss": 0.2498,
      "step": 6569
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.19384372234344482,
      "learning_rate": 2.8032472552849577e-06,
      "loss": 0.3765,
      "step": 6570
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.13209019601345062,
      "learning_rate": 2.7927679194996503e-06,
      "loss": 0.2299,
      "step": 6571
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.17715229094028473,
      "learning_rate": 2.7823079303865517e-06,
      "loss": 0.2502,
      "step": 6572
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1479668915271759,
      "learning_rate": 2.7718672900274856e-06,
      "loss": 0.2512,
      "step": 6573
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.18897077441215515,
      "learning_rate": 2.7614460005004007e-06,
      "loss": 0.3366,
      "step": 6574
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.22124913334846497,
      "learning_rate": 2.7510440638793713e-06,
      "loss": 0.4275,
      "step": 6575
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.19001983106136322,
      "learning_rate": 2.740661482234652e-06,
      "loss": 0.2733,
      "step": 6576
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.16071276366710663,
      "learning_rate": 2.7302982576326462e-06,
      "loss": 0.2433,
      "step": 6577
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1397472769021988,
      "learning_rate": 2.7199543921358704e-06,
      "loss": 0.2431,
      "step": 6578
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.2010508030653,
      "learning_rate": 2.709629887803056e-06,
      "loss": 0.355,
      "step": 6579
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.201638326048851,
      "learning_rate": 2.6993247466889913e-06,
      "loss": 0.2706,
      "step": 6580
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1776190847158432,
      "learning_rate": 2.6890389708446927e-06,
      "loss": 0.2728,
      "step": 6581
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.1674908846616745,
      "learning_rate": 2.6787725623172777e-06,
      "loss": 0.2999,
      "step": 6582
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.17047907412052155,
      "learning_rate": 2.6685255231500005e-06,
      "loss": 0.3026,
      "step": 6583
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.21401822566986084,
      "learning_rate": 2.658297855382297e-06,
      "loss": 0.3253,
      "step": 6584
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.18073968589305878,
      "learning_rate": 2.648089561049716e-06,
      "loss": 0.2733,
      "step": 6585
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.16805195808410645,
      "learning_rate": 2.637900642183977e-06,
      "loss": 0.2507,
      "step": 6586
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.18204814195632935,
      "learning_rate": 2.6277311008129136e-06,
      "loss": 0.2568,
      "step": 6587
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.2020474076271057,
      "learning_rate": 2.61758093896054e-06,
      "loss": 0.2497,
      "step": 6588
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.14152498543262482,
      "learning_rate": 2.607450158646985e-06,
      "loss": 0.254,
      "step": 6589
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.22822552919387817,
      "learning_rate": 2.5973387618885236e-06,
      "loss": 0.3261,
      "step": 6590
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.2009998857975006,
      "learning_rate": 2.5872467506975697e-06,
      "loss": 0.3587,
      "step": 6591
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.20925185084342957,
      "learning_rate": 2.577174127082693e-06,
      "loss": 0.265,
      "step": 6592
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.15089651942253113,
      "learning_rate": 2.5671208930486026e-06,
      "loss": 0.2954,
      "step": 6593
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.17341087758541107,
      "learning_rate": 2.557087050596141e-06,
      "loss": 0.3508,
      "step": 6594
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.16095584630966187,
      "learning_rate": 2.547072601722289e-06,
      "loss": 0.2533,
      "step": 6595
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.13869282603263855,
      "learning_rate": 2.537077548420186e-06,
      "loss": 0.2109,
      "step": 6596
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.21303768455982208,
      "learning_rate": 2.5271018926790845e-06,
      "loss": 0.2575,
      "step": 6597
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.15762968361377716,
      "learning_rate": 2.517145636484386e-06,
      "loss": 0.2941,
      "step": 6598
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.1277630478143692,
      "learning_rate": 2.5072087818176382e-06,
      "loss": 0.2269,
      "step": 6599
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.18907859921455383,
      "learning_rate": 2.4972913306565372e-06,
      "loss": 0.2789,
      "step": 6600
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.20850858092308044,
      "learning_rate": 2.4873932849748925e-06,
      "loss": 0.3231,
      "step": 6601
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.15045499801635742,
      "learning_rate": 2.4775146467426624e-06,
      "loss": 0.261,
      "step": 6602
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.16569073498249054,
      "learning_rate": 2.4676554179259515e-06,
      "loss": 0.2653,
      "step": 6603
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.1544344127178192,
      "learning_rate": 2.457815600486979e-06,
      "loss": 0.2927,
      "step": 6604
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.17466288805007935,
      "learning_rate": 2.447995196384134e-06,
      "loss": 0.265,
      "step": 6605
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.1587432324886322,
      "learning_rate": 2.4381942075719087e-06,
      "loss": 0.2782,
      "step": 6606
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.15380987524986267,
      "learning_rate": 2.4284126360009428e-06,
      "loss": 0.2663,
      "step": 6607
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.14975133538246155,
      "learning_rate": 2.4186504836180235e-06,
      "loss": 0.2703,
      "step": 6608
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.16020312905311584,
      "learning_rate": 2.4089077523660517e-06,
      "loss": 0.301,
      "step": 6609
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.17054897546768188,
      "learning_rate": 2.3991844441840884e-06,
      "loss": 0.2783,
      "step": 6610
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.15071254968643188,
      "learning_rate": 2.3894805610073068e-06,
      "loss": 0.2876,
      "step": 6611
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.19172973930835724,
      "learning_rate": 2.3797961047670293e-06,
      "loss": 0.2961,
      "step": 6612
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.16288790106773376,
      "learning_rate": 2.3701310773907028e-06,
      "loss": 0.3079,
      "step": 6613
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.18829959630966187,
      "learning_rate": 2.3604854808019106e-06,
      "loss": 0.367,
      "step": 6614
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.16506940126419067,
      "learning_rate": 2.350859316920362e-06,
      "loss": 0.2379,
      "step": 6615
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.1629675328731537,
      "learning_rate": 2.3412525876618906e-06,
      "loss": 0.2591,
      "step": 6616
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.19231227040290833,
      "learning_rate": 2.3316652949385122e-06,
      "loss": 0.3276,
      "step": 6617
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.15995967388153076,
      "learning_rate": 2.322097440658311e-06,
      "loss": 0.24,
      "step": 6618
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.1771794706583023,
      "learning_rate": 2.3125490267255414e-06,
      "loss": 0.3303,
      "step": 6619
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.13881367444992065,
      "learning_rate": 2.3030200550405613e-06,
      "loss": 0.1951,
      "step": 6620
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.17058348655700684,
      "learning_rate": 2.293510527499898e-06,
      "loss": 0.251,
      "step": 6621
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.20473460853099823,
      "learning_rate": 2.2840204459961713e-06,
      "loss": 0.3066,
      "step": 6622
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.15279096364974976,
      "learning_rate": 2.2745498124181474e-06,
      "loss": 0.3884,
      "step": 6623
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.15858739614486694,
      "learning_rate": 2.265098628650708e-06,
      "loss": 0.2791,
      "step": 6624
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.15840162336826324,
      "learning_rate": 2.2556668965749038e-06,
      "loss": 0.2603,
      "step": 6625
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.22172462940216064,
      "learning_rate": 2.2462546180678557e-06,
      "loss": 0.3524,
      "step": 6626
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.16369275748729706,
      "learning_rate": 2.236861795002854e-06,
      "loss": 0.2546,
      "step": 6627
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1901201754808426,
      "learning_rate": 2.2274884292493137e-06,
      "loss": 0.3131,
      "step": 6628
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1488351821899414,
      "learning_rate": 2.2181345226727547e-06,
      "loss": 0.2533,
      "step": 6629
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.17138762772083282,
      "learning_rate": 2.2088000771348537e-06,
      "loss": 0.305,
      "step": 6630
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1322556436061859,
      "learning_rate": 2.199485094493392e-06,
      "loss": 0.1934,
      "step": 6631
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.12793835997581482,
      "learning_rate": 2.1901895766022753e-06,
      "loss": 0.2199,
      "step": 6632
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.12797853350639343,
      "learning_rate": 2.1809135253115565e-06,
      "loss": 0.2193,
      "step": 6633
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1687110960483551,
      "learning_rate": 2.1716569424673925e-06,
      "loss": 0.3081,
      "step": 6634
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1709473878145218,
      "learning_rate": 2.162419829912088e-06,
      "loss": 0.2782,
      "step": 6635
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1523628830909729,
      "learning_rate": 2.1532021894840495e-06,
      "loss": 0.283,
      "step": 6636
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.14604909718036652,
      "learning_rate": 2.1440040230178203e-06,
      "loss": 0.2844,
      "step": 6637
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.38540083169937134,
      "learning_rate": 2.13482533234407e-06,
      "loss": 0.3221,
      "step": 6638
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.24730508029460907,
      "learning_rate": 2.125666119289582e-06,
      "loss": 0.3469,
      "step": 6639
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.13270428776741028,
      "learning_rate": 2.1165263856772645e-06,
      "loss": 0.3773,
      "step": 6640
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.16735471785068512,
      "learning_rate": 2.107406133326173e-06,
      "loss": 0.2599,
      "step": 6641
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.16721846163272858,
      "learning_rate": 2.098305364051434e-06,
      "loss": 0.3135,
      "step": 6642
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.17600220441818237,
      "learning_rate": 2.089224079664365e-06,
      "loss": 0.2869,
      "step": 6643
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.17518918216228485,
      "learning_rate": 2.080162281972342e-06,
      "loss": 0.2735,
      "step": 6644
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.16888083517551422,
      "learning_rate": 2.07111997277889e-06,
      "loss": 0.2258,
      "step": 6645
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1732051819562912,
      "learning_rate": 2.0620971538836797e-06,
      "loss": 0.3356,
      "step": 6646
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.19521811604499817,
      "learning_rate": 2.0530938270824528e-06,
      "loss": 0.354,
      "step": 6647
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.15167208015918732,
      "learning_rate": 2.0441099941671095e-06,
      "loss": 0.202,
      "step": 6648
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.13715095818042755,
      "learning_rate": 2.0351456569256522e-06,
      "loss": 0.1918,
      "step": 6649
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.18813379108905792,
      "learning_rate": 2.0262008171422097e-06,
      "loss": 0.333,
      "step": 6650
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1955900341272354,
      "learning_rate": 2.0172754765970135e-06,
      "loss": 0.4661,
      "step": 6651
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1570044457912445,
      "learning_rate": 2.008369637066465e-06,
      "loss": 0.2999,
      "step": 6652
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.14222478866577148,
      "learning_rate": 1.9994833003230127e-06,
      "loss": 0.2457,
      "step": 6653
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.1869804859161377,
      "learning_rate": 1.990616468135298e-06,
      "loss": 0.2892,
      "step": 6654
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.17501799762248993,
      "learning_rate": 1.9817691422680083e-06,
      "loss": 0.2887,
      "step": 6655
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.17843614518642426,
      "learning_rate": 1.9729413244820026e-06,
      "loss": 0.2856,
      "step": 6656
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.16691970825195312,
      "learning_rate": 1.9641330165342197e-06,
      "loss": 0.2417,
      "step": 6657
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.14760468900203705,
      "learning_rate": 1.955344220177746e-06,
      "loss": 0.2399,
      "step": 6658
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1933535635471344,
      "learning_rate": 1.9465749371617716e-06,
      "loss": 0.3073,
      "step": 6659
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.21119824051856995,
      "learning_rate": 1.9378251692315996e-06,
      "loss": 0.3419,
      "step": 6660
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.13396809995174408,
      "learning_rate": 1.92909491812866e-06,
      "loss": 0.1998,
      "step": 6661
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.3931615948677063,
      "learning_rate": 1.920384185590485e-06,
      "loss": 0.1572,
      "step": 6662
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.18655698001384735,
      "learning_rate": 1.9116929733507314e-06,
      "loss": 0.312,
      "step": 6663
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.18036556243896484,
      "learning_rate": 1.9030212831391724e-06,
      "loss": 0.3324,
      "step": 6664
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1531112641096115,
      "learning_rate": 1.8943691166816714e-06,
      "loss": 0.242,
      "step": 6665
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1741226464509964,
      "learning_rate": 1.8857364757002505e-06,
      "loss": 0.2773,
      "step": 6666
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1629665642976761,
      "learning_rate": 1.8771233619130023e-06,
      "loss": 0.2657,
      "step": 6667
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.13415519893169403,
      "learning_rate": 1.868529777034167e-06,
      "loss": 0.1781,
      "step": 6668
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.16412034630775452,
      "learning_rate": 1.859955722774065e-06,
      "loss": 0.2737,
      "step": 6669
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.14291810989379883,
      "learning_rate": 1.8514012008391757e-06,
      "loss": 0.2515,
      "step": 6670
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.18713369965553284,
      "learning_rate": 1.8428662129320374e-06,
      "loss": 0.349,
      "step": 6671
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.16543304920196533,
      "learning_rate": 1.8343507607513467e-06,
      "loss": 0.3178,
      "step": 6672
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.17169205844402313,
      "learning_rate": 1.825854845991859e-06,
      "loss": 0.2726,
      "step": 6673
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.13158416748046875,
      "learning_rate": 1.8173784703445107e-06,
      "loss": 0.2082,
      "step": 6674
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.16835393011569977,
      "learning_rate": 1.8089216354962967e-06,
      "loss": 0.3222,
      "step": 6675
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.16346970200538635,
      "learning_rate": 1.8004843431303376e-06,
      "loss": 0.2554,
      "step": 6676
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.13834457099437714,
      "learning_rate": 1.7920665949258675e-06,
      "loss": 0.2272,
      "step": 6677
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.19891728460788727,
      "learning_rate": 1.7836683925582354e-06,
      "loss": 0.2871,
      "step": 6678
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.18584300577640533,
      "learning_rate": 1.7752897376988931e-06,
      "loss": 0.32,
      "step": 6679
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1705804318189621,
      "learning_rate": 1.7669306320153734e-06,
      "loss": 0.2556,
      "step": 6680
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.16850914061069489,
      "learning_rate": 1.7585910771713898e-06,
      "loss": 0.3178,
      "step": 6681
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1629156917333603,
      "learning_rate": 1.7502710748266926e-06,
      "loss": 0.2384,
      "step": 6682
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.16291435062885284,
      "learning_rate": 1.7419706266372015e-06,
      "loss": 0.2121,
      "step": 6683
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.14262482523918152,
      "learning_rate": 1.7336897342548731e-06,
      "loss": 0.2368,
      "step": 6684
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1613597720861435,
      "learning_rate": 1.7254283993278441e-06,
      "loss": 0.3018,
      "step": 6685
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.21056747436523438,
      "learning_rate": 1.717186623500311e-06,
      "loss": 0.2903,
      "step": 6686
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.1447371542453766,
      "learning_rate": 1.7089644084126056e-06,
      "loss": 0.2475,
      "step": 6687
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.15806035697460175,
      "learning_rate": 1.7007617557011412e-06,
      "loss": 0.2839,
      "step": 6688
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.16226594150066376,
      "learning_rate": 1.6925786669984566e-06,
      "loss": 0.3178,
      "step": 6689
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.19695380330085754,
      "learning_rate": 1.6844151439331935e-06,
      "loss": 0.2621,
      "step": 6690
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.14150236546993256,
      "learning_rate": 1.6762711881300962e-06,
      "loss": 0.2473,
      "step": 6691
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.2018568366765976,
      "learning_rate": 1.6681468012100021e-06,
      "loss": 0.2887,
      "step": 6692
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.18035629391670227,
      "learning_rate": 1.660041984789895e-06,
      "loss": 0.269,
      "step": 6693
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.16617269814014435,
      "learning_rate": 1.6519567404828295e-06,
      "loss": 0.297,
      "step": 6694
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.825700581073761,
      "learning_rate": 1.6438910698979514e-06,
      "loss": 0.4,
      "step": 6695
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.19306212663650513,
      "learning_rate": 1.6358449746405436e-06,
      "loss": 0.2837,
      "step": 6696
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.17318199574947357,
      "learning_rate": 1.6278184563119914e-06,
      "loss": 0.2642,
      "step": 6697
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.16381952166557312,
      "learning_rate": 1.6198115165097393e-06,
      "loss": 0.3533,
      "step": 6698
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.18666739761829376,
      "learning_rate": 1.6118241568274128e-06,
      "loss": 0.205,
      "step": 6699
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.17508763074874878,
      "learning_rate": 1.6038563788546623e-06,
      "loss": 0.2713,
      "step": 6700
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.1296393871307373,
      "learning_rate": 1.5959081841772972e-06,
      "loss": 0.2228,
      "step": 6701
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.2115357667207718,
      "learning_rate": 1.5879795743771964e-06,
      "loss": 0.2967,
      "step": 6702
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.18367555737495422,
      "learning_rate": 1.5800705510323532e-06,
      "loss": 0.2855,
      "step": 6703
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.12417295575141907,
      "learning_rate": 1.572181115716853e-06,
      "loss": 0.2023,
      "step": 6704
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.12588228285312653,
      "learning_rate": 1.5643112700008955e-06,
      "loss": 0.2175,
      "step": 6705
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.15207162499427795,
      "learning_rate": 1.556461015450794e-06,
      "loss": 0.2478,
      "step": 6706
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.15977521240711212,
      "learning_rate": 1.5486303536289215e-06,
      "loss": 0.2543,
      "step": 6707
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.14921985566616058,
      "learning_rate": 1.5408192860937865e-06,
      "loss": 0.2639,
      "step": 6708
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.11621146649122238,
      "learning_rate": 1.5330278143999898e-06,
      "loss": 0.2321,
      "step": 6709
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.16409316658973694,
      "learning_rate": 1.5252559400982248e-06,
      "loss": 0.4608,
      "step": 6710
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.17741146683692932,
      "learning_rate": 1.5175036647352981e-06,
      "loss": 0.2918,
      "step": 6711
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.17981719970703125,
      "learning_rate": 1.5097709898540979e-06,
      "loss": 0.2904,
      "step": 6712
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.16891510784626007,
      "learning_rate": 1.5020579169936044e-06,
      "loss": 0.252,
      "step": 6713
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.16082824766635895,
      "learning_rate": 1.4943644476889452e-06,
      "loss": 0.2827,
      "step": 6714
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.1250203400850296,
      "learning_rate": 1.4866905834712842e-06,
      "loss": 0.2061,
      "step": 6715
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.12875647842884064,
      "learning_rate": 1.479036325867933e-06,
      "loss": 0.2207,
      "step": 6716
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.17804911732673645,
      "learning_rate": 1.471401676402262e-06,
      "loss": 0.3203,
      "step": 6717
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.1420336365699768,
      "learning_rate": 1.463786636593789e-06,
      "loss": 0.2234,
      "step": 6718
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.1593582183122635,
      "learning_rate": 1.4561912079580575e-06,
      "loss": 0.2707,
      "step": 6719
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.14873318374156952,
      "learning_rate": 1.4486153920067802e-06,
      "loss": 0.2861,
      "step": 6720
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.17274659872055054,
      "learning_rate": 1.4410591902477066e-06,
      "loss": 0.258,
      "step": 6721
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.1654425859451294,
      "learning_rate": 1.4335226041847338e-06,
      "loss": 0.2851,
      "step": 6722
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.125417098402977,
      "learning_rate": 1.4260056353178176e-06,
      "loss": 0.2103,
      "step": 6723
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.16843988001346588,
      "learning_rate": 1.4185082851430276e-06,
      "loss": 0.2308,
      "step": 6724
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.16975973546504974,
      "learning_rate": 1.411030555152515e-06,
      "loss": 0.2344,
      "step": 6725
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.19575518369674683,
      "learning_rate": 1.4035724468345557e-06,
      "loss": 0.355,
      "step": 6726
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.14090636372566223,
      "learning_rate": 1.3961339616734847e-06,
      "loss": 0.2942,
      "step": 6727
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.13725900650024414,
      "learning_rate": 1.3887151011497512e-06,
      "loss": 0.2768,
      "step": 6728
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.19593986868858337,
      "learning_rate": 1.3813158667398852e-06,
      "loss": 0.3506,
      "step": 6729
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.19480186700820923,
      "learning_rate": 1.3739362599165305e-06,
      "loss": 0.2901,
      "step": 6730
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.16559675335884094,
      "learning_rate": 1.366576282148413e-06,
      "loss": 0.2599,
      "step": 6731
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15973734855651855,
      "learning_rate": 1.3592359349003492e-06,
      "loss": 0.2398,
      "step": 6732
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15102636814117432,
      "learning_rate": 1.3519152196332374e-06,
      "loss": 0.1893,
      "step": 6733
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.12139880657196045,
      "learning_rate": 1.3446141378041122e-06,
      "loss": 0.1911,
      "step": 6734
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1776733100414276,
      "learning_rate": 1.3373326908660665e-06,
      "loss": 0.2742,
      "step": 6735
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15922535955905914,
      "learning_rate": 1.3300708802682748e-06,
      "loss": 0.2703,
      "step": 6736
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1334899514913559,
      "learning_rate": 1.322828707456014e-06,
      "loss": 0.2115,
      "step": 6737
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.16689011454582214,
      "learning_rate": 1.315606173870676e-06,
      "loss": 0.2621,
      "step": 6738
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.17336547374725342,
      "learning_rate": 1.3084032809497216e-06,
      "loss": 0.2611,
      "step": 6739
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.16037045419216156,
      "learning_rate": 1.3012200301267042e-06,
      "loss": 0.298,
      "step": 6740
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1570121794939041,
      "learning_rate": 1.294056422831269e-06,
      "loss": 0.3026,
      "step": 6741
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.14517270028591156,
      "learning_rate": 1.2869124604891537e-06,
      "loss": 0.2587,
      "step": 6742
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15918037295341492,
      "learning_rate": 1.2797881445221871e-06,
      "loss": 0.2666,
      "step": 6743
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15423935651779175,
      "learning_rate": 1.272683476348291e-06,
      "loss": 0.2526,
      "step": 6744
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.14210210740566254,
      "learning_rate": 1.2655984573814672e-06,
      "loss": 0.2604,
      "step": 6745
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.22530312836170197,
      "learning_rate": 1.2585330890318103e-06,
      "loss": 0.4796,
      "step": 6746
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.14657782018184662,
      "learning_rate": 1.2514873727055066e-06,
      "loss": 0.247,
      "step": 6747
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.19041232764720917,
      "learning_rate": 1.244461309804823e-06,
      "loss": 0.3291,
      "step": 6748
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.16348402202129364,
      "learning_rate": 1.237454901728141e-06,
      "loss": 0.3107,
      "step": 6749
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15710791945457458,
      "learning_rate": 1.23046814986989e-06,
      "loss": 0.2822,
      "step": 6750
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15380370616912842,
      "learning_rate": 1.223501055620624e-06,
      "loss": 0.2622,
      "step": 6751
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1786593645811081,
      "learning_rate": 1.2165536203669669e-06,
      "loss": 0.2523,
      "step": 6752
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.13871297240257263,
      "learning_rate": 1.2096258454916244e-06,
      "loss": 0.2563,
      "step": 6753
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.2121458649635315,
      "learning_rate": 1.202717732373393e-06,
      "loss": 0.3483,
      "step": 6754
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1639394462108612,
      "learning_rate": 1.1958292823871842e-06,
      "loss": 0.2579,
      "step": 6755
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.22247421741485596,
      "learning_rate": 1.1889604969039458e-06,
      "loss": 0.3836,
      "step": 6756
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.23505908250808716,
      "learning_rate": 1.182111377290751e-06,
      "loss": 0.3206,
      "step": 6757
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.21947261691093445,
      "learning_rate": 1.1752819249107316e-06,
      "loss": 0.3464,
      "step": 6758
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15748418867588043,
      "learning_rate": 1.1684721411231558e-06,
      "loss": 0.2743,
      "step": 6759
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15875904262065887,
      "learning_rate": 1.1616820272832952e-06,
      "loss": 0.2759,
      "step": 6760
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1353229433298111,
      "learning_rate": 1.1549115847425796e-06,
      "loss": 0.2714,
      "step": 6761
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.15059731900691986,
      "learning_rate": 1.148160814848487e-06,
      "loss": 0.2546,
      "step": 6762
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1989482343196869,
      "learning_rate": 1.1414297189446088e-06,
      "loss": 0.3371,
      "step": 6763
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.1852981597185135,
      "learning_rate": 1.134718298370563e-06,
      "loss": 0.2565,
      "step": 6764
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.18753209710121155,
      "learning_rate": 1.1280265544621361e-06,
      "loss": 0.2267,
      "step": 6765
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.17419780790805817,
      "learning_rate": 1.1213544885511184e-06,
      "loss": 0.3161,
      "step": 6766
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1499728411436081,
      "learning_rate": 1.114702101965437e-06,
      "loss": 0.2529,
      "step": 6767
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.20354114472866058,
      "learning_rate": 1.1080693960290655e-06,
      "loss": 0.2537,
      "step": 6768
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.17053207755088806,
      "learning_rate": 1.101456372062093e-06,
      "loss": 0.279,
      "step": 6769
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1811027079820633,
      "learning_rate": 1.0948630313806663e-06,
      "loss": 0.3437,
      "step": 6770
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.21585805714130402,
      "learning_rate": 1.0882893752970357e-06,
      "loss": 0.3097,
      "step": 6771
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.12380845099687576,
      "learning_rate": 1.0817354051195216e-06,
      "loss": 0.1762,
      "step": 6772
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.16450554132461548,
      "learning_rate": 1.075201122152525e-06,
      "loss": 0.2789,
      "step": 6773
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.16409878432750702,
      "learning_rate": 1.0686865276965274e-06,
      "loss": 0.2581,
      "step": 6774
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.14019444584846497,
      "learning_rate": 1.0621916230481032e-06,
      "loss": 0.2674,
      "step": 6775
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.16847896575927734,
      "learning_rate": 1.0557164094999072e-06,
      "loss": 0.281,
      "step": 6776
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1899905949831009,
      "learning_rate": 1.0492608883406418e-06,
      "loss": 0.3183,
      "step": 6777
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.17422077059745789,
      "learning_rate": 1.0428250608551571e-06,
      "loss": 0.304,
      "step": 6778
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.16106826066970825,
      "learning_rate": 1.0364089283243062e-06,
      "loss": 0.2319,
      "step": 6779
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.14440156519412994,
      "learning_rate": 1.0300124920250898e-06,
      "loss": 0.2558,
      "step": 6780
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.24288804829120636,
      "learning_rate": 1.023635753230534e-06,
      "loss": 0.3135,
      "step": 6781
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.16979609429836273,
      "learning_rate": 1.0172787132097793e-06,
      "loss": 0.3135,
      "step": 6782
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1478944718837738,
      "learning_rate": 1.010941373228047e-06,
      "loss": 0.2076,
      "step": 6783
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1649366319179535,
      "learning_rate": 1.004623734546617e-06,
      "loss": 0.3367,
      "step": 6784
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.14886035025119781,
      "learning_rate": 9.9832579842285e-07,
      "loss": 0.2348,
      "step": 6785
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.11893434822559357,
      "learning_rate": 9.920475661102102e-07,
      "loss": 0.2108,
      "step": 6786
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.23269851505756378,
      "learning_rate": 9.857890388582091e-07,
      "loss": 0.2371,
      "step": 6787
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.19038216769695282,
      "learning_rate": 9.795502179124504e-07,
      "loss": 0.3269,
      "step": 6788
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.15845248103141785,
      "learning_rate": 9.733311045146187e-07,
      "loss": 0.253,
      "step": 6789
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1388166844844818,
      "learning_rate": 9.671316999024792e-07,
      "loss": 0.2456,
      "step": 6790
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.15769989788532257,
      "learning_rate": 9.609520053098676e-07,
      "loss": 0.2792,
      "step": 6791
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.13102473318576813,
      "learning_rate": 9.547920219666883e-07,
      "loss": 0.2249,
      "step": 6792
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1728917956352234,
      "learning_rate": 9.486517510989279e-07,
      "loss": 0.3155,
      "step": 6793
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.16129882633686066,
      "learning_rate": 9.425311939286752e-07,
      "loss": 0.2695,
      "step": 6794
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1730843186378479,
      "learning_rate": 9.364303516740558e-07,
      "loss": 0.3316,
      "step": 6795
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1639452874660492,
      "learning_rate": 9.303492255493096e-07,
      "loss": 0.3191,
      "step": 6796
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.14056015014648438,
      "learning_rate": 9.242878167647128e-07,
      "loss": 0.2162,
      "step": 6797
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.16143901646137238,
      "learning_rate": 9.18246126526634e-07,
      "loss": 0.3149,
      "step": 6798
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1781778633594513,
      "learning_rate": 9.122241560375444e-07,
      "loss": 0.2939,
      "step": 6799
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.18244457244873047,
      "learning_rate": 9.06221906495952e-07,
      "loss": 0.2985,
      "step": 6800
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.18930865824222565,
      "learning_rate": 9.002393790964569e-07,
      "loss": 0.2863,
      "step": 6801
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.1981910616159439,
      "learning_rate": 8.942765750297288e-07,
      "loss": 0.2791,
      "step": 6802
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.15402379631996155,
      "learning_rate": 8.883334954825184e-07,
      "loss": 0.2444,
      "step": 6803
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.16374781727790833,
      "learning_rate": 8.824101416376463e-07,
      "loss": 0.2663,
      "step": 6804
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.20547276735305786,
      "learning_rate": 8.765065146740137e-07,
      "loss": 0.3415,
      "step": 6805
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.13166937232017517,
      "learning_rate": 8.706226157665697e-07,
      "loss": 0.2382,
      "step": 6806
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.14364436268806458,
      "learning_rate": 8.647584460863889e-07,
      "loss": 0.2315,
      "step": 6807
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.1567939817905426,
      "learning_rate": 8.589140068005708e-07,
      "loss": 0.32,
      "step": 6808
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.17173221707344055,
      "learning_rate": 8.530892990723071e-07,
      "loss": 0.2519,
      "step": 6809
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.14512795209884644,
      "learning_rate": 8.472843240608485e-07,
      "loss": 0.2095,
      "step": 6810
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.16034269332885742,
      "learning_rate": 8.414990829215485e-07,
      "loss": 0.2626,
      "step": 6811
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.17784498631954193,
      "learning_rate": 8.357335768057972e-07,
      "loss": 0.2433,
      "step": 6812
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.184023916721344,
      "learning_rate": 8.299878068610989e-07,
      "loss": 0.387,
      "step": 6813
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.15682215988636017,
      "learning_rate": 8.242617742309833e-07,
      "loss": 0.2214,
      "step": 6814
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.2040691077709198,
      "learning_rate": 8.185554800550832e-07,
      "loss": 0.3355,
      "step": 6815
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.14231494069099426,
      "learning_rate": 8.128689254691014e-07,
      "loss": 0.2499,
      "step": 6816
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.20397889614105225,
      "learning_rate": 8.072021116047879e-07,
      "loss": 0.3339,
      "step": 6817
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.16522319614887238,
      "learning_rate": 8.015550395899962e-07,
      "loss": 0.3039,
      "step": 6818
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.14672745764255524,
      "learning_rate": 7.959277105486163e-07,
      "loss": 0.2153,
      "step": 6819
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.18153193593025208,
      "learning_rate": 7.903201256006521e-07,
      "loss": 0.2677,
      "step": 6820
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.14157487452030182,
      "learning_rate": 7.847322858621331e-07,
      "loss": 0.2931,
      "step": 6821
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.130215123295784,
      "learning_rate": 7.791641924451809e-07,
      "loss": 0.2668,
      "step": 6822
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.16013099253177643,
      "learning_rate": 7.73615846458009e-07,
      "loss": 0.2952,
      "step": 6823
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.1979249268770218,
      "learning_rate": 7.680872490048452e-07,
      "loss": 0.3004,
      "step": 6824
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.21534965932369232,
      "learning_rate": 7.625784011860426e-07,
      "loss": 0.3398,
      "step": 6825
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.16426168382167816,
      "learning_rate": 7.570893040979799e-07,
      "loss": 0.2988,
      "step": 6826
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.18749475479125977,
      "learning_rate": 7.516199588331385e-07,
      "loss": 0.2826,
      "step": 6827
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.1888887882232666,
      "learning_rate": 7.461703664800479e-07,
      "loss": 0.2982,
      "step": 6828
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.23210856318473816,
      "learning_rate": 7.407405281233182e-07,
      "loss": 0.3113,
      "step": 6829
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.20053517818450928,
      "learning_rate": 7.353304448436293e-07,
      "loss": 0.3532,
      "step": 6830
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.15979067981243134,
      "learning_rate": 7.29940117717709e-07,
      "loss": 0.2995,
      "step": 6831
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.1804533451795578,
      "learning_rate": 7.245695478183767e-07,
      "loss": 0.2224,
      "step": 6832
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.48085305094718933,
      "learning_rate": 7.192187362145109e-07,
      "loss": 0.4032,
      "step": 6833
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.16058345139026642,
      "learning_rate": 7.138876839710485e-07,
      "loss": 0.2904,
      "step": 6834
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.202053502202034,
      "learning_rate": 7.085763921490074e-07,
      "loss": 0.2695,
      "step": 6835
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.17399121820926666,
      "learning_rate": 7.032848618054644e-07,
      "loss": 0.3309,
      "step": 6836
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.19373884797096252,
      "learning_rate": 6.980130939935769e-07,
      "loss": 0.3642,
      "step": 6837
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1733892410993576,
      "learning_rate": 6.927610897625502e-07,
      "loss": 0.3177,
      "step": 6838
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.14060905575752258,
      "learning_rate": 6.875288501576593e-07,
      "loss": 0.2383,
      "step": 6839
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1345752477645874,
      "learning_rate": 6.8231637622026e-07,
      "loss": 0.2149,
      "step": 6840
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1660863310098648,
      "learning_rate": 6.771236689877669e-07,
      "loss": 0.2401,
      "step": 6841
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.17107881605625153,
      "learning_rate": 6.719507294936533e-07,
      "loss": 0.2665,
      "step": 6842
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.20428700745105743,
      "learning_rate": 6.667975587674624e-07,
      "loss": 0.2551,
      "step": 6843
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.17561687529087067,
      "learning_rate": 6.61664157834807e-07,
      "loss": 0.2732,
      "step": 6844
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.17591063678264618,
      "learning_rate": 6.56550527717359e-07,
      "loss": 0.2983,
      "step": 6845
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.24314099550247192,
      "learning_rate": 6.514566694328705e-07,
      "loss": 0.2777,
      "step": 6846
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.13025109469890594,
      "learning_rate": 6.463825839951309e-07,
      "loss": 0.1943,
      "step": 6847
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1547628790140152,
      "learning_rate": 6.413282724140213e-07,
      "loss": 0.2514,
      "step": 6848
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.17102158069610596,
      "learning_rate": 6.362937356954702e-07,
      "loss": 0.3562,
      "step": 6849
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.19992445409297943,
      "learning_rate": 6.312789748414872e-07,
      "loss": 0.2864,
      "step": 6850
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.178043931722641,
      "learning_rate": 6.262839908501072e-07,
      "loss": 0.2653,
      "step": 6851
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.18903020024299622,
      "learning_rate": 6.213087847154908e-07,
      "loss": 0.3263,
      "step": 6852
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.14750510454177856,
      "learning_rate": 6.163533574278013e-07,
      "loss": 0.2701,
      "step": 6853
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.14987465739250183,
      "learning_rate": 6.114177099733165e-07,
      "loss": 0.2772,
      "step": 6854
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.18965621292591095,
      "learning_rate": 6.065018433343505e-07,
      "loss": 0.315,
      "step": 6855
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1723516881465912,
      "learning_rate": 6.016057584892654e-07,
      "loss": 0.1973,
      "step": 6856
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.14013279974460602,
      "learning_rate": 5.967294564125147e-07,
      "loss": 0.2432,
      "step": 6857
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.19366054236888885,
      "learning_rate": 5.918729380746002e-07,
      "loss": 0.2914,
      "step": 6858
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.17168134450912476,
      "learning_rate": 5.870362044421041e-07,
      "loss": 0.2828,
      "step": 6859
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.19776345789432526,
      "learning_rate": 5.822192564776451e-07,
      "loss": 0.2799,
      "step": 6860
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.19114039838314056,
      "learning_rate": 5.774220951399234e-07,
      "loss": 0.3441,
      "step": 6861
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.18761056661605835,
      "learning_rate": 5.726447213836861e-07,
      "loss": 0.3193,
      "step": 6862
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.16879059374332428,
      "learning_rate": 5.678871361597616e-07,
      "loss": 0.3491,
      "step": 6863
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.18831738829612732,
      "learning_rate": 5.631493404150146e-07,
      "loss": 0.3189,
      "step": 6864
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.2067323923110962,
      "learning_rate": 5.58431335092402e-07,
      "loss": 0.3444,
      "step": 6865
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.16170744597911835,
      "learning_rate": 5.53733121130906e-07,
      "loss": 0.2468,
      "step": 6866
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1879088133573532,
      "learning_rate": 5.490546994656009e-07,
      "loss": 0.3503,
      "step": 6867
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.24579918384552002,
      "learning_rate": 5.443960710275975e-07,
      "loss": 0.2487,
      "step": 6868
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.12557274103164673,
      "learning_rate": 5.397572367440984e-07,
      "loss": 0.2182,
      "step": 6869
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.14076465368270874,
      "learning_rate": 5.351381975383429e-07,
      "loss": 0.2395,
      "step": 6870
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.18270668387413025,
      "learning_rate": 5.30538954329618e-07,
      "loss": 0.3116,
      "step": 6871
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.16354484856128693,
      "learning_rate": 5.259595080333135e-07,
      "loss": 0.2765,
      "step": 6872
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.14878477156162262,
      "learning_rate": 5.213998595608338e-07,
      "loss": 0.3157,
      "step": 6873
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.1610889881849289,
      "learning_rate": 5.168600098196752e-07,
      "loss": 0.2416,
      "step": 6874
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.1913338005542755,
      "learning_rate": 5.123399597133705e-07,
      "loss": 0.3197,
      "step": 6875
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.16593097150325775,
      "learning_rate": 5.078397101415333e-07,
      "loss": 0.3124,
      "step": 6876
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.14116117358207703,
      "learning_rate": 5.03359261999825e-07,
      "loss": 0.2362,
      "step": 6877
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.1485193371772766,
      "learning_rate": 4.988986161799548e-07,
      "loss": 0.2446,
      "step": 6878
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.1491926908493042,
      "learning_rate": 4.94457773569712e-07,
      "loss": 0.2344,
      "step": 6879
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.16331924498081207,
      "learning_rate": 4.900367350529455e-07,
      "loss": 0.2987,
      "step": 6880
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.16220837831497192,
      "learning_rate": 4.856355015095404e-07,
      "loss": 0.2507,
      "step": 6881
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.11625955998897552,
      "learning_rate": 4.812540738154403e-07,
      "loss": 0.2259,
      "step": 6882
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.15332917869091034,
      "learning_rate": 4.76892452842681e-07,
      "loss": 0.2132,
      "step": 6883
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.15345340967178345,
      "learning_rate": 4.7255063945932375e-07,
      "loss": 0.2713,
      "step": 6884
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.2057037353515625,
      "learning_rate": 4.682286345295106e-07,
      "loss": 0.2952,
      "step": 6885
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.19113066792488098,
      "learning_rate": 4.6392643891340904e-07,
      "loss": 0.3008,
      "step": 6886
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.2297634333372116,
      "learning_rate": 4.596440534672786e-07,
      "loss": 0.3161,
      "step": 6887
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.16382749378681183,
      "learning_rate": 4.553814790434041e-07,
      "loss": 0.3017,
      "step": 6888
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.18446843326091766,
      "learning_rate": 4.511387164901737e-07,
      "loss": 0.2583,
      "step": 6889
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.17218086123466492,
      "learning_rate": 4.4691576665196743e-07,
      "loss": 0.3199,
      "step": 6890
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.14837756752967834,
      "learning_rate": 4.427126303692908e-07,
      "loss": 0.2964,
      "step": 6891
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.15062688291072845,
      "learning_rate": 4.3852930847865236e-07,
      "loss": 0.2337,
      "step": 6892
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.20597954094409943,
      "learning_rate": 4.343658018126418e-07,
      "loss": 0.3038,
      "step": 6893
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.17753392457962036,
      "learning_rate": 4.3022211119990717e-07,
      "loss": 0.3358,
      "step": 6894
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.13114826381206512,
      "learning_rate": 4.260982374651334e-07,
      "loss": 0.2066,
      "step": 6895
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.17667770385742188,
      "learning_rate": 4.219941814290973e-07,
      "loss": 0.2569,
      "step": 6896
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.14447934925556183,
      "learning_rate": 4.179099439085898e-07,
      "loss": 0.223,
      "step": 6897
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.16850903630256653,
      "learning_rate": 4.138455257164831e-07,
      "loss": 0.3089,
      "step": 6898
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.16076506674289703,
      "learning_rate": 4.0980092766169653e-07,
      "loss": 0.247,
      "step": 6899
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.15336740016937256,
      "learning_rate": 4.057761505492086e-07,
      "loss": 0.2618,
      "step": 6900
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.17340458929538727,
      "learning_rate": 4.0177119518004514e-07,
      "loss": 0.26,
      "step": 6901
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.21290519833564758,
      "learning_rate": 3.977860623513019e-07,
      "loss": 0.3986,
      "step": 6902
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.19634974002838135,
      "learning_rate": 3.9382075285611107e-07,
      "loss": 0.3777,
      "step": 6903
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.19418372213840485,
      "learning_rate": 3.8987526748367474e-07,
      "loss": 0.3032,
      "step": 6904
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.13714902102947235,
      "learning_rate": 3.8594960701924257e-07,
      "loss": 0.2372,
      "step": 6905
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.20575407147407532,
      "learning_rate": 3.820437722441117e-07,
      "loss": 0.4423,
      "step": 6906
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.17736537754535675,
      "learning_rate": 3.781577639356493e-07,
      "loss": 0.3091,
      "step": 6907
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.12939995527267456,
      "learning_rate": 3.7429158286725884e-07,
      "loss": 0.2344,
      "step": 6908
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.19781196117401123,
      "learning_rate": 3.704452298084249e-07,
      "loss": 0.3327,
      "step": 6909
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.15625286102294922,
      "learning_rate": 3.6661870552464617e-07,
      "loss": 0.2466,
      "step": 6910
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.17705008387565613,
      "learning_rate": 3.628120107775135e-07,
      "loss": 0.3018,
      "step": 6911
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.18289561569690704,
      "learning_rate": 3.590251463246541e-07,
      "loss": 0.2976,
      "step": 6912
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.20300845801830292,
      "learning_rate": 3.552581129197319e-07,
      "loss": 0.3132,
      "step": 6913
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.13731801509857178,
      "learning_rate": 3.5151091131250256e-07,
      "loss": 0.2277,
      "step": 6914
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.21829529106616974,
      "learning_rate": 3.4778354224873635e-07,
      "loss": 0.3318,
      "step": 6915
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.17340752482414246,
      "learning_rate": 3.440760064702731e-07,
      "loss": 0.2538,
      "step": 6916
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.18776166439056396,
      "learning_rate": 3.4038830471502247e-07,
      "loss": 0.3227,
      "step": 6917
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.17087259888648987,
      "learning_rate": 3.3672043771690863e-07,
      "loss": 0.3388,
      "step": 6918
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.15112213790416718,
      "learning_rate": 3.330724062059476e-07,
      "loss": 0.2324,
      "step": 6919
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.159246563911438,
      "learning_rate": 3.2944421090816966e-07,
      "loss": 0.3286,
      "step": 6920
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.2016809582710266,
      "learning_rate": 3.2583585254569727e-07,
      "loss": 0.3082,
      "step": 6921
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.13242025673389435,
      "learning_rate": 3.22247331836667e-07,
      "loss": 0.2251,
      "step": 6922
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.1552233099937439,
      "learning_rate": 3.1867864949529644e-07,
      "loss": 0.2664,
      "step": 6923
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.18136420845985413,
      "learning_rate": 3.1512980623182866e-07,
      "loss": 0.3092,
      "step": 6924
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.14132405817508698,
      "learning_rate": 3.116008027525874e-07,
      "loss": 0.2342,
      "step": 6925
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.17324477434158325,
      "learning_rate": 3.0809163975992203e-07,
      "loss": 0.3367,
      "step": 6926
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.14340974390506744,
      "learning_rate": 3.046023179522517e-07,
      "loss": 0.2498,
      "step": 6927
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.16061294078826904,
      "learning_rate": 3.0113283802403193e-07,
      "loss": 0.2807,
      "step": 6928
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.16493810713291168,
      "learning_rate": 2.97683200665777e-07,
      "loss": 0.3189,
      "step": 6929
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.17624710500240326,
      "learning_rate": 2.942534065640601e-07,
      "loss": 0.2878,
      "step": 6930
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.16914115846157074,
      "learning_rate": 2.908434564014795e-07,
      "loss": 0.2849,
      "step": 6931
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.14466841518878937,
      "learning_rate": 2.8745335085671456e-07,
      "loss": 0.1886,
      "step": 6932
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.1622796505689621,
      "learning_rate": 2.840830906044811e-07,
      "loss": 0.2563,
      "step": 6933
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.1391720175743103,
      "learning_rate": 2.807326763155316e-07,
      "loss": 0.2018,
      "step": 6934
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.17878031730651855,
      "learning_rate": 2.7740210865669914e-07,
      "loss": 0.3224,
      "step": 6935
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.1761733442544937,
      "learning_rate": 2.7409138829084247e-07,
      "loss": 0.259,
      "step": 6936
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.2032470405101776,
      "learning_rate": 2.708005158768789e-07,
      "loss": 0.3015,
      "step": 6937
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.15654049813747406,
      "learning_rate": 2.675294920697624e-07,
      "loss": 0.2771,
      "step": 6938
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.14115743339061737,
      "learning_rate": 2.6427831752053877e-07,
      "loss": 0.2306,
      "step": 6939
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.15154753625392914,
      "learning_rate": 2.610469928762349e-07,
      "loss": 0.2743,
      "step": 6940
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.18966656923294067,
      "learning_rate": 2.578355187799919e-07,
      "loss": 0.2177,
      "step": 6941
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.14828632771968842,
      "learning_rate": 2.546438958709652e-07,
      "loss": 0.2318,
      "step": 6942
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.12459664791822433,
      "learning_rate": 2.5147212478436875e-07,
      "loss": 0.1804,
      "step": 6943
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.1638716459274292,
      "learning_rate": 2.4832020615146447e-07,
      "loss": 0.2572,
      "step": 6944
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.12545821070671082,
      "learning_rate": 2.451881405995726e-07,
      "loss": 0.2098,
      "step": 6945
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.13887885212898254,
      "learning_rate": 2.42075928752028e-07,
      "loss": 0.2101,
      "step": 6946
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.18052901327610016,
      "learning_rate": 2.389835712282573e-07,
      "loss": 0.2904,
      "step": 6947
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.16431961953639984,
      "learning_rate": 2.359110686437127e-07,
      "loss": 0.2651,
      "step": 6948
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.17774233222007751,
      "learning_rate": 2.32858421609905e-07,
      "loss": 0.2669,
      "step": 6949
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.17000725865364075,
      "learning_rate": 2.2982563073437046e-07,
      "loss": 0.3274,
      "step": 6950
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.198212131857872,
      "learning_rate": 2.2681269662072625e-07,
      "loss": 0.3974,
      "step": 6951
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.16914522647857666,
      "learning_rate": 2.2381961986862598e-07,
      "loss": 0.3108,
      "step": 6952
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.15773577988147736,
      "learning_rate": 2.2084640107374877e-07,
      "loss": 0.2529,
      "step": 6953
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.14242695271968842,
      "learning_rate": 2.1789304082785455e-07,
      "loss": 0.2414,
      "step": 6954
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.14285381138324738,
      "learning_rate": 2.1495953971872872e-07,
      "loss": 0.2421,
      "step": 6955
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.1880299299955368,
      "learning_rate": 2.1204589833020427e-07,
      "loss": 0.2745,
      "step": 6956
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.1621032953262329,
      "learning_rate": 2.0915211724218397e-07,
      "loss": 0.2426,
      "step": 6957
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.16593420505523682,
      "learning_rate": 2.0627819703059604e-07,
      "loss": 0.2582,
      "step": 6958
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.18092741072177887,
      "learning_rate": 2.0342413826742734e-07,
      "loss": 0.24,
      "step": 6959
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.152113139629364,
      "learning_rate": 2.005899415206902e-07,
      "loss": 0.2314,
      "step": 6960
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.15883222222328186,
      "learning_rate": 1.9777560735448897e-07,
      "loss": 0.2596,
      "step": 6961
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.16999560594558716,
      "learning_rate": 1.9498113632892e-07,
      "loss": 0.2817,
      "step": 6962
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.2180453985929489,
      "learning_rate": 1.9220652900016068e-07,
      "loss": 0.2547,
      "step": 6963
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.17082971334457397,
      "learning_rate": 1.8945178592043588e-07,
      "loss": 0.2807,
      "step": 6964
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.15968352556228638,
      "learning_rate": 1.8671690763799599e-07,
      "loss": 0.2565,
      "step": 6965
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.15574724972248077,
      "learning_rate": 1.8400189469717222e-07,
      "loss": 0.2389,
      "step": 6966
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.12323184311389923,
      "learning_rate": 1.8130674763828793e-07,
      "loss": 0.2339,
      "step": 6967
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.1234026700258255,
      "learning_rate": 1.7863146699776956e-07,
      "loss": 0.2015,
      "step": 6968
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.17486266791820526,
      "learning_rate": 1.7597605330805788e-07,
      "loss": 0.2772,
      "step": 6969
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.15359435975551605,
      "learning_rate": 1.7334050709764127e-07,
      "loss": 0.3175,
      "step": 6970
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.1326553225517273,
      "learning_rate": 1.7072482889106678e-07,
      "loss": 0.2297,
      "step": 6971
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.16606974601745605,
      "learning_rate": 1.68129019208918e-07,
      "loss": 0.2914,
      "step": 6972
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.14277350902557373,
      "learning_rate": 1.65553078567815e-07,
      "loss": 0.2576,
      "step": 6973
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.13283656537532806,
      "learning_rate": 1.6299700748045875e-07,
      "loss": 0.2101,
      "step": 6974
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.15058815479278564,
      "learning_rate": 1.604608064555424e-07,
      "loss": 0.2633,
      "step": 6975
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.2314216047525406,
      "learning_rate": 1.579444759978621e-07,
      "loss": 0.362,
      "step": 6976
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.13492842018604279,
      "learning_rate": 1.554480166082062e-07,
      "loss": 0.2404,
      "step": 6977
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15323354303836823,
      "learning_rate": 1.5297142878345494e-07,
      "loss": 0.2876,
      "step": 6978
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.17937782406806946,
      "learning_rate": 1.505147130164919e-07,
      "loss": 0.3452,
      "step": 6979
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.1741582751274109,
      "learning_rate": 1.4807786979627035e-07,
      "loss": 0.3073,
      "step": 6980
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.13899090886116028,
      "learning_rate": 1.4566089960778018e-07,
      "loss": 0.2547,
      "step": 6981
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.13367336988449097,
      "learning_rate": 1.4326380293206987e-07,
      "loss": 0.2034,
      "step": 6982
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.20511983335018158,
      "learning_rate": 1.4088658024622448e-07,
      "loss": 0.2711,
      "step": 6983
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.1765129715204239,
      "learning_rate": 1.3852923202335445e-07,
      "loss": 0.3363,
      "step": 6984
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.16342274844646454,
      "learning_rate": 1.361917587326289e-07,
      "loss": 0.284,
      "step": 6985
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.1580802947282791,
      "learning_rate": 1.3387416083928683e-07,
      "loss": 0.2403,
      "step": 6986
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15300370752811432,
      "learning_rate": 1.3157643880457038e-07,
      "loss": 0.2749,
      "step": 6987
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.16808228194713593,
      "learning_rate": 1.292985930857915e-07,
      "loss": 0.3154,
      "step": 6988
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.16053371131420135,
      "learning_rate": 1.270406241362876e-07,
      "loss": 0.2357,
      "step": 6989
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15220728516578674,
      "learning_rate": 1.248025324054658e-07,
      "loss": 0.2322,
      "step": 6990
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15701651573181152,
      "learning_rate": 1.225843183387476e-07,
      "loss": 0.3186,
      "step": 6991
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15831798315048218,
      "learning_rate": 1.2038598237762433e-07,
      "loss": 0.2675,
      "step": 6992
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15591785311698914,
      "learning_rate": 1.1820752495961263e-07,
      "loss": 0.2737,
      "step": 6993
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15022964775562286,
      "learning_rate": 1.160489465182879e-07,
      "loss": 0.2477,
      "step": 6994
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.1399627923965454,
      "learning_rate": 1.1391024748326206e-07,
      "loss": 0.2403,
      "step": 6995
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15777543187141418,
      "learning_rate": 1.1179142828017242e-07,
      "loss": 0.2483,
      "step": 6996
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.16327255964279175,
      "learning_rate": 1.0969248933073717e-07,
      "loss": 0.2846,
      "step": 6997
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.16374483704566956,
      "learning_rate": 1.0761343105268884e-07,
      "loss": 0.2963,
      "step": 6998
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.22048050165176392,
      "learning_rate": 1.0555425385981866e-07,
      "loss": 0.3006,
      "step": 6999
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.1756269931793213,
      "learning_rate": 1.0351495816193212e-07,
      "loss": 0.3019,
      "step": 7000
    }
  ],
  "logging_steps": 1,
  "max_steps": 7102,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "total_flos": 2.194078438342103e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
